


get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 19763.98it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 6772.25it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 27384.68it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 7388.39it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).


epoch:0,	loss:20.262367069721222	loss1:0

>>>>>>>>>>>>>>>>>>>start train......



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 31311.45it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 7057.82it/s]
define model...


epoch:0,	loss:20.301468789577484	loss1:0
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
right_count:3	total:433	 Answer ACC: 0.006928406466512702
right_codes_count:0	total:1974	Code ACC: 0.0	wrong_be_tree_count:286	wrong_total:430	 wrong be tree ACC: 0.6651162790697674
right_checker:106	total:1974	checker ACC: 0.05369807779788971	temp:0	temp1:0	wrong_total:430	
save best model to ./output/model_save_name_0/best_model

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_2.py", line 68, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 180, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 527, in forward
    bertout = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 1030, in forward
    return_dict=return_dict,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 617, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 500, in forward
    past_key_value=self_attn_past_key_value,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 432, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 323, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 39.45 GiB total capacity; 1.39 GiB already allocated; 17.31 MiB free; 1.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
right_count:5	total:433	 Answer ACC: 0.011547344110854504
right_codes_count:0	total:1987	Code ACC: 0.0	wrong_be_tree_count:297	wrong_total:428	 wrong be tree ACC: 0.6939252336448598
right_checker:109	total:1987	checker ACC: 0.0548565648496151	temp:0	temp1:0	wrong_total:428	
save best model to ./output/model_save_name_1/best_model


epoch:1,	loss:10.85657112300396	loss1:0


epoch:1,	loss:10.87967498600483	loss1:0



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 19977.83it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 7368.40it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:888	total:1974	Code ACC: 0.44984802431610943	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:946	total:1974	checker ACC: 0.47923001646995544	temp:0	temp1:0	wrong_total:433	
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:888	total:1987	Code ACC: 0.44690488173125315	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:917	total:1987	checker ACC: 0.46149972081184387	temp:0	temp1:0	wrong_total:433	

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss:20.24896603822708	loss1:0
right_count:2	total:433	 Answer ACC: 0.004618937644341801
right_codes_count:0	total:1976	Code ACC: 0.0	wrong_be_tree_count:296	wrong_total:431	 wrong be tree ACC: 0.6867749419953596
right_checker:104	total:1976	checker ACC: 0.05263157933950424	temp:0	temp1:0	wrong_total:431	
save best model to ./output/model_save_name_3/best_model


epoch:2,	loss:3.6097057163715363	loss1:0


epoch:2,	loss:3.591933697462082	loss1:0


epoch:1,	loss:10.88575592637062	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:888	total:1976	Code ACC: 0.4493927125506073	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:926	total:1976	checker ACC: 0.46862348914146423	temp:0	temp1:0	wrong_total:433	
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:858	total:1974	Code ACC: 0.43465045592705165	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:879	total:1974	checker ACC: 0.4452887773513794	temp:0	temp1:0	wrong_total:433	
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:856	total:1987	Code ACC: 0.43080020130850527	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:887	total:1987	checker ACC: 0.44640159606933594	temp:0	temp1:0	wrong_total:433	


epoch:2,	loss:3.6292936354875565	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:858	total:1976	Code ACC: 0.4342105263157895	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:883	total:1976	checker ACC: 0.4468623697757721	temp:0	temp1:0	wrong_total:433	


epoch:3,	loss:2.204282645136118	loss1:0


epoch:3,	loss:2.2270876429975033	loss1:0


epoch:3,	loss:2.318716712296009	loss1:0
right_count:15	total:433	 Answer ACC: 0.03464203233256351
right_codes_count:990	total:1974	Code ACC: 0.5015197568389058	wrong_be_tree_count:223	wrong_total:418	 wrong be tree ACC: 0.5334928229665071
right_checker:996	total:1974	checker ACC: 0.5045592784881592	temp:0	temp1:0	wrong_total:418	
save best model to ./output/model_save_name_0/best_model
right_count:5	total:433	 Answer ACC: 0.011547344110854504
right_codes_count:949	total:1987	Code ACC: 0.47760442878711623	wrong_be_tree_count:275	wrong_total:428	 wrong be tree ACC: 0.6425233644859814
right_checker:971	total:1987	checker ACC: 0.48867636919021606	temp:0	temp1:0	wrong_total:428	
save best model to ./output/model_save_name_1/best_model
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:891	total:1976	Code ACC: 0.4509109311740891	wrong_be_tree_count:393	wrong_total:433	 wrong be tree ACC: 0.9076212471131639
right_checker:904	total:1976	checker ACC: 0.45748987793922424	temp:0	temp1:0	wrong_total:433	









get train data loader...
get train data loader...
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]  0%|          | 0/1732 [00:00<?, ?it/s]  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1732/1732 [00:00<00:00, 33424.29it/s]100%|██████████| 1730/1730 [00:00<00:00, 31120.22it/s]100%|██████████| 1730/1730 [00:00<00:00, 29704.70it/s]
get dev data loader...

get dev data loader...

get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 8395.24it/s]100%|██████████| 433/433 [00:00<00:00, 8360.50it/s]  0%|          | 0/431 [00:00<?, ?it/s]
define model...

define model...
100%|██████████| 431/431 [00:00<00:00, 6570.80it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......

>>>>>>>>>>>>>>>>>>>start train......

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_2.py", line 68, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 180, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 527, in forward
    bertout = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 1030, in forward
    return_dict=return_dict,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 617, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 500, in forward
    past_key_value=self_attn_past_key_value,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 432, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 306, in forward
    key_layer = self.transpose_for_scores(self.key(hidden_states))
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 39.45 GiB total capacity; 3.96 GiB already allocated; 9.31 MiB free; 4.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_3.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 180, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 527, in forward
    bertout = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 1030, in forward
    return_dict=return_dict,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 617, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 500, in forward
    past_key_value=self_attn_past_key_value,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 432, in forward
    output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 357, in forward
    attention_probs = self.dropout(attention_probs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 39.45 GiB total capacity; 4.06 GiB already allocated; 9.31 MiB free; 4.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


epoch:4,	loss:1.920010156929493	loss1:0


epoch:0,	loss:20.23572713136673	loss1:0


epoch:4,	loss:1.8825669065117836	loss1:0
right_count:33	total:433	 Answer ACC: 0.07621247113163972
right_codes_count:1049	total:1976	Code ACC: 0.5308704453441295	wrong_be_tree_count:126	wrong_total:400	 wrong be tree ACC: 0.315
right_checker:1060	total:1976	checker ACC: 0.5364372730255127	temp:0	temp1:0	wrong_total:400	
save best model to ./output/model_save_name_3/best_model
right_count:25	total:433	 Answer ACC: 0.057736720554272515
right_codes_count:1028	total:1974	Code ACC: 0.5207700101317123	wrong_be_tree_count:172	wrong_total:408	 wrong be tree ACC: 0.4215686274509804
right_checker:1039	total:1974	checker ACC: 0.5263424515724182	temp:0	temp1:0	wrong_total:408	
save best model to ./output/model_save_name_0/best_model
right_count:4	total:431	 Answer ACC: 0.009280742459396751
right_codes_count:0	total:1985	Code ACC: 0.0	wrong_be_tree_count:285	wrong_total:427	 wrong be tree ACC: 0.667447306791569
right_checker:82	total:1985	checker ACC: 0.04130982235074043	temp:0	temp1:0	wrong_total:427	
save best model to ./output/model_save_name_4/best_model


epoch:4,	loss:1.9051045551896095	loss1:0
right_count:34	total:433	 Answer ACC: 0.07852193995381063
right_codes_count:1038	total:1987	Code ACC: 0.5223955712128837	wrong_be_tree_count:123	wrong_total:399	 wrong be tree ACC: 0.3082706766917293
right_checker:1062	total:1987	checker ACC: 0.5344740748405457	temp:0	temp1:0	wrong_total:399	
save best model to ./output/model_save_name_1/best_model


epoch:5,	loss:1.7889051251113415	loss1:0


epoch:1,	loss:10.851088777184486	loss1:0


epoch:5,	loss:1.7441455647349358	loss1:0
right_count:37	total:433	 Answer ACC: 0.08545034642032333
right_codes_count:1056	total:1976	Code ACC: 0.5344129554655871	wrong_be_tree_count:186	wrong_total:396	 wrong be tree ACC: 0.4696969696969697
right_checker:1083	total:1976	checker ACC: 0.5480769276618958	temp:0	temp1:0	wrong_total:396	
save best model to ./output/model_save_name_3/best_model
right_count:0	total:431	 Answer ACC: 0.0
right_codes_count:879	total:1985	Code ACC: 0.4428211586901763	wrong_be_tree_count:431	wrong_total:431	 wrong be tree ACC: 1.0
right_checker:910	total:1985	checker ACC: 0.45843827724456787	temp:0	temp1:0	wrong_total:431	
right_count:84	total:433	 Answer ACC: 0.19399538106235567
right_codes_count:1149	total:1974	Code ACC: 0.5820668693009119	wrong_be_tree_count:90	wrong_total:349	 wrong be tree ACC: 0.25787965616045844
right_checker:1163	total:1974	checker ACC: 0.5891590714454651	temp:0	temp1:0	wrong_total:349	
save best model to ./output/model_save_name_0/best_model


epoch:5,	loss:1.76550729945302	loss1:0
right_count:93	total:433	 Answer ACC: 0.21478060046189376
right_codes_count:1143	total:1987	Code ACC: 0.5752390538500252	wrong_be_tree_count:79	wrong_total:340	 wrong be tree ACC: 0.2323529411764706
right_checker:1185	total:1987	checker ACC: 0.5963764190673828	temp:0	temp1:0	wrong_total:340	
save best model to ./output/model_save_name_1/best_model


epoch:2,	loss:3.6033812016248703	loss1:0
right_count:0	total:431	 Answer ACC: 0.0
right_codes_count:848	total:1985	Code ACC: 0.4272040302267002	wrong_be_tree_count:431	wrong_total:431	 wrong be tree ACC: 1.0
right_checker:875	total:1985	checker ACC: 0.4408060610294342	temp:0	temp1:0	wrong_total:431	


epoch:6,	loss:1.676905807107687	loss1:0


epoch:6,	loss:1.6704445146024227	loss1:0
right_count:68	total:433	 Answer ACC: 0.15704387990762125
right_codes_count:1150	total:1976	Code ACC: 0.5819838056680162	wrong_be_tree_count:139	wrong_total:365	 wrong be tree ACC: 0.38082191780821917
right_checker:1174	total:1976	checker ACC: 0.5941295623779297	temp:0	temp1:0	wrong_total:365	
save best model to ./output/model_save_name_3/best_model


epoch:6,	loss:1.7120564803481102	loss1:0


epoch:3,	loss:2.2700388953089714	loss1:0
right_count:80	total:433	 Answer ACC: 0.18475750577367206
right_codes_count:1197	total:1974	Code ACC: 0.6063829787234043	wrong_be_tree_count:85	wrong_total:353	 wrong be tree ACC: 0.24079320113314448
right_checker:1204	total:1974	checker ACC: 0.609929084777832	temp:0	temp1:0	wrong_total:353	
right_count:87	total:433	 Answer ACC: 0.20092378752886836
right_codes_count:1193	total:1987	Code ACC: 0.6004026170105687	wrong_be_tree_count:89	wrong_total:346	 wrong be tree ACC: 0.25722543352601157
right_checker:1216	total:1987	checker ACC: 0.6119778156280518	temp:0	temp1:0	wrong_total:346	
right_count:1	total:431	 Answer ACC: 0.002320185614849188
right_codes_count:869	total:1985	Code ACC: 0.43778337531486144	wrong_be_tree_count:405	wrong_total:430	 wrong be tree ACC: 0.9418604651162791
right_checker:883	total:1985	checker ACC: 0.444836288690567	temp:0	temp1:0	wrong_total:430	


epoch:7,	loss:1.5967241562902927	loss1:0


epoch:7,	loss:1.5116351023316383	loss1:0


epoch:4,	loss:1.9040009416639805	loss1:0



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 19293.28it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 5772.65it/s]
define model...


epoch:7,	loss:1.5655574798583984	loss1:0
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
right_count:96	total:433	 Answer ACC: 0.22170900692840648
right_codes_count:1276	total:1976	Code ACC: 0.645748987854251	wrong_be_tree_count:115	wrong_total:337	 wrong be tree ACC: 0.34124629080118696
right_checker:1285	total:1976	checker ACC: 0.6503036618232727	temp:0	temp1:0	wrong_total:337	
save best model to ./output/model_save_name_3/best_model

>>>>>>>>>>>>>>>>>>>start train......
right_count:102	total:433	 Answer ACC: 0.23556581986143188
right_codes_count:1246	total:1974	Code ACC: 0.6312056737588653	wrong_be_tree_count:101	wrong_total:331	 wrong be tree ACC: 0.30513595166163143
right_checker:1234	total:1974	checker ACC: 0.6251266598701477	temp:0	temp1:0	wrong_total:331	
save best model to ./output/model_save_name_0/best_model
right_count:112	total:433	 Answer ACC: 0.2586605080831409
right_codes_count:1275	total:1987	Code ACC: 0.6416708605938601	wrong_be_tree_count:103	wrong_total:321	 wrong be tree ACC: 0.32087227414330216
right_checker:1287	total:1987	checker ACC: 0.6477100849151611	temp:0	temp1:0	wrong_total:321	
save best model to ./output/model_save_name_1/best_model


epoch:0,	loss:30.145991325378418	loss1:0
right_count:23	total:431	 Answer ACC: 0.05336426914153132
right_codes_count:995	total:1985	Code ACC: 0.5012594458438288	wrong_be_tree_count:232	wrong_total:408	 wrong be tree ACC: 0.5686274509803921
right_checker:1013	total:1985	checker ACC: 0.5103274583816528	temp:0	temp1:0	wrong_total:408	
save best model to ./output/model_save_name_4/best_model
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:198	total:1963	Code ACC: 0.10086602139582272	wrong_be_tree_count:419	wrong_total:433	 wrong be tree ACC: 0.9676674364896074
right_checker:290	total:1963	checker ACC: 0.14773306250572205	temp:0	temp1:0	wrong_total:433	
save best model to ./output/model_save_name_2/best_model


epoch:8,	loss:1.4026527106761932	loss1:3700.6834926605225


epoch:8,	loss:1.3715521022677422	loss1:3661.700448036194


epoch:1,	loss:11.239796176552773	loss1:0


epoch:5,	loss:1.7599921189248562	loss1:0


epoch:8,	loss:1.4060809798538685	loss1:3599.522532939911
right_count:160	total:433	 Answer ACC: 0.3695150115473441
right_codes_count:1413	total:1976	Code ACC: 0.715080971659919	wrong_be_tree_count:71	wrong_total:273	 wrong be tree ACC: 0.2600732600732601
right_checker:1438	total:1976	checker ACC: 0.7277328372001648	temp:0	temp1:0	wrong_total:273	
save best model to ./output/model_save_name_3/best_model
right_count:148	total:433	 Answer ACC: 0.3418013856812933
right_codes_count:1378	total:1974	Code ACC: 0.6980749746707193	wrong_be_tree_count:71	wrong_total:285	 wrong be tree ACC: 0.24912280701754386
right_checker:1457	total:1974	checker ACC: 0.7380952835083008	temp:0	temp1:0	wrong_total:285	
save best model to ./output/model_save_name_0/best_model
right_count:71	total:431	 Answer ACC: 0.16473317865429235
right_codes_count:1082	total:1985	Code ACC: 0.545088161209068	wrong_be_tree_count:142	wrong_total:360	 wrong be tree ACC: 0.39444444444444443
right_checker:1135	total:1985	checker ACC: 0.5717884302139282	temp:0	temp1:0	wrong_total:360	
save best model to ./output/model_save_name_4/best_model
right_count:151	total:433	 Answer ACC: 0.34872979214780603
right_codes_count:1378	total:1987	Code ACC: 0.6935078007045797	wrong_be_tree_count:87	wrong_total:282	 wrong be tree ACC: 0.30851063829787234
right_checker:1467	total:1987	checker ACC: 0.7382988929748535	temp:0	temp1:0	wrong_total:282	
save best model to ./output/model_save_name_1/best_model


epoch:6,	loss:1.6667873300611973	loss1:0


epoch:9,	loss:1.2262420244514942	loss1:2589.220603942871


epoch:9,	loss:1.1919205375015736	loss1:2490.115092277527


epoch:9,	loss:1.2321858629584312	loss1:2546.2602078914642
right_count:177	total:433	 Answer ACC: 0.40877598152424943
right_codes_count:1499	total:1976	Code ACC: 0.7586032388663968	wrong_be_tree_count:52	wrong_total:256	 wrong be tree ACC: 0.203125
right_checker:1468	total:1976	checker ACC: 0.7429149746894836	temp:0	temp1:0	wrong_total:256	
save best model to ./output/model_save_name_3/best_model
right_count:86	total:431	 Answer ACC: 0.19953596287703015
right_codes_count:1186	total:1985	Code ACC: 0.5974811083123426	wrong_be_tree_count:89	wrong_total:345	 wrong be tree ACC: 0.2579710144927536
right_checker:1214	total:1985	checker ACC: 0.6115869283676147	temp:0	temp1:0	wrong_total:345	
save best model to ./output/model_save_name_4/best_model
right_count:174	total:433	 Answer ACC: 0.4018475750577367
right_codes_count:1457	total:1974	Code ACC: 0.7380952380952381	wrong_be_tree_count:63	wrong_total:259	 wrong be tree ACC: 0.24324324324324326
right_checker:1435	total:1974	checker ACC: 0.7269504070281982	temp:0	temp1:0	wrong_total:259	
save best model to ./output/model_save_name_0/best_model
right_count:170	total:433	 Answer ACC: 0.39260969976905313
right_codes_count:1491	total:1987	Code ACC: 0.7503774534474081	wrong_be_tree_count:59	wrong_total:263	 wrong be tree ACC: 0.22433460076045628
right_checker:1407	total:1987	checker ACC: 0.7081026434898376	temp:0	temp1:0	wrong_total:263	
save best model to ./output/model_save_name_1/best_model


epoch:10,	loss:1.0998147502541542	loss1:1941.4986686706543
right_count:204	total:433	 Answer ACC: 0.47113163972286376
right_codes_count:1520	total:1976	Code ACC: 0.7692307692307693	wrong_be_tree_count:64	wrong_total:229	 wrong be tree ACC: 0.2794759825327511
right_checker:1520	total:1976	checker ACC: 0.7692307829856873	temp:0	temp1:0	wrong_total:229	
save best model to ./output/model_save_name_3/best_model


epoch:10,	loss:1.1029058117419481	loss1:1964.7929375171661


epoch:7,	loss:1.5359921120107174	loss1:0


epoch:10,	loss:1.1419479548931122	loss1:1960.226289510727


epoch:11,	loss:1.0210169404745102	loss1:1703.2735024690628
right_count:177	total:433	 Answer ACC: 0.40877598152424943
right_codes_count:1457	total:1974	Code ACC: 0.7380952380952381	wrong_be_tree_count:54	wrong_total:256	 wrong be tree ACC: 0.2109375
right_checker:1524	total:1974	checker ACC: 0.7720364928245544	temp:0	temp1:0	wrong_total:256	
save best model to ./output/model_save_name_0/best_model
right_count:193	total:433	 Answer ACC: 0.4457274826789838
right_codes_count:1495	total:1987	Code ACC: 0.7523905385002516	wrong_be_tree_count:85	wrong_total:240	 wrong be tree ACC: 0.3541666666666667
right_checker:1509	total:1987	checker ACC: 0.759436309337616	temp:0	temp1:0	wrong_total:240	
save best model to ./output/model_save_name_1/best_model
right_count:217	total:433	 Answer ACC: 0.5011547344110855
right_codes_count:1567	total:1976	Code ACC: 0.7930161943319838	wrong_be_tree_count:75	wrong_total:216	 wrong be tree ACC: 0.3472222222222222
right_checker:1558	total:1976	checker ACC: 0.7884615659713745	temp:0	temp1:0	wrong_total:216	
save best model to ./output/model_save_name_3/best_model
right_count:120	total:431	 Answer ACC: 0.27842227378190254
right_codes_count:1304	total:1985	Code ACC: 0.6569269521410579	wrong_be_tree_count:44	wrong_total:311	 wrong be tree ACC: 0.1414790996784566
right_checker:1302	total:1985	checker ACC: 0.6559193730354309	temp:0	temp1:0	wrong_total:311	
save best model to ./output/model_save_name_4/best_model


epoch:11,	loss:0.9625569269992411	loss1:1635.64058303833


epoch:12,	loss:1.07009182497859	loss1:1490.0601065158844


epoch:8,	loss:1.3796356916427612	loss1:3584.282539844513


epoch:11,	loss:0.9907075082883239	loss1:1615.4997673034668
right_count:240	total:433	 Answer ACC: 0.5542725173210161
right_codes_count:1625	total:1976	Code ACC: 0.8223684210526315	wrong_be_tree_count:52	wrong_total:193	 wrong be tree ACC: 0.2694300518134715
right_checker:1490	total:1976	checker ACC: 0.7540485858917236	temp:0	temp1:0	wrong_total:193	
save best model to ./output/model_save_name_3/best_model
right_count:217	total:433	 Answer ACC: 0.5011547344110855
right_codes_count:1543	total:1974	Code ACC: 0.7816616008105369	wrong_be_tree_count:66	wrong_total:216	 wrong be tree ACC: 0.3055555555555556
right_checker:1477	total:1974	checker ACC: 0.7482270002365112	temp:0	temp1:0	wrong_total:216	
save best model to ./output/model_save_name_0/best_model
right_count:231	total:433	 Answer ACC: 0.5334872979214781
right_codes_count:1571	total:1987	Code ACC: 0.7906391545042778	wrong_be_tree_count:69	wrong_total:202	 wrong be tree ACC: 0.3415841584158416
right_checker:1460	total:1987	checker ACC: 0.7347760200500488	temp:0	temp1:0	wrong_total:202	
save best model to ./output/model_save_name_1/best_model
right_count:154	total:431	 Answer ACC: 0.35730858468677495
right_codes_count:1421	total:1985	Code ACC: 0.7158690176322419	wrong_be_tree_count:71	wrong_total:277	 wrong be tree ACC: 0.2563176895306859
right_checker:1401	total:1985	checker ACC: 0.7057934403419495	temp:0	temp1:0	wrong_total:277	
save best model to ./output/model_save_name_4/best_model


epoch:9,	loss:1.198455123230815	loss1:2509.995388507843


epoch:12,	loss:1.0315569564700127	loss1:1504.8618774414062


epoch:13,	loss:0.8899331279098988	loss1:1392.8193907737732


epoch:12,	loss:0.893395883962512	loss1:1456.4846144914627
right_count:255	total:433	 Answer ACC: 0.5889145496535797
right_codes_count:1654	total:1976	Code ACC: 0.8370445344129555	wrong_be_tree_count:69	wrong_total:178	 wrong be tree ACC: 0.38764044943820225
right_checker:1475	total:1976	checker ACC: 0.7464575171470642	temp:0	temp1:0	wrong_total:178	
save best model to ./output/model_save_name_3/best_model
right_count:261	total:433	 Answer ACC: 0.6027713625866051
right_codes_count:1624	total:1987	Code ACC: 0.8173125314544539	wrong_be_tree_count:61	wrong_total:172	 wrong be tree ACC: 0.3546511627906977
right_checker:1493	total:1987	checker ACC: 0.7513839602470398	temp:0	temp1:0	wrong_total:172	
save best model to ./output/model_save_name_1/best_model
right_count:168	total:431	 Answer ACC: 0.38979118329466356
right_codes_count:1478	total:1985	Code ACC: 0.7445843828715365	wrong_be_tree_count:65	wrong_total:263	 wrong be tree ACC: 0.24714828897338403
right_checker:1442	total:1985	checker ACC: 0.7264483571052551	temp:0	temp1:0	wrong_total:263	
save best model to ./output/model_save_name_4/best_model
right_count:239	total:433	 Answer ACC: 0.5519630484988453
right_codes_count:1582	total:1974	Code ACC: 0.8014184397163121	wrong_be_tree_count:63	wrong_total:194	 wrong be tree ACC: 0.3247422680412371
right_checker:1480	total:1974	checker ACC: 0.7497467398643494	temp:0	temp1:0	wrong_total:194	
save best model to ./output/model_save_name_0/best_model


epoch:14,	loss:0.7703827265650034	loss1:1282.2338252067566
right_count:281	total:433	 Answer ACC: 0.648960739030023
right_codes_count:1676	total:1976	Code ACC: 0.8481781376518218	wrong_be_tree_count:54	wrong_total:152	 wrong be tree ACC: 0.35526315789473684
right_checker:1478	total:1976	checker ACC: 0.7479757070541382	temp:0	temp1:0	wrong_total:152	
save best model to ./output/model_save_name_3/best_model


epoch:10,	loss:1.0751363933086395	loss1:1890.1080605983734


epoch:13,	loss:0.9022400882095098	loss1:1396.8600816726685


epoch:13,	loss:0.8453986011445522	loss1:1354.1694617271423
right_count:256	total:433	 Answer ACC: 0.5912240184757506
right_codes_count:1621	total:1987	Code ACC: 0.8158027176648214	wrong_be_tree_count:65	wrong_total:177	 wrong be tree ACC: 0.3672316384180791
right_checker:1488	total:1987	checker ACC: 0.7488675713539124	temp:0	temp1:0	wrong_total:177	
right_count:243	total:433	 Answer ACC: 0.5612009237875288
right_codes_count:1592	total:1974	Code ACC: 0.806484295845998	wrong_be_tree_count:63	wrong_total:190	 wrong be tree ACC: 0.33157894736842103
right_checker:1484	total:1974	checker ACC: 0.7517730593681335	temp:0	temp1:0	wrong_total:190	
save best model to ./output/model_save_name_0/best_model
right_count:194	total:431	 Answer ACC: 0.45011600928074247
right_codes_count:1518	total:1985	Code ACC: 0.764735516372796	wrong_be_tree_count:77	wrong_total:237	 wrong be tree ACC: 0.32489451476793246
right_checker:1480	total:1985	checker ACC: 0.745591938495636	temp:0	temp1:0	wrong_total:237	
save best model to ./output/model_save_name_4/best_model


epoch:15,	loss:0.7057861108332872	loss1:1125.3588349819183
right_count:310	total:433	 Answer ACC: 0.7159353348729792
right_codes_count:1723	total:1976	Code ACC: 0.8719635627530364	wrong_be_tree_count:41	wrong_total:123	 wrong be tree ACC: 0.3333333333333333
right_checker:1474	total:1976	checker ACC: 0.7459514141082764	temp:0	temp1:0	wrong_total:123	
save best model to ./output/model_save_name_3/best_model


epoch:14,	loss:0.7672004529740661	loss1:1285.2002620697021
right_count:287	total:433	 Answer ACC: 0.6628175519630485
right_codes_count:1673	total:1987	Code ACC: 0.8419728233517866	wrong_be_tree_count:51	wrong_total:146	 wrong be tree ACC: 0.3493150684931507
right_checker:1464	total:1987	checker ACC: 0.7367891073226929	temp:0	temp1:0	wrong_total:146	
save best model to ./output/model_save_name_1/best_model


epoch:14,	loss:0.7264787955209613	loss1:1211.434274673462


epoch:11,	loss:1.0831105336546898	loss1:1665.9905624389648


epoch:16,	loss:0.6106791145866737	loss1:985.0172462463379
right_count:255	total:433	 Answer ACC: 0.5889145496535797
right_codes_count:1617	total:1974	Code ACC: 0.8191489361702128	wrong_be_tree_count:58	wrong_total:178	 wrong be tree ACC: 0.3258426966292135
right_checker:1518	total:1974	checker ACC: 0.7689970135688782	temp:0	temp1:0	wrong_total:178	
save best model to ./output/model_save_name_0/best_model
right_count:228	total:431	 Answer ACC: 0.5290023201856149
right_codes_count:1567	total:1985	Code ACC: 0.7894206549118388	wrong_be_tree_count:76	wrong_total:203	 wrong be tree ACC: 0.37438423645320196
right_checker:1442	total:1985	checker ACC: 0.7264483571052551	temp:0	temp1:0	wrong_total:203	
save best model to ./output/model_save_name_4/best_model
right_count:321	total:433	 Answer ACC: 0.7413394919168591
right_codes_count:1727	total:1976	Code ACC: 0.8739878542510121	wrong_be_tree_count:35	wrong_total:112	 wrong be tree ACC: 0.3125
right_checker:1476	total:1976	checker ACC: 0.7469635605812073	temp:0	temp1:0	wrong_total:112	
save best model to ./output/model_save_name_3/best_model


epoch:15,	loss:0.6974366120994091	loss1:1089.2584927082062
right_count:302	total:433	 Answer ACC: 0.6974595842956121
right_codes_count:1698	total:1987	Code ACC: 0.8545546049320584	wrong_be_tree_count:45	wrong_total:131	 wrong be tree ACC: 0.3435114503816794
right_checker:1446	total:1987	checker ACC: 0.7277302145957947	temp:0	temp1:0	wrong_total:131	
save best model to ./output/model_save_name_1/best_model


epoch:12,	loss:0.9321291837841272	loss1:1504.4617004394531


epoch:15,	loss:0.6614044914022088	loss1:1093.8702716827393


epoch:17,	loss:0.5482582184486091	loss1:854.8338794708252
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1976	Code ACC: 0.8795546558704453	wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
right_checker:1462	total:1976	checker ACC: 0.7398785352706909	temp:0	temp1:0	wrong_total:102	
save best model to ./output/model_save_name_3/best_model


epoch:16,	loss:0.6042460761964321	loss1:939.6152000427246
right_count:237	total:431	 Answer ACC: 0.5498839907192575
right_codes_count:1599	total:1985	Code ACC: 0.8055415617128463	wrong_be_tree_count:74	wrong_total:194	 wrong be tree ACC: 0.38144329896907214
right_checker:1468	total:1985	checker ACC: 0.7395465970039368	temp:0	temp1:0	wrong_total:194	
save best model to ./output/model_save_name_4/best_model
right_count:293	total:433	 Answer ACC: 0.6766743648960739
right_codes_count:1666	total:1974	Code ACC: 0.8439716312056738	wrong_be_tree_count:56	wrong_total:140	 wrong be tree ACC: 0.4
right_checker:1468	total:1974	checker ACC: 0.743667721748352	temp:0	temp1:0	wrong_total:140	
save best model to ./output/model_save_name_0/best_model
right_count:314	total:433	 Answer ACC: 0.7251732101616628
right_codes_count:1700	total:1987	Code ACC: 0.8555611474584801	wrong_be_tree_count:43	wrong_total:119	 wrong be tree ACC: 0.36134453781512604
right_checker:1475	total:1987	checker ACC: 0.7423250675201416	temp:0	temp1:0	wrong_total:119	
save best model to ./output/model_save_name_1/best_model


epoch:18,	loss:0.5003003976889886	loss1:756.5001792907715
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1758	total:1976	Code ACC: 0.8896761133603239	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1526	total:1976	checker ACC: 0.77226722240448	temp:0	temp1:0	wrong_total:88	
save best model to ./output/model_save_name_3/best_model


epoch:13,	loss:0.7934614196419716	loss1:1308.7387342453003


epoch:16,	loss:0.5849425954511389	loss1:956.1235218048096


epoch:17,	loss:0.5727745946496725	loss1:852.1585525870323


epoch:19,	loss:0.4740470200777054	loss1:742.3253221511841
right_count:271	total:431	 Answer ACC: 0.62877030162413
right_codes_count:1634	total:1985	Code ACC: 0.8231738035264483	wrong_be_tree_count:55	wrong_total:160	 wrong be tree ACC: 0.34375
right_checker:1496	total:1985	checker ACC: 0.7536523938179016	temp:0	temp1:0	wrong_total:160	
save best model to ./output/model_save_name_4/best_model
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:26	wrong_total:90	 wrong be tree ACC: 0.28888888888888886
right_checker:1514	total:1976	checker ACC: 0.7661943435668945	temp:0	temp1:0	wrong_total:90	
right_count:296	total:433	 Answer ACC: 0.6836027713625866
right_codes_count:1677	total:1974	Code ACC: 0.8495440729483282	wrong_be_tree_count:44	wrong_total:137	 wrong be tree ACC: 0.32116788321167883
right_checker:1491	total:1974	checker ACC: 0.7553191781044006	temp:0	temp1:0	wrong_total:137	
save best model to ./output/model_save_name_0/best_model
right_count:318	total:433	 Answer ACC: 0.7344110854503464
right_codes_count:1714	total:1987	Code ACC: 0.8626069451434323	wrong_be_tree_count:44	wrong_total:115	 wrong be tree ACC: 0.3826086956521739
right_checker:1483	total:1987	checker ACC: 0.7463512420654297	temp:0	temp1:0	wrong_total:115	
save best model to ./output/model_save_name_1/best_model


epoch:20,	loss:0.43164131650701165	loss1:629.1943397521973
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:25	wrong_total:93	 wrong be tree ACC: 0.26881720430107525
right_checker:1546	total:1976	checker ACC: 0.7823886871337891	temp:0	temp1:0	wrong_total:93	
                                        

epoch:17,	loss:0.5369032621383667	loss1:836.9675839543343


epoch:14,	loss:0.7216112203896046	loss1:1164.938237786293


epoch:21,	loss:0.3889817774761468	loss1:589.6300563812256


epoch:18,	loss:0.5146580878645182	loss1:780.7504930496216
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1765	total:1976	Code ACC: 0.8932186234817814	wrong_be_tree_count:26	wrong_total:83	 wrong be tree ACC: 0.3132530120481928
right_checker:1587	total:1976	checker ACC: 0.8031376600265503	temp:0	temp1:0	wrong_total:83	
save best model to ./output/model_save_name_3/best_model
right_count:309	total:433	 Answer ACC: 0.7136258660508084
right_codes_count:1679	total:1974	Code ACC: 0.8505572441742655	wrong_be_tree_count:45	wrong_total:124	 wrong be tree ACC: 0.3629032258064516
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:124	
save best model to ./output/model_save_name_0/best_model
right_count:323	total:433	 Answer ACC: 0.745958429561201
right_codes_count:1715	total:1987	Code ACC: 0.8631102164066432	wrong_be_tree_count:41	wrong_total:110	 wrong be tree ACC: 0.37272727272727274
right_checker:1520	total:1987	checker ACC: 0.7649722695350647	temp:0	temp1:0	wrong_total:110	
save best model to ./output/model_save_name_1/best_model
right_count:276	total:431	 Answer ACC: 0.6403712296983759
right_codes_count:1646	total:1985	Code ACC: 0.8292191435768262	wrong_be_tree_count:51	wrong_total:155	 wrong be tree ACC: 0.32903225806451614
right_checker:1506	total:1985	checker ACC: 0.7586901783943176	temp:0	temp1:0	wrong_total:155	
save best model to ./output/model_save_name_4/best_model


epoch:22,	loss:0.3616814436390996	loss1:529.008355140686
                                                                                                                                                                                                                                                                                                                                                              right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1777	total:1976	Code ACC: 0.8992914979757085	wrong_be_tree_count:19	wrong_total:78	 wrong be tree ACC: 0.24358974358974358
right_checker:1625	total:1976	checker ACC: 0.8223684430122375	temp:0	temp1:0	wrong_total:78	
save best model to ./output/model_save_name_3/best_model


epoch:18,	loss:0.5035597315873019	loss1:829.872465133667


epoch:15,	loss:0.6729809455573559	loss1:1054.6619911193848


epoch:19,	loss:0.47990638948976994	loss1:784.3375155925751
right_count:186	total:433	 Answer ACC: 0.4295612009237875
right_codes_count:1536	total:1963	Code ACC: 0.782475802343352	wrong_be_tree_count:50	wrong_total:247	 wrong be tree ACC: 0.20242914979757085
right_checker:1355	total:1963	checker ACC: 0.6902700066566467	temp:0	temp1:0	wrong_total:247	
save best model to ./output/model_save_name_2/best_model
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 

epoch:10,	loss:1.1304299216717482	loss1:2046.719937801361
right_count:193	total:433	 Answer ACC: 0.4457274826789838
right_codes_count:1514	total:1963	Code ACC: 0.7712684666327051	wrong_be_tree_count:75	wrong_total:240	 wrong be tree ACC: 0.3125
right_checker:1432	total:1963	checker ACC: 0.7294957041740417	temp:0	temp1:0	wrong_total:240	
save best model to ./output/model_save_name_2/best_model


epoch:11,	loss:1.0172373368404806	loss1:1849.181095123291
right_count:238	total:433	 Answer ACC: 0.5496535796766744
right_codes_count:1610	total:1963	Code ACC: 0.8201732042791645	wrong_be_tree_count:46	wrong_total:195	 wrong be tree ACC: 0.2358974358974359
right_checker:1495	total:1963	checker ACC: 0.7615894079208374	temp:0	temp1:0	wrong_total:195	
save best model to ./output/model_save_name_2/best_model
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   

epoch:12,	loss:1.0640830900520086	loss1:1587.564115524292
right_count:276	total:433	 Answer ACC: 0.6374133949191686
right_codes_count:1659	total:1963	Code ACC: 0.8451349974528782	wrong_be_tree_count:53	wrong_total:157	 wrong be tree ACC: 0.3375796178343949
right_checker:1444	total:1963	checker ACC: 0.7356088161468506	temp:0	temp1:0	wrong_total:157	
save best model to ./output/model_save_name_2/best_model


epoch:13,	loss:0.8937061820179224	loss1:1445.2872838974
right_codes_count:1781	total:1976	Code ACC: 0.9013157894736842	wrong_be_tree_count:21	wrong_total:74	 wrong be tree ACC: 0.28378378378378377
right_checker:1641	total:1976	checker ACC: 0.8304656147956848	temp:0	temp1:0	wrong_total:74	


epoch:17,	loss:0.5172937298193574	loss1:862.6859474182129


epoch:20,	loss:0.419129800517112	loss1:661.0193891525269


epoch:21,	loss:0.39196121448185295	loss1:591.9617199897766
                                                                                                                                                                           

epoch:26,	loss:0.33053516363725066	loss1:478.52456521987915
right_count:318	total:431	 Answer ACC: 0.7378190255220418
right_codes_count:1705	total:1985	Code ACC: 0.8589420654911839	wrong_be_tree_count:48	wrong_total:113	 wrong be tree ACC: 0.4247787610619469
right_checker:1521	total:1985	checker ACC: 0.7662468552589417	temp:0	temp1:0	wrong_total:113	
save best model to ./output/model_save_name_4/best_model
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1775	total:1976	Code ACC: 0.8982793522267206	wrong_be_tree_count:25	wrong_total:77	 wrong be tree ACC: 0.3246753246753247
right_checker:1654	total:1976	checker ACC: 0.8370445370674133	temp:0	temp1:0	wrong_total:77	
right_count:314	total:433	 Answer ACC: 0.7251732101616628
right_codes_count:1718	total:1974	Code ACC: 0.8703140830800405	wrong_be_tree_count:45	wrong_total:119	 wrong be tree ACC: 0.37815126050420167
right_checker:1547	total:1974	checker ACC: 0.7836880087852478	temp:0	temp1:0	wrong_total:119	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1740	total:1987	Code ACC: 0.875691997986915	wrong_be_tree_count:35	wrong_total:101	 wrong be tree ACC: 0.3465346534653465
right_checker:1559	total:1987	checker ACC: 0.7845998406410217	temp:0	temp1:0	wrong_total:101	


epoch:18,	loss:0.4698085836134851	loss1:730.1821441650391
 

epoch:27,	loss:0.29203024262096733	loss1:420.7424576282501


epoch:21,	loss:0.40364309772849083	loss1:630.0449171066284


epoch:22,	loss:0.37199167162179947	loss1:533.3809579610825
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:24	wrong_total:82	 wrong be tree ACC: 0.2926829268292683
right_checker:1677	total:1976	checker ACC: 0.8486842513084412	temp:0	temp1:0	wrong_total:82	
right_count:324	total:431	 Answer ACC: 0.7517401392111369
right_codes_count:1724	total:1985	Code ACC: 0.8685138539042822	wrong_be_tree_count:31	wrong_total:107	 wrong be tree ACC: 0.2897196261682243
right_checker:1514	total:1985	checker ACC: 0.7627204060554504	temp:0	temp1:0	wrong_total:107	
save best model to ./output/model_save_name_4/best_model
right_count:318	total:433	 Answer ACC: 0.7344110854503464
right_codes_count:1721	total:1974	Code ACC: 0.8718338399189463	wrong_be_tree_count:42	wrong_total:115	 wrong be tree ACC: 0.3652173913043478
right_checker:1507	total:1974	checker ACC: 0.7634245753288269	temp:0	temp1:0	wrong_total:115	
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1750	total:1987	Code ACC: 0.8807247106190237	wrong_be_tree_count:39	wrong_total:100	 wrong be tree ACC: 0.39
right_checker:1579	total:1987	checker ACC: 0.7946652770042419	temp:0	temp1:0	wrong_total:100	


epoch:28,	loss:0.2810612339526415	loss1:400.94753444194794
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1780	total:1976	Code ACC: 0.9008097165991903	wrong_be_tree_count:26	wrong_total:81	 wrong be tree ACC: 0.32098765432098764
right_checker:1674	total:1976	checker ACC: 0.8471660017967224	temp:0	temp1:0	wrong_total:81	


epoch:23,	loss:0.4315948844887316	loss1:560.4997450113297


epoch:19,	loss:0.4588859463110566	loss1:655.0618319511414


epoch:22,	loss:0.35629050206625834	loss1:533.716968536377


epoch:29,	loss:0.24256599927321076	loss1:353.7465629577637
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1753	total:1987	Code ACC: 0.8822345244086562	wrong_be_tree_count:38	wrong_total:93	 wrong be tree ACC: 0.40860215053763443
right_checker:1565	total:1987	checker ACC: 0.7876194715499878	temp:0	temp1:0	wrong_total:93	
save best model to ./output/model_save_name_1/best_model


epoch:17,	loss:0.5651309180539101	loss1:956.5301303863525
ght_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:32	wrong_total:108	 wrong be tree ACC: 0.2962962962962963
right_checker:1627	total:1974	checker ACC: 0.8242148160934448	temp:0	temp1:0	wrong_total:108	
save best model to ./output/model_save_name_0/best_model
right_count:367	total:433	 Answer ACC: 0.8475750577367206
right_codes_count:1789	total:1976	Code ACC: 0.9053643724696356	wrong_be_tree_count:24	wrong_total:66	 wrong be tree ACC: 0.36363636363636365
right_checker:1699	total:1976	checker ACC: 0.8598178625106812	temp:0	temp1:0	wrong_total:66	
save best model to ./output/model_save_name_3/best_model
right_count:336	total:431	 Answer ACC: 0.7795823665893271
right_codes_count:1722	total:1985	Code ACC: 0.8675062972292191	wrong_be_tree_count:30	wrong_total:95	 wrong be tree ACC: 0.3157894736842105
right_checker:1501	total:1985	checker ACC: 0.7561712861061096	temp:0	temp1:0	wrong_total:95	
save best model to ./output/model_save_name_4/best_model


epoch:30,	loss:0.22079091233899817	loss1:331.04535883665085


epoch:24,	loss:0.3453944679349661	loss1:492.65011394023895
                                                                                                                                                                                                                                                                                             

epoch:23,	loss:0.4170737722888589	loss1:510.6736434698105


epoch:20,	loss:0.4290885366499424	loss1:662.2009887695312
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1770	total:1976	Code ACC: 0.895748987854251	wrong_be_tree_count:21	wrong_total:78	 wrong be tree ACC: 0.2692307692307692
right_checker:1700	total:1976	checker ACC: 0.8603239059448242	temp:0	temp1:0	wrong_total:78	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1758	total:1987	Code ACC: 0.8847508807247106	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
right_checker:1574	total:1987	checker ACC: 0.7921489477157593	temp:0	temp1:0	wrong_total:90	
save best model to ./output/model_save_name_1/best_model
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1725	total:1974	Code ACC: 0.8738601823708206	wrong_be_tree_count:35	wrong_total:108	 wrong be tree ACC: 0.32407407407407407
right_checker:1575	total:1974	checker ACC: 0.7978723645210266	temp:0	temp1:0	wrong_total:108	
save best model to ./output/model_save_name_0/best_model
right_count:328	total:431	 Answer ACC: 0.7610208816705336
right_codes_count:1727	total:1985	Code ACC: 0.8700251889168765	wrong_be_tree_count:31	wrong_total:103	 wrong be tree ACC: 0.30097087378640774
right_checker:1514	total:1985	checker ACC: 0.7627204060554504	temp:0	temp1:0	wrong_total:103	


epoch:31,	loss:0.23391222395002842	loss1:310.92188477516174


epoch:21,	loss:0.3694265396334231	loss1:543.5831394195557
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1772	total:1976	Code ACC: 0.8967611336032388	wrong_be_tree_count:21	wrong_total:82	 wrong be tree ACC: 0.25609756097560976
right_checker:1674	total:1976	checker ACC: 0.8471660017967224	temp:0	temp1:0	wrong_total:82	


epoch:24,	loss:0.34909965423867106	loss1:532.2991018891335
right_count:336	total:431	 Answer ACC: 0.7795823665893271
right_codes_count:1735	total:1985	Code ACC: 0.8740554156171285	wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
right_checker:1547	total:1985	checker ACC: 0.7793450951576233	temp:0	temp1:0	wrong_total:95	
save best model to ./output/model_save_name_4/best_model


epoch:21,	loss:0.4099227285478264	loss1:648.7643089294434
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1785	total:1963	Code ACC: 0.9093224656138563	wrong_be_tree_count:28	wrong_total:80	 wrong be tree ACC: 0.35
right_checker:1515	total:1963	checker ACC: 0.7717779278755188	temp:0	temp1:0	wrong_total:80	
0	wrong_total:108	
save best model to ./output/model_save_name_0/best_model


epoch:32,	loss:0.2275854066829197	loss1:353.71601724624634
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1758	total:1987	Code ACC: 0.8847508807247106	wrong_be_tree_count:23	wrong_total:79	 wrong be tree ACC: 0.2911392405063291
right_checker:1644	total:1987	checker ACC: 0.8273779153823853	temp:0	temp1:0	wrong_total:79	
save best model to ./output/model_save_name_1/best_model
right_count:360	total:433	 Answer ACC: 0.8314087759815243
right_codes_count:1777	total:1976	Code ACC: 0.8992914979757085	wrong_be_tree_count:22	wrong_total:73	 wrong be tree ACC: 0.3013698630136986
right_checker:1706	total:1976	checker ACC: 0.8633603453636169	temp:0	temp1:0	wrong_total:73	


epoch:22,	loss:0.3420091769658029	loss1:523.2784555852413


epoch:33,	loss:0.20619309786707163	loss1:299.2094497680664
right_count:339	total:431	 Answer ACC: 0.7865429234338747
right_codes_count:1747	total:1985	Code ACC: 0.8801007556675063	wrong_be_tree_count:33	wrong_total:92	 wrong be tree ACC: 0.358695652173913
right_checker:1544	total:1985	checker ACC: 0.7778337597846985	temp:0	temp1:0	wrong_total:92	
save best model to ./output/model_save_name_4/best_model


epoch:25,	loss:0.3085699296207167	loss1:509.9539499282837
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1781	total:1976	Code ACC: 0.9013157894736842	wrong_be_tree_count:30	wrong_total:78	 wrong be tree ACC: 0.38461538461538464
right_checker:1690	total:1976	checker ACC: 0.8552631735801697	temp:0	temp1:0	wrong_total:78	


epoch:26,	loss:0.3110916796140373	loss1:424.3955707550049
right_count:326	total:433	 Answer ACC: 0.7528868360277137
right_codes_count:1729	total:1974	Code ACC: 0.875886524822695	wrong_be_tree_count:43	wrong_total:107	 wrong be tree ACC: 0.40186915887850466
right_checker:1612	total:1974	checker ACC: 0.8166160583496094	temp:0	temp1:0	wrong_total:107	
save best model to ./output/model_save_name_0/best_model
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1760	total:1987	Code ACC: 0.8857574232511324	wrong_be_tree_count:29	wrong_total:86	 wrong be tree ACC: 0.3372093023255814
right_checker:1606	total:1987	checker ACC: 0.8082535862922668	temp:0	temp1:0	wrong_total:86	


epoch:34,	loss:0.18734001883422025	loss1:261.82367968559265


epoch:23,	loss:0.32281676190905273	loss1:506.6043949127197
                                                                                                                                                                        right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:30	wrong_total:76	 wrong be tree ACC: 0.39473684210526316
right_checker:1678	total:1976	checker ACC: 0.8491902947425842	temp:0	temp1:0	wrong_total:76	
right_count:333	total:431	 Answer ACC: 0.7726218097447796
right_codes_count:1734	total:1985	Code ACC: 0.873551637279597	wrong_be_tree_count:28	wrong_total:98	 wrong be tree ACC: 0.2857142857142857
right_checker:1619	total:1985	checker ACC: 0.8156171441078186	temp:0	temp1:0	wrong_total:98	


epoch:27,	loss:0.28453625878319144	loss1:404.30026292800903


epoch:35,	loss:0.17588117899140343	loss1:236.13001990318298


epoch:26,	loss:0.2930733631365001	loss1:431.98041117191315


epoch:24,	loss:0.3005604612408206	loss1:474.9268569946289
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1778	total:1976	Code ACC: 0.8997975708502024	wrong_be_tree_count:27	wrong_total:79	 wrong be tree ACC: 0.34177215189873417
right_checker:1718	total:1976	checker ACC: 0.8694332242012024	temp:0	temp1:0	wrong_total:79	
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1768	total:1987	Code ACC: 0.8897835933568193	wrong_be_tree_count:32	wrong_total:77	 wrong be tree ACC: 0.4155844155844156
right_checker:1675	total:1987	checker ACC: 0.8429793119430542	temp:0	temp1:0	wrong_total:77	
save best model to ./output/model_save_name_1/best_model
right_count:326	total:433	 Answer ACC: 0.7528868360277137
right_codes_count:1728	total:1974	Code ACC: 0.8753799392097265	wrong_be_tree_count:34	wrong_total:107	 wrong be tree ACC: 0.3177570093457944
right_checker:1667	total:1974	checker ACC: 0.8444782495498657	temp:0	temp1:0	wrong_total:107	
save best model to ./output/model_save_name_0/best_model
right_count:342	total:431	 Answer ACC: 0.7935034802784223
right_codes_count:1746	total:1985	Code ACC: 0.8795969773299748	wrong_be_tree_count:31	wrong_total:89	 wrong be tree ACC: 0.34831460674157305
right_checker:1608	total:1985	checker ACC: 0.810075581073761	temp:0	temp1:0	wrong_total:89	
save best model to ./output/model_save_name_4/best_model


epoch:36,	loss:0.17055567516945302	loss1:226.6870710849762
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:27	wrong_total:78	 wrong be tree ACC: 0.34615384615384615
right_checker:1745	total:1976	checker ACC: 0.8830971717834473	temp:0	temp1:0	wrong_total:78	


epoch:25,	loss:0.2862231032922864	loss1:452.71454334259033


epoch:37,	loss:0.1934561561793089	loss1:297.15330016613007


epoch:28,	loss:0.26420569280162454	loss1:419.5842409133911
                                                                                                                                                                         

epoch:27,	loss:0.34331328934058547	loss1:443.5810811519623
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1714	total:1976	checker ACC: 0.8674089312553406	temp:0	temp1:0	wrong_total:85	
right_count:322	total:433	 Answer ACC: 0.74364896073903
right_codes_count:1724	total:1974	Code ACC: 0.8733535967578521	wrong_be_tree_count:38	wrong_total:111	 wrong be tree ACC: 0.34234234234234234
right_checker:1643	total:1974	checker ACC: 0.8323202133178711	temp:0	temp1:0	wrong_total:111	
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1757	total:1987	Code ACC: 0.8842476094614997	wrong_be_tree_count:26	wrong_total:80	 wrong be tree ACC: 0.325
right_checker:1660	total:1987	checker ACC: 0.8354302644729614	temp:0	temp1:0	wrong_total:80	
right_count:342	total:431	 Answer ACC: 0.7935034802784223
right_codes_count:1739	total:1985	Code ACC: 0.8760705289672545	wrong_be_tree_count:32	wrong_total:89	 wrong be tree ACC: 0.3595505617977528
right_checker:1598	total:1985	checker ACC: 0.805037796497345	temp:0	temp1:0	wrong_total:89	
save best model to ./output/model_save_name_4/best_model


epoch:38,	loss:0.1855438204947859	loss1:258.78818678855896
                                                                                                                                                                                                                                                                                    

epoch:26,	loss:0.28865027893334627	loss1:465.8289632797241


epoch:28,	loss:0.29747983475681394	loss1:474.76431465148926


epoch:29,	loss:0.23969998891698197	loss1:344.76486349105835
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1772	total:1976	Code ACC: 0.8967611336032388	wrong_be_tree_count:28	wrong_total:79	 wrong be tree ACC: 0.35443037974683544
right_checker:1707	total:1976	checker ACC: 0.86386638879776	temp:0	temp1:0	wrong_total:79	
right_count:340	total:431	 Answer ACC: 0.7888631090487239
right_codes_count:1737	total:1985	Code ACC: 0.8750629722921914	wrong_be_tree_count:28	wrong_total:91	 wrong be tree ACC: 0.3076923076923077
right_checker:1605	total:1985	checker ACC: 0.8085642457008362	temp:0	temp1:0	wrong_total:91	
right_count:354	total:433	 Answer ACC: 0.8175519630484989
rigright_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1769	total:1963	Code ACC: 0.9011716760061131	wrong_be_tree_count:34	wrong_total:80	 wrong be tree ACC: 0.425
right_checker:1698	total:1963	checker ACC: 0.8650025725364685	temp:0	temp1:0	wrong_total:80	
3672055427
right_codes_count:1722	total:1974	Code ACC: 0.8723404255319149	wrong_be_tree_count:43	wrong_total:108	 wrong be tree ACC: 0.39814814814814814
right_checker:1638	total:1974	checker ACC: 0.8297872543334961	temp:0	temp1:0	wrong_total:108	


epoch:39,	loss:0.1622896094340831	loss1:236.89294701814651
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1770	total:1976	Code ACC: 0.895748987854251	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1750	total:1976	checker ACC: 0.8856275677680969	temp:0	temp1:0	wrong_total:89	


epoch:27,	loss:0.29483190458267927	loss1:421.38923025131226


epoch:29,	loss:0.2501416445011273	loss1:373.9835524559021
 

epoch:30,	loss:0.28175271674990654	loss1:332.2724544405937
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1746	total:1985	Code ACC: 0.8795969773299748	wrong_be_tree_count:23	wrong_total:86	 wrong be tree ACC: 0.26744186046511625
right_checker:1655	total:1985	checker ACC: 0.8337531685829163	temp:0	temp1:0	wrong_total:86	
save best model to ./output/model_save_name_4/best_model


epoch:40,	loss:0.15094950422644615	loss1:204.23023796081543
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
right_checker:1719	total:1974	checker ACC: 0.8708207011222839	temp:0	temp1:0	wrong_total:98	
save best model to ./output/model_save_name_0/best_model
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
right_checker:1757	total:1987	checker ACC: 0.8842475414276123	temp:0	temp1:0	wrong_total:86	
right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1780	total:1976	Code ACC: 0.9008097165991903	wrong_be_tree_count:25	wrong_total:76	 wrong be tree ACC: 0.32894736842105265
right_checker:1759	total:1976	checker ACC: 0.8901821970939636	temp:0	temp1:0	wrong_total:76	


epoch:31,	loss:0.2480733190313913	loss1:354.910573720932


epoch:41,	loss:0.1482778307981789	loss1:185.03462040424347
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1761	total:1987	Code ACC: 0.8862606945143432	wrong_be_tree_count:33	wrong_total:88	 wrong be tree ACC: 0.375
right_checker:1673	total:1987	checker ACC: 0.8419727683067322	temp:0	temp1:0	wrong_total:88	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1768	total:1976	Code ACC: 0.8947368421052632	wrong_be_tree_count:30	wrong_total:82	 wrong be tree ACC: 0.36585365853658536
right_checker:1705	total:1976	checker ACC: 0.8628543019294739	temp:0	temp1:0	wrong_total:82	


epoch:30,	loss:0.2741401782259345	loss1:318.06866466999054


epoch:28,	loss:0.2828433366958052	loss1:402.0556252002716
right_count:316	total:433	 Answer ACC: 0.7297921478060047
right_codes_count:1718	total:1974	Code ACC: 0.8703140830800405	wrong_be_tree_count:43	wrong_total:117	 wrong be tree ACC: 0.36752136752136755
right_checker:1688	total:1974	checker ACC: 0.8551165461540222	temp:0	temp1:0	wrong_total:117	
right_count:338	total:431	 Answer ACC: 0.7842227378190255
right_codes_count:1741	total:1985	Code ACC: 0.8770780856423174	wrong_be_tree_count:29	wrong_total:93	 wrong be tree ACC: 0.3118279569892473
right_checker:1599	total:1985	checker ACC: 0.8055415749549866	temp:0	temp1:0	wrong_total:93	


epoch:32,	loss:0.21723167994059622	loss1:300.08024168014526
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1785	total:1963	Code ACC: 0.9093224656138563	wrong_be_tree_count:34	wrong_total:80	 wrong be tree ACC: 0.425
right_checker:1668	total:1963	checker ACC: 0.8497198224067688	temp:0	temp1:0	wrong_total:80	
de ACC: 0.8857574232511324	wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
right_checker:1665	total:1987	checker ACC: 0.8379465937614441	temp:0	temp1:0	wrong_total:91	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1769	total:1976	Code ACC: 0.895242914979757	wrong_be_tree_count:27	wrong_total:82	 wrong be tree ACC: 0.32926829268292684
right_checker:1768	total:1976	checker ACC: 0.8947368860244751	temp:0	temp1:0	wrong_total:82	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:44	wrong_total:101	 wrong be tree ACC: 0.43564356435643564
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:101	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1754	total:1985	Code ACC: 0.8836272040302267	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
right_checker:1641	total:1985	checker ACC: 0.8267002701759338	temp:0	temp1:0	wrong_total:85	
save best model to ./output/model_save_name_4/best_model


epoch:33,	loss:0.2048222532030195	loss1:286.506649017334
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:34	wrong_total:90	 wrong be tree ACC: 0.37777777777777777
right_checker:1706	total:1987	checker ACC: 0.8585807085037231	temp:0	temp1:0	wrong_total:90	


epoch:43,	loss:0.15620866464450955	loss1:220.56554007530212


epoch:32,	loss:0.2191753548104316	loss1:324.12586402893066
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:35	wrong_total:82	 wrong be tree ACC: 0.4268292682926829
right_checker:1735	total:1976	checker ACC: 0.8780364394187927	temp:0	temp1:0	wrong_total:82	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1729	total:1974	Code ACC: 0.875886524822695	wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
right_checker:1667	total:1974	checker ACC: 0.8444782495498657	temp:0	temp1:0	wrong_total:98	
save best model to ./output/model_save_name_0/best_model


epoch:34,	loss:0.18560219486244023	loss1:285.50177335739136
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1762	total:1987	Code ACC: 0.8867639657775541	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
right_checker:1716	total:1987	checker ACC: 0.8636134266853333	temp:0	temp1:0	wrong_total:92	


epoch:30,	loss:0.24490012973546982	loss1:336.3651578426361


epoch:44,	loss:0.12392174929846078	loss1:168.42365789413452
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1776	total:1976	Code ACC: 0.8987854251012146	wrong_be_tree_count:24	wrong_total:82	 wrong be tree ACC: 0.2926829268292683
right_checker:1753	total:1976	checker ACC: 0.8871457576751709	temp:0	temp1:0	wrong_total:82	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1749	total:1985	Code ACC: 0.8811083123425693	wrong_be_tree_count:23	wrong_total:88	 wrong be tree ACC: 0.26136363636363635
right_checker:1650	total:1985	checker ACC: 0.8312342762947083	temp:0	temp1:0	wrong_total:88	


epoch:35,	loss:0.18718547870230395	loss1:287.26092410087585


epoch:33,	loss:0.21537079324480146	loss1:322.9700164794922
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1756	total:1987	Code ACC: 0.8837443381982889	wrong_be_tree_count:35	wrong_total:94	 wrong be tree ACC: 0.3723404255319149
right_checker:1707	total:1987	checker ACC: 0.8590840101242065	temp:0	temp1:0	wrong_total:94	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
right_checker:1690	total:1974	checker ACC: 0.8561297059059143	temp:0	temp1:0	wrong_total:99	


epoch:39,	loss:0.16518485714914277	loss1:247.11126685142517
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1788	total:1963	Code ACC: 0.9108507386653082	wrong_be_tree_count:37	wrong_total:81	 wrong be tree ACC: 0.4567901234567901
right_checker:1712	total:1963	checker ACC: 0.8721345067024231	temp:0	temp1:0	wrong_total:81	
ecker ACC: 0.8815789818763733	temp:0	temp1:0	wrong_total:91	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1755	total:1985	Code ACC: 0.8841309823677582	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1612	total:1985	checker ACC: 0.8120906949043274	temp:0	temp1:0	wrong_total:88	


epoch:34,	loss:0.19974924554117024	loss1:286.9481360912323


epoch:46,	loss:0.11909208994620712	loss1:166.13028728961945


epoch:36,	loss:0.18432526930700988	loss1:272.79241597652435


epoch:32,	loss:0.2111811744980514	loss1:316.59178376197815
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:45	wrong_total:102	 wrong be tree ACC: 0.4411764705882353
right_checker:1680	total:1974	checker ACC: 0.8510638475418091	temp:0	temp1:0	wrong_total:102	
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1775	total:1976	Code ACC: 0.8982793522267206	wrong_be_tree_count:32	wrong_total:79	 wrong be tree ACC: 0.4050632911392405
right_checker:1772	total:1976	checker ACC: 0.8967611789703369	temp:0	temp1:0	wrong_total:79	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1753	total:1987	Code ACC: 0.8822345244086562	wrong_be_tree_count:36	wrong_total:93	 wrong be tree ACC: 0.3870967741935484
right_checker:1701	total:1987	checker ACC: 0.8560643792152405	temp:0	temp1:0	wrong_total:93	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1757	total:1985	Code ACC: 0.8851385390428211	wrong_be_tree_count:31	wrong_total:87	 wrong be tree ACC: 0.3563218390804598
right_checker:1636	total:1985	checker ACC: 0.8241813778877258	temp:0	temp1:0	wrong_total:87	


epoch:35,	loss:0.19281384791247547	loss1:279.75497674942017


epoch:47,	loss:0.10686086164787412	loss1:146.24243181943893


epoch:33,	loss:0.18412357196211815	loss1:269.667268037796


epoch:37,	loss:0.17241013946477324	loss1:239.97493934631348
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1773	total:1976	Code ACC: 0.8972672064777328	wrong_be_tree_count:28	wrong_total:79	 wrong be tree ACC: 0.35443037974683544
right_checker:1772	total:1976	checker ACC: 0.8967611789703369	temp:0	temp1:0	wrong_total:79	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1749	total:1974	Code ACC: 0.8860182370820668	wrong_be_tree_count:35	wrong_total:92	 wrong be tree ACC: 0.3804347826086957
right_checker:1713	total:1974	checker ACC: 0.8677812218666077	temp:0	temp1:0	wrong_total:92	
save best model to ./output/model_save_name_0/best_model
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1755	total:1987	Code ACC: 0.883241066935078	wrong_be_tree_count:39	wrong_total:94	 wrong be tree ACC: 0.4148936170212766
right_checker:1717	total:1987	checker ACC: 0.8641167283058167	temp:0	temp1:0	wrong_total:94	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1758	total:1985	Code ACC: 0.8856423173803526	wrong_be_tree_count:27	wrong_total:83	 wrong be tree ACC: 0.3253012048192771
right_checker:1653	total:1985	checker ACC: 0.8327456116676331	temp:0	temp1:0	wrong_total:83	
save best model to ./output/model_save_name_4/best_model


epoch:48,	loss:0.12162928865291178	loss1:120.94113516807556
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1770	total:1976	Code ACC: 0.895748987854251	wrong_be_tree_count:23	wrong_total:80	 wrong be tree ACC: 0.2875
right_checker:1765	total:1976	checker ACC: 0.8932186365127563	temp:0	temp1:0	wrong_total:80	


epoch:38,	loss:0.15850045953993686	loss1:245.58834433555603
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1751	total:1987	Code ACC: 0.8812279818822345	wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
right_checker:1744	total:1987	checker ACC: 0.8777050375938416	temp:0	temp1:0	wrong_total:102	
right_count:358	total:433	 Answer ACC: 0.8267898383371824
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:30	wrong_total:75	 wrong be tree ACC: 0.4
right_checker:1717	total:1963	checker ACC: 0.8746816515922546	temp:0	temp1:0	wrong_total:75	
                                                                                                                                                                                                                                                                     

epoch:44,	loss:0.13441108708502725	loss1:161.17592978477478
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:24	wrong_total:77	 wrong be tree ACC: 0.3116883116883117
right_checker:1715	total:1963	checker ACC: 0.8736627697944641	temp:0	temp1:0	wrong_total:77	


epoch:45,	loss:0.1284735861045192	loss1:151.86217164993286
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1788	total:1963	Code ACC: 0.9108507386653082	wrong_be_tree_count:36	wrong_total:81	 wrong be tree ACC: 0.4444444444444444
right_checker:1707	total:1963	checker ACC: 0.8695874214172363	temp:0	temp1:0	wrong_total:81	
                                                                                                                                                                                                                                                                                                                                                                                                              

epoch:46,	loss:0.12606149091152474	loss1:154.2967729791999
right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1796	total:1963	Code ACC: 0.9149261334691798	wrong_be_tree_count:28	wrong_total:76	 wrong be tree ACC: 0.3684210526315789
right_checker:1751	total:1963	checker ACC: 0.8920020461082458	temp:0	temp1:0	wrong_total:76	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        

epoch:47,	loss:0.12200455996207893	loss1:142.37602877616882
                                                                                                                                                                                                                                      right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1780	total:1963	Code ACC: 0.9067753438614365	wrong_be_tree_count:39	wrong_total:85	 wrong be tree ACC: 0.4588235294117647
right_checker:1683	total:1963	checker ACC: 0.8573611974716187	temp:0	temp1:0	wrong_total:85	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              

epoch:48,	loss:0.13460810424294323	loss1:148.96744641661644
right_count:359	total:433	 Answer ACC: 0.8290993071593533
right_codes_count:1791	total:1963	Code ACC: 0.9123790117167601	wrong_be_tree_count:30	wrong_total:74	 wrong be tree ACC: 0.40540540540540543
right_checker:1744	total:1963	checker ACC: 0.8884360790252686	temp:0	temp1:0	wrong_total:74	
save best model to ./output/model_save_name_2/best_model
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             

epoch:49,	loss:0.13034594780765474	loss1:163.00642973184586
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1791	total:1963	Code ACC: 0.9123790117167601	wrong_be_tree_count:31	wrong_total:81	 wrong be tree ACC: 0.38271604938271603
right_checker:1727	total:1963	checker ACC: 0.879775881767273	temp:0	temp1:0	wrong_total:81	
                                                                                                                                                                                                                                                                                                                                                             

epoch:50,	loss:0.19748147227801383	loss1:142.947867333889
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1791	total:1963	Code ACC: 0.9123790117167601	wrong_be_tree_count:34	wrong_total:79	 wrong be tree ACC: 0.43037974683544306
right_checker:1708	total:1963	checker ACC: 0.8700968027114868	temp:0	temp1:0	wrong_total:79	


epoch:51,	loss:0.12311762661556713	loss1:181.08401024341583
                                                                                                                                                                                                                                                                                                                                                   right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:38	wrong_total:78	 wrong be tree ACC: 0.48717948717948717
right_checker:1717	total:1963	checker ACC: 0.8746816515922546	temp:0	temp1:0	wrong_total:78	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     

epoch:52,	loss:0.10559573129285127	loss1:163.8344987630844
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1782	total:1963	Code ACC: 0.9077941925624045	wrong_be_tree_count:33	wrong_total:86	 wrong be tree ACC: 0.38372093023255816
right_checker:1746	total:1963	checker ACC: 0.8894549608230591	temp:0	temp1:0	wrong_total:86	


epoch:53,	loss:0.10923991003073752	loss1:134.83988547325134
ght_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1774	total:1976	Code ACC: 0.8977732793522267	wrong_be_tree_count:33	wrong_total:82	 wrong be tree ACC: 0.4024390243902439
right_checker:1744	total:1976	checker ACC: 0.8825911283493042	temp:0	temp1:0	wrong_total:82	


epoch:41,	loss:0.1635856640059501	loss1:233.3488665819168


epoch:39,	loss:0.1554734348319471	loss1:193.01759696006775


epoch:45,	loss:0.14521790127037093	loss1:173.86906898021698


epoch:56,	loss:0.08066370591404848	loss1:96.44266772270203
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:36	wrong_total:97	 wrong be tree ACC: 0.3711340206185567
right_checker:1731	total:1974	checker ACC: 0.8768997192382812	temp:0	temp1:0	wrong_total:97	
right_count:339	total:431	 Answer ACC: 0.7865429234338747
right_codes_count:1753	total:1985	Code ACC: 0.8831234256926952	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1691	total:1985	checker ACC: 0.8518891930580139	temp:0	temp1:0	wrong_total:92	
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1748	total:1987	Code ACC: 0.879718168092602	wrong_be_tree_count:24	wrong_total:86	 wrong be tree ACC: 0.27906976744186046
right_checker:1700	total:1987	checker ACC: 0.8555610775947571	temp:0	temp1:0	wrong_total:86	
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1769	total:1976	Code ACC: 0.895242914979757	wrong_be_tree_count:32	wrong_total:78	 wrong be tree ACC: 0.41025641025641024
right_checker:1760	total:1976	checker ACC: 0.8906883001327515	temp:0	temp1:0	wrong_total:78	


epoch:42,	loss:0.15560291823931038	loss1:252.554461479187


epoch:40,	loss:0.1587724392011296	loss1:216.22707152366638


epoch:57,	loss:0.08285054116277024	loss1:109.4991811811924


epoch:46,	loss:0.13165440570446663	loss1:169.76391161978245
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:42	wrong_total:104	 wrong be tree ACC: 0.40384615384615385
right_checker:1747	total:1974	checker ACC: 0.8850051164627075	temp:0	temp1:0	wrong_total:104	
right_count:358	total:433	 Answer ACC: 0.8267898383371824
right_codes_count:1772	total:1976	Code ACC: 0.8967611336032388	wrong_be_tree_count:31	wrong_total:75	 wrong be tree ACC: 0.41333333333333333
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:75	
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1755	total:1987	Code ACC: 0.883241066935078	wrong_be_tree_count:26	wrong_total:87	 wrong be tree ACC: 0.2988505747126437
right_checker:1766	total:1987	checker ACC: 0.8887770175933838	temp:0	temp1:0	wrong_total:87	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1750	total:1985	Code ACC: 0.8816120906801007	wrong_be_tree_count:39	wrong_total:87	 wrong be tree ACC: 0.4482758620689655
right_checker:1676	total:1985	checker ACC: 0.8443325161933899	temp:0	temp1:0	wrong_total:87	


epoch:43,	loss:0.15023016289342195	loss1:204.59941625595093


epoch:41,	loss:0.1391814854578115	loss1:190.24478101730347


epoch:58,	loss:0.0758968246736913	loss1:91.73638215661049


epoch:47,	loss:0.12906175112584606	loss1:157.5317338705063
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1776	total:1976	Code ACC: 0.8987854251012146	wrong_be_tree_count:31	wrong_total:80	 wrong be tree ACC: 0.3875
right_checker:1781	total:1976	checker ACC: 0.9013158082962036	temp:0	temp1:0	wrong_total:80	


epoch:57,	loss:0.09159204293973744	loss1:121.35054898262024
t_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:31	wrong_total:95	 wrong be tree ACC: 0.3263157894736842
right_checker:1725	total:1974	checker ACC: 0.873860239982605	temp:0	temp1:0	wrong_total:95	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1754	total:1987	Code ACC: 0.8827377956718672	wrong_be_tree_count:35	wrong_total:97	 wrong be tree ACC: 0.36082474226804123
right_checker:1720	total:1987	checker ACC: 0.8656265139579773	temp:0	temp1:0	wrong_total:97	
right_count:340	total:431	 Answer ACC: 0.7888631090487239
right_codes_count:1741	total:1985	Code ACC: 0.8770780856423174	wrong_be_tree_count:39	wrong_total:91	 wrong be tree ACC: 0.42857142857142855
right_checker:1691	total:1985	checker ACC: 0.8518891930580139	temp:0	temp1:0	wrong_total:91	


epoch:59,	loss:0.07739747071173042	loss1:96.24066251516342
                                                                                                                                                                                                                                       

epoch:42,	loss:0.14326751953922212	loss1:191.10275596380234
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1766	total:1976	Code ACC: 0.8937246963562753	wrong_be_tree_count:31	wrong_total:81	 wrong be tree ACC: 0.38271604938271603
right_checker:1783	total:1976	checker ACC: 0.9023279547691345	temp:0	temp1:0	wrong_total:81	


epoch:44,	loss:0.14410104998387396	loss1:205.3276252746582


epoch:48,	loss:0.12942264694720507	loss1:163.37498480081558
right_count:347	total:431	 Answer ACC: 0.8051044083526682
right_codes_count:1755	total:1985	Code ACC: 0.8841309823677582	wrong_be_tree_count:35	wrong_total:84	 wrong be tree ACC: 0.4166666666666667
right_checker:1691	total:1985	checker ACC: 0.8518891930580139	temp:0	temp1:0	wrong_total:84	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:36	wrong_total:97	 wrong be tree ACC: 0.3711340206185567
right_checker:1735	total:1974	checker ACC: 0.8789260983467102	temp:0	temp1:0	wrong_total:97	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1757	total:1987	Code ACC: 0.8842476094614997	wrong_be_tree_count:30	wrong_total:97	 wrong be tree ACC: 0.30927835051546393
right_checker:1747	total:1987	checker ACC: 0.8792148232460022	temp:0	temp1:0	wrong_total:97	


epoch:60,	loss:0.07336789561668411	loss1:93.21962380409241
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:32	wrong_total:80	 wrong be tree ACC: 0.4
right_checker:1769	total:1976	checker ACC: 0.8952429294586182	temp:0	temp1:0	wrong_total:80	


epoch:43,	loss:0.12702785106375813	loss1:186.83678579330444
                                                                                                                                                                                                                                                                                                

epoch:45,	loss:0.1455586662341375	loss1:193.37189429998398


epoch:49,	loss:0.12706416856963187	loss1:163.64495012164116


epoch:61,	loss:0.07642183717689477	loss1:77.21132311224937
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1757	total:1985	Code ACC: 0.8851385390428211	wrong_be_tree_count:31	wrong_total:82	 wrong be tree ACC: 0.3780487804878049
right_checker:1692	total:1985	checker ACC: 0.8523929715156555	temp:0	temp1:0	wrong_total:82	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:35	wrong_total:82	 wrong be tree ACC: 0.4268292682926829
right_checker:1768	total:1976	checker ACC: 0.8947368860244751	temp:0	temp1:0	wrong_total:82	
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:37	wrong_total:100	 wrong be tree ACC: 0.37
right_checker:1679	total:1974	checker ACC: 0.850557267665863	temp:0	temp1:0	wrong_total:100	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1756	total:1987	Code ACC: 0.8837443381982889	wrong_be_tree_count:33	wrong_total:94	 wrong be tree ACC: 0.35106382978723405
right_checker:1735	total:1987	checker ACC: 0.8731756210327148	temp:0	temp1:0	wrong_total:94	


epoch:61,	loss:0.08815502922516316	loss1:85.88357823486328


epoch:44,	loss:0.12610872614459367	loss1:165.6288069486618


epoch:46,	loss:0.1303544088441413	loss1:188.969986140728


epoch:50,	loss:0.1280033669900149	loss1:138.68581079691648
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1774	total:1976	Code ACC: 0.8977732793522267	wrong_be_tree_count:30	wrong_total:79	 wrong be tree ACC: 0.379746835443038
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:79	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1758	total:1985	Code ACC: 0.8856423173803526	wrong_be_tree_count:30	wrong_total:87	 wrong be tree ACC: 0.3448275862068966
right_checker:1689	total:1985	checker ACC: 0.8508816361427307	temp:0	temp1:0	wrong_total:87	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
right_checker:1744	total:1974	checker ACC: 0.8834853768348694	temp:0	temp1:0	wrong_total:98	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:33	wrong_total:91	 wrong be tree ACC: 0.3626373626373626
right_checker:1715	total:1987	checker ACC: 0.8631101846694946	temp:0	temp1:0	wrong_total:91	


epoch:45,	loss:0.1219954166590469	loss1:171.01435813307762


epoch:63,	loss:0.06706778533407487	loss1:78.8500602543354
right_count:342	total:431	 Answer ACC: 0.7935034802784223
right_codes_count:1748	total:1985	Code ACC: 0.8806045340050378	wrong_be_tree_count:33	wrong_total:89	 wrong be tree ACC: 0.3707865168539326
right_checker:1706	total:1985	checker ACC: 0.8594458699226379	temp:0	temp1:0	wrong_total:89	


epoch:47,	loss:0.16830694931559265	loss1:175.07387125492096


epoch:51,	loss:0.1342094315623399	loss1:171.8490035533905
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:32	wrong_total:81	 wrong be tree ACC: 0.3950617283950617
right_checker:1770	total:1976	checker ACC: 0.895749032497406	temp:0	temp1:0	wrong_total:81	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1751	total:1987	Code ACC: 0.8812279818822345	wrong_be_tree_count:36	wrong_total:90	 wrong be tree ACC: 0.4
right_checker:1711	total:1987	checker ACC: 0.8610970973968506	temp:0	temp1:0	wrong_total:90	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:37	wrong_total:101	 wrong be tree ACC: 0.36633663366336633
right_checker:1716	total:1974	checker ACC: 0.8693009614944458	temp:0	temp1:0	wrong_total:101	


epoch:64,	loss:0.06390751233266201	loss1:79.96904617547989
                                                                                                                                                                                                                                                                                                  

epoch:46,	loss:0.11699678131844848	loss1:134.88106425106525


epoch:48,	loss:0.15234534279443324	loss1:218.68492770195007


epoch:52,	loss:0.11613035208210931	loss1:160.96938753128052
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:28	wrong_total:81	 wrong be tree ACC: 0.345679012345679
right_checker:1786	total:1976	checker ACC: 0.9038462042808533	temp:0	temp1:0	wrong_total:81	
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:29	wrong_total:82	 wrong be tree ACC: 0.35365853658536583
right_checker:1696	total:1985	checker ACC: 0.8544080853462219	temp:0	temp1:0	wrong_total:82	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:34	wrong_total:99	 wrong be tree ACC: 0.3434343434343434
right_checker:1730	total:1974	checker ACC: 0.8763931393623352	temp:0	temp1:0	wrong_total:99	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1761	total:1987	Code ACC: 0.8862606945143432	wrong_be_tree_count:24	wrong_total:90	 wrong be tree ACC: 0.26666666666666666
right_checker:1767	total:1987	checker ACC: 0.8892802596092224	temp:0	temp1:0	wrong_total:90	


epoch:65,	loss:0.06490480851425673	loss1:73.8514628559351
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:30	wrong_total:82	 wrong be tree ACC: 0.36585365853658536
right_checker:1792	total:1976	checker ACC: 0.906882643699646	temp:0	temp1:0	wrong_total:82	


epoch:47,	loss:0.11752932635135949	loss1:153.7607673406601


epoch:49,	loss:0.13643748499453068	loss1:195.14184445142746


epoch:53,	loss:0.1264160550199449	loss1:140.58648735284805
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:36	wrong_total:98	 wrong be tree ACC: 0.3673469387755102
right_checker:1724	total:1974	checker ACC: 0.8733536601066589	temp:0	temp1:0	wrong_total:98	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1767	total:1987	Code ACC: 0.8892803220936084	wrong_be_tree_count:31	wrong_total:91	 wrong be tree ACC: 0.34065934065934067
right_checker:1746	total:1987	checker ACC: 0.8787115812301636	temp:0	temp1:0	wrong_total:91	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1759	total:1985	Code ACC: 0.8861460957178842	wrong_be_tree_count:34	wrong_total:86	 wrong be tree ACC: 0.3953488372093023
right_checker:1698	total:1985	checker ACC: 0.8554156422615051	temp:0	temp1:0	wrong_total:86	


epoch:66,	loss:0.06802390221491805	loss1:76.24167263507843
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1768	total:1976	Code ACC: 0.8947368421052632	wrong_be_tree_count:29	wrong_total:81	 wrong be tree ACC: 0.35802469135802467
right_checker:1785	total:1976	checker ACC: 0.9033401012420654	temp:0	temp1:0	wrong_total:81	


epoch:48,	loss:0.10634098830632865	loss1:139.98552504181862


epoch:67,	loss:0.06283185645679623	loss1:75.01190911233425


epoch:50,	loss:0.1188109683280345	loss1:146.80311119556427


epoch:54,	loss:0.1132376160894637	loss1:132.25380790233612
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1772	total:1976	Code ACC: 0.8967611336032388	wrong_be_tree_count:32	wrong_total:81	 wrong be tree ACC: 0.3950617283950617
right_checker:1787	total:1976	checker ACC: 0.9043522477149963	temp:0	temp1:0	wrong_total:81	
right_count:347	total:431	 Answer ACC: 0.8051044083526682
right_codes_count:1763	total:1985	Code ACC: 0.8881612090680101	wrong_be_tree_count:32	wrong_total:84	 wrong be tree ACC: 0.38095238095238093
right_checker:1700	total:1985	checker ACC: 0.8564231991767883	temp:0	temp1:0	wrong_total:84	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:37	wrong_total:97	 wrong be tree ACC: 0.38144329896907214
right_checker:1714	total:1974	checker ACC: 0.8682878017425537	temp:0	temp1:0	wrong_total:97	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1751	total:1987	Code ACC: 0.8812279818822345	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
right_checker:1756	total:1987	checker ACC: 0.8837442994117737	temp:0	temp1:0	wrong_total:99	


epoch:68,	loss:0.06269245694784331	loss1:64.61435243487358
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:33	wrong_total:80	 wrong be tree ACC: 0.4125
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:80	
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1788	total:1963	Code ACC: 0.9108507386653082	wrong_be_tree_count:34	wrong_total:78	 wrong be tree ACC: 0.4358974358974359
right_checker:1754	total:1963	checker ACC: 0.8935303688049316	temp:0	temp1:0	wrong_total:78	
                                                                                                                                                                                                                                                      

epoch:71,	loss:0.07303076069729286	loss1:62.760110944509506
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1779	total:1963	Code ACC: 0.9062659195109526	wrong_be_tree_count:37	wrong_total:83	 wrong be tree ACC: 0.4457831325301205
right_checker:1741	total:1963	checker ACC: 0.8869078159332275	temp:0	temp1:0	wrong_total:83	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           

epoch:72,	loss:0.07375901693376363	loss1:72.01467957347631
                                                             right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1786	total:1963	Code ACC: 0.9098318899643403	wrong_be_tree_count:36	wrong_total:85	 wrong be tree ACC: 0.4235294117647059
right_checker:1738	total:1963	checker ACC: 0.8853795528411865	temp:0	temp1:0	wrong_total:85	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       

epoch:73,	loss:0.07156492559442995	loss1:77.13459831476212
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1787	total:1963	Code ACC: 0.9103413143148242	wrong_be_tree_count:29	wrong_total:79	 wrong be tree ACC: 0.3670886075949367
right_checker:1746	total:1963	checker ACC: 0.8894549608230591	temp:0	temp1:0	wrong_total:79	
                                                                                                                                                                                        

epoch:74,	loss:0.06896607241651509	loss1:62.47801521420479
  right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:32	wrong_total:80	 wrong be tree ACC: 0.4
right_checker:1757	total:1963	checker ACC: 0.8950586318969727	temp:0	temp1:0	wrong_total:80	
wrong_total:96	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1760	total:1985	Code ACC: 0.8866498740554156	wrong_be_tree_count:32	wrong_total:88	 wrong be tree ACC: 0.36363636363636365
right_checker:1715	total:1985	checker ACC: 0.8639798760414124	temp:0	temp1:0	wrong_total:88	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1749	total:1987	Code ACC: 0.8802214393558128	wrong_be_tree_count:34	wrong_total:91	 wrong be tree ACC: 0.37362637362637363
right_checker:1771	total:1987	checker ACC: 0.8912933468818665	temp:0	temp1:0	wrong_total:91	
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1766	total:1976	Code ACC: 0.8937246963562753	wrong_be_tree_count:28	wrong_total:78	 wrong be tree ACC: 0.358974358974359
right_checker:1786	total:1976	checker ACC: 0.9038462042808533	temp:0	temp1:0	wrong_total:78	


epoch:54,	loss:0.10943558036160539	loss1:128.88215279579163
                                                                                                                                                                                                                                                                                                  

epoch:52,	loss:0.09289637007168494	loss1:115.80174165964127


epoch:73,	loss:0.05561177752679214	loss1:51.98266902565956


epoch:58,	loss:0.10501568529434735	loss1:126.90672515332699
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:34	wrong_total:78	 wrong be tree ACC: 0.4358974358974359
right_checker:1783	total:1976	checker ACC: 0.9023279547691345	temp:0	temp1:0	wrong_total:78	
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:35	wrong_total:100	 wrong be tree ACC: 0.35
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:100	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1752	total:1987	Code ACC: 0.8817312531454454	wrong_be_tree_count:38	wrong_total:98	 wrong be tree ACC: 0.3877551020408163
right_checker:1743	total:1987	checker ACC: 0.8772017359733582	temp:0	temp1:0	wrong_total:98	
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:37	wrong_total:82	 wrong be tree ACC: 0.45121951219512196
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:82	


epoch:74,	loss:0.0575589555373881	loss1:57.94264915585518


epoch:53,	loss:0.09293599353986792	loss1:94.56678731739521
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1768	total:1976	Code ACC: 0.8947368421052632	wrong_be_tree_count:31	wrong_total:77	 wrong be tree ACC: 0.4025974025974026
right_checker:1781	total:1976	checker ACC: 0.9013158082962036	temp:0	temp1:0	wrong_total:77	


epoch:55,	loss:0.1065095001613372	loss1:150.4025514125824


epoch:59,	loss:0.09868229512358084	loss1:98.78569358587265
right_count:337	total:431	 Answer ACC: 0.7819025522041764
right_codes_count:1754	total:1985	Code ACC: 0.8836272040302267	wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
right_checker:1705	total:1985	checker ACC: 0.8589420914649963	temp:0	temp1:0	wrong_total:94	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:33	wrong_total:92	 wrong be tree ACC: 0.358695652173913
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:92	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1748	total:1987	Code ACC: 0.879718168092602	wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
right_checker:1753	total:1987	checker ACC: 0.8822344541549683	temp:0	temp1:0	wrong_total:98	


epoch:75,	loss:0.05503709862023243	loss1:57.4744368493557
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1764	total:1976	Code ACC: 0.8927125506072875	wrong_be_tree_count:32	wrong_total:81	 wrong be tree ACC: 0.3950617283950617
right_checker:1781	total:1976	checker ACC: 0.9013158082962036	temp:0	temp1:0	wrong_total:81	


epoch:54,	loss:0.09009041657554917	loss1:90.27783554792404
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1786	total:1963	Code ACC: 0.909831889964270096


epoch:56,	loss:0.11382308334577829	loss1:124.5616946220398
right_count:359	total:433	 Answer ACC: 0.8290993071593533
right_codes_count:1771	total:1976	Code ACC: 0.896255060728745	wrong_be_tree_count:31	wrong_total:74	 wrong be tree ACC: 0.4189189189189189
right_checker:1785	total:1976	checker ACC: 0.9033401012420654	temp:0	temp1:0	wrong_total:74	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:30	wrong_total:83	 wrong be tree ACC: 0.3614457831325301
right_checker:1707	total:1985	checker ACC: 0.8599496483802795	temp:0	temp1:0	wrong_total:83	
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1751	total:1987	Code ACC: 0.8812279818822345	wrong_be_tree_count:40	wrong_total:102	 wrong be tree ACC: 0.39215686274509803
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:102	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:31	wrong_total:93	 wrong be tree ACC: 0.3333333333333333
right_checker:1734	total:1974	checker ACC: 0.8784195184707642	temp:0	temp1:0	wrong_total:93	


epoch:77,	loss:0.05322964757215232	loss1:46.47219242155552


epoch:55,	loss:0.0873478309076745	loss1:107.06713676452637
right_count:349	total:433	 Answer ACC: 0.8060046189376443
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:33	wrong_total:84	 wrong be tree ACC: 0.39285714285714285
right_checker:1789	total:1976	checker ACC: 0.9053643941879272	temp:0	temp1:0	wrong_total:84	


epoch:57,	loss:0.11194759968202561	loss1:152.1775273680687


epoch:61,	loss:0.08843558421358466	loss1:93.4094420671463
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:33	wrong_total:82	 wrong be tree ACC: 0.4024390243902439
right_checker:1700	total:1985	checker ACC: 0.8564231991767883	temp:0	temp1:0	wrong_total:82	
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:34	wrong_total:96	 wrong be tree ACC: 0.3541666666666667
right_checker:1737	total:1974	checker ACC: 0.8799392580986023	temp:0	temp1:0	wrong_total:96	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:36	wrong_total:91	 wrong be tree ACC: 0.3956043956043956
right_checker:1765	total:1987	checker ACC: 0.8882737159729004	temp:0	temp1:0	wrong_total:91	


epoch:78,	loss:0.05461251021188218	loss1:57.0583685785532
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:29	wrong_total:77	 wrong be tree ACC: 0.37662337662337664
right_checker:1782	total:1976	checker ACC: 0.9018219113349915	temp:0	temp1:0	wrong_total:77	


epoch:56,	loss:0.08888646401464939	loss1:99.9828731417656
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1754	total:1985	Code ACC: 0.8836272040302267	wrong_be_tree_count:29	wrong_total:86	 wrong be tree ACC: 0.3372093023255814
right_checker:1693	total:1985	checker ACC: 0.8528967499732971	temp:0	temp1:0	wrong_total:86	


epoch:79,	loss:0.0536406074243132	loss1:57.874073158949614


epoch:58,	loss:0.10348574569798075	loss1:132.77803254127502


epoch:62,	loss:0.09428384876810014	loss1:115.65920579433441
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1760	total:1976	Code ACC: 0.8906882591093117	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1786	total:1976	checker ACC: 0.9038462042808533	temp:0	temp1:0	wrong_total:85	


epoch:57,	loss:0.0878563275327906	loss1:93.5761997550726
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:33	wrong_total:94	 wrong be tree ACC: 0.35106382978723405
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:94	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1758	total:1987	Code ACC: 0.8847508807247106	wrong_be_tree_count:43	wrong_total:92	 wrong be tree ACC: 0.4673913043478261
right_checker:1756	total:1987	checker ACC: 0.8837442994117737	temp:0	temp1:0	wrong_total:92	
right_count:347	total:431	 Answer ACC: 0.8051044083526682
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:25	wrong_total:84	 wrong be tree ACC: 0.2976190476190476
right_checker:1723	total:1985	checker ACC: 0.8680101037025452	temp:0	temp1:0	wrong_total:84	


epoch:58,	loss:0.09319808805594221	loss1:108.3815900683403


epoch:80,	loss:0.05440998243284412	loss1:74.74608840048313


epoch:63,	loss:0.08783011873310897	loss1:96.35578742623329


epoch:59,	loss:0.09786726842503413	loss1:128.16060662269592
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:32	wrong_total:78	 wrong be tree ACC: 0.41025641025641024
right_checker:1788	total:1976	checker ACC: 0.9048583507537842	temp:0	temp1:0	wrong_total:78	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1763	total:1985	Code ACC: 0.8881612090680101	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1704	total:1985	checker ACC: 0.8584383130073547	temp:0	temp1:0	wrong_total:83	
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1770	total:1987	Code ACC: 0.8907901358832411	wrong_be_tree_count:36	wrong_total:88	 wrong be tree ACC: 0.4090909090909091
right_checker:1750	total:1987	checker ACC: 0.8807246685028076	temp:0	temp1:0	wrong_total:88	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1735	total:1974	Code ACC: 0.8789260385005065	wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.3333333333333333
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:99	
                                                             

epoch:81,	loss:0.05252168907645682	loss1:68.40356870368123


epoch:59,	loss:0.0916239381331252	loss1:99.921087667346
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1758	total:1976	Code ACC: 0.8896761133603239	wrong_be_tree_count:37	wrong_total:83	 wrong be tree ACC: 0.4457831325301205
right_checker:1782	total:1976	checker ACC: 0.9018219113349915	temp:0	temp1:0	wrong_total:83	


epoch:64,	loss:0.08637720244587399	loss1:79.58988207578659


epoch:60,	loss:0.09663383065708331	loss1:106.96026527881622
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
right_checker:1690	total:1985	checker ACC: 0.8513854146003723	temp:0	temp1:0	wrong_total:86	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.3333333333333333
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:99	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1750	total:1987	Code ACC: 0.8807247106190237	wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
right_checker:1761	total:1987	checker ACC: 0.8862606287002563	temp:0	temp1:0	wrong_total:98	


epoch:82,	loss:0.05262785905506462	loss1:52.01009051501751
right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1765	total:1976	Code ACC: 0.8932186234817814	wrong_be_tree_count:31	wrong_total:79	 wrong be tree ACC: 0.3924050632911392
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:79	


epoch:61,	loss:0.08484750491334125	loss1:110.47773478925228
t_codes_count:1787	total:1963	Code ACC: 0.9103413143148242	wrong_be_tree_count:33	wrong_total:78	 wrong be tree ACC: 0.4230769230769231
right_checker:1750	total:1963	checker ACC: 0.8914926648139954	temp:0	temp1:0	wrong_total:78	


epoch:89,	loss:0.06578662269748747	loss1:63.2776869982481
                                                                                                                           right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:34	wrong_total:78	 wrong be tree ACC: 0.4358974358974359
right_checker:1757	total:1963	checker ACC: 0.8950586318969727	temp:0	temp1:0	wrong_total:78	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      

epoch:90,	loss:0.06577761097651091	loss1:79.05968809127808
                                                                                                                                                                                                                                                                                               right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1790	total:1963	Code ACC: 0.9118695873662761	wrong_be_tree_count:34	wrong_total:77	 wrong be tree ACC: 0.44155844155844154
right_checker:1756	total:1963	checker ACC: 0.8945491909980774	temp:0	temp1:0	wrong_total:77	


epoch:91,	loss:0.06348739016539184	loss1:44.903299778699875
                                                                                                                                                                                                                                                                                                    right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1782	total:1963	Code ACC: 0.9077941925624045	wrong_be_tree_count:29	wrong_total:77	 wrong be tree ACC: 0.37662337662337664
right_checker:1750	total:1963	checker ACC: 0.8914926648139954	temp:0	temp1:0	wrong_total:77	
                                                                                                                                                                                                                                                                                                   

epoch:92,	loss:0.06127063854364678	loss1:51.23029002547264
right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1789	total:1963	Code ACC: 0.9113601630157921	wrong_be_tree_count:34	wrong_total:76	 wrong be tree ACC: 0.4473684210526316
right_checker:1749	total:1963	checker ACC: 0.8909832239151001	temp:0	temp1:0	wrong_total:76	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             

epoch:93,	loss:0.05839695007307455	loss1:39.08588142320514
t_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:28	wrong_total:90	 wrong be tree ACC: 0.3111111111111111
right_checker:1746	total:1974	checker ACC: 0.8844985365867615	temp:0	temp1:0	wrong_total:90	
save best model to ./output/model_save_name_0/best_model
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1753	total:1987	Code ACC: 0.8822345244086562	wrong_be_tree_count:34	wrong_total:93	 wrong be tree ACC: 0.3655913978494624
right_checker:1760	total:1987	checker ACC: 0.8857573866844177	temp:0	temp1:0	wrong_total:93	


epoch:86,	loss:0.053450638719368726	loss1:42.19481364637613
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:39	wrong_total:85	 wrong be tree ACC: 0.4588235294117647
right_checker:1791	total:1976	checker ACC: 0.9063765406608582	temp:0	temp1:0	wrong_total:85	


epoch:62,	loss:0.07576075446559116	loss1:93.42674282193184


epoch:68,	loss:0.07865060813492164	loss1:75.41026899218559
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:32	wrong_total:85	 wrong be tree ACC: 0.3764705882352941
right_checker:1717	total:1985	checker ACC: 0.8649874329566956	temp:0	temp1:0	wrong_total:85	


epoch:87,	loss:0.05055367413297063	loss1:44.68395313620567


epoch:64,	loss:0.08656226175662596	loss1:87.96266549825668
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1761	total:1987	Code ACC: 0.8862606945143432	wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:91	
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1765	total:1976	Code ACC: 0.8932186234817814	wrong_be_tree_count:36	wrong_total:81	 wrong be tree ACC: 0.4444444444444444
right_checker:1784	total:1976	checker ACC: 0.9028340578079224	temp:0	temp1:0	wrong_total:81	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:32	wrong_total:98	 wrong be tree ACC: 0.32653061224489793
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:98	


epoch:63,	loss:0.0707349009171594	loss1:80.82601553201675


epoch:88,	loss:0.048851308471057564	loss1:50.748528242111206


epoch:69,	loss:0.07468604475434404	loss1:59.28908434510231


epoch:65,	loss:0.10357012646272779	loss1:98.7940651923418
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1764	total:1976	Code ACC: 0.8927125506072875	wrong_be_tree_count:32	wrong_total:80	 wrong be tree ACC: 0.4
right_checker:1779	total:1976	checker ACC: 0.9003036618232727	temp:0	temp1:0	wrong_total:80	
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:27	wrong_total:82	 wrong be tree ACC: 0.32926829268292684
right_checker:1731	total:1985	checker ACC: 0.872040331363678	temp:0	temp1:0	wrong_total:82	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1759	total:1987	Code ACC: 0.8852541519879215	wrong_be_tree_count:30	wrong_total:90	 wrong be tree ACC: 0.3333333333333333
right_checker:1753	total:1987	checker ACC: 0.8822344541549683	temp:0	temp1:0	wrong_total:90	
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:32	wrong_total:96	 wrong be tree ACC: 0.3333333333333333
right_checker:1764	total:1974	checker ACC: 0.8936170935630798	temp:0	temp1:0	wrong_total:96	


epoch:64,	loss:0.06963935749081429	loss1:85.61749184131622


epoch:89,	loss:0.04455356998369098	loss1:33.34037408232689


epoch:66,	loss:0.09494635028750054	loss1:103.41165600344539


epoch:70,	loss:0.07868271064944565	loss1:63.26294360309839
right_count:353	total:433	 Answer ACC: 0.815242494226328
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:34	wrong_total:80	 wrong be tree ACC: 0.425
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:80	
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1774	total:1985	Code ACC: 0.8937027707808565	wrong_be_tree_count:26	wrong_total:82	 wrong be tree ACC: 0.3170731707317073
right_checker:1729	total:1985	checker ACC: 0.8710327744483948	temp:0	temp1:0	wrong_total:82	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:30	wrong_total:94	 wrong be tree ACC: 0.3191489361702128
right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:94	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:44	wrong_total:90	 wrong be tree ACC: 0.4888888888888889
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:90	


epoch:90,	loss:0.04707815276560723	loss1:55.17532929033041


epoch:65,	loss:0.06884846927641775	loss1:76.04661700129509
                                                                                                                                                                                                                                       right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1764	total:1976	Code ACC: 0.8927125506072875	wrong_be_tree_count:34	wrong_total:82	 wrong be tree ACC: 0.4146341463414634
right_checker:1780	total:1976	checker ACC: 0.9008097648620605	temp:0	temp1:0	wrong_total:82	


epoch:71,	loss:0.07453650987736182	loss1:78.3530836775899


epoch:67,	loss:0.08971171694429358	loss1:108.0916456580162
right_count:350	total:431	 Answer ACC: 0.8120649651972158
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:26	wrong_total:81	 wrong be tree ACC: 0.32098765432098764
right_checker:1716	total:1985	checker ACC: 0.864483654499054	temp:0	temp1:0	wrong_total:81	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:32	wrong_total:98	 wrong be tree ACC: 0.32653061224489793
right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:98	
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1753	total:1987	Code ACC: 0.8822345244086562	wrong_be_tree_count:39	wrong_total:95	 wrong be tree ACC: 0.4105263157894737
right_checker:1763	total:1987	checker ACC: 0.8872671723365784	temp:0	temp1:0	wrong_total:95	


epoch:91,	loss:0.049915293806407135	loss1:54.84757335484028
right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1769	total:1976	Code ACC: 0.895242914979757	wrong_be_tree_count:34	wrong_total:78	 wrong be tree ACC: 0.4358974358974359
right_checker:1781	total:1976	checker ACC: 0.9013158082962036	temp:0	temp1:0	wrong_total:78	


epoch:92,	loss:0.0472606724488287	loss1:48.437311824411154
                                                                                                                                                                                                                                                                                                    

epoch:66,	loss:0.06693429462757194	loss1:79.44661381840706


epoch:72,	loss:0.07727294406140572	loss1:72.51153999567032


epoch:68,	loss:0.08109295504982583	loss1:79.34619498252869
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1764	total:1976	Code ACC: 0.8927125506072875	wrong_be_tree_count:36	wrong_total:82	 wrong be tree ACC: 0.43902439024390244
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:82	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1763	total:1985	Code ACC: 0.8881612090680101	wrong_be_tree_count:33	wrong_total:87	 wrong be tree ACC: 0.3793103448275862
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:87	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1754	total:1987	Code ACC: 0.8827377956718672	wrong_be_tree_count:38	wrong_total:98	 wrong be tree ACC: 0.3877551020408163
right_checker:1758	total:1987	checker ACC: 0.8847508430480957	temp:0	temp1:0	wrong_total:98	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.4605263157894737
right_checker:1754	total:1963	checker ACC: 0.8935303688049316	temp:0	temp1:0	wrong_total:76	
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     

epoch:103,	loss:0.08453549665864557	loss1:68.09500076621771
                                                                                                                                                                                                                                      right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1787	total:1963	Code ACC: 0.9103413143148242	wrong_be_tree_count:31	wrong_total:76	 wrong be tree ACC: 0.40789473684210525
right_checker:1755	total:1963	checker ACC: 0.8940397500991821	temp:0	temp1:0	wrong_total:76	


epoch:104,	loss:0.06624008767539635	loss1:56.469682686030865
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       right_count:355	total:433	 Answer ACC: 0.8198614318706697
right_codes_count:1788	total:1963	Code ACC: 0.9108507386653082	wrong_be_tree_count:36	wrong_total:78	 wrong be tree ACC: 0.46153846153846156
right_checker:1757	total:1963	checker ACC: 0.8950586318969727	temp:0	temp1:0	wrong_total:78	
                                                                                                                                                                                       

epoch:105,	loss:0.056638685206053196	loss1:46.254648961126804
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      right_count:354	total:433	 Answer ACC: 0.8175519630484989
right_codes_count:1787	total:1963	Code ACC: 0.9103413143148242	wrong_be_tree_count:37	wrong_total:79	 wrong be tree ACC: 0.46835443037974683
right_checker:1759	total:1963	checker ACC: 0.8960774540901184	temp:0	temp1:0	wrong_total:79	
                                                                                                                                                                                                                                                                                  

epoch:106,	loss:0.05975580680751591	loss1:55.39170341193676
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1785	total:1963	Code ACC: 0.9093224656138563	wrong_be_tree_count:31	wrong_total:77	 wrong be tree ACC: 0.4025974025974026
right_checker:1760	total:1963	checker ACC: 0.8965868949890137	temp:0	temp1:0	wrong_total:77	


epoch:107,	loss:0.056537177064456046	loss1:47.43162575364113
right_count:357	total:433	 Answer ACC: 0.8244803695150116
right_codes_count:1788	total:1963	Code ACC: 0.9108507386653082	wrong_be_tree_count:31	wrong_total:76	 wro106235565819861
right_codes_count:1765	total:1976	Code ACC: 0.8932186234817814	wrong_be_tree_count:34	wrong_total:82	 wrong be tree ACC: 0.4146341463414634
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:82	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1757	total:1985	Code ACC: 0.8851385390428211	wrong_be_tree_count:29	wrong_total:86	 wrong be tree ACC: 0.3372093023255814
right_checker:1735	total:1985	checker ACC: 0.8740554451942444	temp:0	temp1:0	wrong_total:86	
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:36	wrong_total:95	 wrong be tree ACC: 0.37894736842105264
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:95	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1755	total:1987	checker ACC: 0.8832409977912903	temp:0	temp1:0	wrong_total:92	


epoch:97,	loss:0.049382498097656935	loss1:43.33392694592476
                                                                                                                                                                                                                                                                                                   

epoch:70,	loss:0.06476763862883672	loss1:61.82091110944748


epoch:72,	loss:0.0806737884413451	loss1:76.62698099762201


epoch:76,	loss:0.0684801311690535	loss1:48.15444815903902
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1767	total:1976	Code ACC: 0.8942307692307693	wrong_be_tree_count:39	wrong_total:82	 wrong be tree ACC: 0.47560975609756095
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:82	
right_count:350	total:431	 Answer ACC: 0.8120649651972158
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:27	wrong_total:81	 wrong be tree ACC: 0.3333333333333333
right_checker:1735	total:1985	checker ACC: 0.8740554451942444	temp:0	temp1:0	wrong_total:81	
right_count:330	total:433	 Answer ACC: 0.7621247113163973
      right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1764	total:1987	checker ACC: 0.8877704739570618	temp:0	temp1:0	wrong_total:92	
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:39	wrong_total:103	 wrong be tree ACC: 0.3786407766990291
right_checker:1743	total:1974	checker ACC: 0.8829787969589233	temp:0	temp1:0	wrong_total:103	


epoch:71,	loss:0.06676740717375651	loss1:78.94814140349627


epoch:98,	loss:0.04556326313468162	loss1:36.621239729225636
                                                                                                                                                                                                                                      right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:37	wrong_total:85	 wrong be tree ACC: 0.43529411764705883
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:85	
right_count:351	total:431	 Answer ACC: 0.814385150812065
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:29	wrong_total:80	 wrong be tree ACC: 0.3625
right_checker:1722	total:1985	checker ACC: 0.8675063252449036	temp:0	temp1:0	wrong_total:80	


epoch:73,	loss:0.09106617473298684	loss1:94.677694439888


epoch:77,	loss:0.06770764061366208	loss1:50.65524165332317
right_count:328	total:433	 Answer ACC: 0.7575057736720554
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:40	wrong_total:105	 wrong be tree ACC: 0.38095238095238093
right_codes_count:1765	total:1987	Code ACC: 0.8882737795671867	wrong_be_tree_count:36	wrong_total:87	 wrong be tree ACC: 0.41379310344827586
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:105	
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:87	


epoch:99,	loss:0.047373297275044024	loss1:37.68031331151724
                                                                                                                                                                                                                                                                                                    

epoch:72,	loss:0.06137642601970583	loss1:65.51437589526176
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1779	total:1976	checker ACC: 0.9003036618232727	temp:0	temp1:0	wrong_total:83	


epoch:74,	loss:0.07838564684789162	loss1:83.28905665874481


epoch:78,	loss:0.06970248822472058	loss1:55.69319427013397
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1759	total:1985	Code ACC: 0.8861460957178842	wrong_be_tree_count:28	wrong_total:83	 wrong be tree ACC: 0.3373493975903614
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:83	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:37	wrong_total:101	 wrong be tree ACC: 0.36633663366336633
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:101	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1762	total:1987	Code ACC: 0.8867639657775541	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:89	


epoch:100,	loss:0.04789021021861117	loss1:40.74178069829941
                                                                                                                                                                                                                                      

epoch:73,	loss:0.061948481597937644	loss1:56.741384737193584
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1769	total:1976	checker ACC: 0.8952429294586182	temp:0	temp1:0	wrong_total:83	


epoch:75,	loss:0.07764971605502069	loss1:86.21026666462421
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:30	wrong_total:82	 wrong be tree ACC: 0.36585365853658536
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:82	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:101	


epoch:101,	loss:0.04664121297537349	loss1:43.32009543478489


epoch:79,	loss:0.06672822697873926	loss1:69.01266795396805


epoch:74,	loss:0.061395820579491556	loss1:66.54714334011078
                                                                                                                                                                                                                                      

epoch:76,	loss:0.07425327779674262	loss1:78.60485637933016
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:38	wrong_total:86	 wrong be tree ACC: 0.4418604651162791
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:86	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1758	total:1987	Code ACC: 0.8847508807247106	wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
right_checker:1755	total:1987	checker ACC: 0.8832409977912903	temp:0	temp1:0	wrong_total:93	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.3333333333333333
right_checker:1758	total:1974	checker ACC: 0.8905775547027588	temp:0	temp1:0	wrong_total:99	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1765	total:1985	Code ACC: 0.889168765743073	wrong_be_tree_count:31	wrong_total:83	 wrong be tree ACC: 0.37349397590361444
right_checker:1726	total:1985	checker ACC: 0.86952143907547	temp:0	temp1:0	wrong_total:83	
                                                                                                                               

epoch:75,	loss:0.06314700975781307	loss1:52.10668383538723
                                                                                                                                                                                                                                      

epoch:102,	loss:0.047480371344136074	loss1:39.35879225283861


epoch:77,	loss:0.06834782897203695	loss1:73.62174378335476


epoch:80,	loss:0.06354337223456241	loss1:60.166150599718094
right_count:349	total:433	 Answer ACC: 0.8060046189376443
right_codes_count:1760	total:1976	Code ACC: 0.8906882591093117	wrong_be_tree_count:36	wrong_total:84	 wrong be tree ACC: 0.42857142857142855
right_checker:1777	total:1976	checker ACC: 0.8992915153503418	temp:0	temp1:0	wrong_total:84	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:29	wrong_total:83	 wrong be tree ACC: 0.3493975903614458
right_checker:1712	total:1985	checker ACC: 0.8624685406684875	temp:0	temp1:0	wrong_total:83	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:38	wrong_total:101	 wrong be tree ACC: 0.37623762376237624
right_checker:1745	total:1974	checker ACC: 0.8839919567108154	temp:0	temp1:0	wrong_total:101	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:36	wrong_total:92	 wrong be tree ACC: 0.391304347826087
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	


epoch:76,	loss:0.06325447869312484	loss1:57.7437304854393
                                                                                                                                                                                                                                                                                                       

epoch:78,	loss:0.07015541010332527	loss1:73.38528425991535


epoch:103,	loss:0.05863076724926941	loss1:32.67205120623112


epoch:81,	loss:0.05738194947480224	loss1:41.95656834542751
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:32	wrong_total:86	 wrong be tree ACC: 0.37209302325581395
right_checker:1694	total:1985	checker ACC: 0.8534005284309387	temp:0	temp1:0	wrong_total:86	
right_count:349	total:433	 Answer ACC: 0.8060046189376443
right_codes_count:1759	total:1976	Code ACC: 0.8901821862348178	wrong_be_tree_count:35	wrong_total:84	 wrong be tree ACC: 0.4166666666666667
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:84	
                                                               right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:41	wrong_total:102	 wrong be tree ACC: 0.4019607843137255
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:102	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:34	wrong_total:89	 wrong be tree ACC: 0.38202247191011235
right_checker:1756	total:1987	checker ACC: 0.8837442994117737	temp:0	temp1:0	wrong_total:89	


epoch:77,	loss:0.05855853838693292	loss1:60.71606990695


epoch:104,	loss:0.05315697321202606	loss1:41.24414134025574


epoch:79,	loss:0.07337737425405066	loss1:77.02236950397491
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1757	total:1976	Code ACC: 0.8891700404858299	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1772	total:1976	checker ACC: 0.8967611789703369	temp:0	temp1:0	wrong_total:83	


epoch:82,	loss:0.0730093625606969	loss1:55.89948383718729
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:35	wrong_total:85	 wrong be tree ACC: 0.4117647058823529
right_checker:1706	total:1985	checker ACC: 0.8594458699226379	temp:0	temp1:0	wrong_total:85	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:32	wrong_total:99	 wrong be tree ACC: 0.32323232323232326
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:99	
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1756	total:1987	Code ACC: 0.8837443381982889	wrong_be_tree_count:35	wrong_total:87	 wrong be tree ACC: 0.40229885057471265
right_checker:1771	total:1987	checker ACC: 0.8912933468818665	temp:0	temp1:0	wrong_total:87	


epoch:105,	loss:0.04312982225019368	loss1:45.966154515743256


epoch:78,	loss:0.05604891195616801	loss1:57.76087957620621
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:26	wrong_total:81	 wrong be tree ACC: 0.32098765432098764
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:81	


epoch:80,	loss:0.06904611695790663	loss1:56.811523109674454


epoch:83,	loss:0.13512525282567367	loss1:74.99161584675312
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:36	wrong_total:86	 wrong be tree ACC: 0.4186046511627907
right_checker:1723	total:1985	checker ACC: 0.8680101037025452	temp:0	temp1:0	wrong_total:86	


epoch:106,	loss:0.04248509086937702	loss1:28.307313822209835
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:31	wrong_total:99	 wrong be tree ACC: 0.31313131313131315
right_checker:1755	total:1974	checker ACC: 0.8890578150749207	temp:0	temp1:0	wrong_total:99	
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:34	wrong_total:85	 wrong be tree ACC: 0.4
right_checker:1753	total:1987	checker ACC: 0.8822344541549683	temp:0	temp1:0	wrong_total:85	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1759	total:1976	Code ACC: 0.8901821862348178	wrong_be_tree_count:32	wrong_total:82	 wrong be tree ACC: 0.3902439024390244
right_checker:1772	total:1976	checker ACC: 0.8967611789703369	temp:0	temp1:0	wrong_total:82	


epoch:79,	loss:0.060407695826143026	loss1:53.68907217681408
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1758	total:1985	Code ACC: 0.8856423173803526	wrong_be_tree_count:30	wrong_total:87	 wrong be tree ACC: 0.3448275862068966
right_checker:1712	total:1985	checker ACC: 0.8624685406684875	temp:0	temp1:0	wrong_total:87	


epoch:107,	loss:0.046964421489974484	loss1:34.836920619010925


epoch:81,	loss:0.06821754010434233	loss1:74.04852497577667


epoch:84,	loss:0.0816652705816523	loss1:72.44465585052967
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1759	total:1976	Code ACC: 0.8901821862348178	wrong_be_tree_count:32	wrong_total:82	 wrong be tree ACC: 0.3902439024390244
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:82	


epoch:80,	loss:0.06538229808211327	loss1:67.46434503793716
                                                                                                                                                                                                                         right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:96	
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:85	


epoch:108,	loss:0.04574682987367851	loss1:41.80036146938801
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1754	total:1985	Code ACC: 0.8836272040302267	wrong_be_tree_count:33	wrong_total:88	 wrong be tree ACC: 0.375
right_checker:1712	total:1985	checker ACC: 0.8624685406684875	temp:0	temp1:0	wrong_total:88	
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1772	total:1976	checker ACC: 0.8967611789703369	temp:0	temp1:0	wrong_total:83	


epoch:82,	loss:0.10915511124767363	loss1:73.15779227018356


epoch:85,	loss:0.06984115453087725	loss1:52.30271327495575
                                                                                                                                                                                                                          

epoch:81,	loss:0.05852247081929818	loss1:78.52347287535667


epoch:109,	loss:0.04449447938532103	loss1:39.812262535095215
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:32	wrong_total:100	 wrong be tree ACC: 0.32
right_checker:1744	total:1974	checker ACC: 0.8834853768348694	temp:0	temp1:0	wrong_total:100	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1760	total:1987	Code ACC: 0.8857574232511324	wrong_be_tree_count:31	wrong_total:82	 wrong be tree ACC: 0.3780487804878049
right_checker:1757	total:1987	checker ACC: 0.8842475414276123	temp:0	temp1:0	wrong_total:82	
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1760	total:1976	Code ACC: 0.8906882591093117	wrong_be_tree_count:36	wrong_total:86	 wrong be tree ACC: 0.4186046511627907
right_checker:1770	total:1976	checker ACC: 0.895749032497406	temp:0	temp1:0	wrong_total:86	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:37	wrong_total:85	 wrong be tree ACC: 0.43529411764705883
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:85	


epoch:110,	loss:0.0446639699221123	loss1:36.667886056005955


epoch:82,	loss:0.05523697231546976	loss1:49.52859582006931


epoch:83,	loss:0.16673707915470004	loss1:79.93785747513175


epoch:86,	loss:0.061735275676255696	loss1:55.94453276693821
 right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:32	wrong_total:83	 wrong be tree ACC: 0.3855421686746988
right_checker:1770	total:1976	checker ACC: 0.895749032497406	temp:0	temp1:0	wrong_total:83	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1761	total:1985	Code ACC: 0.8871536523929471	wrong_be_tree_count:32	wrong_total:85	 wrong be tree ACC: 0.3764705882352941
right_checker:1718	total:1985	checker ACC: 0.8654912114143372	temp:0	temp1:0	wrong_total:85	
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:36	wrong_total:102	 wrong be tree ACC: 0.35294117647058826
right_checker:1742	total:1974	checker ACC: 0.8824721574783325	temp:0	temp1:0	wrong_total:102	
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1759	total:1987	Code ACC: 0.8852541519879215	wrong_be_tree_count:32	wrong_total:87	 wrong be tree ACC: 0.367816091954023
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:87	


epoch:111,	loss:0.04243696643970907	loss1:37.738271936774254
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1764	total:1976	Code ACC: 0.8927125506072875	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1769	total:1976	checker ACC: 0.8952429294586182	temp:0	temp1:0	wrong_total:83	


epoch:83,	loss:0.0502163448400097	loss1:57.380325362086296


epoch:84,	loss:0.08266252222983894	loss1:96.68875326961279


epoch:87,	loss:0.05719666549703106	loss1:51.36005436256528


epoch:112,	loss:0.07094848662381992	loss1:41.11145660281181
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1759	total:1985	Code ACC: 0.8861460957178842	wrong_be_tree_count:28	wrong_total:86	 wrong be tree ACC: 0.32558139534883723
right_checker:1723	total:1985	checker ACC: 0.8680101037025452	temp:0	temp1:0	wrong_total:86	
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:34	wrong_total:88	 wrong be tree ACC: 0.38636363636363635
right_checker:1753	total:1987	checker ACC: 0.8822344541549683	temp:0	temp1:0	wrong_total:88	
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
right_checker:1735	total:1974	checker ACC: 0.8789260983467102	temp:0	temp1:0	wrong_total:102	
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:36	wrong_total:86	 wrong be tree ACC: 0.4186046511627907
right_checker:1774	total:1976	checker ACC: 0.8977733254432678	temp:0	temp1:0	wrong_total:86	


epoch:84,	loss:0.055952142720343545	loss1:60.55376440286636


epoch:113,	loss:0.04528500440210337	loss1:45.744631469249725


epoch:85,	loss:0.07684201974188909	loss1:71.47299844771624
                                                                                                                                                                                                                                                                                                                                                                                                                                          

epoch:88,	loss:0.0614073830365669	loss1:67.1948107406497
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1758	total:1976	Code ACC: 0.8896761133603239	wrong_be_tree_count:35	wrong_total:86	 wrong be tree ACC: 0.4069767441860465
right_checker:1777	total:1976	checker ACC: 0.8992915153503418	temp:0	temp1:0	wrong_total:86	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1761	total:1985	Code ACC: 0.8871536523929471	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1712	total:1985	checker ACC: 0.8624685406684875	temp:0	temp1:0	wrong_total:85	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:34	wrong_total:99	 wrong be tree ACC: 0.3434343434343434
right_checker:1747	total:1974	checker ACC: 0.8850051164627075	temp:0	temp1:0	wrong_total:99	
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1760	total:1987	Code ACC: 0.8857574232511324	wrong_be_tree_count:37	wrong_total:88	 wrong be tree ACC: 0.42045454545454547
right_checker:1758	total:1987	checker ACC: 0.8847508430480957	temp:0	temp1:0	wrong_total:88	


epoch:114,	loss:0.04270764253396919	loss1:39.62059827148914


epoch:85,	loss:0.05320690455118893	loss1:53.72392970696092
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1760	total:1976	Code ACC: 0.8906882591093117	wrong_be_tree_count:35	wrong_total:86	 wrong be tree ACC: 0.4069767441860465
right_checker:1777	total:1976	checker ACC: 0.8992915153503418	temp:0	temp1:0	wrong_total:86	


epoch:86,	loss:0.07113472234323126	loss1:61.16246658563614


epoch:89,	loss:0.06530851882416755	loss1:62.792740769684315


epoch:115,	loss:0.043056501333921915	loss1:32.26903785765171
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1759	total:1985	Code ACC: 0.8861460957178842	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1711	total:1985	checker ACC: 0.861964762210846	temp:0	temp1:0	wrong_total:85	
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.3333333333333333
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:99	
right_count:349	total:433	 Answer ACC: 0.8060046189376443
right_codes_count:1755	total:1987	Code ACC: 0.883241066935078	wrong_be_tree_count:31	wrong_total:84	 wrong be tree ACC: 0.36904761904761907
right_checker:1761	total:1987	checker ACC: 0.8862606287002563	temp:0	temp1:0	wrong_total:84	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:32	wrong_total:82	 wrong be tree ACC: 0.3902439024390244
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:82	


epoch:86,	loss:0.05469116097083315	loss1:52.07352802157402
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1761	total:1985	Code ACC: 0.8871536523929471	wrong_be_tree_count:27	wrong_total:85	 wrong be tree ACC: 0.3176470588235294
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:85	


epoch:116,	loss:0.04172229498362867	loss1:41.23480336368084


epoch:87,	loss:0.0655166219221428	loss1:86.04475644230843


epoch:90,	loss:0.06203591539087938	loss1:57.1254321038723
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:32	wrong_total:82	 wrong be tree ACC: 0.3902439024390244
right_checker:1778	total:1976	checker ACC: 0.8997976183891296	temp:0	temp1:0	wrong_total:82	


epoch:87,	loss:0.04859489949012641	loss1:34.96975613385439
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:37	wrong_total:100	 wrong be tree ACC: 0.37
right_checker:1737	total:1974	checker ACC: 0.8799392580986023	temp:0	temp1:0	wrong_total:100	
right_count:347	total:433	 Answer ACC: 0.8013856812933026
right_codes_count:1757	total:1987	Code ACC: 0.8842476094614997	wrong_be_tree_count:34	wrong_total:86	 wrong be tree ACC: 0.3953488372093023
right_checker:1759	total:1987	checker ACC: 0.8852540850639343	temp:0	temp1:0	wrong_total:86	


epoch:117,	loss:0.04542021037195809	loss1:37.35007495060563
right_count:352	total:433	 Answer ACC: 0.812933025404157
right_codes_count:1763	total:1976	Code ACC: 0.8922064777327935	wrong_be_tree_count:32	wrong_total:81	 wrong be tree ACC: 0.3950617283950617
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:81	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1715	total:1985	checker ACC: 0.8639798760414124	temp:0	temp1:0	wrong_total:85	


epoch:91,	loss:0.061060475738486275	loss1:57.71467273682356


epoch:88,	loss:0.0698497203302395	loss1:65.62787276506424


epoch:118,	loss:0.04334326077514561	loss1:46.325769022107124


epoch:88,	loss:0.05217489771894179	loss1:54.22225911915302
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:32	wrong_total:98	 wrong be tree ACC: 0.32653061224489793
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:98	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:91	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:34	wrong_total:82	 wrong be tree ACC: 0.4146341463414634
right_checker:1775	total:1976	checker ACC: 0.8982793688774109	temp:0	temp1:0	wrong_total:82	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1761	total:1985	Code ACC: 0.8871536523929471	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1715	total:1985	checker ACC: 0.8639798760414124	temp:0	temp1:0	wrong_total:85	


epoch:89,	loss:0.06762376986443996	loss1:64.25179440900683


epoch:92,	loss:0.05992014490766451	loss1:39.46204458922148


epoch:119,	loss:0.041788621801970294	loss1:53.16393895447254


epoch:89,	loss:0.05050924787065014	loss1:43.52473342418671
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:28	wrong_total:97	 wrong be tree ACC: 0.28865979381443296
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:97	
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:33	wrong_total:82	 wrong be tree ACC: 0.4024390243902439
right_checker:1775	total:1976	checker ACC: 0.8982793688774109	temp:0	temp1:0	wrong_total:82	
right_count:349	total:433	 Answer ACC: 0.8060046189376443
right_codes_count:1760	total:1987	Code ACC: 0.8857574232511324	wrong_be_tree_count:30	wrong_total:84	 wrong be tree ACC: 0.35714285714285715
right_checker:1760	total:1987	checker ACC: 0.8857573866844177	temp:0	temp1:0	wrong_total:84	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1713	total:1985	checker ACC: 0.8629723191261292	temp:0	temp1:0	wrong_total:85	


epoch:90,	loss:0.06532975305890432	loss1:67.6983959376812


epoch:120,	loss:0.058094380918191746	loss1:37.74013686180115


epoch:93,	loss:0.061646602291148156	loss1:39.382078520953655


epoch:90,	loss:0.047530132807878545	loss1:52.387804556638
right_count:351	total:433	 Answer ACC: 0.8106235565819861
right_codes_count:1762	total:1976	Code ACC: 0.8917004048582996	wrong_be_tree_count:33	wrong_total:82	 wrong be tree ACC: 0.4024390243902439
right_checker:1775	total:1976	checker ACC: 0.8982793688774109	temp:0	temp1:0	wrong_total:82	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:29	wrong_total:97	 wrong be tree ACC: 0.29896907216494845
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:97	
right_count:348	total:433	 Answer ACC: 0.8036951501154734
right_codes_count:1755	total:1987	Code ACC: 0.883241066935078	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1763	total:1987	checker ACC: 0.8872671723365784	temp:0	temp1:0	wrong_total:85	
right_count:347	total:431	 Answer ACC: 0.8051044083526682
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:31	wrong_total:84	 wrong be tree ACC: 0.36904761904761907
right_checker:1724	total:1985	checker ACC: 0.8685138821601868	temp:0	temp1:0	wrong_total:84	


epoch:121,	loss:0.04265616985867382	loss1:43.085940569639206


epoch:91,	loss:0.06164398510372848	loss1:46.7471264898777


epoch:91,	loss:0.04922531083866488	loss1:60.60222950577736
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:94,	loss:0.05600459472134389	loss1:45.354801811277866
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:28	wrong_total:97	 wrong be tree ACC: 0.28865979381443296
right_checker:1744	total:1974	checker ACC: 0.8834853768348694	temp:0	temp1:0	wrong_total:97	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1762	total:1987	Code ACC: 0.8867639657775541	wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
right_checker:1757	total:1987	checker ACC: 0.8842475414276123	temp:0	temp1:0	wrong_total:91	


epoch:122,	loss:0.04254092397059139	loss1:35.346307039260864
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1765	total:1985	Code ACC: 0.889168765743073	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1718	total:1985	checker ACC: 0.8654912114143372	temp:0	temp1:0	wrong_total:85	
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:92,	loss:0.05534716451074928	loss1:54.239047802984715


epoch:123,	loss:0.040544931194745004	loss1:35.30261404812336


epoch:95,	loss:0.05280873872106895	loss1:43.195289358496666


epoch:92,	loss:0.06525184505153447	loss1:67.51734346151352
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1762	total:1985	Code ACC: 0.8876574307304785	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:85	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1761	total:1987	Code ACC: 0.8862606945143432	wrong_be_tree_count:35	wrong_total:90	 wrong be tree ACC: 0.3888888888888889
right_checker:1755	total:1987	checker ACC: 0.8832409977912903	temp:0	temp1:0	wrong_total:90	
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:34	wrong_total:101	 wrong be tree ACC: 0.33663366336633666
right_checker:1743	total:1974	checker ACC: 0.8829787969589233	temp:0	temp1:0	wrong_total:101	


epoch:124,	loss:0.038088416680693626	loss1:33.334418177604675
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:93,	loss:0.06052969570737332	loss1:51.05317598953843


epoch:93,	loss:0.07069713738746941	loss1:56.47326731681824


epoch:96,	loss:0.05402443476123153	loss1:50.88486332446337


epoch:125,	loss:0.043446129005133116	loss1:42.11370088905096
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1757	total:1985	Code ACC: 0.8851385390428211	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
right_checker:1716	total:1985	checker ACC: 0.864483654499054	temp:0	temp1:0	wrong_total:86	
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:36	wrong_total:100	 wrong be tree ACC: 0.36
right_checker:1753	total:1974	checker ACC: 0.8880445957183838	temp:0	temp1:0	wrong_total:100	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:89	
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:94,	loss:0.078463581885444	loss1:44.48123915493488
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
right_checker:1713	total:1985	checker ACC: 0.8629723191261292	temp:0	temp1:0	wrong_total:85	


epoch:94,	loss:0.06482705057624116	loss1:60.263221859931946


epoch:126,	loss:0.051418577204458416	loss1:33.459195498377085


epoch:97,	loss:0.05500395892886445	loss1:40.404437117278576
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:95,	loss:0.054013018889236264	loss1:61.0673086643219
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1750	total:1974	Code ACC: 0.8865248226950354	wrong_be_tree_count:27	wrong_total:95	 wrong be tree ACC: 0.28421052631578947
right_checker:1745	total:1974	checker ACC: 0.8839919567108154	temp:0	temp1:0	wrong_total:95	
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:38	wrong_total:88	 wrong be tree ACC: 0.4318181818181818
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:88	
right_count:351	total:431	 Answer ACC: 0.814385150812065
right_codes_count:1771	total:1985	Code ACC: 0.892191435768262	wrong_be_tree_count:33	wrong_total:80	 wrong be tree ACC: 0.4125
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:80	


epoch:127,	loss:0.04151503745379159	loss1:38.660712376236916


epoch:96,	loss:0.07283750473288819	loss1:57.021340265870094
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:33	wrong_total:83	 wrong be tree ACC: 0.39759036144578314
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:95,	loss:0.062117095236317255	loss1:64.7874653339386


epoch:98,	loss:0.05411714344518259	loss1:40.81981633603573


epoch:128,	loss:0.04104762885981472	loss1:29.04347361624241
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:29	wrong_total:96	 wrong be tree ACC: 0.3020833333333333
right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:96	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1765	total:1985	Code ACC: 0.889168765743073	wrong_be_tree_count:31	wrong_total:83	 wrong be tree ACC: 0.37349397590361444
right_checker:1723	total:1985	checker ACC: 0.8680101037025452	temp:0	temp1:0	wrong_total:83	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1762	total:1987	Code ACC: 0.8867639657775541	wrong_be_tree_count:40	wrong_total:93	 wrong be tree ACC: 0.43010752688172044
right_checker:1760	total:1987	checker ACC: 0.8857573866844177	temp:0	temp1:0	wrong_total:93	
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	


epoch:96,	loss:0.06110369873204036	loss1:62.43773344904184


epoch:97,	loss:0.05685007415013388	loss1:57.55152436345816


epoch:129,	loss:0.045401498096907744	loss1:46.55351768434048


epoch:99,	loss:0.052101373206824064	loss1:37.04763271659613
right_count:350	total:433	 Answer ACC: 0.8083140877598153
right_codes_count:1761	total:1976	Code ACC: 0.8911943319838057	wrong_be_tree_count:34	wrong_total:83	 wrong be tree ACC: 0.40963855421686746
right_checker:1776	total:1976	checker ACC: 0.8987854719161987	temp:0	temp1:0	wrong_total:83	
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:27	wrong_total:95	 wrong be tree ACC: 0.28421052631578947
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:95	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:35	wrong_total:87	 wrong be tree ACC: 0.40229885057471265
right_checker:1735	total:1985	checker ACC: 0.8740554451942444	temp:0	temp1:0	wrong_total:87	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1767	total:1987	Code ACC: 0.8892803220936084	wrong_be_tree_count:35	wrong_total:90	 wrong be tree ACC: 0.3888888888888889
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:90	



final_test


epoch:98,	loss:0.0495997343750787	loss1:50.35692211985588


epoch:97,	loss:0.06115174959995784	loss1:57.16838262975216


epoch:100,	loss:0.05584299337351695	loss1:42.965212896466255
right_count:367	total:433	 Answer ACC: 0.8475750577367206
right_codes_count:1789	total:1976	Code ACC: 0.9053643724696356	wrong_be_tree_count:24	wrong_total:66	 wrong be tree ACC: 0.36363636363636365
right_checker:1699	total:1976	checker ACC: 0.8598178625106812	temp:0	temp1:0	wrong_total:66	
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
final_test
Answer acc:0.8475750577367206


right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1758	total:1985	Code ACC: 0.8856423173803526	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
right_checker:1728	total:1985	checker ACC: 0.8705289959907532	temp:0	temp1:0	wrong_total:86	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:29	wrong_total:94	 wrong be tree ACC: 0.30851063829787234
right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:94	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
right_checker:1752	total:1987	checker ACC: 0.8817312121391296	temp:0	temp1:0	wrong_total:89	


epoch:99,	loss:0.047817246813792735	loss1:62.32210087776184


epoch:98,	loss:0.06273859462089604	loss1:70.93238616734743


epoch:101,	loss:0.056837989162886515	loss1:48.71091568470001
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1761	total:1985	Code ACC: 0.8871536523929471	wrong_be_tree_count:33	wrong_total:88	 wrong be tree ACC: 0.375
right_checker:1722	total:1985	checker ACC: 0.8675063252449036	temp:0	temp1:0	wrong_total:88	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1769	total:1987	Code ACC: 0.8902868646200301	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:90	
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:31	wrong_total:100	 wrong be tree ACC: 0.31
right_checker:1754	total:1974	checker ACC: 0.8885512351989746	temp:0	temp1:0	wrong_total:100	


epoch:100,	loss:0.04712589372138609	loss1:40.422940369695425


epoch:102,	loss:0.05682886065915227	loss1:47.63023307919502


epoch:99,	loss:0.0594045727775665	loss1:63.0156706571579
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1763	total:1985	Code ACC: 0.8881612090680101	wrong_be_tree_count:34	wrong_total:88	 wrong be tree ACC: 0.38636363636363635
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:88	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1769	total:1987	Code ACC: 0.8902868646200301	wrong_be_tree_count:40	wrong_total:90	 wrong be tree ACC: 0.4444444444444444
right_checker:1751	total:1987	checker ACC: 0.8812279105186462	temp:0	temp1:0	wrong_total:90	
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:31	wrong_total:95	 wrong be tree ACC: 0.3263157894736842
right_checker:1759	total:1974	checker ACC: 0.8910841345787048	temp:0	temp1:0	wrong_total:95	


epoch:101,	loss:0.04656952442746842	loss1:49.90384678542614
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:35	wrong_total:87	 wrong be tree ACC: 0.40229885057471265
right_checker:1729	total:1985	checker ACC: 0.8710327744483948	temp:0	temp1:0	wrong_total:87	


epoch:103,	loss:0.08456279657548293	loss1:38.88582019507885


epoch:100,	loss:0.06647494714707136	loss1:54.384863913059235
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1768	total:1987	Code ACC: 0.8897835933568193	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
right_checker:1753	total:1987	checker ACC: 0.8822344541549683	temp:0	temp1:0	wrong_total:89	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:32	wrong_total:97	 wrong be tree ACC: 0.32989690721649484
right_checker:1763	total:1974	checker ACC: 0.893110454082489	temp:0	temp1:0	wrong_total:97	


epoch:102,	loss:0.044536967885505874	loss1:46.5228059142828
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1760	total:1985	Code ACC: 0.8866498740554156	wrong_be_tree_count:35	wrong_total:88	 wrong be tree ACC: 0.3977272727272727
right_checker:1725	total:1985	checker ACC: 0.8690176606178284	temp:0	temp1:0	wrong_total:88	


epoch:104,	loss:0.05505907954648137	loss1:56.555532705038786


epoch:101,	loss:0.06226475554285571	loss1:44.60770873725414


epoch:103,	loss:0.04455500679614488	loss1:40.135062739253044
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1765	total:1987	Code ACC: 0.8882737795671867	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:90	
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:32	wrong_total:98	 wrong be tree ACC: 0.32653061224489793
right_checker:1753	total:1974	checker ACC: 0.8880445957183838	temp:0	temp1:0	wrong_total:98	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1769	total:1985	Code ACC: 0.891183879093199	wrong_be_tree_count:33	wrong_total:86	 wrong be tree ACC: 0.38372093023255816
right_checker:1717	total:1985	checker ACC: 0.8649874329566956	temp:0	temp1:0	wrong_total:86	


epoch:105,	loss:0.053310248633351875	loss1:59.87402058392763


epoch:104,	loss:0.04392366859246977	loss1:41.62959394603968


epoch:102,	loss:0.0628485440311124	loss1:50.40773342177272
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1771	total:1987	Code ACC: 0.8912934071464519	wrong_be_tree_count:36	wrong_total:92	 wrong be tree ACC: 0.391304347826087
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:92	
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:29	wrong_total:96	 wrong be tree ACC: 0.3020833333333333
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:96	
right_count:342	total:431	 Answer ACC: 0.7935034802784223
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1725	total:1985	checker ACC: 0.8690176606178284	temp:0	temp1:0	wrong_total:89	


epoch:105,	loss:0.044954410070204176	loss1:38.985985308885574


epoch:103,	loss:0.0599541146248157	loss1:58.32959379628301


epoch:106,	loss:0.052903155628882814	loss1:50.38853681832552
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:32	wrong_total:86	 wrong be tree ACC: 0.37209302325581395
right_checker:1724	total:1985	checker ACC: 0.8685138821601868	temp:0	temp1:0	wrong_total:86	
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:32	wrong_total:97	 wrong be tree ACC: 0.32989690721649484
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:97	
right_count:345	total:433	 Answer ACC: 0.7967667436489607
right_codes_count:1771	total:1987	Code ACC: 0.8912934071464519	wrong_be_tree_count:35	wrong_total:88	 wrong be tree ACC: 0.3977272727272727
right_checker:1750	total:1987	checker ACC: 0.8807246685028076	temp:0	temp1:0	wrong_total:88	


epoch:106,	loss:0.0435683974683343	loss1:39.99213773012161


epoch:104,	loss:0.06222921883454546	loss1:49.500740215182304


epoch:107,	loss:0.05241151776863262	loss1:45.628141328692436
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:87	 wrong be tree ACC: 0.3563218390804598
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:87	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1769	total:1987	Code ACC: 0.8902868646200301	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:89	
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:96	


epoch:107,	loss:0.04537432448705658	loss1:36.083838894963264
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:88	


epoch:105,	loss:0.05884827312820562	loss1:44.22757063806057


epoch:108,	loss:0.051418468181509525	loss1:48.2070131264627
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:31	wrong_total:97	 wrong be tree ACC: 0.31958762886597936
right_checker:1757	total:1974	checker ACC: 0.8900709748268127	temp:0	temp1:0	wrong_total:97	
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1770	total:1987	Code ACC: 0.8907901358832411	wrong_be_tree_count:36	wrong_total:87	 wrong be tree ACC: 0.41379310344827586
right_checker:1754	total:1987	checker ACC: 0.8827377557754517	temp:0	temp1:0	wrong_total:87	


epoch:108,	loss:0.04602804587921128	loss1:28.546369276940823
right_count:350	total:431	 Answer ACC: 0.8120649651972158
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:30	wrong_total:81	 wrong be tree ACC: 0.37037037037037035
right_checker:1726	total:1985	checker ACC: 0.86952143907547	temp:0	temp1:0	wrong_total:81	


epoch:106,	loss:0.05837930391498958	loss1:61.024394027888775


epoch:109,	loss:0.049394181463867426	loss1:43.58873124420643


epoch:109,	loss:0.04270301373617258	loss1:38.413083374500275
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:30	wrong_total:94	 wrong be tree ACC: 0.3191489361702128
right_checker:1759	total:1974	checker ACC: 0.8910841345787048	temp:0	temp1:0	wrong_total:94	
right_count:346	total:433	 Answer ACC: 0.7990762124711316
right_codes_count:1770	total:1987	Code ACC: 0.8907901358832411	wrong_be_tree_count:34	wrong_total:87	 wrong be tree ACC: 0.39080459770114945
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:87	
right_count:347	total:431	 Answer ACC: 0.8051044083526682
right_codes_count:1769	total:1985	Code ACC: 0.891183879093199	wrong_be_tree_count:32	wrong_total:84	 wrong be tree ACC: 0.38095238095238093
right_checker:1722	total:1985	checker ACC: 0.8675063252449036	temp:0	temp1:0	wrong_total:84	


epoch:107,	loss:0.05651064467838296	loss1:44.97305738925934


epoch:110,	loss:0.05785855386056937	loss1:45.5850456468761


epoch:110,	loss:0.044610571494558826	loss1:37.02657359838486
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:96	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1770	total:1987	Code ACC: 0.8907901358832411	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
right_checker:1747	total:1987	checker ACC: 0.8792148232460022	temp:0	temp1:0	wrong_total:90	
right_count:349	total:431	 Answer ACC: 0.8097447795823666
right_codes_count:1770	total:1985	Code ACC: 0.8916876574307305	wrong_be_tree_count:32	wrong_total:82	 wrong be tree ACC: 0.3902439024390244
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:82	


epoch:111,	loss:0.05817841619136743	loss1:41.60775749385357


epoch:108,	loss:0.059157279323699186	loss1:55.42464900389314


epoch:111,	loss:0.049815254478744464	loss1:37.90459166094661
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:31	wrong_total:95	 wrong be tree ACC: 0.3263157894736842
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:95	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1764	total:1987	Code ACC: 0.8877705083039759	wrong_be_tree_count:42	wrong_total:94	 wrong be tree ACC: 0.44680851063829785
right_checker:1746	total:1987	checker ACC: 0.8787115812301636	temp:0	temp1:0	wrong_total:94	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:33	wrong_total:86	 wrong be tree ACC: 0.38372093023255816
right_checker:1714	total:1985	checker ACC: 0.8634760975837708	temp:0	temp1:0	wrong_total:86	


epoch:112,	loss:0.04617136403976474	loss1:38.18468828126788


epoch:109,	loss:0.058256164367776364	loss1:54.23723889887333


epoch:112,	loss:0.07006154337432235	loss1:37.54420195519924
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:30	wrong_total:97	 wrong be tree ACC: 0.30927835051546393
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:97	
right_count:348	total:431	 Answer ACC: 0.8074245939675174
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:83	 wrong be tree ACC: 0.37349397590361444
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:83	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1770	total:1987	Code ACC: 0.8907901358832411	wrong_be_tree_count:36	wrong_total:90	 wrong be tree ACC: 0.4
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:90	


epoch:110,	loss:0.06415389411267824	loss1:58.44574995338917


epoch:113,	loss:0.044476208080595825	loss1:42.89788329601288


epoch:113,	loss:0.05150115204742178	loss1:49.64174810051918
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:30	wrong_total:94	 wrong be tree ACC: 0.3191489361702128
right_checker:1754	total:1974	checker ACC: 0.8885512351989746	temp:0	temp1:0	wrong_total:94	
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:36	wrong_total:90	 wrong be tree ACC: 0.4
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:90	
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1723	total:1985	checker ACC: 0.8680101037025452	temp:0	temp1:0	wrong_total:85	


epoch:114,	loss:0.04370264380122535	loss1:30.322853460907936


epoch:111,	loss:0.056228811667097034	loss1:51.86224032193422


epoch:114,	loss:0.0521274546154018	loss1:43.14566797018051
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:29	wrong_total:94	 wrong be tree ACC: 0.30851063829787234
right_checker:1755	total:1974	checker ACC: 0.8890578150749207	temp:0	temp1:0	wrong_total:94	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:29	wrong_total:86	 wrong be tree ACC: 0.3372093023255814
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:86	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:89	


epoch:115,	loss:0.04337711468542693	loss1:36.03599056601524


epoch:115,	loss:0.05061154643590271	loss1:39.25855925679207


epoch:112,	loss:0.07633904644171707	loss1:35.27910993993282
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
right_checker:1721	total:1985	checker ACC: 0.867002546787262	temp:0	temp1:0	wrong_total:85	
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1767	total:1987	Code ACC: 0.8892803220936084	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:89	
right_count:338	total:433	 Answer ACC: 0.7806004618937644
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:30	wrong_total:95	 wrong be tree ACC: 0.3157894736842105
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:95	


epoch:116,	loss:0.04303900125887594	loss1:47.96900935843587
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:85	 wrong be tree ACC: 0.36470588235294116
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:85	


epoch:116,	loss:0.05011012073373422	loss1:56.26678215712309


epoch:113,	loss:0.05910616628534626	loss1:59.661920338869095
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1768	total:1987	Code ACC: 0.8897835933568193	wrong_be_tree_count:36	wrong_total:90	 wrong be tree ACC: 0.4
right_checker:1750	total:1987	checker ACC: 0.8807246685028076	temp:0	temp1:0	wrong_total:90	
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:29	wrong_total:96	 wrong be tree ACC: 0.3020833333333333
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:96	


epoch:117,	loss:0.046763992169871926	loss1:38.10884324461222
right_count:346	total:431	 Answer ACC: 0.802784222737819
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:85	 wrong be tree ACC: 0.36470588235294116
right_checker:1720	total:1985	checker ACC: 0.8664987683296204	temp:0	temp1:0	wrong_total:85	


epoch:117,	loss:0.05812787963077426	loss1:34.21789725124836


epoch:118,	loss:0.05921038775704801	loss1:40.14289248548448


epoch:114,	loss:0.056493306656193454	loss1:53.46185341477394
right_count:344	total:433	 Answer ACC: 0.7944572748267898
right_codes_count:1769	total:1987	Code ACC: 0.8902868646200301	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:89	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:28	wrong_total:94	 wrong be tree ACC: 0.2978723404255319
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:94	
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:30	wrong_total:87	 wrong be tree ACC: 0.3448275862068966
right_checker:1717	total:1985	checker ACC: 0.8649874329566956	temp:0	temp1:0	wrong_total:87	


epoch:119,	loss:0.04239004100963939	loss1:46.96649856492877


epoch:118,	loss:0.05122540139927878	loss1:46.72600084170699


epoch:115,	loss:0.05598803160683019	loss1:42.41190977022052
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1767	total:1987	Code ACC: 0.8892803220936084	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:90	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1746	total:1974	Code ACC: 0.8844984802431611	wrong_be_tree_count:29	wrong_total:94	 wrong be tree ACC: 0.30851063829787234
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:94	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
right_checker:1716	total:1985	checker ACC: 0.864483654499054	temp:0	temp1:0	wrong_total:86	


epoch:120,	loss:0.06691019833669998	loss1:37.89777798205614


epoch:119,	loss:0.05341113422764465	loss1:37.4476515725255


epoch:116,	loss:0.05409568622962979	loss1:43.01935540139675
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:86	
right_count:342	total:433	 Answer ACC: 0.789838337182448
right_codes_count:1767	total:1987	Code ACC: 0.8892803220936084	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:91	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:29	wrong_total:93	 wrong be tree ACC: 0.3118279569892473
right_checker:1753	total:1974	checker ACC: 0.8880445957183838	temp:0	temp1:0	wrong_total:93	


epoch:121,	loss:0.042967972287442535	loss1:36.149909272789955


epoch:120,	loss:0.050506440049503	loss1:31.39074967801571


epoch:117,	loss:0.060011664987541735	loss1:36.959923073649406
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:31	wrong_total:87	 wrong be tree ACC: 0.3563218390804598
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:87	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1765	total:1987	Code ACC: 0.8882737795671867	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1748	total:1987	checker ACC: 0.8797181248664856	temp:0	temp1:0	wrong_total:92	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:28	wrong_total:94	 wrong be tree ACC: 0.2978723404255319
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:94	


epoch:122,	loss:0.04282966272603517	loss1:36.630435079336166


epoch:121,	loss:0.05412952053666231	loss1:44.64177084714174


epoch:118,	loss:0.052335504500661045	loss1:52.426994778215885
right_count:344	total:431	 Answer ACC: 0.7981438515081206
right_codes_count:1767	total:1985	Code ACC: 0.890176322418136	wrong_be_tree_count:31	wrong_total:87	 wrong be tree ACC: 0.3563218390804598
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:87	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1750	total:1987	checker ACC: 0.8807246685028076	temp:0	temp1:0	wrong_total:92	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1746	total:1974	Code ACC: 0.8844984802431611	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:93	


epoch:123,	loss:0.040865818223210226	loss1:41.05490970611572
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:86	


epoch:119,	loss:0.06063497651484795	loss1:56.81660042703152


epoch:122,	loss:0.0513927875799709	loss1:58.05594375729561


epoch:124,	loss:0.06774732726626098	loss1:39.44178918004036
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:27	wrong_total:92	 wrong be tree ACC: 0.29347826086956524
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:92	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1763	total:1987	Code ACC: 0.8872672370407649	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1750	total:1987	checker ACC: 0.8807246685028076	temp:0	temp1:0	wrong_total:92	
right_count:345	total:431	 Answer ACC: 0.8004640371229699
right_codes_count:1768	total:1985	Code ACC: 0.8906801007556675	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:86	


epoch:120,	loss:0.057452228327747434	loss1:45.28770798444748


epoch:123,	loss:0.048601113114273176	loss1:28.98396909981966


epoch:125,	loss:0.04318615514785051	loss1:40.089674569666386
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:28	wrong_total:94	 wrong be tree ACC: 0.2978723404255319
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:94	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:88	


epoch:126,	loss:0.041525463312609645	loss1:35.01058927923441


epoch:121,	loss:0.05529937178653199	loss1:48.632110986858606


epoch:124,	loss:0.05166611936874688	loss1:31.94893668591976
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:88	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:28	wrong_total:94	 wrong be tree ACC: 0.2978723404255319
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:94	


epoch:127,	loss:0.051989433413837105	loss1:40.73607172071934


epoch:122,	loss:0.056805875512509374	loss1:49.491336449980736


epoch:125,	loss:0.049548566013982054	loss1:41.39397618174553
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:28	wrong_total:94	 wrong be tree ACC: 0.2978723404255319
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:94	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:88	


epoch:128,	loss:0.042561727022984996	loss1:31.800215888768435


epoch:123,	loss:0.060353466018568724	loss1:51.83593509159982


epoch:126,	loss:0.056181759835453704	loss1:42.819984309375286
right_count:339	total:433	 Answer ACC: 0.7829099307159353
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:27	wrong_total:94	 wrong be tree ACC: 0.2872340425531915
right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:94	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:88	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	


epoch:129,	loss:0.042874216131167486	loss1:44.485198616981506


epoch:124,	loss:0.05500830459641293	loss1:50.907523687928915


epoch:127,	loss:0.04880887778563192	loss1:28.756936997175217
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_count:343	total:431	 Answer ACC: 0.7958236658932715
right_codes_count:1766	total:1985	Code ACC: 0.8896725440806046	wrong_be_tree_count:30	wrong_total:88	 wrong be tree ACC: 0.3409090909090909
right_checker:1719	total:1985	checker ACC: 0.8659949898719788	temp:0	temp1:0	wrong_total:88	



final_test


epoch:128,	loss:0.047612811906219576	loss1:44.88538827933371


epoch:125,	loss:0.056351879769863444	loss1:68.3585132881999
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	
right_count:352	total:431	 Answer ACC: 0.8167053364269141
right_codes_count:1764	total:1985	Code ACC: 0.8886649874055416	wrong_be_tree_count:33	wrong_total:79	 wrong be tree ACC: 0.4177215189873418
right_checker:1696	total:1985	checker ACC: 0.8544080853462219	temp:0	temp1:0	wrong_total:79	
total input dataset len: 1732
after process dataset len: 1732
total passed: 0
total input dataset len: 431
after process dataset len: 431
total passed: 0
final_test
Answer acc:0.8167053364269141




epoch:129,	loss:0.047966160369469435	loss1:40.100303292274475


epoch:126,	loss:0.05678954731411068	loss1:39.90768142044544
right_count:341	total:433	 Answer ACC: 0.7875288683602771
right_codes_count:1766	total:1987	Code ACC: 0.8887770508303976	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
right_checker:1749	total:1987	checker ACC: 0.8802213668823242	temp:0	temp1:0	wrong_total:92	
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	



final_test


epoch:127,	loss:0.05994948372244835	loss1:51.9436057806015
right_count:356	total:433	 Answer ACC: 0.8221709006928406
right_codes_count:1768	total:1987	Code ACC: 0.8897835933568193	wrong_be_tree_count:32	wrong_total:77	 wrong be tree ACC: 0.4155844155844156
right_checker:1675	total:1987	checker ACC: 0.8429793119430542	temp:0	temp1:0	wrong_total:77	
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
final_test
Answer acc:0.8221709006928406


right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	


epoch:128,	loss:0.056765684130368754	loss1:54.62692658230662
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	


epoch:129,	loss:0.05535694634590982	loss1:46.60687245428562
right_count:340	total:433	 Answer ACC: 0.7852193995381063
right_codes_count:1745	total:1974	Code ACC: 0.8839918946301925	wrong_be_tree_count:27	wrong_total:93	 wrong be tree ACC: 0.2903225806451613
right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:93	



final_test
right_count:343	total:433	 Answer ACC: 0.792147806004619
right_codes_count:1743	total:1974	Code ACC: 0.8829787234042553	wrong_be_tree_count:28	wrong_total:90	 wrong be tree ACC: 0.3111111111111111
right_checker:1746	total:1974	checker ACC: 0.8844985365867615	temp:0	temp1:0	wrong_total:90	
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
final_test
Answer acc:0.792147806004619





get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 21891.73it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 6591.92it/s]
define model...



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 31577.29it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 6638.98it/s]
define model...
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_1.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 5, 1024] to be smaller than self [40, 52, 768] apart from dimension 1


epoch:0,	loss:27.83554059267044	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:90	total:1974	Code ACC: 0.04559270516717325	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1301	total:1974	checker ACC: 0.6590679287910461	temp:0	temp1:0	wrong_total:433	
save best model to ./output/model_save_name_0/best_model


epoch:1,	loss:16.971221774816513	loss1:0
right_count:1	total:433	 Answer ACC: 0.0023094688221709007
right_codes_count:330	total:1974	Code ACC: 0.16717325227963525	wrong_be_tree_count:425	wrong_total:432	 wrong be tree ACC: 0.9837962962962963
right_checker:1246	total:1974	checker ACC: 0.631205677986145	temp:0	temp1:0	wrong_total:432	
save best model to ./output/model_save_name_0/best_model



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 23255.39it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 5925.11it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_1.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 5, 1024] to be smaller than self [40, 52, 768] apart from dimension 1


epoch:2,	loss:5.8315935134887695	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:859	total:1974	Code ACC: 0.4351570415400203	wrong_be_tree_count:429	wrong_total:433	 wrong be tree ACC: 0.9907621247113164
right_checker:1157	total:1974	checker ACC: 0.5861195921897888	temp:0	temp1:0	wrong_total:433	


epoch:3,	loss:3.244096327573061	loss1:0
right_count:31	total:433	 Answer ACC: 0.07159353348729793
right_codes_count:983	total:1974	Code ACC: 0.4979736575481256	wrong_be_tree_count:281	wrong_total:402	 wrong be tree ACC: 0.6990049751243781
100%|██████████| 1730/1730 [00:00<00:00, 32145.24it/s]100%|██████████| 1730/1730 [00:00<00:00, 26745.54it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 35403.60it/s]
define model...

get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 35215.50it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
right_checker:1041	total:1974	checker ACC: 0.5273556709289551	temp:0	temp1:0	wrong_total:402	
save best model to ./output/model_save_name_0/best_model


epoch:4,	loss:2.8682239651679993	loss1:0
>>>>>>>>>>>>>>>start train......
after process dataset len: 433
total passed: 0
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_2.py", line 68, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 6, 1024] to be smaller than self [40, 52, 768] apart from dimension 1
Traceback (most recent call last):
  File "train_3.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 6, 1024] to be smaller than self [40, 52, 768] apart from dimension 1
right_count:70	total:433	 Answer ACC: 0.16166281755196305
right_codes_count:1124	total:1974	Code ACC: 0.569402228976697	wrong_be_tree_count:160	wrong_total:363	 wrong be tree ACC: 0.44077134986225897
right_checker:914	total:1974	checker ACC: 0.4630192816257477	temp:0	temp1:0	wrong_total:363	
save best model to ./output/model_save_name_0/best_model


epoch:5,	loss:2.671072520315647	loss1:0
  | 0/1732 [00:00<?, ?it/s]100%|██████████| 1732/1732 [00:00<00:00, 27185.90it/s]
get dev data loader...
  0%|          | 0/431 [00:00<?, ?it/s]100%|██████████| 431/431 [00:00<00:00, 6098.22it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
right_count:80	total:433	 Answer ACC: 0.18475750577367206
right_codes_count:1156	total:1974	Code ACC: 0.585612968591692	wrong_be_tree_count:162	wrong_total:353	 wrong be tree ACC: 0.45892351274787535
right_checker:888	total:1974	checker ACC: 0.4498480558395386	temp:0	temp1:0	wrong_total:353	
 line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 7, 1024] to be smaller than self [40, 69, 768] apart from dimension 1
save best model to ./output/model_save_name_0/best_model


epoch:6,	loss:2.5221133418381214	loss1:0
right_count:92	total:433	 Answer ACC: 0.21247113163972287
right_codes_count:1219	total:1974	Code ACC: 0.6175278622087133	wrong_be_tree_count:104	wrong_total:341	 wrong be tree ACC: 0.30498533724340177
right_checker:851	total:1974	checker ACC: 0.4311043918132782	temp:0	temp1:0	wrong_total:341	
save best model to ./output/model_save_name_0/best_model



get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 27321.78it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 28168.47it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_3.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 6, 1024] to be smaller than self [40, 52, 768] apart from dimension 1



get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 25330.31it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 4532.12it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_3.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 6, 1024] to be smaller than self [40, 52, 768] apart from dimension 1


epoch:7,	loss:2.393087588250637	loss1:0
right_count:97	total:433	 Answer ACC: 0.22401847575057737
right_codes_count:1233	total:1974	Code ACC: 0.6246200607902735	wrong_be_tree_count:93	wrong_total:336	 wrong be tree ACC: 0.2767857142857143
right_checker:804	total:1974	checker ACC: 0.4072948396205902	temp:0	temp1:0	wrong_total:336	
save best model to ./output/model_save_name_0/best_model


epoch:8,	loss:2.237429700791836	loss1:3406.234447479248
0<?, ?it/s]100%|██████████| 1732/1732 [00:00<00:00, 25324.50it/s]
get dev data loader...
  0%|          | 0/431 [00:00<?, ?it/s]100%|██████████| 431/431 [00:00<00:00, 5089.57it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......
total input dataset len: 1732
after process dataset len: 1732
total passed: 0
total input dataset len: 431
after process dataset len: 431
total passed: 0
Traceback (most recent call last):
  File "train_4.py", line 66, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 181, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 530, in forward
    p_hidden = torch.gather(token_embeddings, 1, num_positions.unsqueeze(-1).expand(-1,-1,self.d_model))
RuntimeError: Size does not match at dimension 2 expected index [40, 7, 1024] to be smaller than self [40, 69, 768] apart from dimension 1
right_count:115	total:433	 Answer ACC: 0.26558891454965355
right_codes_count:1309	total:1974	Code ACC: 0.6631205673758865	wrong_be_tree_count:43	wrong_total:318	 wrong be tree ACC: 0.13522012578616352
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:318	
save best model to ./output/model_save_name_0/best_model


epoch:9,	loss:2.1282781399786472	loss1:2370.815794944763
right_count:121	total:433	 Answer ACC: 0.279445727482679
right_codes_count:1331	total:1974	Code ACC: 0.6742654508611955	wrong_be_tree_count:62	wrong_total:312	 wrong be tree ACC: 0.1987179487179487
right_checker:1496	total:1974	checker ACC: 0.7578521370887756	temp:0	temp1:0	wrong_total:312	
save best model to ./output/model_save_name_0/best_model


epoch:10,	loss:1.9872408248484135	loss1:2045.7548871040344
right_count:147	total:433	 Answer ACC: 0.3394919168591224
right_codes_count:1391	total:1974	Code ACC: 0.704660587639311	wrong_be_tree_count:51	wrong_total:286	 wrong be tree ACC: 0.17832167832167833
right_checker:1527	total:1974	checker ACC: 0.7735562920570374	temp:0	temp1:0	wrong_total:286	
save best model to ./output/model_save_name_0/best_model


epoch:11,	loss:1.865948835387826	loss1:1916.685576915741
right_count:157	total:433	 Answer ACC: 0.3625866050808314
right_codes_count:1414	total:1974	Code ACC: 0.7163120567375887	wrong_be_tree_count:72	wrong_total:276	 wrong be tree ACC: 0.2608695652173913
right_checker:1558	total:1974	checker ACC: 0.7892604470252991	temp:0	temp1:0	wrong_total:276	
save best model to ./output/model_save_name_0/best_model


epoch:12,	loss:1.7383171785622835	loss1:1771.3332557678223
right_count:165	total:433	 Answer ACC: 0.3810623556581986
right_codes_count:1442	total:1974	Code ACC: 0.7304964539007093	wrong_be_tree_count:57	wrong_total:268	 wrong be tree ACC: 0.2126865671641791
right_checker:1562	total:1974	checker ACC: 0.7912867665290833	temp:0	temp1:0	wrong_total:268	
save best model to ./output/model_save_name_0/best_model


epoch:13,	loss:1.6559641547501087	loss1:1716.6063694953918
right_count:174	total:433	 Answer ACC: 0.4018475750577367
right_codes_count:1443	total:1974	Code ACC: 0.7310030395136778	wrong_be_tree_count:69	wrong_total:259	 wrong be tree ACC: 0.26640926640926643
right_checker:1595	total:1974	checker ACC: 0.8080040812492371	temp:0	temp1:0	wrong_total:259	
save best model to ./output/model_save_name_0/best_model


epoch:14,	loss:1.5389176309108734	loss1:1596.685954093933
right_count:199	total:433	 Answer ACC: 0.45958429561200925
right_codes_count:1510	total:1974	Code ACC: 0.7649442755825735	wrong_be_tree_count:66	wrong_total:234	 wrong be tree ACC: 0.28205128205128205
right_checker:1554	total:1974	checker ACC: 0.7872340679168701	temp:0	temp1:0	wrong_total:234	
save best model to ./output/model_save_name_0/best_model


epoch:15,	loss:1.4690725021064281	loss1:1511.7687816619873
right_count:212	total:433	 Answer ACC: 0.4896073903002309
right_codes_count:1538	total:1974	Code ACC: 0.779128672745694	wrong_be_tree_count:77	wrong_total:221	 wrong be tree ACC: 0.34841628959276016
right_checker:1537	total:1974	checker ACC: 0.7786221504211426	temp:0	temp1:0	wrong_total:221	
save best model to ./output/model_save_name_0/best_model


epoch:16,	loss:1.403578044846654	loss1:1456.0404644012451
right_count:221	total:433	 Answer ACC: 0.5103926096997691
right_codes_count:1533	total:1974	Code ACC: 0.776595744680851	wrong_be_tree_count:87	wrong_total:212	 wrong be tree ACC: 0.41037735849056606
right_checker:1545	total:1974	checker ACC: 0.7826747894287109	temp:0	temp1:0	wrong_total:212	
save best model to ./output/model_save_name_0/best_model


epoch:17,	loss:1.3208657931536436	loss1:1424.5352387428284
right_count:231	total:433	 Answer ACC: 0.5334872979214781
right_codes_count:1571	total:1974	Code ACC: 0.7958459979736575	wrong_be_tree_count:70	wrong_total:202	 wrong be tree ACC: 0.3465346534653465
right_checker:1499	total:1974	checker ACC: 0.7593718767166138	temp:0	temp1:0	wrong_total:202	
save best model to ./output/model_save_name_0/best_model


epoch:18,	loss:1.3016754686832428	loss1:1335.5718269348145
right_count:238	total:433	 Answer ACC: 0.5496535796766744
right_codes_count:1603	total:1974	Code ACC: 0.8120567375886525	wrong_be_tree_count:65	wrong_total:195	 wrong be tree ACC: 0.3333333333333333
right_checker:1511	total:1974	checker ACC: 0.7654508948326111	temp:0	temp1:0	wrong_total:195	
save best model to ./output/model_save_name_0/best_model


epoch:19,	loss:1.1990350913256407	loss1:1262.1592664718628
right_count:261	total:433	 Answer ACC: 0.6027713625866051
right_codes_count:1626	total:1974	Code ACC: 0.8237082066869301	wrong_be_tree_count:56	wrong_total:172	 wrong be tree ACC: 0.32558139534883723
right_checker:1448	total:1974	checker ACC: 0.7335360050201416	temp:0	temp1:0	wrong_total:172	
save best model to ./output/model_save_name_0/best_model


epoch:20,	loss:1.1626405948773026	loss1:1246.5515699386597
right_count:268	total:433	 Answer ACC: 0.6189376443418014
right_codes_count:1627	total:1974	Code ACC: 0.8242147922998987	wrong_be_tree_count:61	wrong_total:165	 wrong be tree ACC: 0.3696969696969697
right_checker:1477	total:1974	checker ACC: 0.7482270002365112	temp:0	temp1:0	wrong_total:165	
save best model to ./output/model_save_name_0/best_model


epoch:21,	loss:1.0930292615666986	loss1:1157.4991521835327
right_count:283	total:433	 Answer ACC: 0.6535796766743649
right_codes_count:1639	total:1974	Code ACC: 0.8302938196555217	wrong_be_tree_count:46	wrong_total:150	 wrong be tree ACC: 0.30666666666666664
right_checker:1505	total:1974	checker ACC: 0.7624114155769348	temp:0	temp1:0	wrong_total:150	
save best model to ./output/model_save_name_0/best_model


epoch:22,	loss:1.0213042413815856	loss1:1098.8786225318909
right_count:291	total:433	 Answer ACC: 0.6720554272517321
right_codes_count:1662	total:1974	Code ACC: 0.8419452887537994	wrong_be_tree_count:46	wrong_total:142	 wrong be tree ACC: 0.323943661971831
right_checker:1472	total:1974	checker ACC: 0.7456940412521362	temp:0	temp1:0	wrong_total:142	
save best model to ./output/model_save_name_0/best_model


epoch:23,	loss:1.0255303317680955	loss1:1128.1972618103027
right_count:292	total:433	 Answer ACC: 0.674364896073903
right_codes_count:1665	total:1974	Code ACC: 0.8434650455927052	wrong_be_tree_count:50	wrong_total:141	 wrong be tree ACC: 0.3546099290780142
right_checker:1444	total:1974	checker ACC: 0.7315096855163574	temp:0	temp1:0	wrong_total:141	
save best model to ./output/model_save_name_0/best_model


epoch:24,	loss:0.9413721952587366	loss1:960.1737158298492
right_count:296	total:433	 Answer ACC: 0.6836027713625866
right_codes_count:1663	total:1974	Code ACC: 0.8424518743667679	wrong_be_tree_count:47	wrong_total:137	 wrong be tree ACC: 0.34306569343065696
right_checker:1474	total:1974	checker ACC: 0.7467072606086731	temp:0	temp1:0	wrong_total:137	
save best model to ./output/model_save_name_0/best_model


epoch:25,	loss:0.9010304911062121	loss1:950.5286288261414
right_count:304	total:433	 Answer ACC: 0.7020785219399538
right_codes_count:1679	total:1974	Code ACC: 0.8505572441742655	wrong_be_tree_count:41	wrong_total:129	 wrong be tree ACC: 0.3178294573643411
right_checker:1437	total:1974	checker ACC: 0.7279635667800903	temp:0	temp1:0	wrong_total:129	
save best model to ./output/model_save_name_0/best_model


epoch:26,	loss:0.8846681630238891	loss1:919.0597906112671
right_count:305	total:433	 Answer ACC: 0.7043879907621247
right_codes_count:1684	total:1974	Code ACC: 0.8530901722391084	wrong_be_tree_count:47	wrong_total:128	 wrong be tree ACC: 0.3671875
right_checker:1443	total:1974	checker ACC: 0.7310031056404114	temp:0	temp1:0	wrong_total:128	
save best model to ./output/model_save_name_0/best_model


epoch:27,	loss:0.8613190688192844	loss1:876.6922655105591
right_count:318	total:433	 Answer ACC: 0.7344110854503464
right_codes_count:1690	total:1974	Code ACC: 0.85612968591692	wrong_be_tree_count:44	wrong_total:115	 wrong be tree ACC: 0.3826086956521739
right_checker:1446	total:1974	checker ACC: 0.7325228452682495	temp:0	temp1:0	wrong_total:115	
save best model to ./output/model_save_name_0/best_model


epoch:28,	loss:0.8216479774564505	loss1:855.2434272766113
right_count:312	total:433	 Answer ACC: 0.7205542725173211
right_codes_count:1704	total:1974	Code ACC: 0.8632218844984803	wrong_be_tree_count:40	wrong_total:121	 wrong be tree ACC: 0.3305785123966942
right_checker:1476	total:1974	checker ACC: 0.7477204203605652	temp:0	temp1:0	wrong_total:121	


epoch:29,	loss:0.8101052157580853	loss1:775.4773578643799
right_count:314	total:433	 Answer ACC: 0.7251732101616628
right_codes_count:1691	total:1974	Code ACC: 0.8566362715298885	wrong_be_tree_count:41	wrong_total:119	 wrong be tree ACC: 0.3445378151260504
right_checker:1496	total:1974	checker ACC: 0.7578521370887756	temp:0	temp1:0	wrong_total:119	


epoch:30,	loss:0.784138074144721	loss1:792.3906383514404
right_count:313	total:433	 Answer ACC: 0.7228637413394919
right_codes_count:1709	total:1974	Code ACC: 0.8657548125633232	wrong_be_tree_count:43	wrong_total:120	 wrong be tree ACC: 0.35833333333333334
right_checker:1479	total:1974	checker ACC: 0.7492401599884033	temp:0	temp1:0	wrong_total:120	


epoch:31,	loss:0.7299512671306729	loss1:761.3259716033936
right_count:322	total:433	 Answer ACC: 0.74364896073903
right_codes_count:1713	total:1974	Code ACC: 0.8677811550151976	wrong_be_tree_count:45	wrong_total:111	 wrong be tree ACC: 0.40540540540540543
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:111	
save best model to ./output/model_save_name_0/best_model


epoch:32,	loss:0.7157757799141109	loss1:720.0709760189056
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1717	total:1974	Code ACC: 0.869807497467072	wrong_be_tree_count:40	wrong_total:108	 wrong be tree ACC: 0.37037037037037035
right_checker:1504	total:1974	checker ACC: 0.761904776096344	temp:0	temp1:0	wrong_total:108	
save best model to ./output/model_save_name_0/best_model


epoch:33,	loss:0.6743073179386556	loss1:707.3833973407745
right_count:321	total:433	 Answer ACC: 0.7413394919168591
right_codes_count:1714	total:1974	Code ACC: 0.8682877406281662	wrong_be_tree_count:46	wrong_total:112	 wrong be tree ACC: 0.4107142857142857
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:112	


epoch:34,	loss:0.6769675291143358	loss1:682.223626613617
right_count:321	total:433	 Answer ACC: 0.7413394919168591
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:40	wrong_total:112	 wrong be tree ACC: 0.35714285714285715
right_checker:1512	total:1974	checker ACC: 0.7659574747085571	temp:0	temp1:0	wrong_total:112	


epoch:35,	loss:0.6581224426627159	loss1:668.1395981311798
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1722	total:1974	Code ACC: 0.8723404255319149	wrong_be_tree_count:45	wrong_total:108	 wrong be tree ACC: 0.4166666666666667
right_checker:1580	total:1974	checker ACC: 0.8004053235054016	temp:0	temp1:0	wrong_total:108	
save best model to ./output/model_save_name_0/best_model


epoch:36,	loss:0.6321631046012044	loss1:624.9406023025513
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:41	wrong_total:102	 wrong be tree ACC: 0.4019607843137255
right_checker:1496	total:1974	checker ACC: 0.7578521370887756	temp:0	temp1:0	wrong_total:102	
save best model to ./output/model_save_name_0/best_model


epoch:37,	loss:0.6108306508976966	loss1:629.1398088932037
right_count:328	total:433	 Answer ACC: 0.7575057736720554
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:42	wrong_total:105	 wrong be tree ACC: 0.4
right_checker:1537	total:1974	checker ACC: 0.7786221504211426	temp:0	temp1:0	wrong_total:105	


epoch:38,	loss:0.5967915691435337	loss1:555.8124904632568
right_count:327	total:433	 Answer ACC: 0.7551963048498845
right_codes_count:1714	total:1974	Code ACC: 0.8682877406281662	wrong_be_tree_count:41	wrong_total:106	 wrong be tree ACC: 0.3867924528301887
right_checker:1522	total:1974	checker ACC: 0.7710233330726624	temp:0	temp1:0	wrong_total:106	


epoch:39,	loss:0.5811195955611765	loss1:601.5247864723206
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1717	total:1974	Code ACC: 0.869807497467072	wrong_be_tree_count:42	wrong_total:108	 wrong be tree ACC: 0.3888888888888889
right_checker:1590	total:1974	checker ACC: 0.8054711818695068	temp:0	temp1:0	wrong_total:108	


epoch:40,	loss:0.5691780676133931	loss1:604.2589211463928
right_count:323	total:433	 Answer ACC: 0.745958429561201
right_codes_count:1728	total:1974	Code ACC: 0.8753799392097265	wrong_be_tree_count:42	wrong_total:110	 wrong be tree ACC: 0.38181818181818183
right_checker:1551	total:1974	checker ACC: 0.785714328289032	temp:0	temp1:0	wrong_total:110	


epoch:41,	loss:0.5380704696290195	loss1:556.4863642156124
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:41	wrong_total:103	 wrong be tree ACC: 0.39805825242718446
right_checker:1539	total:1974	checker ACC: 0.7796353101730347	temp:0	temp1:0	wrong_total:103	


epoch:42,	loss:0.5281604509800673	loss1:547.8497443199158
right_count:324	total:433	 Answer ACC: 0.7482678983833718
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:46	wrong_total:109	 wrong be tree ACC: 0.42201834862385323
right_checker:1583	total:1974	checker ACC: 0.8019250631332397	temp:0	temp1:0	wrong_total:109	


epoch:43,	loss:0.5344051872380078	loss1:538.5477924346924
right_count:323	total:433	 Answer ACC: 0.745958429561201
right_codes_count:1725	total:1974	Code ACC: 0.8738601823708206	wrong_be_tree_count:40	wrong_total:110	 wrong be tree ACC: 0.36363636363636365
right_checker:1622	total:1974	checker ACC: 0.8216819167137146	temp:0	temp1:0	wrong_total:110	


epoch:44,	loss:0.5107590169645846	loss1:503.82050681114197
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:42	wrong_total:104	 wrong be tree ACC: 0.40384615384615385
right_checker:1595	total:1974	checker ACC: 0.8080040812492371	temp:0	temp1:0	wrong_total:104	


epoch:45,	loss:0.48386912723071873	loss1:479.34945261478424
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1731	total:1974	Code ACC: 0.8768996960486323	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1611	total:1974	checker ACC: 0.8161094784736633	temp:0	temp1:0	wrong_total:102	
save best model to ./output/model_save_name_0/best_model


epoch:46,	loss:0.49106456991285086	loss1:505.18217730522156
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1722	total:1974	Code ACC: 0.8723404255319149	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1602	total:1974	checker ACC: 0.8115501999855042	temp:0	temp1:0	wrong_total:102	
save best model to ./output/model_save_name_0/best_model


epoch:47,	loss:0.4859173959121108	loss1:504.8981502056122
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1725	total:1974	Code ACC: 0.8738601823708206	wrong_be_tree_count:43	wrong_total:101	 wrong be tree ACC: 0.42574257425742573
right_checker:1591	total:1974	checker ACC: 0.8059777617454529	temp:0	temp1:0	wrong_total:101	
save best model to ./output/model_save_name_0/best_model


epoch:48,	loss:0.4635675912722945	loss1:485.25843143463135
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1731	total:1974	Code ACC: 0.8768996960486323	wrong_be_tree_count:45	wrong_total:103	 wrong be tree ACC: 0.4368932038834951
right_checker:1625	total:1974	checker ACC: 0.8232016563415527	temp:0	temp1:0	wrong_total:103	


epoch:49,	loss:0.46445621829479933	loss1:443.9629988670349
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1726	total:1974	Code ACC: 0.8743667679837892	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1606	total:1974	checker ACC: 0.8135765194892883	temp:0	temp1:0	wrong_total:102	


epoch:50,	loss:0.45020891237072647	loss1:497.67160856723785
right_count:326	total:433	 Answer ACC: 0.7528868360277137
right_codes_count:1720	total:1974	Code ACC: 0.8713272543059777	wrong_be_tree_count:41	wrong_total:107	 wrong be tree ACC: 0.38317757009345793
right_checker:1614	total:1974	checker ACC: 0.8176292181015015	temp:0	temp1:0	wrong_total:107	


epoch:51,	loss:0.42425371101126075	loss1:423.0382721424103
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1619	total:1974	checker ACC: 0.8201621770858765	temp:0	temp1:0	wrong_total:102	


epoch:52,	loss:0.4123945264145732	loss1:414.60521579533815
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1604	total:1974	checker ACC: 0.8125633597373962	temp:0	temp1:0	wrong_total:102	


epoch:53,	loss:0.40550086414441466	loss1:385.60601568222046
right_count:326	total:433	 Answer ACC: 0.7528868360277137
right_codes_count:1722	total:1974	Code ACC: 0.8723404255319149	wrong_be_tree_count:40	wrong_total:107	 wrong be tree ACC: 0.37383177570093457
right_checker:1605	total:1974	checker ACC: 0.8130699396133423	temp:0	temp1:0	wrong_total:107	


epoch:54,	loss:0.42952747689560056	loss1:437.1296321749687
right_count:324	total:433	 Answer ACC: 0.7482678983833718
right_codes_count:1724	total:1974	Code ACC: 0.8733535967578521	wrong_be_tree_count:51	wrong_total:109	 wrong be tree ACC: 0.46788990825688076
right_checker:1596	total:1974	checker ACC: 0.8085106611251831	temp:0	temp1:0	wrong_total:109	


epoch:55,	loss:0.40896352636627853	loss1:422.30527651309967
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1729	total:1974	Code ACC: 0.875886524822695	wrong_be_tree_count:45	wrong_total:103	 wrong be tree ACC: 0.4368932038834951
right_checker:1626	total:1974	checker ACC: 0.8237082362174988	temp:0	temp1:0	wrong_total:103	


epoch:56,	loss:0.39850505953654647	loss1:400.9896430969238
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1726	total:1974	Code ACC: 0.8743667679837892	wrong_be_tree_count:45	wrong_total:104	 wrong be tree ACC: 0.4326923076923077
right_checker:1598	total:1974	checker ACC: 0.8095238208770752	temp:0	temp1:0	wrong_total:104	


epoch:57,	loss:0.38250151881948113	loss1:439.49193382263184
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1728	total:1974	Code ACC: 0.8753799392097265	wrong_be_tree_count:45	wrong_total:103	 wrong be tree ACC: 0.4368932038834951
right_checker:1626	total:1974	checker ACC: 0.8237082362174988	temp:0	temp1:0	wrong_total:103	


epoch:58,	loss:0.37292023771442473	loss1:339.1215669512749
right_count:328	total:433	 Answer ACC: 0.7575057736720554
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:46	wrong_total:105	 wrong be tree ACC: 0.4380952380952381
right_checker:1596	total:1974	checker ACC: 0.8085106611251831	temp:0	temp1:0	wrong_total:105	


epoch:59,	loss:0.38491973583586514	loss1:381.42673230171204
right_count:328	total:433	 Answer ACC: 0.7575057736720554
right_codes_count:1731	total:1974	Code ACC: 0.8768996960486323	wrong_be_tree_count:50	wrong_total:105	 wrong be tree ACC: 0.47619047619047616
right_checker:1602	total:1974	checker ACC: 0.8115501999855042	temp:0	temp1:0	wrong_total:105	


epoch:60,	loss:0.37794351764023304	loss1:383.5787885785103
right_count:326	total:433	 Answer ACC: 0.7528868360277137
right_codes_count:1729	total:1974	Code ACC: 0.875886524822695	wrong_be_tree_count:43	wrong_total:107	 wrong be tree ACC: 0.40186915887850466
right_checker:1619	total:1974	checker ACC: 0.8201621770858765	temp:0	temp1:0	wrong_total:107	


epoch:61,	loss:0.36144724674522877	loss1:376.69657492637634
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:47	wrong_total:102	 wrong be tree ACC: 0.46078431372549017
right_checker:1658	total:1974	checker ACC: 0.8399189710617065	temp:0	temp1:0	wrong_total:102	


epoch:62,	loss:0.36135036684572697	loss1:360.88542729616165
right_count:327	total:433	 Answer ACC: 0.7551963048498845
right_codes_count:1726	total:1974	Code ACC: 0.8743667679837892	wrong_be_tree_count:44	wrong_total:106	 wrong be tree ACC: 0.41509433962264153
right_checker:1620	total:1974	checker ACC: 0.8206687569618225	temp:0	temp1:0	wrong_total:106	


epoch:63,	loss:0.3559875125065446	loss1:373.4941316843033
right_count:327	total:433	 Answer ACC: 0.7551963048498845
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:47	wrong_total:106	 wrong be tree ACC: 0.44339622641509435
right_checker:1624	total:1974	checker ACC: 0.8226950764656067	temp:0	temp1:0	wrong_total:106	


epoch:64,	loss:0.3352001359453425	loss1:315.7426748275757
right_count:327	total:433	 Answer ACC: 0.7551963048498845
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:47	wrong_total:106	 wrong be tree ACC: 0.44339622641509435
right_checker:1640	total:1974	checker ACC: 0.830800473690033	temp:0	temp1:0	wrong_total:106	


epoch:65,	loss:0.3651154220569879	loss1:341.2455644607544
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:47	wrong_total:100	 wrong be tree ACC: 0.47
right_checker:1645	total:1974	checker ACC: 0.8333333730697632	temp:0	temp1:0	wrong_total:100	
save best model to ./output/model_save_name_0/best_model


epoch:66,	loss:0.342094917781651	loss1:295.13811326026917
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
right_checker:1626	total:1974	checker ACC: 0.8237082362174988	temp:0	temp1:0	wrong_total:100	
save best model to ./output/model_save_name_0/best_model


epoch:67,	loss:0.3330155360745266	loss1:315.2836836576462
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:36	wrong_total:103	 wrong be tree ACC: 0.34951456310679613
right_checker:1670	total:1974	checker ACC: 0.8459979891777039	temp:0	temp1:0	wrong_total:103	


epoch:68,	loss:0.329526009503752	loss1:322.93375808000565
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1733	total:1974	Code ACC: 0.8779128672745694	wrong_be_tree_count:34	wrong_total:100	 wrong be tree ACC: 0.34
right_checker:1634	total:1974	checker ACC: 0.8277609348297119	temp:0	temp1:0	wrong_total:100	
save best model to ./output/model_save_name_0/best_model


epoch:69,	loss:0.323625179938972	loss1:326.4302122592926
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:39	wrong_total:104	 wrong be tree ACC: 0.375
right_checker:1654	total:1974	checker ACC: 0.8378926515579224	temp:0	temp1:0	wrong_total:104	


epoch:70,	loss:0.31673026958014816	loss1:305.5687290132046
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1730	total:1974	Code ACC: 0.8763931104356636	wrong_be_tree_count:50	wrong_total:108	 wrong be tree ACC: 0.46296296296296297
right_checker:1645	total:1974	checker ACC: 0.8333333730697632	temp:0	temp1:0	wrong_total:108	


epoch:71,	loss:0.32596847461536527	loss1:295.3631103038788
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:49	wrong_total:102	 wrong be tree ACC: 0.4803921568627451
right_checker:1650	total:1974	checker ACC: 0.8358663320541382	temp:0	temp1:0	wrong_total:102	


epoch:72,	loss:0.31002083548810333	loss1:304.31939935684204
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1735	total:1974	Code ACC: 0.8789260385005065	wrong_be_tree_count:45	wrong_total:102	 wrong be tree ACC: 0.4411764705882353
right_checker:1635	total:1974	checker ACC: 0.828267514705658	temp:0	temp1:0	wrong_total:102	


epoch:73,	loss:0.3064609804423526	loss1:282.6489316225052
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:43	wrong_total:100	 wrong be tree ACC: 0.43
right_checker:1640	total:1974	checker ACC: 0.830800473690033	temp:0	temp1:0	wrong_total:100	
save best model to ./output/model_save_name_0/best_model


epoch:74,	loss:0.3156695952638984	loss1:306.4463860988617
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1735	total:1974	Code ACC: 0.8789260385005065	wrong_be_tree_count:45	wrong_total:97	 wrong be tree ACC: 0.4639175257731959
right_checker:1637	total:1974	checker ACC: 0.82928067445755	temp:0	temp1:0	wrong_total:97	
save best model to ./output/model_save_name_0/best_model


epoch:75,	loss:0.3046782414894551	loss1:302.6197212934494
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:38	wrong_total:99	 wrong be tree ACC: 0.3838383838383838
right_checker:1675	total:1974	checker ACC: 0.8485309481620789	temp:0	temp1:0	wrong_total:99	


epoch:76,	loss:0.3006913729477674	loss1:307.65363639593124
right_count:336	total:433	 Answer ACC: 0.7759815242494227
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:41	wrong_total:97	 wrong be tree ACC: 0.422680412371134
right_checker:1666	total:1974	checker ACC: 0.8439716696739197	temp:0	temp1:0	wrong_total:97	
save best model to ./output/model_save_name_0/best_model


epoch:77,	loss:0.2990361083066091	loss1:289.7135272026062
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:44	wrong_total:103	 wrong be tree ACC: 0.42718446601941745
right_checker:1660	total:1974	checker ACC: 0.8409321308135986	temp:0	temp1:0	wrong_total:103	


epoch:78,	loss:0.2973381311749108	loss1:290.84899723529816
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:46	wrong_total:98	 wrong be tree ACC: 0.46938775510204084
right_checker:1641	total:1974	checker ACC: 0.831307053565979	temp:0	temp1:0	wrong_total:98	


epoch:79,	loss:0.303858365630731	loss1:277.51026356220245
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:44	wrong_total:100	 wrong be tree ACC: 0.44
right_checker:1667	total:1974	checker ACC: 0.8444782495498657	temp:0	temp1:0	wrong_total:100	


epoch:80,	loss:0.2949271104298532	loss1:273.16379791498184
right_count:325	total:433	 Answer ACC: 0.7505773672055427
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:45	wrong_total:108	 wrong be tree ACC: 0.4166666666666667
right_checker:1652	total:1974	checker ACC: 0.8368794918060303	temp:0	temp1:0	wrong_total:108	


epoch:81,	loss:0.28307898878119886	loss1:288.0194655060768
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1732	total:1974	Code ACC: 0.8774062816616008	wrong_be_tree_count:42	wrong_total:103	 wrong be tree ACC: 0.4077669902912621
right_checker:1678	total:1974	checker ACC: 0.850050687789917	temp:0	temp1:0	wrong_total:103	


epoch:82,	loss:0.28778867120854557	loss1:252.2920833826065
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:39	wrong_total:102	 wrong be tree ACC: 0.38235294117647056
right_checker:1659	total:1974	checker ACC: 0.8404255509376526	temp:0	temp1:0	wrong_total:102	


epoch:83,	loss:0.299976515583694	loss1:288.584757566452
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:45	wrong_total:102	 wrong be tree ACC: 0.4411764705882353
right_checker:1676	total:1974	checker ACC: 0.8490375280380249	temp:0	temp1:0	wrong_total:102	


epoch:84,	loss:0.28019339160528034	loss1:275.3318430185318
right_count:328	total:433	 Answer ACC: 0.7575057736720554
right_codes_count:1727	total:1974	Code ACC: 0.8748733535967579	wrong_be_tree_count:47	wrong_total:105	 wrong be tree ACC: 0.44761904761904764
right_checker:1671	total:1974	checker ACC: 0.8465046286582947	temp:0	temp1:0	wrong_total:105	


epoch:85,	loss:0.26939939917065203	loss1:257.5361688733101
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:45	wrong_total:99	 wrong be tree ACC: 0.45454545454545453
right_checker:1668	total:1974	checker ACC: 0.8449848294258118	temp:0	temp1:0	wrong_total:99	


epoch:86,	loss:0.26829783141147345	loss1:248.15347957611084
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:43	wrong_total:99	 wrong be tree ACC: 0.43434343434343436
right_checker:1665	total:1974	checker ACC: 0.8434650897979736	temp:0	temp1:0	wrong_total:99	


epoch:87,	loss:0.272182256099768	loss1:248.85054297745228
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
right_checker:1676	total:1974	checker ACC: 0.8490375280380249	temp:0	temp1:0	wrong_total:100	


epoch:88,	loss:0.27432009554468095	loss1:250.99921029806137
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:44	wrong_total:101	 wrong be tree ACC: 0.43564356435643564
right_checker:1666	total:1974	checker ACC: 0.8439716696739197	temp:0	temp1:0	wrong_total:101	


epoch:89,	loss:0.2676556487567723	loss1:262.4409087598324
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:44	wrong_total:100	 wrong be tree ACC: 0.44
right_checker:1650	total:1974	checker ACC: 0.8358663320541382	temp:0	temp1:0	wrong_total:100	


epoch:90,	loss:0.27505690534599125	loss1:279.79061329364777
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
right_checker:1679	total:1974	checker ACC: 0.850557267665863	temp:0	temp1:0	wrong_total:96	
save best model to ./output/model_save_name_0/best_model


epoch:91,	loss:0.27117602596990764	loss1:218.90723115205765
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:42	wrong_total:100	 wrong be tree ACC: 0.42
right_checker:1651	total:1974	checker ACC: 0.8363729119300842	temp:0	temp1:0	wrong_total:100	


epoch:92,	loss:0.26953126303851604	loss1:254.74657474458218
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
right_checker:1662	total:1974	checker ACC: 0.8419453501701355	temp:0	temp1:0	wrong_total:99	


epoch:93,	loss:0.265305986860767	loss1:229.23855304718018
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:41	wrong_total:102	 wrong be tree ACC: 0.4019607843137255
right_checker:1648	total:1974	checker ACC: 0.8348531126976013	temp:0	temp1:0	wrong_total:102	


epoch:94,	loss:0.2591298260667827	loss1:232.7035528421402
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
right_checker:1678	total:1974	checker ACC: 0.850050687789917	temp:0	temp1:0	wrong_total:99	


epoch:95,	loss:0.2553395489230752	loss1:214.38255727291107
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1747	total:1974	Code ACC: 0.8850050658561297	wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
right_checker:1670	total:1974	checker ACC: 0.8459979891777039	temp:0	temp1:0	wrong_total:98	


epoch:96,	loss:0.258999343495816	loss1:257.2697846889496
right_count:335	total:433	 Answer ACC: 0.7736720554272517
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:42	wrong_total:98	 wrong be tree ACC: 0.42857142857142855
right_checker:1680	total:1974	checker ACC: 0.8510638475418091	temp:0	temp1:0	wrong_total:98	


epoch:97,	loss:0.2638962719356641	loss1:235.7441076040268
right_count:334	total:433	 Answer ACC: 0.7713625866050808
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
right_checker:1678	total:1974	checker ACC: 0.850050687789917	temp:0	temp1:0	wrong_total:99	


epoch:98,	loss:0.2596916184993461	loss1:248.8199907541275
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1671	total:1974	checker ACC: 0.8465046286582947	temp:0	temp1:0	wrong_total:102	


epoch:99,	loss:0.24810656276531518	loss1:217.9816227555275
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
right_checker:1675	total:1974	checker ACC: 0.8485309481620789	temp:0	temp1:0	wrong_total:100	


epoch:100,	loss:0.25851022196002305	loss1:273.7060101032257
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:45	wrong_total:103	 wrong be tree ACC: 0.4368932038834951
right_checker:1670	total:1974	checker ACC: 0.8459979891777039	temp:0	temp1:0	wrong_total:103	


epoch:101,	loss:0.2443548203445971	loss1:235.12916445732117
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:38	wrong_total:101	 wrong be tree ACC: 0.37623762376237624
right_checker:1663	total:1974	checker ACC: 0.8424519300460815	temp:0	temp1:0	wrong_total:101	


epoch:102,	loss:0.26052082795649767	loss1:210.56811007857323
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:44	wrong_total:103	 wrong be tree ACC: 0.42718446601941745
right_checker:1668	total:1974	checker ACC: 0.8449848294258118	temp:0	temp1:0	wrong_total:103	


epoch:103,	loss:0.26486799446865916	loss1:217.5935549736023
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:44	wrong_total:104	 wrong be tree ACC: 0.4230769230769231
right_checker:1666	total:1974	checker ACC: 0.8439716696739197	temp:0	temp1:0	wrong_total:104	


epoch:104,	loss:0.2576215008739382	loss1:209.01209476590157
right_count:330	total:433	 Answer ACC: 0.7621247113163973
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:103	 wrong be tree ACC: 0.4174757281553398
right_checker:1674	total:1974	checker ACC: 0.8480243682861328	temp:0	temp1:0	wrong_total:103	


epoch:105,	loss:0.2426984526682645	loss1:206.24065119028091
right_count:329	total:433	 Answer ACC: 0.7598152424942263
right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:44	wrong_total:104	 wrong be tree ACC: 0.4230769230769231
right_checker:1665	total:1974	checker ACC: 0.8434650897979736	temp:0	temp1:0	wrong_total:104	


epoch:106,	loss:0.253772117808694	loss1:214.01766180992126
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1668	total:1974	checker ACC: 0.8449848294258118	temp:0	temp1:0	wrong_total:102	


epoch:107,	loss:0.25048212078399956	loss1:220.92788207530975
right_count:333	total:433	 Answer ACC: 0.76905311778291
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:45	wrong_total:100	 wrong be tree ACC: 0.45
right_checker:1658	total:1974	checker ACC: 0.8399189710617065	temp:0	temp1:0	wrong_total:100	


epoch:108,	loss:0.24647480703424662	loss1:247.09565556049347
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:41	wrong_total:102	 wrong be tree ACC: 0.4019607843137255
right_checker:1676	total:1974	checker ACC: 0.8490375280380249	temp:0	temp1:0	wrong_total:102	


epoch:109,	loss:0.24819194991141558	loss1:219.3091995716095
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:101	 wrong be tree ACC: 0.42574257425742573
right_checker:1672	total:1974	checker ACC: 0.8470112085342407	temp:0	temp1:0	wrong_total:101	


epoch:110,	loss:0.24590901972260326	loss1:219.81823480129242
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:101	 wrong be tree ACC: 0.42574257425742573
right_checker:1672	total:1974	checker ACC: 0.8470112085342407	temp:0	temp1:0	wrong_total:101	


epoch:111,	loss:0.24713001173222438	loss1:233.38023847341537
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:44	wrong_total:101	 wrong be tree ACC: 0.43564356435643564
right_checker:1659	total:1974	checker ACC: 0.8404255509376526	temp:0	temp1:0	wrong_total:101	


epoch:112,	loss:0.2604868223425001	loss1:221.62391078472137
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:45	wrong_total:101	 wrong be tree ACC: 0.44554455445544555
right_checker:1669	total:1974	checker ACC: 0.8454914093017578	temp:0	temp1:0	wrong_total:101	


epoch:113,	loss:0.2422967494931072	loss1:245.97281205654144
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:42	wrong_total:102	 wrong be tree ACC: 0.4117647058823529
right_checker:1669	total:1974	checker ACC: 0.8454914093017578	temp:0	temp1:0	wrong_total:102	


epoch:114,	loss:0.2493701073108241	loss1:238.56196305155754
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
right_checker:1683	total:1974	checker ACC: 0.852583646774292	temp:0	temp1:0	wrong_total:101	


epoch:115,	loss:0.2528203490655869	loss1:226.55010491609573
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
right_checker:1671	total:1974	checker ACC: 0.8465046286582947	temp:0	temp1:0	wrong_total:102	


epoch:116,	loss:0.24104927480220795	loss1:238.89436620473862
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1734	total:1974	Code ACC: 0.878419452887538	wrong_be_tree_count:42	wrong_total:102	 wrong be tree ACC: 0.4117647058823529
right_checker:1675	total:1974	checker ACC: 0.8485309481620789	temp:0	temp1:0	wrong_total:102	


epoch:117,	loss:0.25112378306221217	loss1:218.71445819735527
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:40	wrong_total:101	 wrong be tree ACC: 0.39603960396039606
right_checker:1674	total:1974	checker ACC: 0.8480243682861328	temp:0	temp1:0	wrong_total:101	


epoch:118,	loss:0.25057087338063866	loss1:244.23677650094032
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:41	wrong_total:102	 wrong be tree ACC: 0.4019607843137255
right_checker:1676	total:1974	checker ACC: 0.8490375280380249	temp:0	temp1:0	wrong_total:102	


epoch:119,	loss:0.2554330660495907	loss1:234.51929569244385
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1668	total:1974	checker ACC: 0.8449848294258118	temp:0	temp1:0	wrong_total:102	


epoch:120,	loss:0.24242273974232376	loss1:215.01563031971455
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:44	wrong_total:101	 wrong be tree ACC: 0.43564356435643564
right_checker:1669	total:1974	checker ACC: 0.8454914093017578	temp:0	temp1:0	wrong_total:101	


epoch:121,	loss:0.24537677969783545	loss1:223.92287185043097
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:122,	loss:0.24627903674263507	loss1:219.14447006583214
right_count:332	total:433	 Answer ACC: 0.766743648960739
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:101	 wrong be tree ACC: 0.42574257425742573
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:101	


epoch:123,	loss:0.24531971872784197	loss1:229.53245481848717
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:124,	loss:0.23685210873372853	loss1:205.93171221017838
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:125,	loss:0.2429425895679742	loss1:217.59643763303757
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1674	total:1974	checker ACC: 0.8480243682861328	temp:0	temp1:0	wrong_total:102	


epoch:126,	loss:0.23972591035999358	loss1:216.38081896305084
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:127,	loss:0.246993649401702	loss1:194.60689271986485
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:128,	loss:0.23405156144872308	loss1:214.64834009110928
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	


epoch:129,	loss:0.22923336958047003	loss1:221.63748109340668
right_count:331	total:433	 Answer ACC: 0.7644341801385681
right_codes_count:1738	total:1974	Code ACC: 0.8804457953394124	wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
right_checker:1673	total:1974	checker ACC: 0.8475177884101868	temp:0	temp1:0	wrong_total:102	



final_test
right_count:337	total:433	 Answer ACC: 0.7782909930715936
right_codes_count:1742	total:1974	Code ACC: 0.8824721377912867	wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
right_checker:1679	total:1974	checker ACC: 0.850557267665863	temp:0	temp1:0	wrong_total:96	
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
final_test
Answer acc:0.7782909930715936


usage: train_0.py [-h] [--log_file LOG_FILE] [--mode MODE] [--seed SEED]
                  [--num_labels NUM_LABELS] [--train_type TRAIN_TYPE]
                  [--re_process_train_data RE_PROCESS_TRAIN_DATA]
                  [--deal_data_imbalance DEAL_DATA_IMBALANCE]
                  [--multi_fc MULTI_FC] [--fc_hidden_size FC_HIDDEN_SIZE]
                  [--use_cls USE_CLS] [--train_max_len TRAIN_MAX_LEN]
                  [--test_dev_max_len TEST_DEV_MAX_LEN]
                  [--use_new_token_type_id USE_NEW_TOKEN_TYPE_ID]
                  [--train_loss TRAIN_LOSS] [--use_multi_gpu USE_MULTI_GPU]
                  [--batch_size BATCH_SIZE] [--num_epochs NUM_EPOCHS]
                  [--lr LR] [--bert_lr BERT_LR] [--warmup WARMUP]
                  [--fc_path FC_PATH]
                  [--pretrain_model_path PRETRAIN_MODEL_PATH]
                  [--train_data_path TRAIN_DATA_PATH]
                  [--dev_data_path DEV_DATA_PATH]
                  [--label2id_path LABEL2ID_PATH] [--gpu_device GPU_DEVICE]
                  [--output_dir OUTPUT_DIR] [--model_name MODEL_NAME]
train_0.py: error: unrecognized arguments: batch_size 4



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 26098.33it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 30127.80it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning


epoch:0,	loss:194.05048590898514	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:369	total:1974	Code ACC: 0.18693009118541035	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1595	total:1974	checker ACC: 0.8080040812492371	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_0.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 235, in train
    refiner.save(save_dir=best_model_dir)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 714, in save
    torch.save(self.ln_code.state_dict(), os.path.join(save_dir, 'ln_code.bin'))
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1270, in __getattr__
    type(self).__name__, name))
AttributeError: 'Refiner' object has no attribute 'ln_code'



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 30807.34it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 32424.59it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning


epoch:0,	loss:115.88431833684444	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:85	total:1974	Code ACC: 0.04305977710233029	wrong_be_tree_count:430	wrong_total:433	 wrong be tree ACC: 0.9930715935334873
right_checker:1845	total:1974	checker ACC: 0.9346504807472229	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:1,	loss:27.148178108036518	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:875	total:1974	Code ACC: 0.4432624113475177	wrong_be_tree_count:432	wrong_total:433	 wrong be tree ACC: 0.9976905311778291
right_checker:1090	total:1974	checker ACC: 0.5521783232688904	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 29162.11it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 33759.01it/s]
define model...



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 30256.63it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 30543.27it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning


epoch:0,	loss:66.48066291213036	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:35	total:1974	Code ACC: 0.01773049645390071	wrong_be_tree_count:346	wrong_total:433	 wrong be tree ACC: 0.7990762124711316
right_checker:1850	total:1974	checker ACC: 0.9371834397315979	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 21555.19it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 33696.38it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_0.py", line 67, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 183, in train
    loss,outputs,p_hidden = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, num_codes_labels=num_codes_labels)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 543, in forward
    t5out = self.t5(input_ids = input_ids, attention_mask=attention_mask)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/model_t5.py", line 996, in forward
    output_hidden_states=output_hidden_states,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/model_t5.py", line 837, in forward
    output_attentions=output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/model_t5.py", line 509, in forward
    output_attentions=output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/model_t5.py", line 416, in forward
    output_attentions=output_attentions,
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/model_t5.py", line 334, in forward
    k = shape(self.k(input))  # (bs, n_heads, qlen, dim_per_head)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.75 GiB total capacity; 16.95 GiB already allocated; 14.19 MiB free; 17.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF



/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
get train data loader...
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 30042.42it/s]
get dev data loader...
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 30338.17it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/envs/UTSC/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning


epoch:0,	loss:35.865194499492645	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:0	total:1974	Code ACC: 0.0	wrong_be_tree_count:426	wrong_total:433	 wrong be tree ACC: 0.9838337182448037
right_checker:1834	total:1974	checker ACC: 0.9290780425071716	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:1,	loss:20.86272232234478	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:204	total:1974	Code ACC: 0.1033434650455927	wrong_be_tree_count:432	wrong_total:433	 wrong be tree ACC: 0.9976905311778291
right_checker:1746	total:1974	checker ACC: 0.8844985365867615	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:2,	loss:6.935972109436989	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:598	total:1974	Code ACC: 0.3029381965552178	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1374	total:1974	checker ACC: 0.6960486769676208	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:3,	loss:4.791745588183403	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:910	total:1974	Code ACC: 0.46099290780141844	wrong_be_tree_count:432	wrong_total:433	 wrong be tree ACC: 0.9976905311778291
right_checker:1057	total:1974	checker ACC: 0.5354610085487366	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:4,	loss:4.18403447419405	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:911	total:1974	Code ACC: 0.461499493414387	wrong_be_tree_count:414	wrong_total:433	 wrong be tree ACC: 0.9561200923787528
right_checker:1050	total:1974	checker ACC: 0.5319149494171143	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:5,	loss:3.702866293489933	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:926	total:1974	Code ACC: 0.4690982776089159	wrong_be_tree_count:383	wrong_total:433	 wrong be tree ACC: 0.8845265588914549
right_checker:1005	total:1974	checker ACC: 0.5091185569763184	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:6,	loss:3.4398780912160873	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:960	total:1974	Code ACC: 0.48632218844984804	wrong_be_tree_count:342	wrong_total:433	 wrong be tree ACC: 0.789838337182448
right_checker:874	total:1974	checker ACC: 0.4427558481693268	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:7,	loss:3.1688848957419395	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:967	total:1974	Code ACC: 0.4898682877406282	wrong_be_tree_count:350	wrong_total:433	 wrong be tree ACC: 0.8083140877598153
right_checker:861	total:1974	checker ACC: 0.43617022037506104	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:8,	loss:2.9548685178160667	loss1:3792.8474745750427
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1086	total:1974	Code ACC: 0.5501519756838906	wrong_be_tree_count:227	wrong_total:433	 wrong be tree ACC: 0.5242494226327945
right_checker:1239	total:1974	checker ACC: 0.6276596188545227	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:9,	loss:2.7471585609018803	loss1:2767.8749494552612
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1086	total:1974	Code ACC: 0.5501519756838906	wrong_be_tree_count:240	wrong_total:433	 wrong be tree ACC: 0.5542725173210161
right_checker:1260	total:1974	checker ACC: 0.6382979154586792	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:10,	loss:2.5992829464375973	loss1:2248.088285803795
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1071	total:1974	Code ACC: 0.5425531914893617	wrong_be_tree_count:263	wrong_total:433	 wrong be tree ACC: 0.6073903002309469
right_checker:1196	total:1974	checker ACC: 0.6058764457702637	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:11,	loss:2.34249409660697	loss1:2036.081680893898
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1140	total:1974	Code ACC: 0.5775075987841946	wrong_be_tree_count:220	wrong_total:433	 wrong be tree ACC: 0.5080831408775982
right_checker:1291	total:1974	checker ACC: 0.6540020704269409	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:12,	loss:2.232553742825985	loss1:1927.3501477241516
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1138	total:1974	Code ACC: 0.5764944275582573	wrong_be_tree_count:215	wrong_total:433	 wrong be tree ACC: 0.49653579676674364
right_checker:1256	total:1974	checker ACC: 0.6362715363502502	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:13,	loss:2.0729288663715124	loss1:1750.4174799919128
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1139	total:1974	Code ACC: 0.577001013171226	wrong_be_tree_count:213	wrong_total:433	 wrong be tree ACC: 0.49191685912240185
right_checker:1284	total:1974	checker ACC: 0.6504559516906738	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:14,	loss:1.8861456215381622	loss1:1644.6011600494385
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1184	total:1974	Code ACC: 0.5997973657548126	wrong_be_tree_count:189	wrong_total:433	 wrong be tree ACC: 0.43648960739030024
right_checker:1260	total:1974	checker ACC: 0.6382979154586792	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:15,	loss:1.7144735539332032	loss1:1445.6897716522217
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1249	total:1974	Code ACC: 0.632725430597771	wrong_be_tree_count:145	wrong_total:433	 wrong be tree ACC: 0.3348729792147806
right_checker:1347	total:1974	checker ACC: 0.6823708415031433	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:16,	loss:1.5565081969834864	loss1:1378.8052577972412
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1231	total:1974	Code ACC: 0.6236068895643364	wrong_be_tree_count:166	wrong_total:433	 wrong be tree ACC: 0.3833718244803695
right_checker:1320	total:1974	checker ACC: 0.6686930656433105	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:17,	loss:1.4485863391309977	loss1:1278.0198147296906
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1277	total:1974	Code ACC: 0.6469098277608916	wrong_be_tree_count:160	wrong_total:433	 wrong be tree ACC: 0.3695150115473441
right_checker:1385	total:1974	checker ACC: 0.7016211152076721	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:18,	loss:1.3292969344183803	loss1:1146.0004234313965
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1332	total:1974	Code ACC: 0.6747720364741642	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1412	total:1974	checker ACC: 0.7152989506721497	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:19,	loss:1.26534184650518	loss1:1051.2386569976807
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1306	total:1974	Code ACC: 0.6616008105369807	wrong_be_tree_count:141	wrong_total:433	 wrong be tree ACC: 0.325635103926097
right_checker:1364	total:1974	checker ACC: 0.6909828186035156	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:20,	loss:1.1171153215691447	loss1:947.2075576782227
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1337	total:1974	Code ACC: 0.6773049645390071	wrong_be_tree_count:117	wrong_total:433	 wrong be tree ACC: 0.2702078521939954
right_checker:1392	total:1974	checker ACC: 0.7051672339439392	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:21,	loss:1.0968180485069752	loss1:932.22651720047
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1340	total:1974	Code ACC: 0.6788247213779128	wrong_be_tree_count:129	wrong_total:433	 wrong be tree ACC: 0.2979214780600462
right_checker:1416	total:1974	checker ACC: 0.7173252701759338	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:22,	loss:0.987505842349492	loss1:816.1661534309387
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1355	total:1974	Code ACC: 0.6864235055724417	wrong_be_tree_count:122	wrong_total:433	 wrong be tree ACC: 0.2817551963048499
right_checker:1388	total:1974	checker ACC: 0.7031408548355103	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:23,	loss:0.9782650610432029	loss1:747.5661380290985
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1360	total:1974	Code ACC: 0.6889564336372846	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1418	total:1974	checker ACC: 0.7183384299278259	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:24,	loss:0.8786187143996358	loss1:725.6606477499008
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1403	total:1974	Code ACC: 0.7107396149949341	wrong_be_tree_count:98	wrong_total:433	 wrong be tree ACC: 0.22632794457274827
right_checker:1473	total:1974	checker ACC: 0.7462006211280823	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:25,	loss:0.8304023531964049	loss1:724.9748488664627
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1402	total:1974	Code ACC: 0.7102330293819655	wrong_be_tree_count:99	wrong_total:433	 wrong be tree ACC: 0.22863741339491916
right_checker:1458	total:1974	checker ACC: 0.7386018633842468	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:26,	loss:0.7775628855451941	loss1:668.4385042190552
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1416	total:1974	Code ACC: 0.7173252279635258	wrong_be_tree_count:98	wrong_total:433	 wrong be tree ACC: 0.22632794457274827
right_checker:1470	total:1974	checker ACC: 0.7446808815002441	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:27,	loss:0.8521194201894104	loss1:638.5767936706543
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:107	wrong_total:433	 wrong be tree ACC: 0.2471131639722864
right_checker:1480	total:1974	checker ACC: 0.7497467398643494	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:28,	loss:0.7478790744207799	loss1:610.9933851957321
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:117	wrong_total:433	 wrong be tree ACC: 0.2702078521939954
right_checker:1455	total:1974	checker ACC: 0.7370821237564087	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:29,	loss:0.6786751393228769	loss1:531.256863117218
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:97	wrong_total:433	 wrong be tree ACC: 0.22401847575057737
right_checker:1494	total:1974	checker ACC: 0.7568389177322388	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:30,	loss:0.6620617960579693	loss1:471.01331412792206
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1403	total:1974	Code ACC: 0.7107396149949341	wrong_be_tree_count:92	wrong_total:433	 wrong be tree ACC: 0.21247113163972287
right_checker:1483	total:1974	checker ACC: 0.7512664794921875	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:31,	loss:0.6321349730715156	loss1:546.3727865219116
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1421	total:1974	Code ACC: 0.7198581560283688	wrong_be_tree_count:99	wrong_total:433	 wrong be tree ACC: 0.22863741339491916
right_checker:1494	total:1974	checker ACC: 0.7568389177322388	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:32,	loss:0.6008004872128367	loss1:468.2316863536835
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1416	total:1974	Code ACC: 0.7173252279635258	wrong_be_tree_count:93	wrong_total:433	 wrong be tree ACC: 0.21478060046189376
right_checker:1504	total:1974	checker ACC: 0.761904776096344	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:33,	loss:0.5399293745867908	loss1:439.8663182258606
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1414	total:1974	Code ACC: 0.7163120567375887	wrong_be_tree_count:87	wrong_total:433	 wrong be tree ACC: 0.20092378752886836
right_checker:1507	total:1974	checker ACC: 0.7634245753288269	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:34,	loss:0.5225249432260171	loss1:394.02865862846375
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:35,	loss:0.5186265904922038	loss1:385.5213926434517
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1443	total:1974	Code ACC: 0.7310030395136778	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1499	total:1974	checker ACC: 0.7593718767166138	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:36,	loss:0.5221712931524962	loss1:378.0131924152374
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1447	total:1974	Code ACC: 0.7330293819655522	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1477	total:1974	checker ACC: 0.7482270002365112	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:37,	loss:0.5003010514192283	loss1:397.8664073944092
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1439	total:1974	Code ACC: 0.7289766970618035	wrong_be_tree_count:84	wrong_total:433	 wrong be tree ACC: 0.19399538106235567
right_checker:1538	total:1974	checker ACC: 0.7791287302970886	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:38,	loss:0.46320012025535107	loss1:347.3948242664337
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1433	total:1974	Code ACC: 0.7259371833839919	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:39,	loss:0.4539700093737338	loss1:359.0913369655609
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1449	total:1974	Code ACC: 0.7340425531914894	wrong_be_tree_count:86	wrong_total:433	 wrong be tree ACC: 0.19861431870669746
right_checker:1559	total:1974	checker ACC: 0.7897670269012451	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:40,	loss:0.4501942712813616	loss1:345.1590212583542
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1464	total:1974	Code ACC: 0.7416413373860182	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1548	total:1974	checker ACC: 0.7841945886611938	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:41,	loss:0.48029620037414134	loss1:374.26301085948944
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:75	wrong_total:433	 wrong be tree ACC: 0.17321016166281755
right_checker:1523	total:1974	checker ACC: 0.7715299129486084	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:42,	loss:0.4394821970781777	loss1:346.4882434606552
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:73	wrong_total:433	 wrong be tree ACC: 0.16859122401847576
right_checker:1531	total:1974	checker ACC: 0.7755826115608215	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:43,	loss:0.4179809794295579	loss1:300.60177806019783
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1436	total:1974	Code ACC: 0.7274569402228976	wrong_be_tree_count:93	wrong_total:433	 wrong be tree ACC: 0.21478060046189376
right_checker:1562	total:1974	checker ACC: 0.7912867665290833	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:44,	loss:0.3958396641537547	loss1:312.58736205101013
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1433	total:1974	Code ACC: 0.7259371833839919	wrong_be_tree_count:92	wrong_total:433	 wrong be tree ACC: 0.21247113163972287
right_checker:1546	total:1974	checker ACC: 0.783181369304657	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:45,	loss:0.4169051687931642	loss1:293.84292712807655
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1445	total:1974	Code ACC: 0.732016210739615	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1566	total:1974	checker ACC: 0.7933130860328674	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:46,	loss:0.3692036625579931	loss1:307.4117519855499
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1577	total:1974	checker ACC: 0.7988855242729187	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:47,	loss:0.4075749386101961	loss1:277.51914098858833
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1435	total:1974	Code ACC: 0.7269503546099291	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1541	total:1974	checker ACC: 0.7806484699249268	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:48,	loss:0.3863347276346758	loss1:276.7135510444641
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1569	total:1974	checker ACC: 0.7948328852653503	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:49,	loss:0.35748971917200834	loss1:245.74523013830185
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1450	total:1974	Code ACC: 0.7345491388044579	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1583	total:1974	checker ACC: 0.8019250631332397	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:50,	loss:0.3287411543133203	loss1:223.69274008274078
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1450	total:1974	Code ACC: 0.7345491388044579	wrong_be_tree_count:92	wrong_total:433	 wrong be tree ACC: 0.21247113163972287
right_checker:1578	total:1974	checker ACC: 0.7993921637535095	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:51,	loss:0.3572125881910324	loss1:265.55439043045044
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1425	total:1974	Code ACC: 0.7218844984802432	wrong_be_tree_count:97	wrong_total:433	 wrong be tree ACC: 0.22401847575057737
right_checker:1548	total:1974	checker ACC: 0.7841945886611938	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:52,	loss:0.3516907018929487	loss1:250.48479303717613
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1469	total:1974	Code ACC: 0.7441742654508612	wrong_be_tree_count:75	wrong_total:433	 wrong be tree ACC: 0.17321016166281755
right_checker:1574	total:1974	checker ACC: 0.7973657846450806	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:53,	loss:0.3627998939482495	loss1:248.70057007670403
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1450	total:1974	Code ACC: 0.7345491388044579	wrong_be_tree_count:74	wrong_total:433	 wrong be tree ACC: 0.17090069284064666
right_checker:1580	total:1974	checker ACC: 0.8004053235054016	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:54,	loss:0.3364357583341189	loss1:237.00001016259193
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1447	total:1974	Code ACC: 0.7330293819655522	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1576	total:1974	checker ACC: 0.7983789443969727	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:55,	loss:0.32108621788211167	loss1:236.47440892457962
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1449	total:1974	Code ACC: 0.7340425531914894	wrong_be_tree_count:75	wrong_total:433	 wrong be tree ACC: 0.17321016166281755
right_checker:1578	total:1974	checker ACC: 0.7993921637535095	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:56,	loss:0.32188039750326425	loss1:232.78553719818592
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1444	total:1974	Code ACC: 0.7315096251266464	wrong_be_tree_count:71	wrong_total:433	 wrong be tree ACC: 0.16397228637413394
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:57,	loss:0.31938881627866067	loss1:233.8108403980732
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1427	total:1974	Code ACC: 0.7228976697061803	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1574	total:1974	checker ACC: 0.7973657846450806	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:58,	loss:0.307157545175869	loss1:204.5292630493641
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1454	total:1974	Code ACC: 0.7365754812563323	wrong_be_tree_count:84	wrong_total:433	 wrong be tree ACC: 0.19399538106235567
right_checker:1576	total:1974	checker ACC: 0.7983789443969727	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:59,	loss:0.30909886746667325	loss1:211.87634625658393
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1577	total:1974	checker ACC: 0.7988855242729187	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:60,	loss:0.32018683203932596	loss1:200.73434364795685
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1456	total:1974	Code ACC: 0.7375886524822695	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1561	total:1974	checker ACC: 0.7907801866531372	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:61,	loss:0.28433362930081785	loss1:178.32388070225716
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1473	total:1974	Code ACC: 0.7462006079027356	wrong_be_tree_count:87	wrong_total:433	 wrong be tree ACC: 0.20092378752886836
right_checker:1576	total:1974	checker ACC: 0.7983789443969727	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:62,	loss:0.28246212226804346	loss1:157.66213631629944
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1460	total:1974	Code ACC: 0.7396149949341438	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1581	total:1974	checker ACC: 0.8009119033813477	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:63,	loss:0.2809691039728932	loss1:182.36379151046276
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:64,	loss:0.27086670021526515	loss1:182.3030939400196
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:73	wrong_total:433	 wrong be tree ACC: 0.16859122401847576
right_checker:1588	total:1974	checker ACC: 0.8044580221176147	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:65,	loss:0.32910447171889246	loss1:200.62007945030928
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1442	total:1974	Code ACC: 0.7304964539007093	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1560	total:1974	checker ACC: 0.7902736067771912	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:66,	loss:0.325932547042612	loss1:224.43414014577866
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1447	total:1974	Code ACC: 0.7330293819655522	wrong_be_tree_count:87	wrong_total:433	 wrong be tree ACC: 0.20092378752886836
right_checker:1581	total:1974	checker ACC: 0.8009119033813477	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:67,	loss:0.305234540021047	loss1:202.07184547185898
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1452	total:1974	Code ACC: 0.7355623100303952	wrong_be_tree_count:85	wrong_total:433	 wrong be tree ACC: 0.19630484988452657
right_checker:1567	total:1974	checker ACC: 0.7938196659088135	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:68,	loss:0.2968907265458256	loss1:207.3099581450224
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:76	wrong_total:433	 wrong be tree ACC: 0.17551963048498845
right_checker:1593	total:1974	checker ACC: 0.806990921497345	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:69,	loss:0.2655433719919529	loss1:147.88590890169144
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1446	total:1974	Code ACC: 0.7325227963525835	wrong_be_tree_count:91	wrong_total:433	 wrong be tree ACC: 0.21016166281755197
right_checker:1574	total:1974	checker ACC: 0.7973657846450806	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:70,	loss:0.2676666653715074	loss1:186.30431884527206
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1452	total:1974	Code ACC: 0.7355623100303952	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:71,	loss:0.270982154768717	loss1:181.11840507388115
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:73	wrong_total:433	 wrong be tree ACC: 0.16859122401847576
right_checker:1590	total:1974	checker ACC: 0.8054711818695068	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:72,	loss:0.266803533420898	loss1:169.22143371403217
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1429	total:1974	Code ACC: 0.7239108409321175	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1545	total:1974	checker ACC: 0.7826747894287109	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:73,	loss:0.26179114129627123	loss1:154.2330935150385
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1456	total:1974	Code ACC: 0.7375886524822695	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1569	total:1974	checker ACC: 0.7948328852653503	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:74,	loss:0.2504529979196377	loss1:148.9542595744133
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1472	total:1974	Code ACC: 0.745694022289767	wrong_be_tree_count:84	wrong_total:433	 wrong be tree ACC: 0.19399538106235567
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:75,	loss:0.2503440155123826	loss1:161.60254257917404
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1446	total:1974	Code ACC: 0.7325227963525835	wrong_be_tree_count:84	wrong_total:433	 wrong be tree ACC: 0.19399538106235567
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:76,	loss:0.254668700217735	loss1:166.04721604287624
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1435	total:1974	Code ACC: 0.7269503546099291	wrong_be_tree_count:89	wrong_total:433	 wrong be tree ACC: 0.20554272517321015
right_checker:1569	total:1974	checker ACC: 0.7948328852653503	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:77,	loss:0.2524787959991954	loss1:155.7220251262188
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1452	total:1974	Code ACC: 0.7355623100303952	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1555	total:1974	checker ACC: 0.7877406477928162	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:78,	loss:0.24266651549260132	loss1:164.90471851825714
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1464	total:1974	Code ACC: 0.7416413373860182	wrong_be_tree_count:87	wrong_total:433	 wrong be tree ACC: 0.20092378752886836
right_checker:1579	total:1974	checker ACC: 0.7998987436294556	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:79,	loss:0.23605056090309517	loss1:129.03293377906084
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1455	total:1974	Code ACC: 0.7370820668693009	wrong_be_tree_count:89	wrong_total:433	 wrong be tree ACC: 0.20554272517321015
right_checker:1577	total:1974	checker ACC: 0.7988855242729187	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:80,	loss:0.2478541777236387	loss1:143.01932683587074
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1472	total:1974	Code ACC: 0.745694022289767	wrong_be_tree_count:81	wrong_total:433	 wrong be tree ACC: 0.18706697459584296
right_checker:1579	total:1974	checker ACC: 0.7998987436294556	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:81,	loss:0.2322708625215455	loss1:156.8058504909277
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1462	total:1974	Code ACC: 0.7406281661600811	wrong_be_tree_count:69	wrong_total:433	 wrong be tree ACC: 0.15935334872979215
right_checker:1598	total:1974	checker ACC: 0.8095238208770752	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:82,	loss:0.2778395411733072	loss1:148.04498210549355
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1577	total:1974	checker ACC: 0.7988855242729187	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:83,	loss:0.3099213283858262	loss1:149.3234411291778
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:71	wrong_total:433	 wrong be tree ACC: 0.16397228637413394
right_checker:1585	total:1974	checker ACC: 0.8029382228851318	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:84,	loss:0.2539713308906357	loss1:153.30845794081688
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1461	total:1974	Code ACC: 0.7401215805471124	wrong_be_tree_count:72	wrong_total:433	 wrong be tree ACC: 0.16628175519630484
right_checker:1591	total:1974	checker ACC: 0.8059777617454529	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:85,	loss:0.23618447285844013	loss1:143.14524649828672
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1476	total:1974	Code ACC: 0.7477203647416414	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1580	total:1974	checker ACC: 0.8004053235054016	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:86,	loss:0.23299662110730424	loss1:139.75110182911158
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1576	total:1974	checker ACC: 0.7983789443969727	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:87,	loss:0.23410108397365548	loss1:135.16851983964443
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1460	total:1974	Code ACC: 0.7396149949341438	wrong_be_tree_count:74	wrong_total:433	 wrong be tree ACC: 0.17090069284064666
right_checker:1578	total:1974	checker ACC: 0.7993921637535095	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:88,	loss:0.22737170009349938	loss1:129.8497083261609
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1454	total:1974	Code ACC: 0.7365754812563323	wrong_be_tree_count:81	wrong_total:433	 wrong be tree ACC: 0.18706697459584296
right_checker:1573	total:1974	checker ACC: 0.7968592047691345	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:89,	loss:0.23347018420463428	loss1:121.3322478979826
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1458	total:1974	Code ACC: 0.7386018237082067	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1584	total:1974	checker ACC: 0.8024316430091858	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:90,	loss:0.2349499549018219	loss1:136.27801276743412
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1463	total:1974	Code ACC: 0.7411347517730497	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1573	total:1974	checker ACC: 0.7968592047691345	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:91,	loss:0.2332469298853539	loss1:137.5618334710598
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1451	total:1974	Code ACC: 0.7350557244174265	wrong_be_tree_count:74	wrong_total:433	 wrong be tree ACC: 0.17090069284064666
right_checker:1578	total:1974	checker ACC: 0.7993921637535095	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:92,	loss:0.2479710552142933	loss1:139.79872873425484
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1450	total:1974	Code ACC: 0.7345491388044579	wrong_be_tree_count:85	wrong_total:433	 wrong be tree ACC: 0.19630484988452657
right_checker:1574	total:1974	checker ACC: 0.7973657846450806	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:93,	loss:0.2375021726184059	loss1:136.38043424487114
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1454	total:1974	Code ACC: 0.7365754812563323	wrong_be_tree_count:73	wrong_total:433	 wrong be tree ACC: 0.16859122401847576
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:94,	loss:0.22154285029682796	loss1:131.0967635549605
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:74	wrong_total:433	 wrong be tree ACC: 0.17090069284064666
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:95,	loss:0.21768998719198862	loss1:111.811334842816
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1468	total:1974	Code ACC: 0.7436676798378926	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1572	total:1974	checker ACC: 0.7963526248931885	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:96,	loss:0.21671338414307684	loss1:117.45919068157673
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1470	total:1974	Code ACC: 0.7446808510638298	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:97,	loss:0.2261461575399153	loss1:123.40793783962727
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1464	total:1974	Code ACC: 0.7416413373860182	wrong_be_tree_count:85	wrong_total:433	 wrong be tree ACC: 0.19630484988452657
right_checker:1566	total:1974	checker ACC: 0.7933130860328674	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:98,	loss:0.22118573216721416	loss1:114.14257840812206
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1469	total:1974	Code ACC: 0.7441742654508612	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1573	total:1974	checker ACC: 0.7968592047691345	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:99,	loss:0.21706812590855407	loss1:130.7142865806818
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1566	total:1974	checker ACC: 0.7933130860328674	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:100,	loss:0.22767802653834224	loss1:121.98408019542694
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1470	total:1974	Code ACC: 0.7446808510638298	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1561	total:1974	checker ACC: 0.7907801866531372	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:101,	loss:0.21317238709889352	loss1:127.80874366313219
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1457	total:1974	Code ACC: 0.7380952380952381	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1568	total:1974	checker ACC: 0.7943263053894043	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:102,	loss:0.21414420023211278	loss1:118.1483659222722
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1463	total:1974	Code ACC: 0.7411347517730497	wrong_be_tree_count:75	wrong_total:433	 wrong be tree ACC: 0.17321016166281755
right_checker:1562	total:1974	checker ACC: 0.7912867665290833	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:103,	loss:0.20671912006218918	loss1:103.38172227144241
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:77	wrong_total:433	 wrong be tree ACC: 0.17782909930715934
right_checker:1565	total:1974	checker ACC: 0.7928065061569214	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:104,	loss:0.23067800153512508	loss1:111.9397092871368
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1462	total:1974	Code ACC: 0.7406281661600811	wrong_be_tree_count:76	wrong_total:433	 wrong be tree ACC: 0.17551963048498845
right_checker:1566	total:1974	checker ACC: 0.7933130860328674	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:105,	loss:0.2120609834601055	loss1:121.93179097026587
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:73	wrong_total:433	 wrong be tree ACC: 0.16859122401847576
right_checker:1570	total:1974	checker ACC: 0.7953394651412964	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:106,	loss:0.20949904166627675	loss1:119.22616126388311
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1472	total:1974	Code ACC: 0.745694022289767	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1562	total:1974	checker ACC: 0.7912867665290833	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:107,	loss:0.21079578962053347	loss1:113.13666232302785
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1468	total:1974	Code ACC: 0.7436676798378926	wrong_be_tree_count:75	wrong_total:433	 wrong be tree ACC: 0.17321016166281755
right_checker:1565	total:1974	checker ACC: 0.7928065061569214	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:108,	loss:0.20960450445272727	loss1:127.35482807457447
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:76	wrong_total:433	 wrong be tree ACC: 0.17551963048498845
right_checker:1566	total:1974	checker ACC: 0.7933130860328674	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:109,	loss:0.22049892280483618	loss1:122.39172707498074
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1463	total:1974	Code ACC: 0.7411347517730497	wrong_be_tree_count:76	wrong_total:433	 wrong be tree ACC: 0.17551963048498845
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:110,	loss:0.23273617430822924	loss1:113.44906192272902
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1469	total:1974	Code ACC: 0.7441742654508612	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1558	total:1974	checker ACC: 0.7892604470252991	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:111,	loss:0.2028137994930148	loss1:102.6842400226742
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1459	total:1974	Code ACC: 0.7391084093211753	wrong_be_tree_count:78	wrong_total:433	 wrong be tree ACC: 0.18013856812933027
right_checker:1565	total:1974	checker ACC: 0.7928065061569214	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:112,	loss:0.20978100306820124	loss1:109.34323811531067
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1559	total:1974	checker ACC: 0.7897670269012451	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:113,	loss:0.20617192814825103	loss1:126.59915262460709
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1457	total:1974	Code ACC: 0.7380952380952381	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1552	total:1974	checker ACC: 0.786220908164978	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:114,	loss:0.20718219474656507	loss1:105.44517546147108
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:81	wrong_total:433	 wrong be tree ACC: 0.18706697459584296
right_checker:1559	total:1974	checker ACC: 0.7897670269012451	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:115,	loss:0.20264200793462805	loss1:112.1082314774394
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1460	total:1974	Code ACC: 0.7396149949341438	wrong_be_tree_count:79	wrong_total:433	 wrong be tree ACC: 0.18244803695150116
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:116,	loss:0.2057052007439779	loss1:105.2046789675951
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1467	total:1974	Code ACC: 0.743161094224924	wrong_be_tree_count:81	wrong_total:433	 wrong be tree ACC: 0.18706697459584296
right_checker:1569	total:1974	checker ACC: 0.7948328852653503	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:117,	loss:0.21240060552372597	loss1:113.62897717952728
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1466	total:1974	Code ACC: 0.7426545086119554	wrong_be_tree_count:80	wrong_total:433	 wrong be tree ACC: 0.18475750577367206
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:118,	loss:0.20118725221436762	loss1:101.28271001577377
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1560	total:1974	checker ACC: 0.7902736067771912	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:119,	loss:0.2145578953786753	loss1:120.0657636076212
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1561	total:1974	checker ACC: 0.7907801866531372	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:120,	loss:0.21857825538609177	loss1:106.41412641108036
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1463	total:1974	Code ACC: 0.7411347517730497	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:121,	loss:0.20124976402439643	loss1:110.36765117384493
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1464	total:1974	Code ACC: 0.7416413373860182	wrong_be_tree_count:81	wrong_total:433	 wrong be tree ACC: 0.18706697459584296
right_checker:1561	total:1974	checker ACC: 0.7907801866531372	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:122,	loss:0.19862103804189246	loss1:104.2071195654571
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1464	total:1974	Code ACC: 0.7416413373860182	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1562	total:1974	checker ACC: 0.7912867665290833	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:123,	loss:0.20063080984982662	loss1:107.8762639388442
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:124,	loss:0.20497448145761155	loss1:121.80691056884825
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:125,	loss:0.19991391360235866	loss1:112.83637489378452
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:83	wrong_total:433	 wrong be tree ACC: 0.19168591224018475
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:126,	loss:0.20512618621069123	loss1:110.66255825012922
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:127,	loss:0.2083099507726729	loss1:102.21392306685448
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:128,	loss:0.2122136283724103	loss1:120.74256446026266
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:129,	loss:0.19649325907448656	loss1:113.99320924282074
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model



final_test
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1465	total:1974	Code ACC: 0.7421479229989868	wrong_be_tree_count:82	wrong_total:433	 wrong be tree ACC: 0.18937644341801385
right_checker:1563	total:1974	checker ACC: 0.7917933464050293	temp:0	temp1:0	wrong_total:433	
total input dataset len: 1730
after process dataset len: 1730
total passed: 0
total input dataset len: 433
after process dataset len: 433
total passed: 0
final_test
Answer acc:0.0





/data/zhyma/miniconda3/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 36452.60it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 39736.86it/s]
define model...

>>>>>>>>>>>>>>>>>>>start train......
/data/zhyma/miniconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:830: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(


epoch:0,	loss:18.81553292274475	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:0	total:1974	Code ACC: 0.0	wrong_be_tree_count:417	wrong_total:433	 wrong be tree ACC: 0.9630484988452656
right_checker:1836	total:1974	checker ACC: 0.9300912618637085	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:1,	loss:14.6288480758667	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:20	total:1974	Code ACC: 0.010131712259371834	wrong_be_tree_count:297	wrong_total:433	 wrong be tree ACC: 0.6859122401847575
right_checker:1877	total:1974	checker ACC: 0.9508612155914307	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:2,	loss:8.166770592331886	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:264	total:1974	Code ACC: 0.1337386018237082	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1688	total:1974	checker ACC: 0.8551165461540222	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:3,	loss:3.5549643710255623	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:568	total:1974	Code ACC: 0.2877406281661601	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1404	total:1974	checker ACC: 0.7112462520599365	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:4,	loss:2.5726911425590515	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:820	total:1974	Code ACC: 0.4154002026342452	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
right_checker:1152	total:1974	checker ACC: 0.5835866332054138	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:5,	loss:2.3019173964858055	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:926	total:1974	Code ACC: 0.4690982776089159	wrong_be_tree_count:391	wrong_total:433	 wrong be tree ACC: 0.9030023094688222
right_checker:1045	total:1974	checker ACC: 0.5293819904327393	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:6,	loss:2.1354478150606155	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:913	total:1974	Code ACC: 0.4625126646403242	wrong_be_tree_count:417	wrong_total:433	 wrong be tree ACC: 0.9630484988452656
right_checker:1041	total:1974	checker ACC: 0.5273556709289551	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:7,	loss:1.91871028393507	loss1:0
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:918	total:1974	Code ACC: 0.46504559270516715	wrong_be_tree_count:397	wrong_total:433	 wrong be tree ACC: 0.9168591224018475
right_checker:980	total:1974	checker ACC: 0.4964539110660553	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:8,	loss:1.785951890051365	loss1:4764.8445653915405
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:952	total:1974	Code ACC: 0.48226950354609927	wrong_be_tree_count:347	wrong_total:433	 wrong be tree ACC: 0.8013856812933026
right_checker:1169	total:1974	checker ACC: 0.5921986103057861	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:9,	loss:1.6902107633650303	loss1:3772.959532022476
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:989	total:1974	Code ACC: 0.5010131712259371	wrong_be_tree_count:310	wrong_total:433	 wrong be tree ACC: 0.7159353348729792
right_checker:1251	total:1974	checker ACC: 0.63373863697052	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:10,	loss:1.6168714240193367	loss1:3049.785677433014
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:991	total:1974	Code ACC: 0.5020263424518744	wrong_be_tree_count:326	wrong_total:433	 wrong be tree ACC: 0.7528868360277137
right_checker:1250	total:1974	checker ACC: 0.633232057094574	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:11,	loss:1.504284618422389	loss1:2553.3548109531403
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1056	total:1974	Code ACC: 0.5349544072948328	wrong_be_tree_count:276	wrong_total:433	 wrong be tree ACC: 0.6374133949191686
right_checker:1265	total:1974	checker ACC: 0.6408308148384094	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:12,	loss:1.43208222463727	loss1:2285.736136674881
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1056	total:1974	Code ACC: 0.5349544072948328	wrong_be_tree_count:276	wrong_total:433	 wrong be tree ACC: 0.6374133949191686
right_checker:1234	total:1974	checker ACC: 0.6251266598701477	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:13,	loss:1.383189331740141	loss1:2204.90070772171
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1121	total:1974	Code ACC: 0.5678824721377913	wrong_be_tree_count:218	wrong_total:433	 wrong be tree ACC: 0.5034642032332564
right_checker:1267	total:1974	checker ACC: 0.6418439745903015	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:14,	loss:1.2745124008506536	loss1:2121.7516288757324
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1151	total:1974	Code ACC: 0.583080040526849	wrong_be_tree_count:197	wrong_total:433	 wrong be tree ACC: 0.45496535796766746
right_checker:1298	total:1974	checker ACC: 0.6575481295585632	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:15,	loss:1.2410543784499168	loss1:2046.5128560066223
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1062	total:1974	Code ACC: 0.5379939209726444	wrong_be_tree_count:274	wrong_total:433	 wrong be tree ACC: 0.6327944572748267
right_checker:1249	total:1974	checker ACC: 0.6327254772186279	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:16,	loss:1.16144778765738	loss1:1909.9433288574219
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1127	total:1974	Code ACC: 0.5709219858156028	wrong_be_tree_count:231	wrong_total:433	 wrong be tree ACC: 0.5334872979214781
right_checker:1291	total:1974	checker ACC: 0.6540020704269409	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:17,	loss:1.1079929117113352	loss1:1781.4061386585236
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1137	total:1974	Code ACC: 0.5759878419452887	wrong_be_tree_count:218	wrong_total:433	 wrong be tree ACC: 0.5034642032332564
right_checker:1301	total:1974	checker ACC: 0.6590679287910461	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:18,	loss:1.0344389714300632	loss1:1756.3546694517136
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1146	total:1974	Code ACC: 0.5805471124620061	wrong_be_tree_count:208	wrong_total:433	 wrong be tree ACC: 0.48036951501154734
right_checker:1323	total:1974	checker ACC: 0.6702128052711487	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:19,	loss:0.9882703674957156	loss1:1617.1218715906143
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1169	total:1974	Code ACC: 0.5921985815602837	wrong_be_tree_count:194	wrong_total:433	 wrong be tree ACC: 0.44803695150115475
right_checker:1312	total:1974	checker ACC: 0.6646403670310974	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:20,	loss:0.9651934802532196	loss1:1572.828863143921
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1213	total:1974	Code ACC: 0.6144883485309017	wrong_be_tree_count:184	wrong_total:433	 wrong be tree ACC: 0.42494226327944573
right_checker:1351	total:1974	checker ACC: 0.6843972206115723	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:21,	loss:0.9389208015054464	loss1:1587.1128673553467
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1218	total:1974	Code ACC: 0.6170212765957447	wrong_be_tree_count:184	wrong_total:433	 wrong be tree ACC: 0.42494226327944573
right_checker:1327	total:1974	checker ACC: 0.6722391247749329	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:22,	loss:0.8775194101035595	loss1:1493.622696891427
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1168	total:1974	Code ACC: 0.5916919959473151	wrong_be_tree_count:210	wrong_total:433	 wrong be tree ACC: 0.48498845265588914
right_checker:1301	total:1974	checker ACC: 0.6590679287910461	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:23,	loss:0.9665631875395775	loss1:1466.9684703350067
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1199	total:1974	Code ACC: 0.6073961499493414	wrong_be_tree_count:186	wrong_total:433	 wrong be tree ACC: 0.4295612009237875
right_checker:1332	total:1974	checker ACC: 0.6747720837593079	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:24,	loss:0.8269435726106167	loss1:1416.183251619339
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1209	total:1974	Code ACC: 0.6124620060790273	wrong_be_tree_count:191	wrong_total:433	 wrong be tree ACC: 0.44110854503464203
right_checker:1298	total:1974	checker ACC: 0.6575481295585632	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:25,	loss:0.7539247935637832	loss1:1291.1971859931946
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1243	total:1974	Code ACC: 0.6296859169199595	wrong_be_tree_count:166	wrong_total:433	 wrong be tree ACC: 0.3833718244803695
right_checker:1336	total:1974	checker ACC: 0.676798403263092	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:26,	loss:0.727364145219326	loss1:1269.490535736084
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1218	total:1974	Code ACC: 0.6170212765957447	wrong_be_tree_count:193	wrong_total:433	 wrong be tree ACC: 0.4457274826789838
right_checker:1293	total:1974	checker ACC: 0.655015230178833	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:27,	loss:0.7481850795447826	loss1:1152.4810180664062
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1281	total:1974	Code ACC: 0.648936170212766	wrong_be_tree_count:157	wrong_total:433	 wrong be tree ACC: 0.3625866050808314
right_checker:1366	total:1974	checker ACC: 0.6919959783554077	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:28,	loss:0.6784727685153484	loss1:1135.8882250785828
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1248	total:1974	Code ACC: 0.6322188449848024	wrong_be_tree_count:176	wrong_total:433	 wrong be tree ACC: 0.4064665127020785
right_checker:1349	total:1974	checker ACC: 0.6833840012550354	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:29,	loss:0.6275836750864983	loss1:1054.5346702635288
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1268	total:1974	Code ACC: 0.6423505572441742	wrong_be_tree_count:165	wrong_total:433	 wrong be tree ACC: 0.3810623556581986
right_checker:1364	total:1974	checker ACC: 0.6909828186035156	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:30,	loss:0.6387296309694648	loss1:1039.889630317688
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1265	total:1974	Code ACC: 0.6408308004052685	wrong_be_tree_count:161	wrong_total:433	 wrong be tree ACC: 0.371824480369515
right_checker:1355	total:1974	checker ACC: 0.6864235401153564	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:31,	loss:0.5606129202060401	loss1:943.4102897644043
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1292	total:1974	Code ACC: 0.6545086119554204	wrong_be_tree_count:149	wrong_total:433	 wrong be tree ACC: 0.3441108545034642
right_checker:1383	total:1974	checker ACC: 0.70060795545578	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:32,	loss:0.5381761118769646	loss1:892.6148258447647
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1270	total:1974	Code ACC: 0.6433637284701115	wrong_be_tree_count:158	wrong_total:433	 wrong be tree ACC: 0.3648960739030023
right_checker:1365	total:1974	checker ACC: 0.6914893984794617	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:33,	loss:0.5066643278114498	loss1:862.1313037872314
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1273	total:1974	Code ACC: 0.6448834853090172	wrong_be_tree_count:165	wrong_total:433	 wrong be tree ACC: 0.3810623556581986
right_checker:1355	total:1974	checker ACC: 0.6864235401153564	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:34,	loss:0.4893720466643572	loss1:785.7755517959595
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1229	total:1974	Code ACC: 0.6225937183383992	wrong_be_tree_count:178	wrong_total:433	 wrong be tree ACC: 0.4110854503464203
right_checker:1309	total:1974	checker ACC: 0.6631206274032593	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:35,	loss:0.5222482429817319	loss1:918.9588856697083
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1247	total:1974	Code ACC: 0.6317122593718338	wrong_be_tree_count:169	wrong_total:433	 wrong be tree ACC: 0.3903002309468822
right_checker:1317	total:1974	checker ACC: 0.6671732664108276	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:36,	loss:0.48018645215779543	loss1:741.5842018723488
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1270	total:1974	Code ACC: 0.6433637284701115	wrong_be_tree_count:156	wrong_total:433	 wrong be tree ACC: 0.36027713625866054
right_checker:1351	total:1974	checker ACC: 0.6843972206115723	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:37,	loss:0.4414497093530372	loss1:723.9849309921265
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1319	total:1974	Code ACC: 0.6681864235055724	wrong_be_tree_count:137	wrong_total:433	 wrong be tree ACC: 0.3163972286374134
right_checker:1435	total:1974	checker ACC: 0.7269504070281982	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:38,	loss:0.4432961391285062	loss1:686.1874239444733
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1314	total:1974	Code ACC: 0.6656534954407295	wrong_be_tree_count:142	wrong_total:433	 wrong be tree ACC: 0.3279445727482679
right_checker:1400	total:1974	checker ACC: 0.7092198729515076	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:39,	loss:0.45638260431587696	loss1:706.2183346748352
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1364	total:1974	Code ACC: 0.690982776089159	wrong_be_tree_count:122	wrong_total:433	 wrong be tree ACC: 0.2817551963048499
right_checker:1450	total:1974	checker ACC: 0.7345491647720337	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:40,	loss:0.42125860322266817	loss1:663.7899349331856
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1341	total:1974	Code ACC: 0.6793313069908815	wrong_be_tree_count:141	wrong_total:433	 wrong be tree ACC: 0.325635103926097
right_checker:1421	total:1974	checker ACC: 0.7198581695556641	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:41,	loss:0.4063459923490882	loss1:596.0602607727051
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1376	total:1974	Code ACC: 0.6970618034447822	wrong_be_tree_count:122	wrong_total:433	 wrong be tree ACC: 0.2817551963048499
right_checker:1465	total:1974	checker ACC: 0.7421479821205139	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:42,	loss:0.42686601635068655	loss1:675.8609862923622
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1373	total:1974	Code ACC: 0.6955420466058764	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1468	total:1974	checker ACC: 0.743667721748352	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:43,	loss:0.4160764319822192	loss1:662.8775772452354
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1394	total:1974	Code ACC: 0.7061803444782169	wrong_be_tree_count:107	wrong_total:433	 wrong be tree ACC: 0.2471131639722864
right_checker:1501	total:1974	checker ACC: 0.7603850364685059	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:44,	loss:0.3734059282578528	loss1:618.2376282811165
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1370	total:1974	Code ACC: 0.6940222897669707	wrong_be_tree_count:106	wrong_total:433	 wrong be tree ACC: 0.24480369515011546
right_checker:1452	total:1974	checker ACC: 0.7355623245239258	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:45,	loss:0.3447891240939498	loss1:547.568549156189
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1375	total:1974	Code ACC: 0.6965552178318136	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1489	total:1974	checker ACC: 0.7543060183525085	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:46,	loss:0.3358673728071153	loss1:515.4495558738708
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1363	total:1974	Code ACC: 0.6904761904761905	wrong_be_tree_count:121	wrong_total:433	 wrong be tree ACC: 0.279445727482679
right_checker:1487	total:1974	checker ACC: 0.7532928586006165	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:47,	loss:0.350654358509928	loss1:477.8119003176689
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1381	total:1974	Code ACC: 0.6995947315096251	wrong_be_tree_count:114	wrong_total:433	 wrong be tree ACC: 0.2632794457274827
right_checker:1492	total:1974	checker ACC: 0.7558257579803467	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:48,	loss:0.33684300165623426	loss1:499.3387062549591
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1368	total:1974	Code ACC: 0.6930091185410334	wrong_be_tree_count:115	wrong_total:433	 wrong be tree ACC: 0.26558891454965355
right_checker:1495	total:1974	checker ACC: 0.7573455572128296	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:49,	loss:0.32911495119333267	loss1:511.74527645111084
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1357	total:1974	Code ACC: 0.6874366767983789	wrong_be_tree_count:128	wrong_total:433	 wrong be tree ACC: 0.2956120092378753
right_checker:1448	total:1974	checker ACC: 0.7335360050201416	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:50,	loss:0.3015793995000422	loss1:449.71179485321045
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1363	total:1974	Code ACC: 0.6904761904761905	wrong_be_tree_count:128	wrong_total:433	 wrong be tree ACC: 0.2956120092378753
right_checker:1471	total:1974	checker ACC: 0.7451874613761902	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:51,	loss:0.29130811779759824	loss1:452.7123942375183
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1383	total:1974	Code ACC: 0.7006079027355623	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1498	total:1974	checker ACC: 0.7588652968406677	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:52,	loss:0.27436117158504203	loss1:423.6694803237915
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1395	total:1974	Code ACC: 0.7066869300911854	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:53,	loss:0.29279244877398014	loss1:441.52866315841675
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1391	total:1974	Code ACC: 0.704660587639311	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1529	total:1974	checker ACC: 0.7745694518089294	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:54,	loss:0.2642957465723157	loss1:346.99461603164673
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1381	total:1974	Code ACC: 0.6995947315096251	wrong_be_tree_count:106	wrong_total:433	 wrong be tree ACC: 0.24480369515011546
right_checker:1506	total:1974	checker ACC: 0.7629179954528809	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:55,	loss:0.26975097181275487	loss1:411.7018256187439
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1380	total:1974	Code ACC: 0.6990881458966566	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1483	total:1974	checker ACC: 0.7512664794921875	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:56,	loss:0.2858044821768999	loss1:389.48118925094604
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1382	total:1974	Code ACC: 0.7001013171225937	wrong_be_tree_count:115	wrong_total:433	 wrong be tree ACC: 0.26558891454965355
right_checker:1492	total:1974	checker ACC: 0.7558257579803467	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:57,	loss:0.24954202491790056	loss1:390.14341735839844
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1385	total:1974	Code ACC: 0.7016210739614995	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1502	total:1974	checker ACC: 0.7608916163444519	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:58,	loss:0.2482561522629112	loss1:398.86015701293945
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1369	total:1974	Code ACC: 0.693515704154002	wrong_be_tree_count:125	wrong_total:433	 wrong be tree ACC: 0.28868360277136257
right_checker:1481	total:1974	checker ACC: 0.7502533197402954	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:59,	loss:0.24351142207160592	loss1:334.9936412572861
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1391	total:1974	Code ACC: 0.704660587639311	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1504	total:1974	checker ACC: 0.761904776096344	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:60,	loss:0.2448060567257926	loss1:367.92190313339233
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1383	total:1974	Code ACC: 0.7006079027355623	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1499	total:1974	checker ACC: 0.7593718767166138	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:61,	loss:0.22753933432977647	loss1:379.346538066864
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1394	total:1974	Code ACC: 0.7061803444782169	wrong_be_tree_count:121	wrong_total:433	 wrong be tree ACC: 0.279445727482679
right_checker:1513	total:1974	checker ACC: 0.7664640545845032	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:62,	loss:0.23877392895519733	loss1:342.75562620162964
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1375	total:1974	Code ACC: 0.6965552178318136	wrong_be_tree_count:125	wrong_total:433	 wrong be tree ACC: 0.28868360277136257
right_checker:1494	total:1974	checker ACC: 0.7568389177322388	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:63,	loss:0.22712171007879078	loss1:360.0025408267975
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1379	total:1974	Code ACC: 0.6985815602836879	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1500	total:1974	checker ACC: 0.7598784565925598	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:64,	loss:0.2216447995742783	loss1:315.28436279296875
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1385	total:1974	Code ACC: 0.7016210739614995	wrong_be_tree_count:110	wrong_total:433	 wrong be tree ACC: 0.2540415704387991
right_checker:1513	total:1974	checker ACC: 0.7664640545845032	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:65,	loss:0.2735784014221281	loss1:341.1500344276428
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:114	wrong_total:433	 wrong be tree ACC: 0.2632794457274827
right_checker:1510	total:1974	checker ACC: 0.764944314956665	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:66,	loss:0.22209213704627473	loss1:334.5238676071167
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1380	total:1974	Code ACC: 0.6990881458966566	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1506	total:1974	checker ACC: 0.7629179954528809	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:67,	loss:0.2242299832869321	loss1:325.69457626342773
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1368	total:1974	Code ACC: 0.6930091185410334	wrong_be_tree_count:124	wrong_total:433	 wrong be tree ACC: 0.2863741339491917
right_checker:1483	total:1974	checker ACC: 0.7512664794921875	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:68,	loss:0.2322562700137496	loss1:375.6542377471924
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1398	total:1974	Code ACC: 0.7082066869300911	wrong_be_tree_count:113	wrong_total:433	 wrong be tree ACC: 0.26096997690531176
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:69,	loss:0.22164986422285438	loss1:309.8220896720886
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1392	total:1974	Code ACC: 0.7051671732522796	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1512	total:1974	checker ACC: 0.7659574747085571	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:70,	loss:0.212385946768336	loss1:326.17979621887207
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1526	total:1974	checker ACC: 0.7730497121810913	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:71,	loss:0.21450261981226504	loss1:304.112820148468
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1387	total:1974	Code ACC: 0.7026342451874367	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1517	total:1974	checker ACC: 0.7684904336929321	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:72,	loss:0.22168735531158745	loss1:297.3456646203995
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1394	total:1974	Code ACC: 0.7061803444782169	wrong_be_tree_count:107	wrong_total:433	 wrong be tree ACC: 0.2471131639722864
right_checker:1518	total:1974	checker ACC: 0.7689970135688782	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:73,	loss:0.21393325366079807	loss1:307.57442712783813
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:110	wrong_total:433	 wrong be tree ACC: 0.2540415704387991
right_checker:1526	total:1974	checker ACC: 0.7730497121810913	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:74,	loss:0.19375886325724423	loss1:278.7312591075897
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1516	total:1974	checker ACC: 0.7679838538169861	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:75,	loss:0.19707598397508264	loss1:282.84266424179077
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1403	total:1974	Code ACC: 0.7107396149949341	wrong_be_tree_count:113	wrong_total:433	 wrong be tree ACC: 0.26096997690531176
right_checker:1526	total:1974	checker ACC: 0.7730497121810913	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:76,	loss:0.19575374899432063	loss1:276.2670798301697
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1373	total:1974	Code ACC: 0.6955420466058764	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1503	total:1974	checker ACC: 0.761398196220398	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:77,	loss:0.18650929600698873	loss1:283.6657044887543
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1378	total:1974	Code ACC: 0.6980749746707193	wrong_be_tree_count:108	wrong_total:433	 wrong be tree ACC: 0.24942263279445728
right_checker:1523	total:1974	checker ACC: 0.7715299129486084	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:78,	loss:0.19097425532527268	loss1:262.2564115524292
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1379	total:1974	Code ACC: 0.6985815602836879	wrong_be_tree_count:111	wrong_total:433	 wrong be tree ACC: 0.25635103926096997
right_checker:1509	total:1974	checker ACC: 0.764437735080719	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:79,	loss:0.1895048669539392	loss1:270.4522120952606
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1389	total:1974	Code ACC: 0.7036474164133738	wrong_be_tree_count:108	wrong_total:433	 wrong be tree ACC: 0.24942263279445728
right_checker:1523	total:1974	checker ACC: 0.7715299129486084	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:80,	loss:0.18881189718376845	loss1:264.74095487594604
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1390	total:1974	Code ACC: 0.7041540020263425	wrong_be_tree_count:107	wrong_total:433	 wrong be tree ACC: 0.2471131639722864
right_checker:1520	total:1974	checker ACC: 0.7700101733207703	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:81,	loss:0.16879449722910067	loss1:231.47884702682495
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1383	total:1974	Code ACC: 0.7006079027355623	wrong_be_tree_count:108	wrong_total:433	 wrong be tree ACC: 0.24942263279445728
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:82,	loss:0.2251324987737462	loss1:260.62309312820435
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1390	total:1974	Code ACC: 0.7041540020263425	wrong_be_tree_count:110	wrong_total:433	 wrong be tree ACC: 0.2540415704387991
right_checker:1522	total:1974	checker ACC: 0.7710233330726624	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:83,	loss:0.24955854355357587	loss1:244.8002574443817
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1373	total:1974	Code ACC: 0.6955420466058764	wrong_be_tree_count:117	wrong_total:433	 wrong be tree ACC: 0.2702078521939954
right_checker:1513	total:1974	checker ACC: 0.7664640545845032	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:84,	loss:0.1960556494523189	loss1:278.6959342956543
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1382	total:1974	Code ACC: 0.7001013171225937	wrong_be_tree_count:106	wrong_total:433	 wrong be tree ACC: 0.24480369515011546
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:85,	loss:0.18167235818691552	loss1:282.82859897613525
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1521	total:1974	checker ACC: 0.7705167531967163	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:86,	loss:0.17526978540990967	loss1:227.4418454170227
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1387	total:1974	Code ACC: 0.7026342451874367	wrong_be_tree_count:111	wrong_total:433	 wrong be tree ACC: 0.25635103926096997
right_checker:1522	total:1974	checker ACC: 0.7710233330726624	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:87,	loss:0.16948058267007582	loss1:229.9987576007843
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1386	total:1974	Code ACC: 0.7021276595744681	wrong_be_tree_count:106	wrong_total:433	 wrong be tree ACC: 0.24480369515011546
right_checker:1531	total:1974	checker ACC: 0.7755826115608215	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:88,	loss:0.17032822682813276	loss1:269.0450210571289
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:115	wrong_total:433	 wrong be tree ACC: 0.26558891454965355
right_checker:1523	total:1974	checker ACC: 0.7715299129486084	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:89,	loss:0.18355936277657747	loss1:246.03812897205353
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1384	total:1974	Code ACC: 0.7011144883485309	wrong_be_tree_count:109	wrong_total:433	 wrong be tree ACC: 0.2517321016166282
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:90,	loss:0.1722687731962651	loss1:220.26526701450348
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1382	total:1974	Code ACC: 0.7001013171225937	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1513	total:1974	checker ACC: 0.7664640545845032	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:91,	loss:0.16628600275726058	loss1:234.17447471618652
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1394	total:1974	Code ACC: 0.7061803444782169	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1518	total:1974	checker ACC: 0.7689970135688782	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:92,	loss:0.1739693358540535	loss1:216.57933235168457
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1392	total:1974	Code ACC: 0.7051671732522796	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:93,	loss:0.17052417411468923	loss1:221.91023755073547
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1387	total:1974	Code ACC: 0.7026342451874367	wrong_be_tree_count:115	wrong_total:433	 wrong be tree ACC: 0.26558891454965355
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:94,	loss:0.15929577653878368	loss1:211.7159128189087
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1396	total:1974	Code ACC: 0.707193515704154	wrong_be_tree_count:114	wrong_total:433	 wrong be tree ACC: 0.2632794457274827
right_checker:1523	total:1974	checker ACC: 0.7715299129486084	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:95,	loss:0.1605973930854816	loss1:211.15541124343872
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1393	total:1974	Code ACC: 0.7056737588652482	wrong_be_tree_count:111	wrong_total:433	 wrong be tree ACC: 0.25635103926096997
right_checker:1527	total:1974	checker ACC: 0.7735562920570374	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:96,	loss:0.16035466236644424	loss1:222.99049019813538
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:112	wrong_total:433	 wrong be tree ACC: 0.2586605080831409
right_checker:1533	total:1974	checker ACC: 0.7765957713127136	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:97,	loss:0.1611579842865467	loss1:209.34997022151947
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1383	total:1974	Code ACC: 0.7006079027355623	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:98,	loss:0.15684094437165186	loss1:222.22539347410202
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1393	total:1974	Code ACC: 0.7056737588652482	wrong_be_tree_count:108	wrong_total:433	 wrong be tree ACC: 0.24942263279445728
right_checker:1540	total:1974	checker ACC: 0.7801418900489807	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:99,	loss:0.16787992522586137	loss1:190.58170968294144
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1398	total:1974	Code ACC: 0.7082066869300911	wrong_be_tree_count:115	wrong_total:433	 wrong be tree ACC: 0.26558891454965355
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:100,	loss:0.19035034254193306	loss1:220.87860751152039
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1387	total:1974	Code ACC: 0.7026342451874367	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1514	total:1974	checker ACC: 0.7669706344604492	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:101,	loss:0.17581944190897048	loss1:228.01088643074036
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1394	total:1974	Code ACC: 0.7061803444782169	wrong_be_tree_count:123	wrong_total:433	 wrong be tree ACC: 0.2840646651270208
right_checker:1516	total:1974	checker ACC: 0.7679838538169861	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:102,	loss:0.15268540801480412	loss1:203.35658764839172
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:122	wrong_total:433	 wrong be tree ACC: 0.2817551963048499
right_checker:1531	total:1974	checker ACC: 0.7755826115608215	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:103,	loss:0.15422378169023432	loss1:213.5118304491043
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1387	total:1974	Code ACC: 0.7026342451874367	wrong_be_tree_count:124	wrong_total:433	 wrong be tree ACC: 0.2863741339491917
right_checker:1516	total:1974	checker ACC: 0.7679838538169861	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:104,	loss:0.18623456661589444	loss1:205.40367078781128
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1391	total:1974	Code ACC: 0.704660587639311	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1524	total:1974	checker ACC: 0.7720364928245544	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:105,	loss:0.1627576949831564	loss1:237.81354188919067
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1528	total:1974	checker ACC: 0.7740628719329834	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:106,	loss:0.16042797651607543	loss1:239.3261038661003
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1396	total:1974	Code ACC: 0.707193515704154	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:107,	loss:0.15291889043874107	loss1:215.73734855651855
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1531	total:1974	checker ACC: 0.7755826115608215	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:108,	loss:0.1489612149889581	loss1:207.0273309648037
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1401	total:1974	Code ACC: 0.709726443768997	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:109,	loss:0.16536980704404414	loss1:243.57568073272705
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1401	total:1974	Code ACC: 0.709726443768997	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:110,	loss:0.18927199975587428	loss1:212.3708180785179
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1405	total:1974	Code ACC: 0.7117527862208713	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1534	total:1974	checker ACC: 0.7771023511886597	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:111,	loss:0.15574916993500665	loss1:221.08057808876038
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:116	wrong_total:433	 wrong be tree ACC: 0.2678983833718245
right_checker:1525	total:1974	checker ACC: 0.7725430727005005	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:112,	loss:0.1728358343243599	loss1:216.42376899719238
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1395	total:1974	Code ACC: 0.7066869300911854	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1521	total:1974	checker ACC: 0.7705167531967163	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:113,	loss:0.15476984484121203	loss1:237.3579626083374
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1390	total:1974	Code ACC: 0.7041540020263425	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1516	total:1974	checker ACC: 0.7679838538169861	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:114,	loss:0.15239698451478034	loss1:199.60050916671753
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1393	total:1974	Code ACC: 0.7056737588652482	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1519	total:1974	checker ACC: 0.7695035934448242	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:115,	loss:0.15181167010450736	loss1:196.0939348936081
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1521	total:1974	checker ACC: 0.7705167531967163	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:116,	loss:0.14929832049529068	loss1:197.4554911851883
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1402	total:1974	Code ACC: 0.7102330293819655	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1530	total:1974	checker ACC: 0.7750760316848755	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:117,	loss:0.20367214572615921	loss1:207.94759356975555
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1397	total:1974	Code ACC: 0.7077001013171226	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1527	total:1974	checker ACC: 0.7735562920570374	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:118,	loss:0.14766749908449128	loss1:204.67511916160583
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1407	total:1974	Code ACC: 0.7127659574468085	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1540	total:1974	checker ACC: 0.7801418900489807	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:119,	loss:0.17615790525451303	loss1:207.62628066539764
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1405	total:1974	Code ACC: 0.7117527862208713	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1538	total:1974	checker ACC: 0.7791287302970886	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:120,	loss:0.16847364837303758	loss1:225.16443240642548
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1402	total:1974	Code ACC: 0.7102330293819655	wrong_be_tree_count:118	wrong_total:433	 wrong be tree ACC: 0.27251732101616627
right_checker:1541	total:1974	checker ACC: 0.7806484699249268	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:121,	loss:0.1508416116121225	loss1:226.5103735923767
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1407	total:1974	Code ACC: 0.7127659574468085	wrong_be_tree_count:120	wrong_total:433	 wrong be tree ACC: 0.27713625866050806
right_checker:1534	total:1974	checker ACC: 0.7771023511886597	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:122,	loss:0.15237943004467525	loss1:199.15548193454742
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1533	total:1974	checker ACC: 0.7765957713127136	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:123,	loss:0.15568433026783168	loss1:198.5141077041626
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1533	total:1974	checker ACC: 0.7765957713127136	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:124,	loss:0.160029438091442	loss1:236.75771403312683
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1533	total:1974	checker ACC: 0.7765957713127136	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:125,	loss:0.15498493268387392	loss1:190.48608392477036
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1533	total:1974	checker ACC: 0.7765957713127136	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:126,	loss:0.14835875777498586	loss1:238.45490300655365
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:127,	loss:0.16062603797763586	loss1:205.97958755493164
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:128,	loss:0.15646294923499227	loss1:203.09789562225342
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model


epoch:129,	loss:0.1520507525310677	loss1:234.72959232330322
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
save best model to ./output/test/best_model



final_test
right_count:0	total:433	 Answer ACC: 0.0
right_codes_count:1406	total:1974	Code ACC: 0.7122593718338399	wrong_be_tree_count:119	wrong_total:433	 wrong be tree ACC: 0.2748267898383372
right_checker:1535	total:1974	checker ACC: 0.7776089310646057	temp:0	temp1:0	wrong_total:433	
after process dataset len: 433
total passed: 0
cuda
final_test
Answer acc:0.0


get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 159960.89it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 174880.47it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
===========================train setting parameters=========================
encoder.embeddings.word_embeddings.weight-torch.Size([30522, 768])
encoder.embeddings.position_embeddings.weight-torch.Size([512, 768])
encoder.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
encoder.embeddings.LayerNorm.weight-torch.Size([768])
encoder.embeddings.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.0.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.1.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.2.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.3.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.4.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.5.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.6.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.7.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.8.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.9.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.10.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.11.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
encoder.pooler.dense.weight-torch.Size([768, 768])
encoder.pooler.dense.bias-torch.Size([768])
code_emb.embedding.weight-torch.Size([29, 768])
fusion_fc.weight-torch.Size([768, 2304])
fusion_fc.bias-torch.Size([768])
geneartor.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.linear1.weight-torch.Size([2048, 768])
geneartor.decoder_layers.linear1.bias-torch.Size([2048])
geneartor.decoder_layers.linear2.weight-torch.Size([768, 2048])
geneartor.decoder_layers.linear2.bias-torch.Size([768])
geneartor.decoder_layers.norm1.weight-torch.Size([768])
geneartor.decoder_layers.norm1.bias-torch.Size([768])
geneartor.decoder_layers.norm2.weight-torch.Size([768])
geneartor.decoder_layers.norm2.bias-torch.Size([768])
geneartor.decoder_layers.norm3.weight-torch.Size([768])
geneartor.decoder_layers.norm3.bias-torch.Size([768])
geneartor.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.0.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.0.linear2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm1.weight-torch.Size([768])
geneartor.decoder.layers.0.norm1.bias-torch.Size([768])
geneartor.decoder.layers.0.norm2.weight-torch.Size([768])
geneartor.decoder.layers.0.norm2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm3.weight-torch.Size([768])
geneartor.decoder.layers.0.norm3.bias-torch.Size([768])
geneartor.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.1.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.1.linear2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm1.weight-torch.Size([768])
geneartor.decoder.layers.1.norm1.bias-torch.Size([768])
geneartor.decoder.layers.1.norm2.weight-torch.Size([768])
geneartor.decoder.layers.1.norm2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm3.weight-torch.Size([768])
geneartor.decoder.layers.1.norm3.bias-torch.Size([768])
geneartor.fc.weight-torch.Size([29, 768])
geneartor.fc.bias-torch.Size([29])
discriminator.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.linear1.weight-torch.Size([2048, 768])
discriminator.decoder_layers.linear1.bias-torch.Size([2048])
discriminator.decoder_layers.linear2.weight-torch.Size([768, 2048])
discriminator.decoder_layers.linear2.bias-torch.Size([768])
discriminator.decoder_layers.norm1.weight-torch.Size([768])
discriminator.decoder_layers.norm1.bias-torch.Size([768])
discriminator.decoder_layers.norm2.weight-torch.Size([768])
discriminator.decoder_layers.norm2.bias-torch.Size([768])
discriminator.decoder_layers.norm3.weight-torch.Size([768])
discriminator.decoder_layers.norm3.bias-torch.Size([768])
discriminator.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.0.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.0.linear2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm1.weight-torch.Size([768])
discriminator.decoder.layers.0.norm1.bias-torch.Size([768])
discriminator.decoder.layers.0.norm2.weight-torch.Size([768])
discriminator.decoder.layers.0.norm2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm3.weight-torch.Size([768])
discriminator.decoder.layers.0.norm3.bias-torch.Size([768])
discriminator.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.1.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.1.linear2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm1.weight-torch.Size([768])
discriminator.decoder.layers.1.norm1.bias-torch.Size([768])
discriminator.decoder.layers.1.norm2.weight-torch.Size([768])
discriminator.decoder.layers.1.norm2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm3.weight-torch.Size([768])
discriminator.decoder.layers.1.norm3.bias-torch.Size([768])
discriminator.fc.weight-torch.Size([2, 768])
discriminator.fc.bias-torch.Size([2])
get_goal1.weight-torch.Size([2048, 1536])
get_goal1.bias-torch.Size([2048])
get_goal2.weight-torch.Size([2048, 1536])
get_goal2.bias-torch.Size([2048])
get_goal3.weight-torch.Size([768, 2048])
get_goal3.bias-torch.Size([768])
get_goal4.weight-torch.Size([768, 2048])
get_goal4.bias-torch.Size([768])

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss_g:109.9640440940857	loss_d:31.93835413455963
train_code_acc:[0.053828007720351706, 0.10572592751447565, 0.16555865322753593]
train_judgement_acc:[0.4868110658374437, 0.49260132961612696, 0.49217242118807636]


test_answer_acc:0.10392609699769054	iter_cnt_mean:2.8545034642032334
test_code_acc:[0.1947502116850127, 0.20745131244707873, 0.20745131244707873]
test_judgement_acc:[0.7764606265876376, 0.7646062658763759, 0.7646062658763759]


epoch:1,	loss_g:101.90697717666626	loss_d:28.18271315097809
train_code_acc:[0.18893416255629422, 0.2987347201372507, 0.37936950461076563]
train_judgement_acc:[0.7396525841732791, 0.6457216384301951, 0.5865322753592108]


test_answer_acc:0.26096997690531176	iter_cnt_mean:2.5057736720554273
test_code_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564]
test_judgement_acc:[0.6604572396274344, 0.6604572396274344, 0.6604572396274344]


epoch:2,	loss_g:89.33104038238525	loss_d:31.095876693725586
train_code_acc:[0.2925155479305168, 0.44134677246407894, 0.5273429122882265]
train_judgement_acc:[0.6244906712416899, 0.5423547072699979, 0.5086853956680248]


test_answer_acc:0.2702078521939954	iter_cnt_mean:2.515011547344111
test_code_acc:[0.3556308213378493, 0.3827265029635902, 0.3827265029635902]
test_judgement_acc:[0.397121083827265, 0.42167654530059273, 0.4242167654530059]


epoch:3,	loss_g:79.18161678314209	loss_d:29.331897974014282
train_code_acc:[0.29680463221102293, 0.4520694831653442, 0.5485738794767318]
train_judgement_acc:[0.6309242976624491, 0.5792408320823504, 0.5301308170705554]


test_answer_acc:0.2632794457274827	iter_cnt_mean:2.5011547344110854
test_code_acc:[0.3657917019475021, 0.37425910245554617, 0.37425910245554617]
test_judgement_acc:[0.4055884843353091, 0.4072819644369179, 0.4072819644369179]


epoch:4,	loss_g:75.45589876174927	loss_d:28.287200570106506
train_code_acc:[0.3259704053184645, 0.49152905854600043, 0.5783830152262492]
train_judgement_acc:[0.6126956894702981, 0.6099077846879691, 0.5938237186360712]


test_answer_acc:0.371824480369515	iter_cnt_mean:2.399538106235566
test_code_acc:[0.46655376799322607, 0.5173581710414903, 0.5207451312447079]
test_judgement_acc:[0.6452159187129551, 0.6299745977984759, 0.6274343776460627]


epoch:5,	loss_g:72.14023637771606	loss_d:27.061599850654602
train_code_acc:[0.36199871327471583, 0.528415183358353, 0.6302809350203732]
train_judgement_acc:[0.6139824147544499, 0.6489384516405747, 0.6551576238473086]


test_answer_acc:0.4665127020785219	iter_cnt_mean:2.2702078521939955
test_code_acc:[0.49026248941574935, 0.5876375952582558, 0.5901778154106689]
test_judgement_acc:[0.6570702794242168, 0.6909398814563928, 0.6917866215071973]


epoch:6,	loss_g:69.38359689712524	loss_d:26.63155686855316
train_code_acc:[0.4284795196225606, 0.5790263778683251, 0.6688826935449281]
train_judgement_acc:[0.6189148616770319, 0.6740295946815354, 0.6890413896633069]


test_answer_acc:0.5127020785219399	iter_cnt_mean:2.235565819861432
test_code_acc:[0.4707874682472481, 0.5850973751058425, 0.5859441151566469]
test_judgement_acc:[0.6562235393734124, 0.7104149026248942, 0.7112616426756986]


epoch:7,	loss_g:65.70945930480957	loss_d:25.03668701648712
train_code_acc:[0.4872399742654943, 0.6487239974265494, 0.729144327686039]
train_judgement_acc:[0.621702766459361, 0.7126313532060905, 0.7364357709628995]


test_answer_acc:0.6789838337182448	iter_cnt_mean:2.0346420323325636
test_code_acc:[0.550381033022862, 0.7019475021168501, 0.7036409822184589]
test_judgement_acc:[0.6409822184589331, 0.8069432684165961, 0.8069432684165961]


epoch:8,	loss_g:61.71664023399353	loss_d:23.153331637382507
train_code_acc:[0.5434269783401244, 0.7053399099292301, 0.767746086210594]
train_judgement_acc:[0.6455071842161698, 0.7555221960111517, 0.7743941668453785]


test_answer_acc:0.7297921478060047	iter_cnt_mean:1.9422632794457275
test_code_acc:[0.594411515664691, 0.7552921253175275, 0.7552921253175275]
test_judgement_acc:[0.6756985605419137, 0.825571549534293, 0.825571549534293]


epoch:9,	loss_g:59.800620317459106	loss_d:21.27185583114624
train_code_acc:[0.5732361140896418, 0.7447994853098864, 0.7981985846021874]
train_judgement_acc:[0.6660947887625992, 0.7898348702552005, 0.8037743941668454]


test_answer_acc:0.7413394919168591	iter_cnt_mean:1.9376443418013858
test_code_acc:[0.5901778154106689, 0.7722269263336156, 0.7722269263336156]
test_judgement_acc:[0.6689246401354784, 0.8416596104995766, 0.8399661303979679]


epoch:10,	loss_g:57.270912408828735	loss_d:20.10444462299347
train_code_acc:[0.5942526270641219, 0.7720351704911002, 0.8207162770748445]
train_judgement_acc:[0.6802487668882694, 0.8155693759382372, 0.8280077203517049]


test_answer_acc:0.7575057736720554	iter_cnt_mean:1.907621247113164
test_code_acc:[0.6011854360711262, 0.7933954276037256, 0.7933954276037256]
test_judgement_acc:[0.6799322607959356, 0.8602878916172735, 0.859441151566469]


epoch:11,	loss_g:55.30571508407593	loss_d:19.483470678329468
train_code_acc:[0.610551147330045, 0.7904782328972765, 0.8361569804846666]
train_judgement_acc:[0.688398027021231, 0.8243619987132748, 0.8376581599828437]


test_answer_acc:0.7321016166281755	iter_cnt_mean:1.8937644341801385
test_code_acc:[0.6189669771380186, 0.7806943268416596, 0.7823878069432684]
test_judgement_acc:[0.6994072819644369, 0.8408128704487722, 0.8408128704487722]


epoch:12,	loss_g:52.81279683113098	loss_d:18.39683973789215
train_code_acc:[0.6180570448209307, 0.8155693759382372, 0.857602401887197]
train_judgement_acc:[0.690542569161484, 0.8415183358352991, 0.8608192150975766]


test_answer_acc:0.8013856812933026	iter_cnt_mean:1.8475750577367205
test_code_acc:[0.607112616426757, 0.8052497883149873, 0.8060965283657917]
test_judgement_acc:[0.7002540220152413, 0.8619813717188823, 0.859441151566469]


epoch:13,	loss_g:49.512606143951416	loss_d:17.806703209877014
train_code_acc:[0.6289942097362213, 0.830152262491958, 0.8760454642933734]
train_judgement_acc:[0.6980484666523697, 0.8513832296804632, 0.8745442847951962]


test_answer_acc:0.8106235565819861	iter_cnt_mean:1.8244803695150116
test_code_acc:[0.6308213378492803, 0.8196443691786621, 0.8221845893310754]
test_judgement_acc:[0.7095681625740897, 0.8814563928873835, 0.8831498729889924]


epoch:14,	loss_g:47.97651743888855	loss_d:17.45708680152893
train_code_acc:[0.6444349131460433, 0.8355136178425906, 0.874329830581171]
train_judgement_acc:[0.706626635213382, 0.8573879476731717, 0.8730431052970191]


test_answer_acc:0.8013856812933026	iter_cnt_mean:1.8244803695150116
test_code_acc:[0.6291278577476714, 0.8094834885690093, 0.8145639288738358]
test_judgement_acc:[0.712108382726503, 0.8670618120237087, 0.8687552921253175]


epoch:15,	loss_g:46.06740999221802	loss_d:16.271496415138245
train_code_acc:[0.6639502466223461, 0.8623203945957538, 0.9002787904782329]
train_judgement_acc:[0.7104868110658374, 0.8835513617842591, 0.902423332618486]


test_answer_acc:0.812933025404157	iter_cnt_mean:1.7297921478060045
test_code_acc:[0.6613039796782387, 0.8086367485182049, 0.8128704487722269]
test_judgement_acc:[0.7417442845046571, 0.8569009314140559, 0.8611346316680779]


epoch:16,	loss_g:43.337907791137695	loss_d:16.165788650512695
train_code_acc:[0.6583744370576882, 0.8648938451640574, 0.9069268711130174]
train_judgement_acc:[0.7094145399957109, 0.8796911859318035, 0.9032811494745872]


test_answer_acc:0.789838337182448	iter_cnt_mean:1.745958429561201
test_code_acc:[0.6689246401354784, 0.8086367485182049, 0.8120237087214225]
test_judgement_acc:[0.7510584250635055, 0.8441998306519899, 0.8501270110076207]


epoch:17,	loss_g:42.08682370185852	loss_d:15.805753827095032
train_code_acc:[0.6729573236114089, 0.875831010079348, 0.9112159553935235]
train_judgement_acc:[0.7117735363499893, 0.8788333690757023, 0.9099292301093717]


test_answer_acc:0.8337182448036952	iter_cnt_mean:1.6882217090069285
test_code_acc:[0.6731583403895004, 0.8221845893310754, 0.825571549534293]
test_judgement_acc:[0.7273497036409822, 0.8797629127857748, 0.8763759525825572]


epoch:18,	loss_g:39.33539962768555	loss_d:15.009867191314697
train_code_acc:[0.6742440488955608, 0.8876259918507399, 0.9279433840874973]
train_judgement_acc:[0.7124168989920652, 0.9007076989062835, 0.9180784902423332]


test_answer_acc:0.815242494226328	iter_cnt_mean:1.7413394919168592
test_code_acc:[0.6613039796782387, 0.8137171888230313, 0.8196443691786621]
test_judgement_acc:[0.7044877222692634, 0.8433530906011855, 0.842506350550381]


epoch:19,	loss_g:38.74559450149536	loss_d:14.371956884860992
train_code_acc:[0.6926871113017371, 0.8889127171348917, 0.9264422045893201]
train_judgement_acc:[0.7261419686896847, 0.8992065194081064, 0.927728929873472]


test_answer_acc:0.8221709006928406	iter_cnt_mean:1.748267898383372
test_code_acc:[0.663844199830652, 0.8272650296359018, 0.8323454699407282]
test_judgement_acc:[0.7519051651143099, 0.8738357324301439, 0.8814563928873835]


epoch:20,	loss_g:37.486109018325806	loss_d:14.569796919822693
train_code_acc:[0.6873257559511045, 0.8949174351276002, 0.9343770105082565]
train_judgement_acc:[0.7207806133390521, 0.897490885695904, 0.9249410250911431]


test_answer_acc:0.8521939953810623	iter_cnt_mean:1.720554272517321
test_code_acc:[0.6587637595258256, 0.825571549534293, 0.8365791701947503]
test_judgement_acc:[0.7535986452159187, 0.8738357324301439, 0.8856900931414056]


epoch:21,	loss_g:36.15638470649719	loss_d:13.637596786022186
train_code_acc:[0.7070555436414325, 0.904567874758739, 0.9420973622131675]
train_judgement_acc:[0.7366502251769247, 0.9112159553935235, 0.9356637357924084]


test_answer_acc:0.8383371824480369	iter_cnt_mean:1.7367205542725173
test_code_acc:[0.6697713801862828, 0.8323454699407282, 0.838272650296359]
test_judgement_acc:[0.7612193056731583, 0.8941574936494496, 0.8966977138018628]


epoch:22,	loss_g:34.955284118652344	loss_d:13.449410080909729
train_code_acc:[0.7068410894274072, 0.9034956036886125, 0.9444563585674458]
train_judgement_acc:[0.7332189577525199, 0.9107870469654729, 0.9386660947887626]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.7136258660508084
test_code_acc:[0.6672311600338696, 0.8484335309060118, 0.8585944115156647]
test_judgement_acc:[0.7324301439458086, 0.8950042337002541, 0.9051651143099069]


epoch:23,	loss_g:33.60605049133301	loss_d:13.14586228132248
train_code_acc:[0.706626635213382, 0.9116448638215741, 0.9496032597040532]
train_judgement_acc:[0.7321466866823934, 0.9187218528844092, 0.9423118164271927]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.6951501154734412
test_code_acc:[0.6706181202370872, 0.8458933107535986, 0.8509737510584251]
test_judgement_acc:[0.7781541066892464, 0.9110922946655376, 0.9136325148179509]


epoch:24,	loss_g:32.24412202835083	loss_d:12.441648840904236
train_code_acc:[0.7282865108299378, 0.9174351276002574, 0.950889984988205]
train_judgement_acc:[0.752948745442848, 0.9180784902423332, 0.9442419043534206]


test_answer_acc:0.8614318706697459	iter_cnt_mean:1.6651270207852193
test_code_acc:[0.6867061812023709, 0.8416596104995766, 0.8484335309060118]
test_judgement_acc:[0.7849280270956817, 0.8890770533446232, 0.8899237933954276]


epoch:25,	loss_g:32.576096057891846	loss_d:11.967236816883087
train_code_acc:[0.7353634998927729, 0.9236542998069912, 0.9583958824790907]
train_judgement_acc:[0.7604546429337337, 0.9253699335191936, 0.9491743512760026]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.6166281755196306
test_code_acc:[0.6960203217612193, 0.8399661303979679, 0.8475867908552075]
test_judgement_acc:[0.7662997459779848, 0.8848433530906011, 0.8856900931414056]


epoch:26,	loss_g:31.087640523910522	loss_d:11.898267984390259
train_code_acc:[0.73686467939095, 0.9270855672313961, 0.9603259704053184]
train_judgement_acc:[0.7570233755093287, 0.9303023804417757, 0.953677889770534]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.628175519630485
test_code_acc:[0.6968670618120237, 0.8543607112616427, 0.8628281117696867]
test_judgement_acc:[0.7603725656223539, 0.8933107535986452, 0.9017781541066893]


epoch:27,	loss_g:31.151394486427307	loss_d:11.508400201797485
train_code_acc:[0.731288869826292, 0.9251554793051684, 0.9583958824790907]
train_judgement_acc:[0.7568089212953034, 0.9270855672313961, 0.9541067981985846]


test_answer_acc:0.8983833718244804	iter_cnt_mean:1.6166281755196306
test_code_acc:[0.6917866215071973, 0.8628281117696867, 0.8653683319220999]
test_judgement_acc:[0.7679932260795935, 0.9127857747671465, 0.9136325148179509]


epoch:28,	loss_g:30.62038290500641	loss_d:11.214929223060608
train_code_acc:[0.7469440274501394, 0.934805918936307, 0.966330688398027]
train_judgement_acc:[0.7731074415612267, 0.938880549002788, 0.956465794552863]


test_answer_acc:0.8660508083140878	iter_cnt_mean:1.6166281755196306
test_code_acc:[0.6934801016088061, 0.8467400508044031, 0.8526672311600338]
test_judgement_acc:[0.77307366638442, 0.8992379339542761, 0.890770533446232]


epoch:29,	loss_g:29.50037717819214	loss_d:11.492612183094025
train_code_acc:[0.7387947673171777, 0.9328758310100793, 0.9648295088998499]
train_judgement_acc:[0.7608835513617842, 0.9318035599399528, 0.9592536993351919]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5889145496535797
test_code_acc:[0.7129551227773073, 0.8577476714648603, 0.8636748518204911]
test_judgement_acc:[0.7552921253175275, 0.890770533446232, 0.890770533446232]


epoch:30,	loss_g:27.170799016952515	loss_d:10.460323512554169
train_code_acc:[0.7568089212953034, 0.9435985417113446, 0.9731932232468368]
train_judgement_acc:[0.7778254342697835, 0.9399528200729145, 0.9674029594681536]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.5773672055427252
test_code_acc:[0.7112616426756986, 0.8543607112616427, 0.8577476714648603]
test_judgement_acc:[0.7832345469940728, 0.8933107535986452, 0.8992379339542761]


epoch:31,	loss_g:28.316048860549927	loss_d:10.366009831428528
train_code_acc:[0.7598112802916577, 0.9408106369290157, 0.9665451426120524]
train_judgement_acc:[0.7834012438344413, 0.9412395453570662, 0.963542783615698]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5704387990762125
test_code_acc:[0.720575783234547, 0.8611346316680779, 0.8662150719729044]
test_judgement_acc:[0.7908552074513124, 0.9093988145639289, 0.9110922946655376]


epoch:32,	loss_g:28.199296236038208	loss_d:10.40029376745224
train_code_acc:[0.7643148187861891, 0.940381728500965, 0.9704053184645078]
train_judgement_acc:[0.7851168775466438, 0.9405961827149903, 0.9659017799699764]


test_answer_acc:0.8683602771362586	iter_cnt_mean:1.5889145496535797
test_code_acc:[0.7129551227773073, 0.8509737510584251, 0.8535139712108383]
test_judgement_acc:[0.7705334462320068, 0.8806096528365792, 0.8797629127857748]


epoch:33,	loss_g:28.00948143005371	loss_d:10.115740716457367
train_code_acc:[0.7653870898563156, 0.9457430838515977, 0.9738365858889128]
train_judgement_acc:[0.7861891486167704, 0.9506755307741798, 0.9656873257559511]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.5935334872979214
test_code_acc:[0.7188823031329382, 0.8619813717188823, 0.8679085520745131]
test_judgement_acc:[0.7883149872988993, 0.8975444538526672, 0.8966977138018628]


epoch:34,	loss_g:24.14394700527191	loss_d:10.133912324905396
train_code_acc:[0.7713918078490243, 0.9483165344199014, 0.9787690328114947]
train_judgement_acc:[0.7864036028307956, 0.948102080205876, 0.9738365858889128]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5750577367205543
test_code_acc:[0.7265029635901779, 0.8628281117696867, 0.8687552921253175]
test_judgement_acc:[0.7764606265876376, 0.8856900931414056, 0.8958509737510584]


epoch:35,	loss_g:25.789180994033813	loss_d:9.864216446876526
train_code_acc:[0.7681749946386447, 0.9483165344199014, 0.9759811280291658]
train_judgement_acc:[0.7883336907570234, 0.9476731717778254, 0.971263135320609]


test_answer_acc:0.8706697459584296	iter_cnt_mean:1.535796766743649
test_code_acc:[0.7442845046570703, 0.8560541913632514, 0.8602878916172735]
test_judgement_acc:[0.785774767146486, 0.8856900931414056, 0.8806096528365792]


epoch:36,	loss_g:25.628962993621826	loss_d:9.689479231834412
train_code_acc:[0.7821145185502895, 0.9521767102723568, 0.9753377653870898]
train_judgement_acc:[0.7898348702552005, 0.9541067981985846, 0.9710486811065837]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5635103926096998
test_code_acc:[0.729043183742591, 0.8611346316680779, 0.8653683319220999]
test_judgement_acc:[0.7976291278577476, 0.8958509737510584, 0.9000846740050804]


epoch:37,	loss_g:24.077689051628113	loss_d:9.01121473312378
train_code_acc:[0.7977696761741369, 0.9558224319107871, 0.9804846665236971]
train_judgement_acc:[0.8099935663735792, 0.9543212524126099, 0.9744799485309886]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.53810623556582
test_code_acc:[0.7408975444538527, 0.8611346316680779, 0.8662150719729044]
test_judgement_acc:[0.7798475867908552, 0.8831498729889924, 0.88653683319221]


epoch:38,	loss_g:24.178918957710266	loss_d:9.096730709075928
train_code_acc:[0.7874758739009221, 0.9547501608406606, 0.9802702123096719]
train_judgement_acc:[0.8012009435985417, 0.9549646150546858, 0.9753377653870898]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.53810623556582
test_code_acc:[0.7324301439458086, 0.8602878916172735, 0.8662150719729044]
test_judgement_acc:[0.7925486875529213, 0.8941574936494496, 0.8924640135478408]


epoch:39,	loss_g:24.002349495887756	loss_d:9.159555435180664
train_code_acc:[0.7906926871113017, 0.9575380656229895, 0.981771391807849]
train_judgement_acc:[0.8027021230967188, 0.9577525198370148, 0.9755522196011152]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5612009237875288
test_code_acc:[0.7273497036409822, 0.8628281117696867, 0.8687552921253175]
test_judgement_acc:[0.7620660457239627, 0.8797629127857748, 0.8848433530906011]


epoch:40,	loss_g:21.16060894727707	loss_d:8.741294413805008
train_code_acc:[0.7913360497533777, 0.9556079776967618, 0.9828436628779755]
train_judgement_acc:[0.8037743941668454, 0.9526056187004075, 0.9785545785974694]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.535796766743649
test_code_acc:[0.7358171041490262, 0.869602032176122, 0.8755292125317528]
test_judgement_acc:[0.7917019475021169, 0.882303132938188, 0.8916172734970365]


epoch:41,	loss_g:22.172513723373413	loss_d:8.828469425439835
train_code_acc:[0.7941239545357066, 0.961398241475445, 0.9843448423761527]
train_judgement_acc:[0.8031310315247695, 0.9601115161912932, 0.9779112159553935]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5473441108545034
test_code_acc:[0.729043183742591, 0.8687552921253175, 0.8738357324301439]
test_judgement_acc:[0.7925486875529213, 0.8899237933954276, 0.8941574936494496]


epoch:42,	loss_g:21.265184938907623	loss_d:8.09946021437645
train_code_acc:[0.8031310315247695, 0.9656873257559511, 0.984559296590178]
train_judgement_acc:[0.8149260132961613, 0.966330688398027, 0.982414754449925]


test_answer_acc:0.9006928406466512	iter_cnt_mean:1.5150115473441108
test_code_acc:[0.7417442845046571, 0.8746824724809483, 0.8789161727349704]
test_judgement_acc:[0.7849280270956817, 0.8958509737510584, 0.9009314140558848]


epoch:43,	loss_g:22.25714409351349	loss_d:8.481724619865417
train_code_acc:[0.8018443062406176, 0.9560368861248123, 0.9815569375938237]
train_judgement_acc:[0.8170705554364144, 0.9541067981985846, 0.976838944885267]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5265588914549653
test_code_acc:[0.7392040643522438, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7832345469940728, 0.8856900931414056, 0.8890770533446232]


epoch:44,	loss_g:19.496668308973312	loss_d:7.995062857866287
train_code_acc:[0.8136392880120095, 0.969118593180356, 0.9864893845164058]
train_judgement_acc:[0.8224319107870469, 0.9676174136821789, 0.982414754449925]


test_answer_acc:0.8960739030023095	iter_cnt_mean:1.4965357967667436
test_code_acc:[0.7485182049110923, 0.8729889923793396, 0.8797629127857748]
test_judgement_acc:[0.768839966130398, 0.88653683319221, 0.8839966130397968]


epoch:45,	loss_g:21.46353244781494	loss_d:8.133282661437988
train_code_acc:[0.8114947458717564, 0.9644006004717993, 0.9834870255200515]
train_judgement_acc:[0.8190006433626421, 0.9628994209736221, 0.9789834870255201]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.5150115473441108
test_code_acc:[0.7400508044030483, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7832345469940728, 0.8916172734970365, 0.8916172734970365]


epoch:46,	loss_g:22.488596439361572	loss_d:8.27105700969696
train_code_acc:[0.8123525627278576, 0.9607548788333691, 0.9828436628779755]
train_judgement_acc:[0.8256487239974265, 0.9616126956894703, 0.9806991207377225]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.508083140877598
test_code_acc:[0.7442845046570703, 0.8611346316680779, 0.8662150719729044]
test_judgement_acc:[0.781541066892464, 0.882303132938188, 0.8899237933954276]


epoch:47,	loss_g:19.373916268348694	loss_d:7.822285413742065
train_code_acc:[0.8144971048681107, 0.961398241475445, 0.987347201372507]
train_judgement_acc:[0.8222174565730217, 0.9607548788333691, 0.9832725713060262]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.4988452655889146
test_code_acc:[0.7535986452159187, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7823878069432684, 0.882303132938188, 0.8882303132938189]


epoch:48,	loss_g:20.99419468641281	loss_d:7.066464811563492
train_code_acc:[0.8295088998498821, 0.9704053184645078, 0.9864893845164058]
train_judgement_acc:[0.8410894274072486, 0.9682607763242548, 0.984559296590178]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5057736720554273
test_code_acc:[0.7510584250635055, 0.8602878916172735, 0.8679085520745131]
test_judgement_acc:[0.7798475867908552, 0.8789161727349704, 0.8856900931414056]


epoch:49,	loss_g:19.493826866149902	loss_d:7.323581755161285
train_code_acc:[0.8102080205876045, 0.9644006004717993, 0.9871327471584816]
train_judgement_acc:[0.8286510829937809, 0.9644006004717993, 0.9832725713060262]


test_answer_acc:0.8983833718244804	iter_cnt_mean:1.5057736720554273
test_code_acc:[0.7468247248094835, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7764606265876376, 0.88653683319221, 0.8916172734970365]


epoch:50,	loss_g:19.677615582942963	loss_d:6.926561057567596
train_code_acc:[0.832940167274287, 0.9671885052541283, 0.9860604760883551]
train_judgement_acc:[0.8443062406176282, 0.966330688398027, 0.9843448423761527]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.510392609699769
test_code_acc:[0.7493649449618967, 0.8729889923793396, 0.8763759525825572]
test_judgement_acc:[0.7679932260795935, 0.8839966130397968, 0.882303132938188]


epoch:51,	loss_g:21.172778487205505	loss_d:6.966444611549377
train_code_acc:[0.8280077203517049, 0.9667595968260776, 0.9864893845164058]
train_judgement_acc:[0.8415183358352991, 0.9646150546858245, 0.9834870255200515]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5311778290993072
test_code_acc:[0.7417442845046571, 0.8611346316680779, 0.8670618120237087]
test_judgement_acc:[0.7849280270956817, 0.8806096528365792, 0.8848433530906011]


epoch:52,	loss_g:18.83261626958847	loss_d:7.191469520330429
train_code_acc:[0.8269354492815784, 0.9652584173279005, 0.9858460218743298]
train_judgement_acc:[0.839373793695046, 0.964186146257774, 0.9813424833797985]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4988452655889146
test_code_acc:[0.7493649449618967, 0.8577476714648603, 0.8602878916172735]
test_judgement_acc:[0.7950889077053345, 0.8763759525825572, 0.8772226926333616]


epoch:53,	loss_g:18.26664012670517	loss_d:6.647767752408981
train_code_acc:[0.8376581599828437, 0.9719064979626849, 0.9903495603688612]
train_judgement_acc:[0.8430195153334763, 0.9710486811065837, 0.9882050182286082]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7544453852667231, 0.8712955122777307, 0.8738357324301439]
test_judgement_acc:[0.7917019475021169, 0.8958509737510584, 0.8950042337002541]


epoch:54,	loss_g:18.142944246530533	loss_d:6.5887636840343475
train_code_acc:[0.8387304310529702, 0.9729787690328114, 0.9899206519408107]
train_judgement_acc:[0.844949603259704, 0.9719064979626849, 0.9886339266566588]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7544453852667231, 0.8704487722269263, 0.8755292125317528]
test_judgement_acc:[0.777307366638442, 0.8873835732430144, 0.8899237933954276]


epoch:55,	loss_g:18.082251012325287	loss_d:6.834055721759796
train_code_acc:[0.8346558009864894, 0.9684752305382801, 0.9886339266566588]
train_judgement_acc:[0.8415183358352991, 0.9669740510401029, 0.9847737508042033]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.489607390300231
test_code_acc:[0.7586790855207451, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.7891617273497037, 0.8992379339542761, 0.8941574936494496]


epoch:56,	loss_g:18.3491308093071	loss_d:6.332460641860962
train_code_acc:[0.844949603259704, 0.9734076774608621, 0.9897061977267854]
train_judgement_acc:[0.8535277718207163, 0.9729787690328114, 0.98949174351276]


test_answer_acc:0.9053117782909931	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7535986452159187, 0.8814563928873835, 0.8856900931414056]
test_judgement_acc:[0.7984758679085521, 0.9017781541066893, 0.9051651143099069]


epoch:57,	loss_g:16.88866651058197	loss_d:6.439118474721909
train_code_acc:[0.843448423761527, 0.9704053184645078, 0.98949174351276]
train_judgement_acc:[0.850525412824362, 0.9695475016084066, 0.9879905640145829]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.756138865368332, 0.8662150719729044, 0.8704487722269263]
test_judgement_acc:[0.785774767146486, 0.8873835732430144, 0.890770533446232]


epoch:58,	loss_g:17.13391402363777	loss_d:6.67358461022377
train_code_acc:[0.8395882479090714, 0.9684752305382801, 0.9879905640145829]
train_judgement_acc:[0.8475230538280077, 0.9671885052541283, 0.9852026592322539]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7603725656223539, 0.8611346316680779, 0.8636748518204911]
test_judgement_acc:[0.79424216765453, 0.8848433530906011, 0.8848433530906011]


epoch:59,	loss_g:18.56510454416275	loss_d:6.230348959565163
train_code_acc:[0.8460218743298306, 0.9725498606047609, 0.9903495603688612]
train_judgement_acc:[0.8511687754664379, 0.9708342268925585, 0.9890628350847094]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7578323454699407, 0.8653683319220999, 0.8687552921253175]
test_judgement_acc:[0.7984758679085521, 0.8899237933954276, 0.8933107535986452]


epoch:60,	loss_g:18.00371289253235	loss_d:6.070077866315842
train_code_acc:[0.8460218743298306, 0.9714775895346344, 0.9901351061548359]
train_judgement_acc:[0.8606047608835513, 0.9695475016084066, 0.9877761098005576]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7612193056731583, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.7866215071972904, 0.8924640135478408, 0.8933107535986452]


epoch:61,	loss_g:20.01139545440674	loss_d:6.020534157752991
train_code_acc:[0.8503109586103367, 0.9721209521767102, 0.9875616555865323]
train_judgement_acc:[0.857602401887197, 0.9710486811065837, 0.9867038387304311]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.508083140877598
test_code_acc:[0.7578323454699407, 0.8679085520745131, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.8966977138018628, 0.903471634208298]


epoch:62,	loss_g:16.161480337381363	loss_d:5.721315920352936
train_code_acc:[0.8458074201158052, 0.9798413038816213, 0.9916362856530131]
train_judgement_acc:[0.8543855886768175, 0.9783401243834441, 0.9886339266566588]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7578323454699407, 0.8687552921253175, 0.8755292125317528]
test_judgement_acc:[0.781541066892464, 0.8856900931414056, 0.8916172734970365]


epoch:63,	loss_g:16.312596172094345	loss_d:5.425095021724701
train_code_acc:[0.8543855886768175, 0.9774823075273429, 0.9924941025091143]
train_judgement_acc:[0.8644649367360069, 0.9766244906712417, 0.9903495603688612]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.508083140877598
test_code_acc:[0.7578323454699407, 0.8687552921253175, 0.8738357324301439]
test_judgement_acc:[0.8052497883149873, 0.9000846740050804, 0.9017781541066893]


epoch:64,	loss_g:17.697062015533447	loss_d:5.86660373210907
train_code_acc:[0.8498820501822861, 0.9721209521767102, 0.9901351061548359]
train_judgement_acc:[0.8618914861677032, 0.9723354063907356, 0.9871327471584816]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.489607390300231
test_code_acc:[0.7595258255715496, 0.8645215918712955, 0.8704487722269263]
test_judgement_acc:[0.8035563082133785, 0.8856900931414056, 0.8890770533446232]


epoch:65,	loss_g:17.480492174625397	loss_d:5.604949116706848
train_code_acc:[0.8475230538280077, 0.9742654943169633, 0.9905640145828866]
train_judgement_acc:[0.8571734934591465, 0.971263135320609, 0.9899206519408107]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7603725656223539, 0.8628281117696867, 0.8662150719729044]
test_judgement_acc:[0.8052497883149873, 0.8882303132938189, 0.8933107535986452]


epoch:66,	loss_g:16.108959794044495	loss_d:5.492205888032913
train_code_acc:[0.8578168561012224, 0.9774823075273429, 0.992923010937165]
train_judgement_acc:[0.8633926656658804, 0.9770533990992923, 0.9918507398670384]


test_answer_acc:0.8660508083140878	iter_cnt_mean:1.508083140877598
test_code_acc:[0.7552921253175275, 0.8577476714648603, 0.8619813717188823]
test_judgement_acc:[0.8010160880609652, 0.8814563928873835, 0.882303132938188]


epoch:67,	loss_g:16.05258983373642	loss_d:5.737160235643387
train_code_acc:[0.8511687754664379, 0.9753377653870898, 0.9914218314389878]
train_judgement_acc:[0.8580313103152477, 0.9753377653870898, 0.9899206519408107]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7603725656223539, 0.8653683319220999, 0.8704487722269263]
test_judgement_acc:[0.7993226079593565, 0.8950042337002541, 0.8975444538526672]


epoch:68,	loss_g:16.502508372068405	loss_d:5.647431313991547
train_code_acc:[0.8543855886768175, 0.974051040102938, 0.9916362856530131]
train_judgement_acc:[0.8648938451640574, 0.9729787690328114, 0.9899206519408107]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.5011547344110854
test_code_acc:[0.7519051651143099, 0.8611346316680779, 0.8679085520745131]
test_judgement_acc:[0.7790008467400508, 0.8873835732430144, 0.8848433530906011]


epoch:69,	loss_g:15.837951004505157	loss_d:5.554554104804993
train_code_acc:[0.85610122238902, 0.9751233111730645, 0.9927085567231396]
train_judgement_acc:[0.8644649367360069, 0.9734076774608621, 0.9916362856530131]


test_answer_acc:0.8637413394919169	iter_cnt_mean:1.508083140877598
test_code_acc:[0.7595258255715496, 0.8602878916172735, 0.8645215918712955]
test_judgement_acc:[0.7823878069432684, 0.8729889923793396, 0.8755292125317528]


epoch:70,	loss_g:16.187167167663574	loss_d:5.505721211433411
train_code_acc:[0.8539566802487669, 0.9742654943169633, 0.9914218314389878]
train_judgement_acc:[0.8608192150975766, 0.9738365858889128, 0.9901351061548359]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7620660457239627, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.7976291278577476, 0.9017781541066893, 0.8966977138018628]


epoch:71,	loss_g:16.104758501052856	loss_d:5.613233953714371
train_code_acc:[0.84559296590178, 0.9753377653870898, 0.9924941025091143]
train_judgement_acc:[0.8558867681749946, 0.9742654943169633, 0.9901351061548359]


test_answer_acc:0.8683602771362586	iter_cnt_mean:1.5011547344110854
test_code_acc:[0.7595258255715496, 0.859441151566469, 0.8628281117696867]
test_judgement_acc:[0.7967823878069432, 0.8831498729889924, 0.8806096528365792]


epoch:72,	loss_g:14.358933448791504	loss_d:4.987307831645012
train_code_acc:[0.8646793909500322, 0.9802702123096719, 0.9942097362213167]
train_judgement_acc:[0.8698262920866395, 0.9798413038816213, 0.9927085567231396]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4849884526558892
test_code_acc:[0.7654530059271804, 0.8619813717188823, 0.8645215918712955]
test_judgement_acc:[0.7959356477561389, 0.8856900931414056, 0.8890770533446232]


epoch:73,	loss_g:15.024829924106598	loss_d:4.98722168803215
train_code_acc:[0.8663950246622346, 0.9774823075273429, 0.9927085567231396]
train_judgement_acc:[0.8747587390092215, 0.9766244906712417, 0.9907784687969119]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7620660457239627, 0.8636748518204911, 0.8679085520745131]
test_judgement_acc:[0.7891617273497037, 0.8899237933954276, 0.88653683319221]


epoch:74,	loss_g:16.61309564113617	loss_d:5.558444768190384
train_code_acc:[0.8616770319536778, 0.974051040102938, 0.9907784687969119]
train_judgement_acc:[0.8648938451640574, 0.9729787690328114, 0.9897061977267854]


test_answer_acc:0.8706697459584296	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7671464860287892, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7967823878069432, 0.8958509737510584, 0.8950042337002541]


epoch:75,	loss_g:14.699428617954254	loss_d:4.895866051316261
train_code_acc:[0.8651082993780828, 0.9804846665236971, 0.9948530988633927]
train_judgement_acc:[0.8751876474372722, 0.9800557580956466, 0.9948530988633927]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.466512702078522
test_code_acc:[0.7646062658763759, 0.8670618120237087, 0.8712955122777307]
test_judgement_acc:[0.785774767146486, 0.8890770533446232, 0.8831498729889924]


epoch:76,	loss_g:16.51466315984726	loss_d:4.926582485437393
train_code_acc:[0.8704696547287154, 0.9813424833797985, 0.992279648295089]
train_judgement_acc:[0.8745442847951962, 0.9804846665236971, 0.992279648295089]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7713801862828111, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.8018628281117697, 0.8992379339542761, 0.8958509737510584]


epoch:77,	loss_g:14.777406454086304	loss_d:4.909389972686768
train_code_acc:[0.8726141968689685, 0.9783401243834441, 0.9939952820072915]
train_judgement_acc:[0.8790478232897276, 0.9772678533133176, 0.9924941025091143]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7679932260795935, 0.869602032176122, 0.8721422523285352]
test_judgement_acc:[0.8027095681625741, 0.90770533446232, 0.9000846740050804]


epoch:78,	loss_g:14.005687654018402	loss_d:4.868793413043022
train_code_acc:[0.8678962041604118, 0.9789834870255201, 0.992923010937165]
train_judgement_acc:[0.8741153763671456, 0.9785545785974694, 0.9927085567231396]


test_answer_acc:0.8660508083140878	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7646062658763759, 0.8619813717188823, 0.8653683319220999]
test_judgement_acc:[0.8086367485182049, 0.8924640135478408, 0.8924640135478408]


epoch:79,	loss_g:15.363223254680634	loss_d:5.014260232448578
train_code_acc:[0.8698262920866395, 0.9774823075273429, 0.9931374651511902]
train_judgement_acc:[0.88076345700193, 0.9781256701694189, 0.9918507398670384]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.4549653579676673
test_code_acc:[0.7747671464860287, 0.8780694326841659, 0.8797629127857748]
test_judgement_acc:[0.8010160880609652, 0.9017781541066893, 0.8992379339542761]


epoch:80,	loss_g:15.70069569349289	loss_d:4.69997102022171
train_code_acc:[0.8741153763671456, 0.9806991207377225, 0.9942097362213167]
train_judgement_acc:[0.8773321895775252, 0.9802702123096719, 0.9935663735792408]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4595842956120093
test_code_acc:[0.7798475867908552, 0.8738357324301439, 0.8763759525825572]
test_judgement_acc:[0.8027095681625741, 0.8856900931414056, 0.88653683319221]


epoch:81,	loss_g:13.895587787032127	loss_d:4.81986927986145
train_code_acc:[0.8702552005146901, 0.9776967617413682, 0.9939952820072915]
train_judgement_acc:[0.8749731932232468, 0.9779112159553935, 0.9933519193652155]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4595842956120093
test_code_acc:[0.7705334462320068, 0.8729889923793396, 0.8738357324301439]
test_judgement_acc:[0.8027095681625741, 0.8966977138018628, 0.8924640135478408]


epoch:82,	loss_g:15.595898747444153	loss_d:5.077857285737991
train_code_acc:[0.8698262920866395, 0.9783401243834441, 0.9916362856530131]
train_judgement_acc:[0.8788333690757023, 0.9779112159553935, 0.9892772892987347]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7739204064352244, 0.8679085520745131, 0.8704487722269263]
test_judgement_acc:[0.8035563082133785, 0.8848433530906011, 0.8806096528365792]


epoch:83,	loss_g:14.758180260658264	loss_d:4.809988498687744
train_code_acc:[0.8721852884409179, 0.9779112159553935, 0.9933519193652155]
train_judgement_acc:[0.8784044606476518, 0.9779112159553935, 0.9927085567231396]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.7671464860287892, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7984758679085521, 0.8924640135478408, 0.8933107535986452]


epoch:84,	loss_g:13.884459257125854	loss_d:5.010305255651474
train_code_acc:[0.8689684752305383, 0.9770533990992923, 0.9924941025091143]
train_judgement_acc:[0.878618914861677, 0.9759811280291658, 0.992923010937165]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7705334462320068, 0.8712955122777307, 0.8746824724809483]
test_judgement_acc:[0.7976291278577476, 0.8941574936494496, 0.8916172734970365]


epoch:85,	loss_g:16.19460368156433	loss_d:4.998683765530586
train_code_acc:[0.8700407463006649, 0.9755522196011152, 0.9916362856530131]
train_judgement_acc:[0.8717563800128673, 0.9766244906712417, 0.9918507398670384]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.768839966130398, 0.869602032176122, 0.8712955122777307]
test_judgement_acc:[0.8035563082133785, 0.8882303132938189, 0.88653683319221]


epoch:86,	loss_g:12.23702096939087	loss_d:4.68577253818512
train_code_acc:[0.8721852884409179, 0.9774823075273429, 0.9957109157194939]
train_judgement_acc:[0.8799056401458288, 0.9772678533133176, 0.995067553077418]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7696867061812024, 0.869602032176122, 0.8721422523285352]
test_judgement_acc:[0.8018628281117697, 0.8856900931414056, 0.8848433530906011]


epoch:87,	loss_g:13.490005016326904	loss_d:4.363053694367409
train_code_acc:[0.8762599185073987, 0.9800557580956466, 0.9939952820072915]
train_judgement_acc:[0.8861248123525627, 0.9800557580956466, 0.9942097362213167]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7713801862828111, 0.8721422523285352, 0.8746824724809483]
test_judgement_acc:[0.8001693480101609, 0.8941574936494496, 0.8924640135478408]


epoch:88,	loss_g:14.403863370418549	loss_d:4.963305801153183
train_code_acc:[0.8713274715848166, 0.9753377653870898, 0.992923010937165]
train_judgement_acc:[0.8766888269354493, 0.9751233111730645, 0.9912073772249624]


test_answer_acc:0.8706697459584296	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.768839966130398, 0.8653683319220999, 0.869602032176122]
test_judgement_acc:[0.8035563082133785, 0.8789161727349704, 0.8772226926333616]


epoch:89,	loss_g:15.084573864936829	loss_d:4.6204903870821
train_code_acc:[0.8781900064336264, 0.9826292086639502, 0.9942097362213167]
train_judgement_acc:[0.8805490027879048, 0.9826292086639502, 0.9937808277932662]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.46189376443418
test_code_acc:[0.7662997459779848, 0.8653683319220999, 0.8687552921253175]
test_judgement_acc:[0.8187976291278577, 0.8831498729889924, 0.882303132938188]


epoch:90,	loss_g:13.368903145194054	loss_d:4.690005287528038
train_code_acc:[0.8739009221531203, 0.979626849667596, 0.992923010937165]
train_judgement_acc:[0.8788333690757023, 0.9798413038816213, 0.9931374651511902]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.77307366638442, 0.8729889923793396, 0.8763759525825572]
test_judgement_acc:[0.8027095681625741, 0.890770533446232, 0.882303132938188]


epoch:91,	loss_g:13.410734206438065	loss_d:4.507939696311951
train_code_acc:[0.8769032811494746, 0.9798413038816213, 0.9939952820072915]
train_judgement_acc:[0.886339266566588, 0.9794123954535706, 0.9935663735792408]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7713801862828111, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.8069432684165961, 0.8983911939034717, 0.8916172734970365]


epoch:92,	loss_g:13.76658844947815	loss_d:4.612342983484268
train_code_acc:[0.8771177353634999, 0.9794123954535706, 0.9952820072914432]
train_judgement_acc:[0.884194724426335, 0.9798413038816213, 0.994424190435342]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.7671464860287892, 0.8662150719729044, 0.8687552921253175]
test_judgement_acc:[0.7967823878069432, 0.8856900931414056, 0.8856900931414056]


epoch:93,	loss_g:14.319661140441895	loss_d:4.61514575779438
train_code_acc:[0.875831010079348, 0.9783401243834441, 0.994424190435342]
train_judgement_acc:[0.8809779112159554, 0.9772678533133176, 0.994424190435342]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7696867061812024, 0.8662150719729044, 0.8679085520745131]
test_judgement_acc:[0.7959356477561389, 0.8856900931414056, 0.8873835732430144]


epoch:94,	loss_g:13.558351159095764	loss_d:4.844873681664467
train_code_acc:[0.8745442847951962, 0.9755522196011152, 0.992923010937165]
train_judgement_acc:[0.8803345485738795, 0.976838944885267, 0.9918507398670384]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.77307366638442, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.7950889077053345, 0.8958509737510584, 0.8899237933954276]


epoch:95,	loss_g:13.629262268543243	loss_d:4.4345159232616425
train_code_acc:[0.8835513617842591, 0.9794123954535706, 0.9935663735792408]
train_judgement_acc:[0.8923439845592966, 0.9781256701694189, 0.992923010937165]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7696867061812024, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.7874682472480948, 0.8797629127857748, 0.8780694326841659]


epoch:96,	loss_g:13.249063789844513	loss_d:4.677347958087921
train_code_acc:[0.8775466437915505, 0.9776967617413682, 0.9948530988633927]
train_judgement_acc:[0.8794767317177783, 0.976838944885267, 0.9948530988633927]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7739204064352244, 0.8721422523285352, 0.8763759525825572]
test_judgement_acc:[0.7993226079593565, 0.8933107535986452, 0.8839966130397968]


epoch:97,	loss_g:13.836454272270203	loss_d:4.798480778932571
train_code_acc:[0.8766888269354493, 0.9783401243834441, 0.9939952820072915]
train_judgement_acc:[0.8805490027879048, 0.9770533990992923, 0.9920651940810636]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4595842956120093
test_code_acc:[0.7756138865368332, 0.8729889923793396, 0.8755292125317528]
test_judgement_acc:[0.8018628281117697, 0.8797629127857748, 0.8772226926333616]


epoch:98,	loss_g:12.348261088132858	loss_d:4.229613810777664
train_code_acc:[0.8820501822860819, 0.982414754449925, 0.9959253699335192]
train_judgement_acc:[0.8925584387733219, 0.9806991207377225, 0.9961398241475445]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7722269263336156, 0.8712955122777307, 0.8738357324301439]
test_judgement_acc:[0.7925486875529213, 0.8814563928873835, 0.8806096528365792]


epoch:99,	loss_g:12.820409119129181	loss_d:4.3578712195158005
train_code_acc:[0.881406819644006, 0.979626849667596, 0.9948530988633927]
train_judgement_acc:[0.8856959039245121, 0.9787690328114947, 0.9948530988633927]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7722269263336156, 0.869602032176122, 0.8721422523285352]
test_judgement_acc:[0.7908552074513124, 0.8780694326841659, 0.8772226926333616]


epoch:100,	loss_g:12.723585069179535	loss_d:4.785223692655563
train_code_acc:[0.8784044606476518, 0.9804846665236971, 0.9946386446493674]
train_judgement_acc:[0.8829079991421831, 0.981771391807849, 0.9937808277932662]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7739204064352244, 0.8721422523285352, 0.8755292125317528]
test_judgement_acc:[0.8027095681625741, 0.882303132938188, 0.8814563928873835]


epoch:101,	loss_g:13.377333998680115	loss_d:4.430413663387299
train_code_acc:[0.8826935449281579, 0.9815569375938237, 0.995067553077418]
train_judgement_acc:[0.8861248123525627, 0.9809135749517478, 0.9948530988633927]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4526558891454966
test_code_acc:[0.777307366638442, 0.8772226926333616, 0.8806096528365792]
test_judgement_acc:[0.8035563082133785, 0.8950042337002541, 0.88653683319221]


epoch:102,	loss_g:13.094847947359085	loss_d:4.69485205411911
train_code_acc:[0.8764743727214239, 0.9781256701694189, 0.9918507398670384]
train_judgement_acc:[0.881406819644006, 0.9787690328114947, 0.9912073772249624]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.4572748267898383
test_code_acc:[0.7756138865368332, 0.8738357324301439, 0.8772226926333616]
test_judgement_acc:[0.8086367485182049, 0.8950042337002541, 0.8882303132938189]


epoch:103,	loss_g:13.111961871385574	loss_d:4.3378985822200775
train_code_acc:[0.879262277503753, 0.9815569375938237, 0.9952820072914432]
train_judgement_acc:[0.8871970834226892, 0.981771391807849, 0.9954964615054686]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7747671464860287, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.8027095681625741, 0.9000846740050804, 0.8924640135478408]


epoch:104,	loss_g:13.17375072836876	loss_d:4.3847620487213135
train_code_acc:[0.8826935449281579, 0.9811280291657731, 0.995067553077418]
train_judgement_acc:[0.8882693544928157, 0.981771391807849, 0.994424190435342]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7747671464860287, 0.869602032176122, 0.8721422523285352]
test_judgement_acc:[0.79424216765453, 0.8797629127857748, 0.8797629127857748]


epoch:105,	loss_g:13.592395052313805	loss_d:4.377618432044983
train_code_acc:[0.8852669954964615, 0.979626849667596, 0.9948530988633927]
train_judgement_acc:[0.8899849882050183, 0.9794123954535706, 0.9935663735792408]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.466512702078522
test_code_acc:[0.7756138865368332, 0.8712955122777307, 0.8746824724809483]
test_judgement_acc:[0.7959356477561389, 0.8924640135478408, 0.8856900931414056]


epoch:106,	loss_g:13.561747968196869	loss_d:4.613782107830048
train_code_acc:[0.879262277503753, 0.9785545785974694, 0.994424190435342]
train_judgement_acc:[0.8803345485738795, 0.9776967617413682, 0.9939952820072915]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.77307366638442, 0.8679085520745131, 0.8721422523285352]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.882303132938188]


epoch:107,	loss_g:12.720275640487671	loss_d:4.538664177060127
train_code_acc:[0.8796911859318035, 0.9806991207377225, 0.9957109157194939]
train_judgement_acc:[0.8831224533562084, 0.9779112159553935, 0.9946386446493674]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7764606265876376, 0.8704487722269263, 0.8746824724809483]
test_judgement_acc:[0.7976291278577476, 0.8916172734970365, 0.8839966130397968]


epoch:108,	loss_g:13.023515701293945	loss_d:4.694225236773491
train_code_acc:[0.8766888269354493, 0.9770533990992923, 0.9952820072914432]
train_judgement_acc:[0.8803345485738795, 0.9766244906712417, 0.9954964615054686]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7756138865368332, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7959356477561389, 0.890770533446232, 0.8848433530906011]


epoch:109,	loss_g:13.031228244304657	loss_d:4.429789304733276
train_code_acc:[0.8822646365001072, 0.9776967617413682, 0.9931374651511902]
train_judgement_acc:[0.8901994424190436, 0.9781256701694189, 0.992923010937165]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7764606265876376, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7993226079593565, 0.8933107535986452, 0.8848433530906011]


epoch:110,	loss_g:14.53345412015915	loss_d:4.468305677175522
train_code_acc:[0.8835513617842591, 0.9811280291657731, 0.9931374651511902]
train_judgement_acc:[0.8876259918507399, 0.9811280291657731, 0.9931374651511902]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.46189376443418
test_code_acc:[0.777307366638442, 0.8721422523285352, 0.8755292125317528]
test_judgement_acc:[0.7984758679085521, 0.8941574936494496, 0.8856900931414056]


epoch:111,	loss_g:12.54978820681572	loss_d:4.487079203128815
train_code_acc:[0.8861248123525627, 0.9794123954535706, 0.9933519193652155]
train_judgement_acc:[0.8893416255629423, 0.9781256701694189, 0.9933519193652155]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7756138865368332, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7984758679085521, 0.8933107535986452, 0.8848433530906011]


epoch:112,	loss_g:13.160272687673569	loss_d:4.633337199687958
train_code_acc:[0.8777610980055758, 0.9791979412395454, 0.994424190435342]
train_judgement_acc:[0.8818357280720566, 0.9783401243834441, 0.9931374651511902]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.466512702078522
test_code_acc:[0.7764606265876376, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7993226079593565, 0.8916172734970365, 0.8839966130397968]


epoch:113,	loss_g:12.980328008532524	loss_d:4.70277513563633
train_code_acc:[0.8822646365001072, 0.9776967617413682, 0.992923010937165]
train_judgement_acc:[0.8854814497104868, 0.9779112159553935, 0.992279648295089]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7756138865368332, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7993226079593565, 0.8933107535986452, 0.8856900931414056]


epoch:114,	loss_g:12.434199899435043	loss_d:4.5478306114673615
train_code_acc:[0.878618914861677, 0.9798413038816213, 0.995067553077418]
train_judgement_acc:[0.8874115376367145, 0.9787690328114947, 0.995067553077418]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7756138865368332, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7993226079593565, 0.8916172734970365, 0.8839966130397968]


epoch:115,	loss_g:12.404149651527405	loss_d:4.432953849434853
train_code_acc:[0.8803345485738795, 0.9804846665236971, 0.9952820072914432]
train_judgement_acc:[0.8846236328543856, 0.9791979412395454, 0.9948530988633927]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7747671464860287, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7967823878069432, 0.8916172734970365, 0.8839966130397968]


epoch:116,	loss_g:13.906858563423157	loss_d:4.38053035736084
train_code_acc:[0.8839802702123096, 0.9800557580956466, 0.9942097362213167]
train_judgement_acc:[0.8889127171348917, 0.9800557580956466, 0.9935663735792408]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7739204064352244, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7959356477561389, 0.8916172734970365, 0.8831498729889924]


epoch:117,	loss_g:11.789255559444427	loss_d:4.505082190036774
train_code_acc:[0.8822646365001072, 0.9785545785974694, 0.9946386446493674]
train_judgement_acc:[0.8891271713489171, 0.9779112159553935, 0.9946386446493674]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7967823878069432, 0.8899237933954276, 0.8831498729889924]


epoch:118,	loss_g:11.440243303775787	loss_d:4.379824250936508
train_code_acc:[0.8824790907141326, 0.979626849667596, 0.9961398241475445]
train_judgement_acc:[0.8899849882050183, 0.9783401243834441, 0.9952820072914432]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7722269263336156, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7967823878069432, 0.8899237933954276, 0.8839966130397968]


epoch:119,	loss_g:14.390601113438606	loss_d:4.593516334891319
train_code_acc:[0.8803345485738795, 0.9766244906712417, 0.9918507398670384]
train_judgement_acc:[0.8874115376367145, 0.9774823075273429, 0.9920651940810636]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7722269263336156, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.8839966130397968]


epoch:120,	loss_g:13.098838955163956	loss_d:4.411355078220367
train_code_acc:[0.8865537207806133, 0.9809135749517478, 0.9946386446493674]
train_judgement_acc:[0.886339266566588, 0.9800557580956466, 0.994424190435342]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.8839966130397968]


epoch:121,	loss_g:12.21890264749527	loss_d:4.154716789722443
train_code_acc:[0.8846236328543856, 0.9834870255200515, 0.9959253699335192]
train_judgement_acc:[0.8925584387733219, 0.9843448423761527, 0.9954964615054686]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.8839966130397968]


epoch:122,	loss_g:12.827936083078384	loss_d:4.142823487520218
train_code_acc:[0.8856959039245121, 0.9822003002358997, 0.9963542783615698]
train_judgement_acc:[0.8947029809135749, 0.9822003002358997, 0.9952820072914432]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.8839966130397968]


epoch:123,	loss_g:13.030361086130142	loss_d:4.275805801153183
train_code_acc:[0.8871970834226892, 0.9798413038816213, 0.9946386446493674]
train_judgement_acc:[0.8923439845592966, 0.9791979412395454, 0.9937808277932662]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:124,	loss_g:15.475156903266907	loss_d:4.498703643679619
train_code_acc:[0.8805490027879048, 0.9787690328114947, 0.9933519193652155]
train_judgement_acc:[0.8871970834226892, 0.9776967617413682, 0.9924941025091143]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:125,	loss_g:14.60682538151741	loss_d:4.417718335986137
train_code_acc:[0.8833369075702338, 0.979626849667596, 0.9933519193652155]
train_judgement_acc:[0.8921295303452713, 0.9789834870255201, 0.992923010937165]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:126,	loss_g:11.576465278863907	loss_d:4.500392496585846
train_code_acc:[0.8801200943598542, 0.9804846665236971, 0.995067553077418]
train_judgement_acc:[0.886982629208664, 0.9785545785974694, 0.9946386446493674]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:127,	loss_g:11.309926986694336	loss_d:4.4486642479896545
train_code_acc:[0.8826935449281579, 0.9819858460218743, 0.9959253699335192]
train_judgement_acc:[0.886339266566588, 0.9809135749517478, 0.9954964615054686]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:128,	loss_g:12.395105749368668	loss_d:4.480927959084511
train_code_acc:[0.8820501822860819, 0.9804846665236971, 0.9946386446493674]
train_judgement_acc:[0.886339266566588, 0.9802702123096719, 0.9946386446493674]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]


epoch:129,	loss_g:13.8386732339859	loss_d:4.667276903986931
train_code_acc:[0.8790478232897276, 0.976838944885267, 0.9942097362213167]
train_judgement_acc:[0.8794767317177783, 0.9776967617413682, 0.9933519193652155]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.77307366638442, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7976291278577476, 0.890770533446232, 0.8831498729889924]
after process dataset len: 433
total passed: 0
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 154376.23it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 97010.50it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
===========================train setting parameters=========================
encoder.embeddings.word_embeddings.weight-torch.Size([30522, 768])
encoder.embeddings.position_embeddings.weight-torch.Size([512, 768])
encoder.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
encoder.embeddings.LayerNorm.weight-torch.Size([768])
encoder.embeddings.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.0.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.1.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.2.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.3.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.4.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.5.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.6.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.7.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.8.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.9.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.10.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.11.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
encoder.pooler.dense.weight-torch.Size([768, 768])
encoder.pooler.dense.bias-torch.Size([768])
code_emb.embedding.weight-torch.Size([29, 768])
fusion_fc.weight-torch.Size([768, 1536])
fusion_fc.bias-torch.Size([768])
geneartor.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.linear1.weight-torch.Size([2048, 768])
geneartor.decoder_layers.linear1.bias-torch.Size([2048])
geneartor.decoder_layers.linear2.weight-torch.Size([768, 2048])
geneartor.decoder_layers.linear2.bias-torch.Size([768])
geneartor.decoder_layers.norm1.weight-torch.Size([768])
geneartor.decoder_layers.norm1.bias-torch.Size([768])
geneartor.decoder_layers.norm2.weight-torch.Size([768])
geneartor.decoder_layers.norm2.bias-torch.Size([768])
geneartor.decoder_layers.norm3.weight-torch.Size([768])
geneartor.decoder_layers.norm3.bias-torch.Size([768])
geneartor.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.0.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.0.linear2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm1.weight-torch.Size([768])
geneartor.decoder.layers.0.norm1.bias-torch.Size([768])
geneartor.decoder.layers.0.norm2.weight-torch.Size([768])
geneartor.decoder.layers.0.norm2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm3.weight-torch.Size([768])
geneartor.decoder.layers.0.norm3.bias-torch.Size([768])
geneartor.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.1.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.1.linear2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm1.weight-torch.Size([768])
geneartor.decoder.layers.1.norm1.bias-torch.Size([768])
geneartor.decoder.layers.1.norm2.weight-torch.Size([768])
geneartor.decoder.layers.1.norm2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm3.weight-torch.Size([768])
geneartor.decoder.layers.1.norm3.bias-torch.Size([768])
geneartor.decoder.layers.2.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.2.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.2.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.2.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.2.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.2.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.2.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.2.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.2.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.2.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.2.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.2.linear2.bias-torch.Size([768])
geneartor.decoder.layers.2.norm1.weight-torch.Size([768])
geneartor.decoder.layers.2.norm1.bias-torch.Size([768])
geneartor.decoder.layers.2.norm2.weight-torch.Size([768])
geneartor.decoder.layers.2.norm2.bias-torch.Size([768])
geneartor.decoder.layers.2.norm3.weight-torch.Size([768])
geneartor.decoder.layers.2.norm3.bias-torch.Size([768])
geneartor.decoder.layers.3.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.3.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.3.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.3.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.3.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.3.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.3.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.3.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.3.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.3.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.3.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.3.linear2.bias-torch.Size([768])
geneartor.decoder.layers.3.norm1.weight-torch.Size([768])
geneartor.decoder.layers.3.norm1.bias-torch.Size([768])
geneartor.decoder.layers.3.norm2.weight-torch.Size([768])
geneartor.decoder.layers.3.norm2.bias-torch.Size([768])
geneartor.decoder.layers.3.norm3.weight-torch.Size([768])
geneartor.decoder.layers.3.norm3.bias-torch.Size([768])
geneartor.fc.weight-torch.Size([29, 768])
geneartor.fc.bias-torch.Size([29])
discriminator.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.linear1.weight-torch.Size([2048, 768])
discriminator.decoder_layers.linear1.bias-torch.Size([2048])
discriminator.decoder_layers.linear2.weight-torch.Size([768, 2048])
discriminator.decoder_layers.linear2.bias-torch.Size([768])
discriminator.decoder_layers.norm1.weight-torch.Size([768])
discriminator.decoder_layers.norm1.bias-torch.Size([768])
discriminator.decoder_layers.norm2.weight-torch.Size([768])
discriminator.decoder_layers.norm2.bias-torch.Size([768])
discriminator.decoder_layers.norm3.weight-torch.Size([768])
discriminator.decoder_layers.norm3.bias-torch.Size([768])
discriminator.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.0.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.0.linear2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm1.weight-torch.Size([768])
discriminator.decoder.layers.0.norm1.bias-torch.Size([768])
discriminator.decoder.layers.0.norm2.weight-torch.Size([768])
discriminator.decoder.layers.0.norm2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm3.weight-torch.Size([768])
discriminator.decoder.layers.0.norm3.bias-torch.Size([768])
discriminator.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.1.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.1.linear2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm1.weight-torch.Size([768])
discriminator.decoder.layers.1.norm1.bias-torch.Size([768])
discriminator.decoder.layers.1.norm2.weight-torch.Size([768])
discriminator.decoder.layers.1.norm2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm3.weight-torch.Size([768])
discriminator.decoder.layers.1.norm3.bias-torch.Size([768])
discriminator.decoder.layers.2.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.2.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.2.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.2.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.2.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.2.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.2.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.2.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.2.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.2.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.2.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.2.linear2.bias-torch.Size([768])
discriminator.decoder.layers.2.norm1.weight-torch.Size([768])
discriminator.decoder.layers.2.norm1.bias-torch.Size([768])
discriminator.decoder.layers.2.norm2.weight-torch.Size([768])
discriminator.decoder.layers.2.norm2.bias-torch.Size([768])
discriminator.decoder.layers.2.norm3.weight-torch.Size([768])
discriminator.decoder.layers.2.norm3.bias-torch.Size([768])
discriminator.decoder.layers.3.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.3.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.3.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.3.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.3.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.3.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.3.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.3.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.3.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.3.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.3.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.3.linear2.bias-torch.Size([768])
discriminator.decoder.layers.3.norm1.weight-torch.Size([768])
discriminator.decoder.layers.3.norm1.bias-torch.Size([768])
discriminator.decoder.layers.3.norm2.weight-torch.Size([768])
discriminator.decoder.layers.3.norm2.bias-torch.Size([768])
discriminator.decoder.layers.3.norm3.weight-torch.Size([768])
discriminator.decoder.layers.3.norm3.bias-torch.Size([768])
discriminator.fc.weight-torch.Size([2, 768])
discriminator.fc.bias-torch.Size([2])

>>>>>>>>>>>>>>>>>>>start train......
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_0.py", line 68, in <module>
    train(args)
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 152, in train
    loss_g, loss_d, code_pred_list, judgement_pred_list, discriminator_label_list = model(input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, tgt_ids=tgt_ids, tgt_mask=tgt_mask,problem_id=problem_id)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 833, in forward
    decoder_inputs = self.fusion_fc(torch.cat((self.code_emb(code_pred), p_hidden, goal),dim=-1))
NameError: name 'goal' is not defined
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 155029.29it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 157979.61it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
===========================train setting parameters=========================
encoder.embeddings.word_embeddings.weight-torch.Size([30522, 768])
encoder.embeddings.position_embeddings.weight-torch.Size([512, 768])
encoder.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
encoder.embeddings.LayerNorm.weight-torch.Size([768])
encoder.embeddings.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.0.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.1.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.2.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.3.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.4.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.5.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.6.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.7.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.8.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.9.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.10.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.11.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
encoder.pooler.dense.weight-torch.Size([768, 768])
encoder.pooler.dense.bias-torch.Size([768])
code_emb.embedding.weight-torch.Size([29, 768])
fusion_fc.weight-torch.Size([768, 1536])
fusion_fc.bias-torch.Size([768])
geneartor.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.linear1.weight-torch.Size([2048, 768])
geneartor.decoder_layers.linear1.bias-torch.Size([2048])
geneartor.decoder_layers.linear2.weight-torch.Size([768, 2048])
geneartor.decoder_layers.linear2.bias-torch.Size([768])
geneartor.decoder_layers.norm1.weight-torch.Size([768])
geneartor.decoder_layers.norm1.bias-torch.Size([768])
geneartor.decoder_layers.norm2.weight-torch.Size([768])
geneartor.decoder_layers.norm2.bias-torch.Size([768])
geneartor.decoder_layers.norm3.weight-torch.Size([768])
geneartor.decoder_layers.norm3.bias-torch.Size([768])
geneartor.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.0.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.0.linear2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm1.weight-torch.Size([768])
geneartor.decoder.layers.0.norm1.bias-torch.Size([768])
geneartor.decoder.layers.0.norm2.weight-torch.Size([768])
geneartor.decoder.layers.0.norm2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm3.weight-torch.Size([768])
geneartor.decoder.layers.0.norm3.bias-torch.Size([768])
geneartor.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.1.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.1.linear2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm1.weight-torch.Size([768])
geneartor.decoder.layers.1.norm1.bias-torch.Size([768])
geneartor.decoder.layers.1.norm2.weight-torch.Size([768])
geneartor.decoder.layers.1.norm2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm3.weight-torch.Size([768])
geneartor.decoder.layers.1.norm3.bias-torch.Size([768])
geneartor.decoder.layers.2.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.2.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.2.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.2.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.2.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.2.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.2.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.2.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.2.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.2.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.2.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.2.linear2.bias-torch.Size([768])
geneartor.decoder.layers.2.norm1.weight-torch.Size([768])
geneartor.decoder.layers.2.norm1.bias-torch.Size([768])
geneartor.decoder.layers.2.norm2.weight-torch.Size([768])
geneartor.decoder.layers.2.norm2.bias-torch.Size([768])
geneartor.decoder.layers.2.norm3.weight-torch.Size([768])
geneartor.decoder.layers.2.norm3.bias-torch.Size([768])
geneartor.decoder.layers.3.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.3.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.3.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.3.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.3.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.3.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.3.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.3.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.3.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.3.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.3.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.3.linear2.bias-torch.Size([768])
geneartor.decoder.layers.3.norm1.weight-torch.Size([768])
geneartor.decoder.layers.3.norm1.bias-torch.Size([768])
geneartor.decoder.layers.3.norm2.weight-torch.Size([768])
geneartor.decoder.layers.3.norm2.bias-torch.Size([768])
geneartor.decoder.layers.3.norm3.weight-torch.Size([768])
geneartor.decoder.layers.3.norm3.bias-torch.Size([768])
geneartor.fc.weight-torch.Size([29, 768])
geneartor.fc.bias-torch.Size([29])
discriminator.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.linear1.weight-torch.Size([2048, 768])
discriminator.decoder_layers.linear1.bias-torch.Size([2048])
discriminator.decoder_layers.linear2.weight-torch.Size([768, 2048])
discriminator.decoder_layers.linear2.bias-torch.Size([768])
discriminator.decoder_layers.norm1.weight-torch.Size([768])
discriminator.decoder_layers.norm1.bias-torch.Size([768])
discriminator.decoder_layers.norm2.weight-torch.Size([768])
discriminator.decoder_layers.norm2.bias-torch.Size([768])
discriminator.decoder_layers.norm3.weight-torch.Size([768])
discriminator.decoder_layers.norm3.bias-torch.Size([768])
discriminator.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.0.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.0.linear2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm1.weight-torch.Size([768])
discriminator.decoder.layers.0.norm1.bias-torch.Size([768])
discriminator.decoder.layers.0.norm2.weight-torch.Size([768])
discriminator.decoder.layers.0.norm2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm3.weight-torch.Size([768])
discriminator.decoder.layers.0.norm3.bias-torch.Size([768])
discriminator.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.1.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.1.linear2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm1.weight-torch.Size([768])
discriminator.decoder.layers.1.norm1.bias-torch.Size([768])
discriminator.decoder.layers.1.norm2.weight-torch.Size([768])
discriminator.decoder.layers.1.norm2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm3.weight-torch.Size([768])
discriminator.decoder.layers.1.norm3.bias-torch.Size([768])
discriminator.decoder.layers.2.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.2.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.2.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.2.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.2.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.2.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.2.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.2.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.2.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.2.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.2.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.2.linear2.bias-torch.Size([768])
discriminator.decoder.layers.2.norm1.weight-torch.Size([768])
discriminator.decoder.layers.2.norm1.bias-torch.Size([768])
discriminator.decoder.layers.2.norm2.weight-torch.Size([768])
discriminator.decoder.layers.2.norm2.bias-torch.Size([768])
discriminator.decoder.layers.2.norm3.weight-torch.Size([768])
discriminator.decoder.layers.2.norm3.bias-torch.Size([768])
discriminator.decoder.layers.3.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.3.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.3.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.3.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.3.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.3.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.3.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.3.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.3.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.3.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.3.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.3.linear2.bias-torch.Size([768])
discriminator.decoder.layers.3.norm1.weight-torch.Size([768])
discriminator.decoder.layers.3.norm1.bias-torch.Size([768])
discriminator.decoder.layers.3.norm2.weight-torch.Size([768])
discriminator.decoder.layers.3.norm2.bias-torch.Size([768])
discriminator.decoder.layers.3.norm3.weight-torch.Size([768])
discriminator.decoder.layers.3.norm3.bias-torch.Size([768])
discriminator.fc.weight-torch.Size([2, 768])
discriminator.fc.bias-torch.Size([2])

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss_g:48.62882328033447	loss_d:24.111584901809692
train_code_acc:[0.02766459360926442, 0.03152476946171992, 0.0345271284580742, 0.03281149474587176, 0.03774394166845379, 0.038172850096504396]
train_judgement_acc:[0.7214239759811281, 0.7064121809993567, 0.7175638001286725, 0.7134891700621917, 0.6976195582243191, 0.7149903495603689]


test_answer_acc:0.013856812933025405	iter_cnt_mean:6.0
test_code_acc:[0.007620660457239628, 0.007620660457239628, 0.007620660457239628, 0.007620660457239628, 0.007620660457239628, 0.007620660457239628]
test_judgement_acc:[0.947502116850127, 0.947502116850127, 0.947502116850127, 0.947502116850127, 0.947502116850127, 0.947502116850127]


epoch:1,	loss_g:47.88727378845215	loss_d:18.74557876586914
train_code_acc:[0.04825219815569376, 0.05168346558009865, 0.049538923439845596, 0.05640145828865537, 0.050825648723997426, 0.046536564443491316]
train_judgement_acc:[0.8490242333261848, 0.8462363285438559, 0.837872614196869, 0.844949603259704, 0.8470941453999571, 0.8492386875402101]


test_answer_acc:0.04157043879907621	iter_cnt_mean:5.849884526558891
test_code_acc:[0.05249788314987299, 0.05249788314987299, 0.05249788314987299, 0.05249788314987299, 0.05249788314987299, 0.05249788314987299]
test_judgement_acc:[0.9542760372565622, 0.9551227773073666, 0.9551227773073666, 0.9551227773073666, 0.9551227773073666, 0.9551227773073666]


epoch:2,	loss_g:44.32180690765381	loss_d:17.766591787338257
train_code_acc:[0.14218314389877762, 0.14733004503538494, 0.1462577739652584, 0.13918078490242333, 0.1462577739652584, 0.1338194295517907]
train_judgement_acc:[0.8533133176066909, 0.8451640574737294, 0.8485953248981343, 0.8580313103152477, 0.8477375080420331, 0.8608192150975766]


test_answer_acc:0.2586605080831409	iter_cnt_mean:4.775981524249422
test_code_acc:[0.3386960203217612, 0.3386960203217612, 0.3386960203217612, 0.3386960203217612, 0.3386960203217612, 0.3386960203217612]
test_judgement_acc:[0.6613039796782387, 0.6613039796782387, 0.6613039796782387, 0.6613039796782387, 0.6613039796782387, 0.6613039796782387]


epoch:3,	loss_g:41.24082374572754	loss_d:30.59829592704773
train_code_acc:[0.317177782543427, 0.3167488741153764, 0.3255414968904139, 0.32296804632211024, 0.3184645078275788, 0.31932232468368005]
train_judgement_acc:[0.6815354921724212, 0.6823933090285225, 0.6755307741797126, 0.677246407891915, 0.6804632211022946, 0.6823933090285225]


test_answer_acc:0.26096997690531176	iter_cnt_mean:4.764434180138569
test_code_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564]
test_judgement_acc:[0.5783234546994073, 0.5783234546994073, 0.5783234546994073, 0.5783234546994073, 0.5783234546994073, 0.5783234546994073]


epoch:4,	loss_g:34.084412574768066	loss_d:29.921881675720215
train_code_acc:[0.36500107227107015, 0.36178425906069056, 0.3673600686253485, 0.36542998069912075, 0.365644434913146, 0.3671456144113232]
train_judgement_acc:[0.5989706197726785, 0.5942526270641219, 0.5925369933519193, 0.6058331546214883, 0.6092644220458932, 0.5938237186360712]


test_answer_acc:0.26096997690531176	iter_cnt_mean:4.764434180138569
test_code_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564]
test_judgement_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564]


epoch:5,	loss_g:31.647220134735107	loss_d:28.838897705078125
train_code_acc:[0.36671670598327255, 0.3725069697619558, 0.37014797340767747, 0.3641432554149689, 0.37014797340767747, 0.36971906497962687]
train_judgement_acc:[0.5850310958610336, 0.5811709200085782, 0.5768818357280721, 0.5839588247909071, 0.5659446708127814, 0.5792408320823504]


test_answer_acc:0.26096997690531176	iter_cnt_mean:4.764434180138569
test_code_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564]
test_judgement_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564, 0.33954276037256564]


epoch:6,	loss_g:32.132325887680054	loss_d:27.20766043663025
train_code_acc:[0.37036242762170274, 0.37851168775466437, 0.36993351919365214, 0.36671670598327255, 0.37014797340767747, 0.37465151190220886]
train_judgement_acc:[0.6431481878618915, 0.654728715419258, 0.6579455286296376, 0.6611623418400172, 0.6534419901351062, 0.6542998069912074]


test_answer_acc:0.26096997690531176	iter_cnt_mean:4.764434180138569
test_code_acc:[0.3615580016934801, 0.3615580016934801, 0.3615580016934801, 0.3615580016934801, 0.3615580016934801, 0.3615580016934801]
test_judgement_acc:[0.3903471634208298, 0.4005080440304826, 0.4005080440304826, 0.4005080440304826, 0.4005080440304826, 0.4005080440304826]


epoch:7,	loss_g:33.65478754043579	loss_d:26.453392505645752
train_code_acc:[0.3782972335406391, 0.3935234827364358, 0.3909500321681321, 0.39523911644863824, 0.38901994424190434, 0.3903066695260562]
train_judgement_acc:[0.6804632211022946, 0.6669526056187004, 0.6781042247480163, 0.675101865751662, 0.6736006862534849, 0.6808921295303453]


test_answer_acc:0.302540415704388	iter_cnt_mean:4.558891454965358
test_code_acc:[0.46062658763759523, 0.46994072819644367, 0.46994072819644367, 0.46994072819644367, 0.46994072819644367, 0.46994072819644367]
test_judgement_acc:[0.6367485182049111, 0.6367485182049111, 0.6367485182049111, 0.6367485182049111, 0.6367485182049111, 0.6367485182049111]


epoch:8,	loss_g:33.16406965255737	loss_d:27.386685371398926
train_code_acc:[0.4061762813639288, 0.4184001715633712, 0.41604117520909284, 0.41432554149689044, 0.42719279433840873, 0.425262706412181]
train_judgement_acc:[0.6429337336478662, 0.646365001072271, 0.6435770962899421, 0.6495818142826506, 0.6534419901351062, 0.6504396311387519]


test_answer_acc:0.2748267898383372	iter_cnt_mean:4.907621247113164
test_code_acc:[0.3454699407281964, 0.35647756138865366, 0.35647756138865366, 0.35647756138865366, 0.35647756138865366, 0.35647756138865366]
test_judgement_acc:[0.594411515664691, 0.6054191363251482, 0.6054191363251482, 0.6054191363251482, 0.6054191363251482, 0.6054191363251482]


epoch:9,	loss_g:35.37761449813843	loss_d:26.698054790496826
train_code_acc:[0.4396311387518765, 0.4471370362427622, 0.451211666309243, 0.4531417542354707, 0.4546429337336479, 0.4649367360068625]
train_judgement_acc:[0.6493673600686254, 0.6480806347844735, 0.6588033454857388, 0.6581599828436628, 0.6654514261205232, 0.6605189791979412]


test_answer_acc:0.325635103926097	iter_cnt_mean:4.521939953810624
test_code_acc:[0.43522438611346315, 0.4403048264182896, 0.4403048264182896, 0.4403048264182896, 0.4403048264182896, 0.4403048264182896]
test_judgement_acc:[0.6477561388653683, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859]


epoch:10,	loss_g:33.370742321014404	loss_d:26.247281789779663
train_code_acc:[0.44606476517263566, 0.4559296590177997, 0.46515119022088786, 0.4750160840660519, 0.4745871756380013, 0.47673171777825435]
train_judgement_acc:[0.6600900707698907, 0.6551576238473086, 0.6607334334119666, 0.6527986274930302, 0.6648080634784473, 0.6671670598327257]


test_answer_acc:0.3394919168591224	iter_cnt_mean:4.4295612009237875
test_code_acc:[0.4707874682472481, 0.48010160880609654, 0.48010160880609654, 0.48010160880609654, 0.48010160880609654, 0.48010160880609654]
test_judgement_acc:[0.6756985605419137, 0.6756985605419137, 0.6756985605419137, 0.6756985605419137, 0.6756985605419137, 0.6756985605419137]


epoch:11,	loss_g:35.74437665939331	loss_d:25.2787823677063
train_code_acc:[0.4880977911215955, 0.49238687540210163, 0.49067124168989923, 0.49538923439845595, 0.5013939523911645, 0.5050396740295947]
train_judgement_acc:[0.6703838730431053, 0.6628779755522196, 0.67016941882908, 0.675101865751662, 0.6708127814711559, 0.6695260561870041]


test_answer_acc:0.3325635103926097	iter_cnt_mean:4.505773672055427
test_code_acc:[0.4394580863674852, 0.4470787468247248, 0.4470787468247248, 0.4470787468247248, 0.4470787468247248, 0.4470787468247248]
test_judgement_acc:[0.6799322607959356, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752]


epoch:12,	loss_g:33.91235828399658	loss_d:24.641936540603638
train_code_acc:[0.5166202015869612, 0.5230538280077204, 0.5224104653656444, 0.5189791979412396, 0.5211237400814926, 0.5221960111516192]
train_judgement_acc:[0.6817499463864465, 0.6738151404675102, 0.6753163199656873, 0.6727428693973837, 0.6742440488955608, 0.6763885910358138]


test_answer_acc:0.3371824480369515	iter_cnt_mean:4.466512702078522
test_code_acc:[0.4504657070279424, 0.46486028789161726, 0.46486028789161726, 0.46486028789161726, 0.46486028789161726, 0.46486028789161726]
test_judgement_acc:[0.7036409822184589, 0.7129551227773073, 0.7129551227773073, 0.7129551227773073, 0.7129551227773073, 0.7129551227773073]


epoch:13,	loss_g:32.54508852958679	loss_d:23.882415533065796
train_code_acc:[0.5352777182071627, 0.5367788977053399, 0.5408535277718207, 0.5451426120523268, 0.5440703409822003, 0.5427836156980484]
train_judgement_acc:[0.688398027021231, 0.6841089427407249, 0.6901136607334334, 0.6896847523053828, 0.6886124812352563, 0.6890413896633069]


test_answer_acc:0.34872979214780603	iter_cnt_mean:4.406466512702078
test_code_acc:[0.49195596951735815, 0.4987298899237934, 0.4987298899237934, 0.4987298899237934, 0.4987298899237934, 0.4987298899237934]
test_judgement_acc:[0.7044877222692634, 0.707874682472481, 0.707874682472481, 0.707874682472481, 0.707874682472481, 0.707874682472481]


epoch:14,	loss_g:30.966545820236206	loss_d:23.1947283744812
train_code_acc:[0.5513617842590607, 0.5550075058974909, 0.5573665022517692, 0.5597254986060476, 0.5556508685395668, 0.5631567660304525]
train_judgement_acc:[0.7031953677889771, 0.7029809135749517, 0.6976195582243191, 0.7016941882907999, 0.7092000857816856, 0.6950461076560155]


test_answer_acc:0.3695150115473441	iter_cnt_mean:4.265588914549654
test_code_acc:[0.5486875529212532, 0.5690093141405589, 0.5690093141405589, 0.5690093141405589, 0.5690093141405589, 0.5690093141405589]
test_judgement_acc:[0.6994072819644369, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752, 0.6875529212531752]


epoch:15,	loss_g:30.792446613311768	loss_d:23.35403609275818
train_code_acc:[0.5689470298091357, 0.5745228393737937, 0.5751662020158697, 0.5755951104439202, 0.5773107441561227, 0.5800986489384516]
train_judgement_acc:[0.7016941882907999, 0.6993351919365216, 0.706626635213382, 0.7072699978554579, 0.7001930087926228, 0.7006219172206734]


test_answer_acc:0.535796766743649	iter_cnt_mean:3.489607390300231
test_code_acc:[0.5859441151566469, 0.6350550381033023, 0.6350550381033023, 0.6350550381033023, 0.6350550381033023, 0.6350550381033023]
test_judgement_acc:[0.6968670618120237, 0.7019475021168501, 0.7019475021168501, 0.7019475021168501, 0.7019475021168501, 0.7019475021168501]


epoch:16,	loss_g:30.064053535461426	loss_d:23.758000373840332
train_code_acc:[0.5689470298091357, 0.5734505683036671, 0.5790263778683251, 0.581814282650654, 0.5815998284366288, 0.5831010079348059]
train_judgement_acc:[0.6834655800986489, 0.6888269354492815, 0.6819644006004718, 0.6808921295303453, 0.6864679390950033, 0.6916148402316106]


test_answer_acc:0.5658198614318707	iter_cnt_mean:3.4318706697459582
test_code_acc:[0.5757832345469941, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859, 0.6511430990685859]
test_judgement_acc:[0.7231160033869602, 0.6926333615580017, 0.6926333615580017, 0.6926333615580017, 0.6926333615580017, 0.6926333615580017]


epoch:17,	loss_g:28.374216079711914	loss_d:23.48435091972351
train_code_acc:[0.5925369933519193, 0.5996139824147545, 0.608406605189792, 0.6028307956251341, 0.6107656015440703, 0.6073343341196654]
train_judgement_acc:[0.6982629208663951, 0.6920437486596611, 0.6787475873900922, 0.690542569161484, 0.6851812138108514, 0.6907570233755094]


test_answer_acc:0.6166281755196305	iter_cnt_mean:3.1454965357967666
test_code_acc:[0.6020321761219306, 0.6850127011007621, 0.6858594411515665, 0.6858594411515665, 0.6858594411515665, 0.6858594411515665]
test_judgement_acc:[0.7163420829805249, 0.7061812023708721, 0.7061812023708721, 0.7061812023708721, 0.7061812023708721, 0.7061812023708721]


epoch:18,	loss_g:26.503490924835205	loss_d:23.849478721618652
train_code_acc:[0.579669740510401, 0.5882479090714132, 0.5972549860604761, 0.5998284366287797, 0.6039030666952606, 0.6062620630495389]
train_judgement_acc:[0.6658803345485739, 0.6729573236114089, 0.6680248766888269, 0.6727428693973837, 0.6731717778254342, 0.6678104224748016]


test_answer_acc:0.6073903002309469	iter_cnt_mean:3.2170900692840645
test_code_acc:[0.5961049957662997, 0.6960203217612193, 0.6968670618120237, 0.6968670618120237, 0.6968670618120237, 0.6968670618120237]
test_judgement_acc:[0.7036409822184589, 0.7104149026248942, 0.7104149026248942, 0.7104149026248942, 0.7104149026248942, 0.7104149026248942]


epoch:19,	loss_g:27.424838066101074	loss_d:22.285448789596558
train_code_acc:[0.6049753377653871, 0.6223461291014368, 0.6229894917435128, 0.6279219386660948, 0.6292086639502467, 0.6302809350203732]
train_judgement_acc:[0.6999785545785975, 0.693973836585889, 0.7004074630066481, 0.6971906497962685, 0.6978340124383444, 0.6991207377224963]


test_answer_acc:0.6189376443418014	iter_cnt_mean:3.161662817551963
test_code_acc:[0.5884843353090601, 0.6960203217612193, 0.6985605419136325, 0.6985605419136325, 0.6985605419136325, 0.6985605419136325]
test_judgement_acc:[0.707874682472481, 0.7188823031329382, 0.720575783234547, 0.720575783234547, 0.720575783234547, 0.720575783234547]


epoch:20,	loss_g:29.78905487060547	loss_d:22.057788133621216
train_code_acc:[0.6126956894702981, 0.6199871327471584, 0.6219172206733863, 0.6259918507398671, 0.6307098434484237, 0.635856744585031]
train_judgement_acc:[0.7083422689255844, 0.7025520051469011, 0.7061977267853313, 0.7057688183572807, 0.7081278147115591, 0.693973836585889]


test_answer_acc:0.6189376443418014	iter_cnt_mean:3.1547344110854505
test_code_acc:[0.5901778154106689, 0.6985605419136325, 0.7002540220152413, 0.7002540220152413, 0.7002540220152413, 0.7002540220152413]
test_judgement_acc:[0.7298899237933955, 0.7544453852667231, 0.7544453852667231, 0.7544453852667231, 0.7544453852667231, 0.7544453852667231]


epoch:21,	loss_g:27.718684911727905	loss_d:21.7405846118927
train_code_acc:[0.6202015869611838, 0.626635213381943, 0.6334977482307528, 0.6360711987990564, 0.6373579240832082, 0.6422903710057902]
train_judgement_acc:[0.706626635213382, 0.7046965472871541, 0.7057688183572807, 0.7143469869182929, 0.7117735363499893, 0.7057688183572807]


test_answer_acc:0.6327944572748267	iter_cnt_mean:3.115473441108545
test_code_acc:[0.5969517358171041, 0.707874682472481, 0.7112616426756986, 0.7112616426756986, 0.7112616426756986, 0.7112616426756986]
test_judgement_acc:[0.7434377646062659, 0.7408975444538527, 0.7400508044030483, 0.7400508044030483, 0.7400508044030483, 0.7400508044030483]


epoch:22,	loss_g:26.859511852264404	loss_d:21.13650608062744
train_code_acc:[0.6326399313746515, 0.6369290156551576, 0.6422903710057902, 0.646365001072271, 0.6480806347844735, 0.6534419901351062]
train_judgement_acc:[0.7147758953463436, 0.7177782543426978, 0.7141325327042677, 0.7229251554793051, 0.7244263349774823, 0.7280720566159125]


test_answer_acc:0.6581986143187067	iter_cnt_mean:2.9907621247113165
test_code_acc:[0.6104995766299746, 0.720575783234547, 0.7239627434377646, 0.7239627434377646, 0.7239627434377646, 0.7239627434377646]
test_judgement_acc:[0.7637595258255715, 0.77307366638442, 0.7747671464860287, 0.7747671464860287, 0.7747671464860287, 0.7747671464860287]


epoch:23,	loss_g:26.681385040283203	loss_d:20.986047983169556
train_code_acc:[0.6397169204374866, 0.6495818142826506, 0.6493673600686254, 0.6545142612052327, 0.6551576238473086, 0.6536564443491315]
train_judgement_acc:[0.7182071627707485, 0.718636071198799, 0.7259275144756594, 0.7248552434055329, 0.7212095217671027, 0.7272142397598113]


test_answer_acc:0.6836027713625866	iter_cnt_mean:2.8775981524249423
test_code_acc:[0.6232006773920407, 0.7341236240474175, 0.7349703640982218, 0.7349703640982218, 0.7349703640982218, 0.7349703640982218]
test_judgement_acc:[0.7417442845046571, 0.7722269263336156, 0.77307366638442, 0.77307366638442, 0.77307366638442, 0.77307366638442]


epoch:24,	loss_g:27.08361506462097	loss_d:21.20180106163025
train_code_acc:[0.635856744585031, 0.6478661805704482, 0.6532275359210808, 0.6566588033454858, 0.6609478876259919, 0.6613767960540424]
train_judgement_acc:[0.7214239759811281, 0.7229251554793051, 0.7177782543426978, 0.7267853313317607, 0.7177782543426978, 0.7177782543426978]


test_answer_acc:0.6674364896073903	iter_cnt_mean:2.905311778290993
test_code_acc:[0.6367485182049111, 0.7298899237933955, 0.7315834038950042, 0.7315834038950042, 0.7315834038950042, 0.7315834038950042]
test_judgement_acc:[0.7578323454699407, 0.7764606265876376, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]


epoch:25,	loss_g:24.554234743118286	loss_d:20.59686279296875
train_code_acc:[0.6474372721423975, 0.6560154407034098, 0.6630924297662449, 0.6660947887625992, 0.6673815140467511, 0.6714561441132318]
train_judgement_acc:[0.7154192579884194, 0.7269997855457859, 0.7250696976195582, 0.731288869826292, 0.7308599613982415, 0.7302165987561655]


test_answer_acc:0.6327944572748267	iter_cnt_mean:3.0739030023094687
test_code_acc:[0.6240474174428451, 0.720575783234547, 0.7222692633361558, 0.7222692633361558, 0.7222692633361558, 0.7222692633361558]
test_judgement_acc:[0.7612193056731583, 0.7739204064352244, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376]


epoch:26,	loss_g:25.405572652816772	loss_d:20.06026268005371
train_code_acc:[0.6487239974265494, 0.6615912502680678, 0.6695260561870041, 0.6781042247480163, 0.6800343126742441, 0.6815354921724212]
train_judgement_acc:[0.7282865108299378, 0.7355779541067982, 0.7370791336049753, 0.7426549431696333, 0.7402959468153549, 0.7452283937379369]


test_answer_acc:0.6651270207852193	iter_cnt_mean:2.884526558891455
test_code_acc:[0.6570702794242168, 0.7375105842506351, 0.7383573243014394, 0.7383573243014394, 0.7383573243014394, 0.7383573243014394]
test_judgement_acc:[0.7713801862828111, 0.7832345469940728, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772]


epoch:27,	loss_g:26.048303604125977	loss_d:21.037516593933105
train_code_acc:[0.6534419901351062, 0.6594467081278147, 0.6688826935449281, 0.6684537851168776, 0.6714561441132318, 0.6690971477589535]
train_judgement_acc:[0.718636071198799, 0.7167059832725713, 0.7235685181213811, 0.7237829723354063, 0.7205661591250269, 0.7267853313317607]


test_answer_acc:0.6558891454965358	iter_cnt_mean:2.861431870669746
test_code_acc:[0.6756985605419137, 0.7341236240474175, 0.7341236240474175, 0.7341236240474175, 0.7341236240474175, 0.7341236240474175]
test_judgement_acc:[0.790008467400508, 0.7984758679085521, 0.7976291278577476, 0.7976291278577476, 0.7976291278577476, 0.7976291278577476]


epoch:28,	loss_g:25.616231203079224	loss_d:20.35969853401184
train_code_acc:[0.6583744370576882, 0.6705983272571306, 0.6770319536778898, 0.6811065837443706, 0.6821788548144971, 0.6834655800986489]
train_judgement_acc:[0.7156337122024448, 0.7244263349774823, 0.7252841518335835, 0.7269997855457859, 0.729787690328115, 0.7342912288226464]


test_answer_acc:0.6327944572748267	iter_cnt_mean:3.0831408775981526
test_code_acc:[0.6342082980524979, 0.7281964436917866, 0.729043183742591, 0.729043183742591, 0.729043183742591, 0.729043183742591]
test_judgement_acc:[0.7806943268416596, 0.7883149872988993, 0.7874682472480948, 0.7874682472480948, 0.7874682472480948, 0.7874682472480948]


epoch:29,	loss_g:25.45902419090271	loss_d:20.02395272254944
train_code_acc:[0.6675959682607763, 0.6789620416041175, 0.6770319536778898, 0.6836800343126742, 0.6864679390950033, 0.6901136607334334]
train_judgement_acc:[0.7304310529701908, 0.73686467939095, 0.7428693973836585, 0.7355779541067982, 0.7435127600257345, 0.7484452069483165]


test_answer_acc:0.6674364896073903	iter_cnt_mean:2.8475750577367207
test_code_acc:[0.6748518204911093, 0.7468247248094835, 0.7468247248094835, 0.7468247248094835, 0.7468247248094835, 0.7468247248094835]
test_judgement_acc:[0.7586790855207451, 0.7933954276037256, 0.7933954276037256, 0.7933954276037256, 0.7933954276037256, 0.7933954276037256]


epoch:30,	loss_g:25.180340051651	loss_d:19.6500506401062
train_code_acc:[0.6712416898992065, 0.6821788548144971, 0.6896847523053828, 0.695475016084066, 0.6969761955822432, 0.7019086425048252]
train_judgement_acc:[0.7372935878190007, 0.7460862105940381, 0.750160840660519, 0.7471584816641647, 0.7553077417971263, 0.7432983058117092]


test_answer_acc:0.6420323325635104	iter_cnt_mean:3.0115473441108547
test_code_acc:[0.6494496189669772, 0.7324301439458086, 0.7332768839966131, 0.7332768839966131, 0.7332768839966131, 0.7332768839966131]
test_judgement_acc:[0.7671464860287892, 0.7959356477561389, 0.7967823878069432, 0.7967823878069432, 0.7967823878069432, 0.7967823878069432]


epoch:31,	loss_g:24.5192449092865	loss_d:19.102864265441895
train_code_acc:[0.6849667595968261, 0.6963328329401672, 0.696118378726142, 0.7006219172206734, 0.7038387304310529, 0.7081278147115591]
train_judgement_acc:[0.7426549431696333, 0.7443705768818357, 0.7553077417971263, 0.7546643791550504, 0.7503752948745442, 0.7514475659446708]


test_answer_acc:0.6651270207852193	iter_cnt_mean:2.8775981524249423
test_code_acc:[0.6782387806943269, 0.7476714648602879, 0.7485182049110923, 0.7485182049110923, 0.7485182049110923, 0.7485182049110923]
test_judgement_acc:[0.7790008467400508, 0.8086367485182049, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093]


epoch:32,	loss_g:24.360541105270386	loss_d:18.887335538864136
train_code_acc:[0.6808921295303453, 0.6941882907999142, 0.7006219172206734, 0.7081278147115591, 0.708771177353635, 0.7141325327042677]
train_judgement_acc:[0.7452283937379369, 0.7486596611623418, 0.7499463864464937, 0.7503752948745442, 0.7595968260776325, 0.7623847308599614]


test_answer_acc:0.6327944572748267	iter_cnt_mean:3.0531177829099305
test_code_acc:[0.6511430990685859, 0.7273497036409822, 0.7273497036409822, 0.7273497036409822, 0.7273497036409822, 0.7273497036409822]
test_judgement_acc:[0.7705334462320068, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728]


epoch:33,	loss_g:24.012460708618164	loss_d:19.2714262008667
train_code_acc:[0.6763885910358138, 0.6916148402316106, 0.6963328329401672, 0.7023375509328759, 0.7049110015011795, 0.705983272571306]
train_judgement_acc:[0.7426549431696333, 0.7420115805275573, 0.75788119236543, 0.7514475659446708, 0.7488741153763672, 0.750160840660519]


test_answer_acc:0.6628175519630485	iter_cnt_mean:2.8660508083140877
test_code_acc:[0.6841659610499576, 0.7425910245554614, 0.7434377646062659, 0.7434377646062659, 0.7434377646062659, 0.7434377646062659]
test_judgement_acc:[0.7984758679085521, 0.8060965283657917, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961]


epoch:34,	loss_g:25.349284410476685	loss_d:19.052621841430664
train_code_acc:[0.6926871113017371, 0.6991207377224963, 0.705983272571306, 0.711559082135964, 0.7102723568518121, 0.7175638001286725]
train_judgement_acc:[0.7407248552434055, 0.750160840660519, 0.7490885695903925, 0.7482307527342912, 0.7542354707269998, 0.7512331117306456]


test_answer_acc:0.6651270207852193	iter_cnt_mean:2.8822170900692843
test_code_acc:[0.6714648602878917, 0.7451312447078747, 0.745977984758679, 0.745977984758679, 0.745977984758679, 0.745977984758679]
test_judgement_acc:[0.8001693480101609, 0.8069432684165961, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005]


epoch:35,	loss_g:24.235984802246094	loss_d:18.57722234725952
train_code_acc:[0.6903281149474587, 0.7051254557152048, 0.7122024447780398, 0.7169204374865966, 0.7220673386232039, 0.7224962470512546]
train_judgement_acc:[0.7486596611623418, 0.755093287583101, 0.7565944670812782, 0.7632425477160626, 0.7617413682178855, 0.7625991850739867]


test_answer_acc:0.674364896073903	iter_cnt_mean:2.7898383371824482
test_code_acc:[0.6960203217612193, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275]
test_judgement_acc:[0.8001693480101609, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093]


epoch:36,	loss_g:22.9532208442688	loss_d:18.758359670639038
train_code_acc:[0.6918292944456359, 0.7021230967188505, 0.7094145399957109, 0.7147758953463436, 0.7177782543426978, 0.717134891700622]
train_judgement_acc:[0.7512331117306456, 0.7574522839373794, 0.7555221960111517, 0.7593823718636071, 0.7591679176495818, 0.7608835513617842]


test_answer_acc:0.6466512702078522	iter_cnt_mean:2.9260969976905313
test_code_acc:[0.6926333615580017, 0.745977984758679, 0.7468247248094835, 0.7468247248094835, 0.7468247248094835, 0.7468247248094835]
test_judgement_acc:[0.7891617273497037, 0.8060965283657917, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961]


epoch:37,	loss_g:22.878928184509277	loss_d:17.723758459091187
train_code_acc:[0.7021230967188505, 0.7109157194938881, 0.7152048037743942, 0.7235685181213811, 0.7323611408964186, 0.7304310529701908]
train_judgement_acc:[0.7580956465794553, 0.7649581814282651, 0.7752519837014797, 0.7806133390521124, 0.7703195367788978, 0.7791121595539352]


test_answer_acc:0.6420323325635104	iter_cnt_mean:2.9399538106235568
test_code_acc:[0.6875529212531752, 0.7375105842506351, 0.7383573243014394, 0.7383573243014394, 0.7383573243014394, 0.7383573243014394]
test_judgement_acc:[0.7823878069432684, 0.8060965283657917, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961, 0.8069432684165961]


epoch:38,	loss_g:22.777545928955078	loss_d:17.72481608390808
train_code_acc:[0.7051254557152048, 0.718636071198799, 0.7201372506969762, 0.7272142397598113, 0.7287154192579884, 0.7285009650439631]
train_judgement_acc:[0.7563800128672529, 0.7668882693544928, 0.7722496247051255, 0.7694617199227964, 0.7746086210594039, 0.7750375294874544]


test_answer_acc:0.6581986143187067	iter_cnt_mean:2.852193995381062
test_code_acc:[0.6985605419136325, 0.7569856054191363, 0.7578323454699407, 0.7578323454699407, 0.7578323454699407, 0.7578323454699407]
test_judgement_acc:[0.7798475867908552, 0.8052497883149873, 0.8044030482641829, 0.8044030482641829, 0.8044030482641829, 0.8044030482641829]


epoch:39,	loss_g:21.847293853759766	loss_d:17.453980445861816
train_code_acc:[0.7158481664164701, 0.7276431481878619, 0.7308599613982415, 0.7379369504610765, 0.7411537636714561, 0.7458717563800129]
train_judgement_acc:[0.7649581814282651, 0.7776109800557581, 0.7793266137679605, 0.7806133390521124, 0.783186789620416, 0.7834012438344413]


test_answer_acc:0.6651270207852193	iter_cnt_mean:2.8175519630484986
test_code_acc:[0.7019475021168501, 0.7485182049110923, 0.7493649449618967, 0.7493649449618967, 0.7493649449618967, 0.7493649449618967]
test_judgement_acc:[0.7925486875529213, 0.8027095681625741, 0.8035563082133785, 0.8035563082133785, 0.8035563082133785, 0.8035563082133785]


epoch:40,	loss_g:22.189737558364868	loss_d:17.29067635536194
train_code_acc:[0.7092000857816856, 0.7250696976195582, 0.7306455071842162, 0.7340767746086211, 0.7405104010293803, 0.7405104010293803]
train_judgement_acc:[0.7707484452069483, 0.7701050825648724, 0.7758953463435556, 0.7806133390521124, 0.7819000643362642, 0.7857602401887197]


test_answer_acc:0.6697459584295612	iter_cnt_mean:2.7898383371824482
test_code_acc:[0.707874682472481, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275, 0.7552921253175275]
test_judgement_acc:[0.7976291278577476, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005]


epoch:41,	loss_g:21.857236623764038	loss_d:17.106852531433105
train_code_acc:[0.7235685181213811, 0.7379369504610765, 0.7450139395239116, 0.7516620201586961, 0.7512331117306456, 0.7544499249410251]
train_judgement_acc:[0.7788977053399099, 0.7803988848380871, 0.7840446064765173, 0.7823289727643148, 0.7864036028307956, 0.7864036028307956]


test_answer_acc:0.6674364896073903	iter_cnt_mean:2.7944572748267897
test_code_acc:[0.712108382726503, 0.7586790855207451, 0.7595258255715496, 0.7595258255715496, 0.7595258255715496, 0.7595258255715496]
test_judgement_acc:[0.7933954276037256, 0.8137171888230313, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358]


epoch:42,	loss_g:21.669849634170532	loss_d:17.039707899093628
train_code_acc:[0.7122024447780398, 0.7345056830366716, 0.7370791336049753, 0.7420115805275573, 0.7437272142397598, 0.7486596611623418]
train_judgement_acc:[0.7746086210594039, 0.7746086210594039, 0.7836156980484666, 0.7814711559082136, 0.7825434269783401, 0.7851168775466438]


test_answer_acc:0.6374133949191686	iter_cnt_mean:2.935334872979215
test_code_acc:[0.6968670618120237, 0.7434377646062659, 0.7434377646062659, 0.7434377646062659, 0.7434377646062659, 0.7434377646062659]
test_judgement_acc:[0.7993226079593565, 0.8060965283657917, 0.8060965283657917, 0.8060965283657917, 0.8060965283657917, 0.8060965283657917]


epoch:43,	loss_g:21.500770092010498	loss_d:16.535808324813843
train_code_acc:[0.7235685181213811, 0.7364357709628995, 0.7392236757452284, 0.7456573021659876, 0.74737293587819, 0.749517478018443]
train_judgement_acc:[0.7808277932661377, 0.7810422474801629, 0.7868325112588462, 0.790907141325327, 0.7958395882479091, 0.7898348702552005]


test_answer_acc:0.6789838337182448	iter_cnt_mean:2.7182448036951503
test_code_acc:[0.7222692633361558, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892]
test_judgement_acc:[0.8044030482641829, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358]


epoch:44,	loss_g:20.379181027412415	loss_d:16.302119970321655
train_code_acc:[0.7342912288226464, 0.7497319322324684, 0.7463006648080635, 0.7503752948745442, 0.7563800128672529, 0.7576667381514047]
train_judgement_acc:[0.7793266137679605, 0.7823289727643148, 0.7911215955393524, 0.7913360497533777, 0.7906926871113017, 0.7936950461076561]


test_answer_acc:0.648960739030023	iter_cnt_mean:2.8822170900692843
test_code_acc:[0.7095681625740897, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055]
test_judgement_acc:[0.7993226079593565, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401]


epoch:45,	loss_g:21.810237646102905	loss_d:15.956998825073242
train_code_acc:[0.7338623203945958, 0.7471584816641647, 0.7548788333690757, 0.7604546429337337, 0.7623847308599614, 0.7660304524983916]
train_judgement_acc:[0.783830152262492, 0.7926227750375295, 0.7902637786832512, 0.7921938666094789, 0.7979841303881622, 0.7979841303881622]


test_answer_acc:0.674364896073903	iter_cnt_mean:2.725173210161663
test_code_acc:[0.724809483488569, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715]
test_judgement_acc:[0.8052497883149873, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:46,	loss_g:21.151053190231323	loss_d:16.10271143913269
train_code_acc:[0.7394381299592537, 0.7475873900922153, 0.7531631996568733, 0.7538065622989492, 0.7561655586532275, 0.7610980055758095]
train_judgement_acc:[0.7851168775466438, 0.7857602401887197, 0.7906926871113017, 0.7876903281149474, 0.7904782328972765, 0.7977696761741369]


test_answer_acc:0.6443418013856813	iter_cnt_mean:2.8822170900692843
test_code_acc:[0.7070279424216765, 0.7502116850127011, 0.7502116850127011, 0.7502116850127011, 0.7502116850127011, 0.7502116850127011]
test_judgement_acc:[0.8052497883149873, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225]


epoch:47,	loss_g:20.844907522201538	loss_d:15.851348638534546
train_code_acc:[0.742440488955608, 0.7565944670812782, 0.7585245550075059, 0.7694617199227964, 0.7688183572807206, 0.7707484452069483]
train_judgement_acc:[0.7879047823289728, 0.7898348702552005, 0.801415397812567, 0.7988419472442634, 0.8022732146686682, 0.8029165773107442]


test_answer_acc:0.6766743648960739	iter_cnt_mean:2.7113163972286376
test_code_acc:[0.7349703640982218, 0.7679932260795935, 0.7679932260795935, 0.7679932260795935, 0.7679932260795935, 0.7679932260795935]
test_judgement_acc:[0.8027095681625741, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182]


epoch:48,	loss_g:20.08479118347168	loss_d:15.537611246109009
train_code_acc:[0.755093287583101, 0.7638859103581386, 0.7662449067124169, 0.7694617199227964, 0.7713918078490243, 0.7728929873472014]
train_judgement_acc:[0.7881192365429981, 0.7891915076131246, 0.7973407677460862, 0.7986274930302381, 0.7949817713918078, 0.8007720351704911]


test_answer_acc:0.6558891454965358	iter_cnt_mean:2.81986143187067
test_code_acc:[0.7104149026248942, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055, 0.7510584250635055]
test_judgement_acc:[0.8035563082133785, 0.7984758679085521, 0.7984758679085521, 0.7984758679085521, 0.7984758679085521, 0.7984758679085521]


epoch:49,	loss_g:19.772566556930542	loss_d:15.109158039093018
train_code_acc:[0.7546643791550504, 0.7673171777825434, 0.7731074415612267, 0.7750375294874544, 0.778254342697834, 0.7801844306240617]
train_judgement_acc:[0.7962684966759597, 0.8016298520265923, 0.7992708556723139, 0.8044177568089212, 0.8063478447351491, 0.8067767531631996]


test_answer_acc:0.6697459584295612	iter_cnt_mean:2.74364896073903
test_code_acc:[0.7315834038950042, 0.7603725656223539, 0.7603725656223539, 0.7603725656223539, 0.7603725656223539, 0.7603725656223539]
test_judgement_acc:[0.8035563082133785, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:50,	loss_g:21.157113075256348	loss_d:15.103150606155396
train_code_acc:[0.7589534634355565, 0.7703195367788978, 0.7690328114947459, 0.770533990992923, 0.7748230752734291, 0.7793266137679605]
train_judgement_acc:[0.7996997641003646, 0.8001286725284151, 0.8089212953034527, 0.8080634784473515, 0.8076345700193008, 0.8106369290156552]


test_answer_acc:0.6558891454965358	iter_cnt_mean:2.8290993071593533
test_code_acc:[0.7188823031329382, 0.7569856054191363, 0.7569856054191363, 0.7569856054191363, 0.7569856054191363, 0.7569856054191363]
test_judgement_acc:[0.817104149026249, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621]


epoch:51,	loss_g:20.741093158721924	loss_d:14.628653883934021
train_code_acc:[0.7610980055758095, 0.7780398884838087, 0.7793266137679605, 0.7799699764100364, 0.7791121595539352, 0.7819000643362642]
train_judgement_acc:[0.8048466652369719, 0.801415397812567, 0.8106369290156552, 0.8106369290156552, 0.8121381085138323, 0.806991207377225]


test_answer_acc:0.6766743648960739	iter_cnt_mean:2.722863741339492
test_code_acc:[0.7256562235393734, 0.7612193056731583, 0.7612193056731583, 0.7612193056731583, 0.7612193056731583, 0.7612193056731583]
test_judgement_acc:[0.8052497883149873, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:52,	loss_g:20.53594160079956	loss_d:14.87699282169342
train_code_acc:[0.7653870898563156, 0.7767531631996569, 0.7778254342697835, 0.7801844306240617, 0.7767531631996569, 0.7784687969118593]
train_judgement_acc:[0.8012009435985417, 0.8078490242333262, 0.8057044820930731, 0.8082779326613768, 0.809135749517478, 0.8108513832296804]


test_answer_acc:0.6928406466512702	iter_cnt_mean:2.651270207852194
test_code_acc:[0.7231160033869602, 0.7671464860287892, 0.7679932260795935, 0.7679932260795935, 0.7679932260795935, 0.7679932260795935]
test_judgement_acc:[0.8128704487722269, 0.8247248094834886, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:53,	loss_g:21.246881008148193	loss_d:14.344818353652954
train_code_acc:[0.7746086210594039, 0.7834012438344413, 0.7876903281149474, 0.7945528629637573, 0.7919794123954536, 0.7941239545357066]
train_judgement_acc:[0.8123525627278576, 0.8144971048681107, 0.8153549217242119, 0.8138537422260348, 0.8181428265065408, 0.8224319107870469]


test_answer_acc:0.6697459584295612	iter_cnt_mean:2.74364896073903
test_code_acc:[0.7349703640982218, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715, 0.7637595258255715]
test_judgement_acc:[0.8010160880609652, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093, 0.8094834885690093]


epoch:54,	loss_g:21.381488800048828	loss_d:14.535775303840637
train_code_acc:[0.7718207162770748, 0.778254342697834, 0.7812567016941883, 0.7810422474801629, 0.7844735149045678, 0.785974694402745]
train_judgement_acc:[0.8007720351704911, 0.8099935663735792, 0.80355993995282, 0.804203302594896, 0.8121381085138323, 0.8127814711559083]


test_answer_acc:0.6836027713625866	iter_cnt_mean:2.699769053117783
test_code_acc:[0.7332768839966131, 0.7646062658763759, 0.7654530059271804, 0.7654530059271804, 0.7654530059271804, 0.7654530059271804]
test_judgement_acc:[0.8094834885690093, 0.8204911092294666, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621]


epoch:55,	loss_g:20.536152362823486	loss_d:14.276844382286072
train_code_acc:[0.7750375294874544, 0.7827578811923654, 0.7904782328972765, 0.7904782328972765, 0.7913360497533777, 0.7941239545357066]
train_judgement_acc:[0.8050611194509972, 0.8125670169418829, 0.809135749517478, 0.8129959253699335, 0.8164271927943384, 0.8159982843662879]


test_answer_acc:0.6951501154734411	iter_cnt_mean:2.6420323325635104
test_code_acc:[0.7307366638441999, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892]
test_judgement_acc:[0.8060965283657917, 0.8221845893310754, 0.8221845893310754, 0.8221845893310754, 0.8221845893310754, 0.8221845893310754]


epoch:56,	loss_g:21.35451054573059	loss_d:14.167869210243225
train_code_acc:[0.7720351704911002, 0.7849024233326185, 0.7885481449710486, 0.7943384087497319, 0.7971263135320609, 0.8001286725284151]
train_judgement_acc:[0.8104224748016299, 0.8076345700193008, 0.814711559082136, 0.811923654299807, 0.8198584602187433, 0.8194295517906927]


test_answer_acc:0.6789838337182448	iter_cnt_mean:2.699769053117783
test_code_acc:[0.7392040643522438, 0.7662997459779848, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892, 0.7671464860287892]
test_judgement_acc:[0.8120237087214225, 0.821337849280271, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666]


epoch:57,	loss_g:24.06509518623352	loss_d:13.424095034599304
train_code_acc:[0.7934805918936307, 0.7975552219601115, 0.7988419472442634, 0.8029165773107442, 0.80355993995282, 0.80355993995282]
train_judgement_acc:[0.8125670169418829, 0.8200729144327686, 0.821788548144971, 0.8222174565730217, 0.8260776324254772, 0.8250053613553506]


test_answer_acc:0.6928406466512702	iter_cnt_mean:2.655889145496536
test_code_acc:[0.7383573243014394, 0.7705334462320068, 0.7705334462320068, 0.7705334462320068, 0.7705334462320068, 0.7705334462320068]
test_judgement_acc:[0.8120237087214225, 0.821337849280271, 0.821337849280271, 0.821337849280271, 0.821337849280271, 0.821337849280271]


epoch:58,	loss_g:20.598064661026	loss_d:13.68741774559021
train_code_acc:[0.7851168775466438, 0.7988419472442634, 0.7977696761741369, 0.8007720351704911, 0.8029165773107442, 0.8102080205876045]
train_judgement_acc:[0.8209307312888698, 0.8198584602187433, 0.8243619987132748, 0.8250053613553506, 0.8337979841303882, 0.8239330902852241]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.561200923787529
test_code_acc:[0.7392040643522438, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.7993226079593565, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149]


epoch:59,	loss_g:20.076886892318726	loss_d:13.649999856948853
train_code_acc:[0.7866180570448209, 0.796482950889985, 0.8007720351704911, 0.8057044820930731, 0.8054900278790478, 0.8052755736650226]
train_judgement_acc:[0.8179283722925156, 0.8179283722925156, 0.8230752734291229, 0.8224319107870469, 0.8192150975766673, 0.8262920866395025]


test_answer_acc:0.6905311778290993	iter_cnt_mean:2.6628175519630486
test_code_acc:[0.7349703640982218, 0.77307366638442, 0.7739204064352244, 0.7739204064352244, 0.7739204064352244, 0.7739204064352244]
test_judgement_acc:[0.8094834885690093, 0.8247248094834886, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:60,	loss_g:21.68981170654297	loss_d:13.721094608306885
train_code_acc:[0.7911215955393524, 0.7977696761741369, 0.8029165773107442, 0.8065622989491743, 0.8024876688826935, 0.8054900278790478]
train_judgement_acc:[0.8177139180784903, 0.8224319107870469, 0.8211451855028952, 0.8166416470083637, 0.8215740939309457, 0.826720995067553]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5473441108545036
test_code_acc:[0.7408975444538527, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552]
test_judgement_acc:[0.8086367485182049, 0.8281117696867062, 0.8281117696867062, 0.8281117696867062, 0.8281117696867062, 0.8281117696867062]


epoch:61,	loss_g:22.896292686462402	loss_d:13.12829327583313
train_code_acc:[0.801415397812567, 0.8078490242333262, 0.8087068410894274, 0.8136392880120095, 0.8149260132961613, 0.8155693759382372]
train_judgement_acc:[0.8194295517906927, 0.8239330902852241, 0.8305811709200086, 0.832940167274287, 0.8292944456358567, 0.8327257130602617]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.551963048498845
test_code_acc:[0.7383573243014394, 0.77307366638442, 0.77307366638442, 0.77307366638442, 0.77307366638442, 0.77307366638442]
test_judgement_acc:[0.8137171888230313, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149, 0.8298052497883149]


epoch:62,	loss_g:22.341458797454834	loss_d:12.84626042842865
train_code_acc:[0.8024876688826935, 0.8102080205876045, 0.8142826506540853, 0.8132103795839588, 0.8177139180784903, 0.8183572807205661]
train_judgement_acc:[0.8318678962041605, 0.8284366287797555, 0.8292944456358567, 0.8318678962041605, 0.8342268925584387, 0.8365858889127171]


test_answer_acc:0.7066974595842956	iter_cnt_mean:2.584295612009238
test_code_acc:[0.7425910245554614, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8154106689246401, 0.8365791701947503, 0.8365791701947503, 0.8365791701947503, 0.8365791701947503, 0.8365791701947503]


epoch:63,	loss_g:23.712427616119385	loss_d:13.096451163291931
train_code_acc:[0.8063478447351491, 0.8093502037315033, 0.8132103795839588, 0.8162127385803131, 0.8211451855028952, 0.821788548144971]
train_judgement_acc:[0.8185717349345915, 0.8280077203517049, 0.8327257130602617, 0.8335835299163629, 0.8312245335620845, 0.8303667167059833]


test_answer_acc:0.7020785219399538	iter_cnt_mean:2.600461893764434
test_code_acc:[0.7442845046570703, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8120237087214225, 0.8314987298899238, 0.8314987298899238, 0.8314987298899238, 0.8314987298899238, 0.8314987298899238]


epoch:64,	loss_g:22.712745904922485	loss_d:12.533314108848572
train_code_acc:[0.8061333905211238, 0.8207162770748445, 0.8241475444992494, 0.8297233540639074, 0.8320823504181857, 0.8271499034956037]
train_judgement_acc:[0.837229251554793, 0.8406605189791979, 0.8404460647651726, 0.837872614196869, 0.839373793695046, 0.842805061119451]


test_answer_acc:0.7182448036951501	iter_cnt_mean:2.531177829099307
test_code_acc:[0.7392040643522438, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772]
test_judgement_acc:[0.8035563082133785, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973]


epoch:65,	loss_g:22.325579404830933	loss_d:12.498605370521545
train_code_acc:[0.8117092000857817, 0.8185717349345915, 0.8213596397169204, 0.8230752734291229, 0.8299378082779326, 0.8288655372078061]
train_judgement_acc:[0.8277932661376796, 0.8340124383444135, 0.8361569804846666, 0.8417327900493244, 0.8391593394810208, 0.8398027021230967]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5681293302540418
test_code_acc:[0.7383573243014394, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8060965283657917, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:66,	loss_g:21.5945143699646	loss_d:12.872093915939331
train_code_acc:[0.8097791121595539, 0.8181428265065408, 0.821788548144971, 0.8181428265065408, 0.8243619987132748, 0.8235041818571734]
train_judgement_acc:[0.826720995067553, 0.832296804632211, 0.8312245335620845, 0.8383015226249195, 0.8370147973407678, 0.8318678962041605]


test_answer_acc:0.6974595842956121	iter_cnt_mean:2.6420323325635104
test_code_acc:[0.7383573243014394, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111]
test_judgement_acc:[0.8086367485182049, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018]


epoch:67,	loss_g:22.41849136352539	loss_d:12.694452047348022
train_code_acc:[0.8112802916577311, 0.819644006004718, 0.8220030023589964, 0.8224319107870469, 0.825219815569376, 0.8262920866395025]
train_judgement_acc:[0.8408749731932232, 0.8374437057688183, 0.8340124383444135, 0.832940167274287, 0.8352991636285653, 0.837872614196869]


test_answer_acc:0.7413394919168591	iter_cnt_mean:2.4341801385681294
test_code_acc:[0.7425910245554614, 0.790008467400508, 0.790008467400508, 0.790008467400508, 0.790008467400508, 0.790008467400508]
test_judgement_acc:[0.8145639288738358, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886]


epoch:68,	loss_g:21.28963613510132	loss_d:12.520878911018372
train_code_acc:[0.8057044820930731, 0.8207162770748445, 0.8232897276431482, 0.825219815569376, 0.8316534419901351, 0.830152262491958]
train_judgement_acc:[0.8335835299163629, 0.8383015226249195, 0.840017156337122, 0.8432339695475016, 0.840017156337122, 0.8408749731932232]


test_answer_acc:0.7020785219399538	iter_cnt_mean:2.600461893764434
test_code_acc:[0.7408975444538527, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8137171888230313, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797]


epoch:69,	loss_g:21.64781165122986	loss_d:12.533772468566895
train_code_acc:[0.8123525627278576, 0.8235041818571734, 0.8275788119236543, 0.8241475444992494, 0.8220030023589964, 0.8290799914218314]
train_judgement_acc:[0.839373793695046, 0.8355136178425906, 0.8348702552005147, 0.8352991636285653, 0.842805061119451, 0.8359425262706413]


test_answer_acc:0.7274826789838337	iter_cnt_mean:2.503464203233256
test_code_acc:[0.7417442845046571, 0.7883149872988993, 0.7883149872988993, 0.7883149872988993, 0.7883149872988993, 0.7883149872988993]
test_judgement_acc:[0.8044030482641829, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:70,	loss_g:23.8908851146698	loss_d:12.506298184394836
train_code_acc:[0.8151404675101865, 0.8224319107870469, 0.8224319107870469, 0.8292944456358567, 0.8256487239974265, 0.8262920866395025]
train_judgement_acc:[0.8355136178425906, 0.8368003431267425, 0.8402316105511474, 0.8335835299163629, 0.8389448852669955, 0.8389448852669955]


test_answer_acc:0.7043879907621247	iter_cnt_mean:2.6096997690531176
test_code_acc:[0.7383573243014394, 0.77307366638442, 0.77307366638442, 0.77307366638442, 0.77307366638442, 0.77307366638442]
test_judgement_acc:[0.8094834885690093, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886, 0.8247248094834886]


epoch:71,	loss_g:20.77171492576599	loss_d:12.322250008583069
train_code_acc:[0.8144971048681107, 0.8209307312888698, 0.8277932661376796, 0.8305811709200086, 0.8295088998498821, 0.8299378082779326]
train_judgement_acc:[0.832296804632211, 0.8391593394810208, 0.8331546214883122, 0.8389448852669955, 0.8421616984773751, 0.8342268925584387]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.556581986143187
test_code_acc:[0.7417442845046571, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8103302286198137, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:72,	loss_g:23.150100708007812	loss_d:11.975905418395996
train_code_acc:[0.8187861891486168, 0.8318678962041605, 0.8352991636285653, 0.8385159768389449, 0.8413038816212739, 0.8376581599828437]
train_judgement_acc:[0.839373793695046, 0.8406605189791979, 0.8481664164700836, 0.8473085996139824, 0.8447351490456787, 0.8500965043963113]


test_answer_acc:0.7251732101616628	iter_cnt_mean:2.5173210161662816
test_code_acc:[0.7349703640982218, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8001693480101609, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313]


epoch:73,	loss_g:20.246689081192017	loss_d:12.248804330825806
train_code_acc:[0.8183572807205661, 0.8280077203517049, 0.8295088998498821, 0.8325112588462363, 0.8295088998498821, 0.8344413467724641]
train_judgement_acc:[0.8348702552005147, 0.83508470941454, 0.8421616984773751, 0.8413038816212739, 0.8421616984773751, 0.8447351490456787]


test_answer_acc:0.7321016166281755	iter_cnt_mean:2.4734411085450345
test_code_acc:[0.7451312447078747, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904]
test_judgement_acc:[0.8035563082133785, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:74,	loss_g:20.90285038948059	loss_d:11.945250511169434
train_code_acc:[0.8211451855028952, 0.8355136178425906, 0.8376581599828437, 0.837229251554793, 0.8370147973407678, 0.8363714346986918]
train_judgement_acc:[0.840017156337122, 0.8374437057688183, 0.8380870684108943, 0.8389448852669955, 0.8475230538280077, 0.8468796911859318]


test_answer_acc:0.7020785219399538	iter_cnt_mean:2.600461893764434
test_code_acc:[0.745977984758679, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376]
test_judgement_acc:[0.8120237087214225, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:75,	loss_g:22.15957260131836	loss_d:12.033457159996033
train_code_acc:[0.8288655372078061, 0.8312245335620845, 0.8342268925584387, 0.8346558009864894, 0.8320823504181857, 0.8374437057688183]
train_judgement_acc:[0.8387304310529702, 0.8365858889127171, 0.8389448852669955, 0.837872614196869, 0.84559296590178, 0.8460218743298306]


test_answer_acc:0.7274826789838337	iter_cnt_mean:2.48729792147806
test_code_acc:[0.7442845046570703, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8094834885690093, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:76,	loss_g:20.825430154800415	loss_d:11.653689861297607
train_code_acc:[0.8337979841303882, 0.8419472442633498, 0.8447351490456787, 0.8468796911859318, 0.8415183358352991, 0.842805061119451]
train_judgement_acc:[0.8496675959682608, 0.84559296590178, 0.8496675959682608, 0.8470941453999571, 0.848380870684109, 0.8507398670383873]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5450346420323324
test_code_acc:[0.7451312447078747, 0.7781541066892464, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8018628281117697, 0.8179508890770534, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:77,	loss_g:23.24581265449524	loss_d:11.672027945518494
train_code_acc:[0.8307956251340339, 0.8395882479090714, 0.8425906069054256, 0.8447351490456787, 0.8458074201158052, 0.8451640574737294]
train_judgement_acc:[0.8466652369719065, 0.8479519622560583, 0.8520265923225392, 0.850525412824362, 0.8511687754664379, 0.850525412824362]


test_answer_acc:0.7043879907621247	iter_cnt_mean:2.5981524249422634
test_code_acc:[0.7417442845046571, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111, 0.7713801862828111]
test_judgement_acc:[0.8010160880609652, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401]


epoch:78,	loss_g:21.791635751724243	loss_d:11.742430210113525
train_code_acc:[0.8337979841303882, 0.8389448852669955, 0.8425906069054256, 0.8443062406176282, 0.842805061119451, 0.8410894274072486]
train_judgement_acc:[0.84559296590178, 0.843448423761527, 0.8490242333261848, 0.8503109586103367, 0.8494531417542355, 0.8485953248981343]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5658198614318706
test_code_acc:[0.7434377646062659, 0.7747671464860287, 0.7756138865368332, 0.7756138865368332, 0.7756138865368332, 0.7756138865368332]
test_judgement_acc:[0.8044030482641829, 0.8154106689246401, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358]


epoch:79,	loss_g:23.905056476593018	loss_d:11.785345673561096
train_code_acc:[0.8359425262706413, 0.8370147973407678, 0.8402316105511474, 0.840017156337122, 0.8402316105511474, 0.8406605189791979]
train_judgement_acc:[0.8406605189791979, 0.850525412824362, 0.8496675959682608, 0.8503109586103367, 0.8451640574737294, 0.8494531417542355]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.561200923787529
test_code_acc:[0.7442845046570703, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8128704487722269, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577]


epoch:80,	loss_g:21.894492149353027	loss_d:11.54704999923706
train_code_acc:[0.8314389877761098, 0.837229251554793, 0.8419472442633498, 0.8415183358352991, 0.84559296590178, 0.844949603259704]
train_judgement_acc:[0.8490242333261848, 0.8507398670383873, 0.8485953248981343, 0.8490242333261848, 0.8513832296804632, 0.8464507827578812]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.556581986143187
test_code_acc:[0.7442845046570703, 0.777307366638442, 0.777307366638442, 0.777307366638442, 0.777307366638442, 0.777307366638442]
test_judgement_acc:[0.8120237087214225, 0.8289585097375106, 0.8289585097375106, 0.8289585097375106, 0.8289585097375106, 0.8289585097375106]


epoch:81,	loss_g:21.490376710891724	loss_d:11.29711902141571
train_code_acc:[0.8357280720566159, 0.8438773321895775, 0.8430195153334763, 0.8466652369719065, 0.8466652369719065, 0.84559296590178]
train_judgement_acc:[0.8511687754664379, 0.8462363285438559, 0.8565301308170705, 0.8535277718207163, 0.8509543212524127, 0.8567445850310959]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5635103926097
test_code_acc:[0.7485182049110923, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8111769686706182, 0.8137171888230313, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358]


epoch:82,	loss_g:21.036821126937866	loss_d:11.893265128135681
train_code_acc:[0.8275788119236543, 0.8282221745657302, 0.8337979841303882, 0.8352991636285653, 0.8331546214883122, 0.8316534419901351]
train_judgement_acc:[0.8312245335620845, 0.8430195153334763, 0.8453785116877547, 0.8413038816212739, 0.8402316105511474, 0.844949603259704]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.556581986143187
test_code_acc:[0.7476714648602879, 0.7756138865368332, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376]
test_judgement_acc:[0.8145639288738358, 0.821337849280271, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666]


epoch:83,	loss_g:20.490803003311157	loss_d:11.707786202430725
train_code_acc:[0.8335835299163629, 0.8365858889127171, 0.8408749731932232, 0.8395882479090714, 0.8432339695475016, 0.8438773321895775]
train_judgement_acc:[0.8419472442633498, 0.8453785116877547, 0.8447351490456787, 0.8462363285438559, 0.8475230538280077, 0.8503109586103367]


test_answer_acc:0.7228637413394919	iter_cnt_mean:2.503464203233256
test_code_acc:[0.7468247248094835, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552]
test_judgement_acc:[0.8120237087214225, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797]


epoch:84,	loss_g:22.278732538223267	loss_d:11.695900201797485
train_code_acc:[0.8305811709200086, 0.8363714346986918, 0.8359425262706413, 0.8404460647651726, 0.8413038816212739, 0.8423761526914004]
train_judgement_acc:[0.8404460647651726, 0.8413038816212739, 0.8462363285438559, 0.8473085996139824, 0.8462363285438559, 0.8507398670383873]


test_answer_acc:0.7182448036951501	iter_cnt_mean:2.5265588914549655
test_code_acc:[0.7493649449618967, 0.7781541066892464, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8179508890770534, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018, 0.8272650296359018]


epoch:85,	loss_g:21.605146169662476	loss_d:11.517934679985046
train_code_acc:[0.8352991636285653, 0.8408749731932232, 0.842805061119451, 0.8438773321895775, 0.8451640574737294, 0.8496675959682608]
train_judgement_acc:[0.8443062406176282, 0.8466652369719065, 0.84559296590178, 0.844949603259704, 0.8539566802487669, 0.850525412824362]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5473441108545036
test_code_acc:[0.7493649449618967, 0.777307366638442, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8154106689246401, 0.8272650296359018, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973]


epoch:86,	loss_g:20.993639945983887	loss_d:11.162176728248596
train_code_acc:[0.8348702552005147, 0.8413038816212739, 0.8464507827578812, 0.8488097791121596, 0.8537422260347416, 0.8535277718207163]
train_judgement_acc:[0.8494531417542355, 0.8522410465365644, 0.8550289513188934, 0.8558867681749946, 0.8479519622560583, 0.855457859746944]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5496535796766744
test_code_acc:[0.7451312447078747, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8069432684165961, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313]


epoch:87,	loss_g:20.35547685623169	loss_d:10.99481475353241
train_code_acc:[0.8488097791121596, 0.8511687754664379, 0.8500965043963113, 0.8492386875402101, 0.855457859746944, 0.8558867681749946]
train_judgement_acc:[0.8530988633926657, 0.8541711344627922, 0.8567445850310959, 0.8627493030238044, 0.8593180355993996, 0.8597469440274501]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.551963048498845
test_code_acc:[0.7502116850127011, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8103302286198137, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225, 0.8120237087214225]


epoch:88,	loss_g:21.869057655334473	loss_d:11.29909360408783
train_code_acc:[0.8425906069054256, 0.8402316105511474, 0.8440917864036028, 0.8477375080420331, 0.8503109586103367, 0.8500965043963113]
train_judgement_acc:[0.8464507827578812, 0.8537422260347416, 0.858245764529273, 0.8543855886768175, 0.8485953248981343, 0.85610122238902]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.5381062355658197
test_code_acc:[0.7493649449618967, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552]
test_judgement_acc:[0.8103302286198137, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621]


epoch:89,	loss_g:20.479122400283813	loss_d:11.514454126358032
train_code_acc:[0.8303667167059833, 0.8417327900493244, 0.840017156337122, 0.8410894274072486, 0.8477375080420331, 0.8423761526914004]
train_judgement_acc:[0.8445206948316535, 0.8458074201158052, 0.8477375080420331, 0.8537422260347416, 0.8460218743298306, 0.8535277718207163]


test_answer_acc:0.7205542725173211	iter_cnt_mean:2.5057736720554273
test_code_acc:[0.7519051651143099, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728]
test_judgement_acc:[0.8154106689246401, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:90,	loss_g:20.797917127609253	loss_d:11.047765254974365
train_code_acc:[0.8496675959682608, 0.8479519622560583, 0.8488097791121596, 0.8513832296804632, 0.8507398670383873, 0.8535277718207163]
train_judgement_acc:[0.8464507827578812, 0.8509543212524127, 0.8569590392451212, 0.8503109586103367, 0.8543855886768175, 0.8550289513188934]


test_answer_acc:0.7297921478060047	iter_cnt_mean:2.459584295612009
test_code_acc:[0.7485182049110923, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772, 0.7840812870448772]
test_judgement_acc:[0.8103302286198137, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:91,	loss_g:21.413824319839478	loss_d:11.230198740959167
train_code_acc:[0.8440917864036028, 0.8475230538280077, 0.8477375080420331, 0.8500965043963113, 0.8507398670383873, 0.8543855886768175]
train_judgement_acc:[0.8509543212524127, 0.8533133176066909, 0.8535277718207163, 0.8586746729573236, 0.8578168561012224, 0.8571734934591465]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.540415704387991
test_code_acc:[0.7510584250635055, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8069432684165961, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:92,	loss_g:20.80557346343994	loss_d:10.683117747306824
train_code_acc:[0.8500965043963113, 0.855457859746944, 0.8558867681749946, 0.858245764529273, 0.8586746729573236, 0.8584602187432983]
train_judgement_acc:[0.861033669311602, 0.8597469440274501, 0.863178211451855, 0.8625348488097792, 0.8569590392451212, 0.8640360283079562]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.535796766743649
test_code_acc:[0.7502116850127011, 0.7798475867908552, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8052497883149873, 0.8196443691786621, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577]


epoch:93,	loss_g:21.48497462272644	loss_d:11.24104130268097
train_code_acc:[0.8423761526914004, 0.8479519622560583, 0.8481664164700836, 0.8528844091786404, 0.8558867681749946, 0.8546000428908428]
train_judgement_acc:[0.8520265923225392, 0.8494531417542355, 0.8563156766030452, 0.8546000428908428, 0.8509543212524127, 0.8535277718207163]


test_answer_acc:0.7274826789838337	iter_cnt_mean:2.4711316397228638
test_code_acc:[0.7502116850127011, 0.7840812870448772, 0.7849280270956817, 0.7849280270956817, 0.7849280270956817, 0.7849280270956817]
test_judgement_acc:[0.8162574089754445, 0.8179508890770534, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:94,	loss_g:20.503870248794556	loss_d:10.869887948036194
train_code_acc:[0.8451640574737294, 0.8492386875402101, 0.8509543212524127, 0.8550289513188934, 0.8571734934591465, 0.8606047608835513]
train_judgement_acc:[0.8546000428908428, 0.8546000428908428, 0.8580313103152477, 0.8580313103152477, 0.861033669311602, 0.8608192150975766]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5381062355658197
test_code_acc:[0.7468247248094835, 0.7764606265876376, 0.777307366638442, 0.777307366638442, 0.777307366638442, 0.777307366638442]
test_judgement_acc:[0.8145639288738358, 0.8272650296359018, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973]


epoch:95,	loss_g:21.823899745941162	loss_d:10.865553855895996
train_code_acc:[0.8368003431267425, 0.8447351490456787, 0.8479519622560583, 0.8466652369719065, 0.8520265923225392, 0.8539566802487669]
train_judgement_acc:[0.8485953248981343, 0.8535277718207163, 0.8533133176066909, 0.8580313103152477, 0.8558867681749946, 0.8595324898134248]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7476714648602879, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8035563082133785, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313]


epoch:96,	loss_g:20.253793239593506	loss_d:11.372013688087463
train_code_acc:[0.8415183358352991, 0.8468796911859318, 0.8466652369719065, 0.8481664164700836, 0.8485953248981343, 0.8460218743298306]
train_judgement_acc:[0.8462363285438559, 0.8470941453999571, 0.8509543212524127, 0.8511687754664379, 0.8513832296804632, 0.8509543212524127]


test_answer_acc:0.7251732101616628	iter_cnt_mean:2.4734411085450345
test_code_acc:[0.7510584250635055, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728, 0.7832345469940728]
test_judgement_acc:[0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401]


epoch:97,	loss_g:21.081388235092163	loss_d:11.459339380264282
train_code_acc:[0.8421616984773751, 0.8466652369719065, 0.8520265923225392, 0.8511687754664379, 0.8488097791121596, 0.8530988633926657]
train_judgement_acc:[0.8503109586103367, 0.8571734934591465, 0.8503109586103367, 0.8503109586103367, 0.8550289513188934, 0.8543855886768175]


test_answer_acc:0.7043879907621247	iter_cnt_mean:2.558891454965358
test_code_acc:[0.7527519051651143, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8137171888230313, 0.821337849280271, 0.821337849280271, 0.821337849280271, 0.821337849280271, 0.821337849280271]


epoch:98,	loss_g:20.366973400115967	loss_d:11.294782638549805
train_code_acc:[0.8404460647651726, 0.8438773321895775, 0.8477375080420331, 0.8515976838944885, 0.8520265923225392, 0.8522410465365644]
train_judgement_acc:[0.8541711344627922, 0.8488097791121596, 0.8569590392451212, 0.8524555007505897, 0.8556723139609693, 0.8569590392451212]


test_answer_acc:0.7066974595842956	iter_cnt_mean:2.558891454965358
test_code_acc:[0.7544453852667231, 0.7798475867908552, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8120237087214225, 0.8196443691786621, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577]


epoch:99,	loss_g:20.414530754089355	loss_d:11.075350403785706
train_code_acc:[0.8436628779755522, 0.8477375080420331, 0.8485953248981343, 0.8496675959682608, 0.8470941453999571, 0.8511687754664379]
train_judgement_acc:[0.8535277718207163, 0.8496675959682608, 0.8537422260347416, 0.8498820501822861, 0.8552434055329188, 0.858245764529273]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5381062355658197
test_code_acc:[0.7519051651143099, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8086367485182049, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534]


epoch:100,	loss_g:20.2793071269989	loss_d:10.69824469089508
train_code_acc:[0.842805061119451, 0.8526699549646151, 0.8548144971048681, 0.8563156766030452, 0.8591035813853742, 0.8565301308170705]
train_judgement_acc:[0.8556723139609693, 0.858245764529273, 0.8608192150975766, 0.861033669311602, 0.8614625777396526, 0.861033669311602]


test_answer_acc:0.7020785219399538	iter_cnt_mean:2.5889145496535795
test_code_acc:[0.7476714648602879, 0.777307366638442, 0.777307366638442, 0.777307366638442, 0.777307366638442, 0.777307366638442]
test_judgement_acc:[0.8027095681625741, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:101,	loss_g:21.08664107322693	loss_d:11.345967054367065
train_code_acc:[0.8370147973407678, 0.839373793695046, 0.8404460647651726, 0.839373793695046, 0.8419472442633498, 0.8417327900493244]
train_judgement_acc:[0.8481664164700836, 0.8440917864036028, 0.8477375080420331, 0.8515976838944885, 0.850525412824362, 0.848380870684109]


test_answer_acc:0.7020785219399538	iter_cnt_mean:2.5889145496535795
test_code_acc:[0.7468247248094835, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376]
test_judgement_acc:[0.8145639288738358, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842, 0.8238780694326842]


epoch:102,	loss_g:19.296854257583618	loss_d:11.182148814201355
train_code_acc:[0.843448423761527, 0.8518121381085139, 0.8498820501822861, 0.8518121381085139, 0.8494531417542355, 0.8552434055329188]
train_judgement_acc:[0.8507398670383873, 0.8535277718207163, 0.8543855886768175, 0.8503109586103367, 0.855457859746944, 0.8530988633926657]


test_answer_acc:0.7066974595842956	iter_cnt_mean:2.5658198614318706
test_code_acc:[0.7493649449618967, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8196443691786621, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973, 0.8264182895850973]


epoch:103,	loss_g:20.347824096679688	loss_d:11.226321935653687
train_code_acc:[0.8368003431267425, 0.8458074201158052, 0.8443062406176282, 0.8503109586103367, 0.8494531417542355, 0.8477375080420331]
train_judgement_acc:[0.8475230538280077, 0.8462363285438559, 0.8509543212524127, 0.8543855886768175, 0.8522410465365644, 0.8515976838944885]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5265588914549655
test_code_acc:[0.7502116850127011, 0.7798475867908552, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8120237087214225, 0.8230313293818797, 0.8221845893310754, 0.8221845893310754, 0.8221845893310754, 0.8221845893310754]


epoch:104,	loss_g:22.103689432144165	loss_d:10.845155239105225
train_code_acc:[0.8466652369719065, 0.8509543212524127, 0.8539566802487669, 0.8558867681749946, 0.8565301308170705, 0.8569590392451212]
train_judgement_acc:[0.8498820501822861, 0.8552434055329188, 0.8642504825219816, 0.8567445850310959, 0.8586746729573236, 0.8599613982414754]


test_answer_acc:0.7182448036951501	iter_cnt_mean:2.5173210161662816
test_code_acc:[0.7493649449618967, 0.7798475867908552, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8120237087214225, 0.821337849280271, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666, 0.8204911092294666]


epoch:105,	loss_g:22.43018937110901	loss_d:10.798609256744385
train_code_acc:[0.8477375080420331, 0.8500965043963113, 0.855457859746944, 0.8588891271713489, 0.8578168561012224, 0.8556723139609693]
train_judgement_acc:[0.8530988633926657, 0.8599613982414754, 0.8621059403817285, 0.863178211451855, 0.8573879476731717, 0.8621059403817285]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.535796766743649
test_code_acc:[0.7510584250635055, 0.7806943268416596, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8077900084674005, 0.8204911092294666, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621, 0.8196443691786621]


epoch:106,	loss_g:21.79549813270569	loss_d:10.468011021614075
train_code_acc:[0.8451640574737294, 0.8522410465365644, 0.8546000428908428, 0.8563156766030452, 0.8584602187432983, 0.8573879476731717]
train_judgement_acc:[0.8597469440274501, 0.8586746729573236, 0.8621059403817285, 0.8627493030238044, 0.8663950246622346, 0.865966116234184]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.540415704387991
test_code_acc:[0.7535986452159187, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552]
test_judgement_acc:[0.8128704487722269, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797, 0.8230313293818797]


epoch:107,	loss_g:20.8164963722229	loss_d:10.826895713806152
train_code_acc:[0.8475230538280077, 0.8524555007505897, 0.8507398670383873, 0.8556723139609693, 0.8530988633926657, 0.8591035813853742]
train_judgement_acc:[0.85610122238902, 0.8511687754664379, 0.8623203945957538, 0.8571734934591465, 0.8633926656658804, 0.8595324898134248]


test_answer_acc:0.7205542725173211	iter_cnt_mean:2.503464203233256
test_code_acc:[0.7510584250635055, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577, 0.8187976291278577]


epoch:108,	loss_g:21.541406631469727	loss_d:10.762106776237488
train_code_acc:[0.8462363285438559, 0.8492386875402101, 0.8515976838944885, 0.8543855886768175, 0.8580313103152477, 0.8567445850310959]
train_judgement_acc:[0.8548144971048681, 0.8601758524555008, 0.8608192150975766, 0.8569590392451212, 0.8584602187432983, 0.8595324898134248]


test_answer_acc:0.7321016166281755	iter_cnt_mean:2.4572748267898383
test_code_acc:[0.7502116850127011, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904, 0.7866215071972904]
test_judgement_acc:[0.8044030482641829, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005, 0.8077900084674005]


epoch:109,	loss_g:21.74142622947693	loss_d:10.715916991233826
train_code_acc:[0.8468796911859318, 0.8524555007505897, 0.8552434055329188, 0.85610122238902, 0.8558867681749946, 0.8584602187432983]
train_judgement_acc:[0.8533133176066909, 0.8563156766030452, 0.8595324898134248, 0.8563156766030452, 0.8614625777396526, 0.8601758524555008]


test_answer_acc:0.7297921478060047	iter_cnt_mean:2.468822170900693
test_code_acc:[0.7502116850127011, 0.785774767146486, 0.785774767146486, 0.785774767146486, 0.785774767146486, 0.785774767146486]
test_judgement_acc:[0.8052497883149873, 0.8103302286198137, 0.8103302286198137, 0.8103302286198137, 0.8103302286198137, 0.8103302286198137]


epoch:110,	loss_g:20.791139364242554	loss_d:11.010465383529663
train_code_acc:[0.8468796911859318, 0.8518121381085139, 0.8530988633926657, 0.8522410465365644, 0.8494531417542355, 0.8513832296804632]
train_judgement_acc:[0.8466652369719065, 0.8546000428908428, 0.85610122238902, 0.8530988633926657, 0.8556723139609693, 0.8616770319536778]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.5496535796766744
test_code_acc:[0.7502116850127011, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376, 0.7764606265876376]
test_judgement_acc:[0.8094834885690093, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:111,	loss_g:19.936529397964478	loss_d:10.953195929527283
train_code_acc:[0.8485953248981343, 0.8530988633926657, 0.8511687754664379, 0.8537422260347416, 0.8565301308170705, 0.850525412824362]
train_judgement_acc:[0.8524555007505897, 0.8518121381085139, 0.8591035813853742, 0.8567445850310959, 0.8537422260347416, 0.8595324898134248]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.5496535796766744
test_code_acc:[0.7510584250635055, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8086367485182049, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401, 0.8154106689246401]


epoch:112,	loss_g:21.775766849517822	loss_d:10.852536082267761
train_code_acc:[0.8464507827578812, 0.8470941453999571, 0.8481664164700836, 0.8509543212524127, 0.8597469440274501, 0.8571734934591465]
train_judgement_acc:[0.8494531417542355, 0.8537422260347416, 0.858245764529273, 0.8683251125884623, 0.8591035813853742, 0.8603903066695261]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7527519051651143, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:113,	loss_g:19.584691286087036	loss_d:10.684416890144348
train_code_acc:[0.8511687754664379, 0.8569590392451212, 0.858245764529273, 0.8599613982414754, 0.8573879476731717, 0.8597469440274501]
train_judgement_acc:[0.861033669311602, 0.8627493030238044, 0.8629637572378297, 0.8586746729573236, 0.8606047608835513, 0.8623203945957538]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5219399538106235
test_code_acc:[0.7527519051651143, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8044030482641829, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182]


epoch:114,	loss_g:19.22821044921875	loss_d:10.475377917289734
train_code_acc:[0.8515976838944885, 0.8535277718207163, 0.8556723139609693, 0.8546000428908428, 0.8618914861677032, 0.8621059403817285]
train_judgement_acc:[0.8550289513188934, 0.8603903066695261, 0.8584602187432983, 0.8666094788762599, 0.8633926656658804, 0.8661805704482093]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5219399538106235
test_code_acc:[0.7527519051651143, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8027095681625741, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182, 0.8111769686706182]


epoch:115,	loss_g:20.77599787712097	loss_d:10.616756200790405
train_code_acc:[0.8464507827578812, 0.8546000428908428, 0.8567445850310959, 0.8537422260347416, 0.8563156766030452, 0.8597469440274501]
train_judgement_acc:[0.8621059403817285, 0.8556723139609693, 0.8573879476731717, 0.8591035813853742, 0.8591035813853742, 0.8573879476731717]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.51270207852194
test_code_acc:[0.7519051651143099, 0.7823878069432684, 0.7823878069432684, 0.7823878069432684, 0.7823878069432684, 0.7823878069432684]
test_judgement_acc:[0.8077900084674005, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:116,	loss_g:20.370439052581787	loss_d:10.349976181983948
train_code_acc:[0.8530988633926657, 0.857602401887197, 0.8603903066695261, 0.8612481235256273, 0.8685395668024877, 0.8668239330902853]
train_judgement_acc:[0.8648938451640574, 0.8623203945957538, 0.8614625777396526, 0.8674672957323611, 0.868754021016513, 0.8678962041604118]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.540415704387991
test_code_acc:[0.7527519051651143, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8052497883149873, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358, 0.8145639288738358]


epoch:117,	loss_g:21.12927508354187	loss_d:11.13007140159607
train_code_acc:[0.848380870684109, 0.8488097791121596, 0.8511687754664379, 0.8528844091786404, 0.8548144971048681, 0.8535277718207163]
train_judgement_acc:[0.848380870684109, 0.8535277718207163, 0.8558867681749946, 0.8565301308170705, 0.8513832296804632, 0.857602401887197]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.5496535796766744
test_code_acc:[0.7527519051651143, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552, 0.7798475867908552]
test_judgement_acc:[0.8069432684165961, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269]


epoch:118,	loss_g:20.188679218292236	loss_d:10.924161553382874
train_code_acc:[0.8488097791121596, 0.8500965043963113, 0.8541711344627922, 0.8552434055329188, 0.8569590392451212, 0.855457859746944]
train_judgement_acc:[0.8481664164700836, 0.8580313103152477, 0.8586746729573236, 0.8586746729573236, 0.8601758524555008, 0.85610122238902]


test_answer_acc:0.7090069284064665	iter_cnt_mean:2.5473441108545036
test_code_acc:[0.7535986452159187, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464, 0.7781541066892464]
test_judgement_acc:[0.8077900084674005, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313, 0.8137171888230313]


epoch:119,	loss_g:20.845341444015503	loss_d:10.705069899559021
train_code_acc:[0.8520265923225392, 0.8530988633926657, 0.8599613982414754, 0.8586746729573236, 0.861033669311602, 0.857602401887197]
train_judgement_acc:[0.8552434055329188, 0.8625348488097792, 0.8588891271713489, 0.8648938451640574, 0.8586746729573236, 0.8618914861677032]


test_answer_acc:0.7113163972286374	iter_cnt_mean:2.5381062355658197
test_code_acc:[0.7535986452159187, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508, 0.7790008467400508]
test_judgement_acc:[0.8077900084674005, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269, 0.8128704487722269]


epoch:120,	loss_g:20.373409271240234	loss_d:10.747045397758484
train_code_acc:[0.8485953248981343, 0.8509543212524127, 0.8528844091786404, 0.8539566802487669, 0.8558867681749946, 0.8556723139609693]
train_judgement_acc:[0.857602401887197, 0.8591035813853742, 0.8571734934591465, 0.857602401887197, 0.8606047608835513, 0.858245764529273]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7535986452159187, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8103302286198137, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:121,	loss_g:19.806569576263428	loss_d:10.80537760257721
train_code_acc:[0.8498820501822861, 0.850525412824362, 0.8546000428908428, 0.855457859746944, 0.8541711344627922, 0.8535277718207163]
train_judgement_acc:[0.8503109586103367, 0.8535277718207163, 0.8550289513188934, 0.8533133176066909, 0.85610122238902, 0.8550289513188934]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7535986452159187, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8111769686706182, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534]


epoch:122,	loss_g:20.90632724761963	loss_d:10.391282796859741
train_code_acc:[0.8507398670383873, 0.8535277718207163, 0.857602401887197, 0.8640360283079562, 0.861033669311602, 0.8612481235256273]
train_judgement_acc:[0.8539566802487669, 0.8623203945957538, 0.8655372078061334, 0.8653227535921081, 0.8651082993780828, 0.8651082993780828]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7535986452159187, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8111769686706182, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534, 0.8179508890770534]


epoch:123,	loss_g:20.04147219657898	loss_d:10.96041750907898
train_code_acc:[0.8468796911859318, 0.8550289513188934, 0.8556723139609693, 0.8565301308170705, 0.8558867681749946, 0.8537422260347416]
train_judgement_acc:[0.8556723139609693, 0.8541711344627922, 0.8580313103152477, 0.8556723139609693, 0.8548144971048681, 0.8563156766030452]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7535986452159187, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8094834885690093, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445, 0.8162574089754445]


epoch:124,	loss_g:20.02404022216797	loss_d:10.995300650596619
train_code_acc:[0.8440917864036028, 0.8481664164700836, 0.8546000428908428, 0.8494531417542355, 0.8565301308170705, 0.8546000428908428]
train_judgement_acc:[0.8558867681749946, 0.8548144971048681, 0.8522410465365644, 0.8595324898134248, 0.8552434055329188, 0.8599613982414754]


test_answer_acc:0.7136258660508084	iter_cnt_mean:2.5288683602771362
test_code_acc:[0.7535986452159187, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596, 0.7806943268416596]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:125,	loss_g:21.720637559890747	loss_d:11.011492013931274
train_code_acc:[0.8479519622560583, 0.8477375080420331, 0.8520265923225392, 0.8573879476731717, 0.8597469440274501, 0.8584602187432983]
train_judgement_acc:[0.8507398670383873, 0.8586746729573236, 0.8586746729573236, 0.8591035813853742, 0.8597469440274501, 0.8552434055329188]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5196304849884528
test_code_acc:[0.7535986452159187, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:126,	loss_g:20.146785974502563	loss_d:10.805830955505371
train_code_acc:[0.8520265923225392, 0.8524555007505897, 0.8584602187432983, 0.8569590392451212, 0.8552434055329188, 0.8595324898134248]
train_judgement_acc:[0.8518121381085139, 0.8591035813853742, 0.8584602187432983, 0.8578168561012224, 0.865966116234184, 0.8595324898134248]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5196304849884528
test_code_acc:[0.7535986452159187, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:127,	loss_g:20.354511976242065	loss_d:10.882431864738464
train_code_acc:[0.8513832296804632, 0.8515976838944885, 0.8552434055329188, 0.85610122238902, 0.8556723139609693, 0.8571734934591465]
train_judgement_acc:[0.8492386875402101, 0.8567445850310959, 0.8567445850310959, 0.857602401887197, 0.8537422260347416, 0.858245764529273]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5196304849884528
test_code_acc:[0.7535986452159187, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:128,	loss_g:20.817826986312866	loss_d:10.598440051078796
train_code_acc:[0.8481664164700836, 0.8518121381085139, 0.8535277718207163, 0.8558867681749946, 0.8573879476731717, 0.8550289513188934]
train_judgement_acc:[0.8543855886768175, 0.8569590392451212, 0.8601758524555008, 0.8588891271713489, 0.8601758524555008, 0.8586746729573236]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5196304849884528
test_code_acc:[0.7535986452159187, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]


epoch:129,	loss_g:20.00243091583252	loss_d:10.523634672164917
train_code_acc:[0.8494531417542355, 0.8573879476731717, 0.8558867681749946, 0.8548144971048681, 0.8584602187432983, 0.8603903066695261]
train_judgement_acc:[0.8567445850310959, 0.8550289513188934, 0.8603903066695261, 0.8586746729573236, 0.8623203945957538, 0.8623203945957538]


test_answer_acc:0.7159353348729792	iter_cnt_mean:2.5196304849884528
test_code_acc:[0.7535986452159187, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464, 0.781541066892464]
test_judgement_acc:[0.8111769686706182, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249, 0.817104149026249]
after process dataset len: 433
total passed: 0
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 80646.25it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 176529.32it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
===========================train setting parameters=========================
encoder.embeddings.word_embeddings.weight-torch.Size([30522, 768])
encoder.embeddings.position_embeddings.weight-torch.Size([512, 768])
encoder.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
encoder.embeddings.LayerNorm.weight-torch.Size([768])
encoder.embeddings.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.0.output.dense.bias-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.1.output.dense.bias-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.2.output.dense.bias-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.3.output.dense.bias-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.4.output.dense.bias-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.5.output.dense.bias-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.6.output.dense.bias-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.7.output.dense.bias-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.8.output.dense.bias-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.9.output.dense.bias-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.10.output.dense.bias-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.query.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.key.bias-torch.Size([768])
encoder.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.self.value.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
encoder.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
encoder.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
encoder.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
encoder.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
encoder.encoder.layer.11.output.dense.bias-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
encoder.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
encoder.pooler.dense.weight-torch.Size([768, 768])
encoder.pooler.dense.bias-torch.Size([768])
code_emb.embedding.weight-torch.Size([29, 768])
fusion_fc.weight-torch.Size([768, 2304])
fusion_fc.bias-torch.Size([768])
geneartor.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder_layers.linear1.weight-torch.Size([2048, 768])
geneartor.decoder_layers.linear1.bias-torch.Size([2048])
geneartor.decoder_layers.linear2.weight-torch.Size([768, 2048])
geneartor.decoder_layers.linear2.bias-torch.Size([768])
geneartor.decoder_layers.norm1.weight-torch.Size([768])
geneartor.decoder_layers.norm1.bias-torch.Size([768])
geneartor.decoder_layers.norm2.weight-torch.Size([768])
geneartor.decoder_layers.norm2.bias-torch.Size([768])
geneartor.decoder_layers.norm3.weight-torch.Size([768])
geneartor.decoder_layers.norm3.bias-torch.Size([768])
geneartor.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.0.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.0.linear2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm1.weight-torch.Size([768])
geneartor.decoder.layers.0.norm1.bias-torch.Size([768])
geneartor.decoder.layers.0.norm2.weight-torch.Size([768])
geneartor.decoder.layers.0.norm2.bias-torch.Size([768])
geneartor.decoder.layers.0.norm3.weight-torch.Size([768])
geneartor.decoder.layers.0.norm3.bias-torch.Size([768])
geneartor.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
geneartor.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
geneartor.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
geneartor.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
geneartor.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
geneartor.decoder.layers.1.linear1.bias-torch.Size([2048])
geneartor.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
geneartor.decoder.layers.1.linear2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm1.weight-torch.Size([768])
geneartor.decoder.layers.1.norm1.bias-torch.Size([768])
geneartor.decoder.layers.1.norm2.weight-torch.Size([768])
geneartor.decoder.layers.1.norm2.bias-torch.Size([768])
geneartor.decoder.layers.1.norm3.weight-torch.Size([768])
geneartor.decoder.layers.1.norm3.bias-torch.Size([768])
geneartor.fc.weight-torch.Size([29, 768])
geneartor.fc.bias-torch.Size([29])
discriminator.decoder_layers.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder_layers.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder_layers.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder_layers.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder_layers.linear1.weight-torch.Size([2048, 768])
discriminator.decoder_layers.linear1.bias-torch.Size([2048])
discriminator.decoder_layers.linear2.weight-torch.Size([768, 2048])
discriminator.decoder_layers.linear2.bias-torch.Size([768])
discriminator.decoder_layers.norm1.weight-torch.Size([768])
discriminator.decoder_layers.norm1.bias-torch.Size([768])
discriminator.decoder_layers.norm2.weight-torch.Size([768])
discriminator.decoder_layers.norm2.bias-torch.Size([768])
discriminator.decoder_layers.norm3.weight-torch.Size([768])
discriminator.decoder_layers.norm3.bias-torch.Size([768])
discriminator.decoder.layers.0.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.0.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.0.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.0.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.0.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.0.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.0.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.0.linear2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm1.weight-torch.Size([768])
discriminator.decoder.layers.0.norm1.bias-torch.Size([768])
discriminator.decoder.layers.0.norm2.weight-torch.Size([768])
discriminator.decoder.layers.0.norm2.bias-torch.Size([768])
discriminator.decoder.layers.0.norm3.weight-torch.Size([768])
discriminator.decoder.layers.0.norm3.bias-torch.Size([768])
discriminator.decoder.layers.1.self_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.self_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.self_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.self_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.multihead_attn.in_proj_weight-torch.Size([2304, 768])
discriminator.decoder.layers.1.multihead_attn.in_proj_bias-torch.Size([2304])
discriminator.decoder.layers.1.multihead_attn.out_proj.weight-torch.Size([768, 768])
discriminator.decoder.layers.1.multihead_attn.out_proj.bias-torch.Size([768])
discriminator.decoder.layers.1.linear1.weight-torch.Size([2048, 768])
discriminator.decoder.layers.1.linear1.bias-torch.Size([2048])
discriminator.decoder.layers.1.linear2.weight-torch.Size([768, 2048])
discriminator.decoder.layers.1.linear2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm1.weight-torch.Size([768])
discriminator.decoder.layers.1.norm1.bias-torch.Size([768])
discriminator.decoder.layers.1.norm2.weight-torch.Size([768])
discriminator.decoder.layers.1.norm2.bias-torch.Size([768])
discriminator.decoder.layers.1.norm3.weight-torch.Size([768])
discriminator.decoder.layers.1.norm3.bias-torch.Size([768])
discriminator.fc.weight-torch.Size([2, 768])
discriminator.fc.bias-torch.Size([2])
get_goal1.weight-torch.Size([2048, 1536])
get_goal1.bias-torch.Size([2048])
get_goal2.weight-torch.Size([2048, 1536])
get_goal2.bias-torch.Size([2048])
get_goal3.weight-torch.Size([768, 2048])
get_goal3.bias-torch.Size([768])
get_goal4.weight-torch.Size([768, 2048])
get_goal4.bias-torch.Size([768])

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss_g:54.09346628189087	loss_d:16.735549926757812
train_code_acc:[0.04803774394166845, 0.09993566373579241, 0.14840231610551147]
train_judgement_acc:[0.46150546858245767, 0.45378511687754663, 0.451211666309243]


test_answer_acc:0.053117782909930716	iter_cnt_mean:2.979214780600462
test_code_acc:[0.07874682472480948, 0.08806096528365792, 0.08890770533446232]
test_judgement_acc:[0.48602878916172737, 0.497883149872989, 0.497883149872989]


epoch:1,	loss_g:51.86755323410034	loss_d:13.418800711631775
train_code_acc:[0.09435985417113446, 0.17756808921295303, 0.24340553291872186]
train_judgement_acc:[0.6740295946815354, 0.6384301951533348, 0.608406605189792]


test_answer_acc:0.24018475750577367	iter_cnt_mean:2.5542725173210163
test_code_acc:[0.32091447925486877, 0.3259949195596952, 0.3259949195596952]
test_judgement_acc:[0.6790855207451313, 0.6740050804403048, 0.6740050804403048]


epoch:2,	loss_g:48.3545241355896	loss_d:15.371893405914307
train_code_acc:[0.23589963542783615, 0.3660733433411967, 0.45099721209521765]
train_judgement_acc:[0.748016298520266, 0.6219172206733863, 0.5449281578383015]


test_answer_acc:0.26096997690531176	iter_cnt_mean:2.5057736720554273
test_code_acc:[0.33954276037256564, 0.33954276037256564, 0.33954276037256564]
test_judgement_acc:[0.6604572396274344, 0.6604572396274344, 0.6604572396274344]


epoch:3,	loss_g:44.95578384399414	loss_d:16.275590896606445
train_code_acc:[0.32296804632211024, 0.45807420115805275, 0.5247694617199228]
train_judgement_acc:[0.6467939095003217, 0.5367788977053399, 0.49110015011794983]


test_answer_acc:0.29330254041570436	iter_cnt_mean:2.556581986143187
test_code_acc:[0.34801016088060965, 0.4022015241320914, 0.40304826418289585]
test_judgement_acc:[0.5258255715495342, 0.5410668924640135, 0.5436071126164268]


epoch:4,	loss_g:40.68191623687744	loss_d:15.068938255310059
train_code_acc:[0.29830581170920006, 0.4565730216598756, 0.5352777182071627]
train_judgement_acc:[0.5541496890413896, 0.5436414325541497, 0.5490027879047823]


test_answer_acc:0.26096997690531176	iter_cnt_mean:2.508083140877598
test_code_acc:[0.35139712108382726, 0.3573243014394581, 0.3573243014394581]
test_judgement_acc:[0.3556308213378493, 0.3615580016934801, 0.3615580016934801]


epoch:5,	loss_g:38.10535717010498	loss_d:14.3968505859375
train_code_acc:[0.2925155479305168, 0.4499249410250911, 0.5502895131889342]
train_judgement_acc:[0.6690971477589535, 0.6009007076989062, 0.5537207806133391]


test_answer_acc:0.28868360277136257	iter_cnt_mean:2.484988452655889
test_code_acc:[0.4038950042337002, 0.43099068585944117, 0.4360711261642676]
test_judgement_acc:[0.5300592718035563, 0.5198983911939035, 0.514817950889077]


epoch:6,	loss_g:37.1676344871521	loss_d:14.298255681991577
train_code_acc:[0.32339695475016084, 0.48874115376367144, 0.581814282650654]
train_judgement_acc:[0.6223461291014368, 0.581814282650654, 0.5861033669311602]


test_answer_acc:0.4018475750577367	iter_cnt_mean:2.367205542725173
test_code_acc:[0.46147332768839966, 0.5241320914479255, 0.529212531752752]
test_judgement_acc:[0.5834038950042337, 0.5817104149026249, 0.5817104149026249]


epoch:7,	loss_g:36.18583679199219	loss_d:13.79269528388977
train_code_acc:[0.3647866180570448, 0.5342054471370362, 0.6339266566588033]
train_judgement_acc:[0.6043319751233112, 0.6289942097362213, 0.6317821145185503]


test_answer_acc:0.44341801385681295	iter_cnt_mean:2.323325635103926
test_code_acc:[0.4724809483488569, 0.5690093141405589, 0.5800169348010161]
test_judgement_acc:[0.6562235393734124, 0.6655376799322608, 0.6621507197290432]


epoch:8,	loss_g:34.6774320602417	loss_d:13.516696572303772
train_code_acc:[0.41282436199871325, 0.5783830152262492, 0.6770319536778898]
train_judgement_acc:[0.5869611837872614, 0.6650225176924727, 0.6851812138108514]


test_answer_acc:0.5796766743648961	iter_cnt_mean:2.143187066974596
test_code_acc:[0.5241320914479255, 0.6655376799322608, 0.6672311600338696]
test_judgement_acc:[0.6689246401354784, 0.7138018628281118, 0.7154953429297206]


epoch:9,	loss_g:33.66427230834961	loss_d:12.674909710884094
train_code_acc:[0.46472228179283726, 0.6283508470941453, 0.7109157194938881]
train_judgement_acc:[0.6262063049538923, 0.7070555436414325, 0.7272142397598113]


test_answer_acc:0.5935334872979214	iter_cnt_mean:2.1085450346420322
test_code_acc:[0.5563082133784928, 0.68077900084674, 0.68077900084674]
test_judgement_acc:[0.6621507197290432, 0.7637595258255715, 0.7654530059271804]


epoch:10,	loss_g:31.866780281066895	loss_d:11.987331986427307
train_code_acc:[0.520694831653442, 0.6886124812352563, 0.7591679176495818]
train_judgement_acc:[0.6384301951533348, 0.7340767746086211, 0.7591679176495818]


test_answer_acc:0.7090069284064665	iter_cnt_mean:1.9745958429561201
test_code_acc:[0.5740897544453852, 0.7332768839966131, 0.7341236240474175]
test_judgement_acc:[0.676545300592718, 0.8145639288738358, 0.8137171888230313]


epoch:11,	loss_g:30.821366786956787	loss_d:11.302900671958923
train_code_acc:[0.5511473300450354, 0.7175638001286725, 0.7793266137679605]
train_judgement_acc:[0.6465794552862963, 0.7668882693544928, 0.7855457859746944]


test_answer_acc:0.7159353348729792	iter_cnt_mean:1.9653579676674364
test_code_acc:[0.5732430143945809, 0.7392040643522438, 0.7392040643522438]
test_judgement_acc:[0.6748518204911093, 0.8060965283657917, 0.8060965283657917]


epoch:12,	loss_g:29.321879386901855	loss_d:10.850111365318298
train_code_acc:[0.5672313960969333, 0.742440488955608, 0.7956251340338838]
train_judgement_acc:[0.657516620201587, 0.785331331760669, 0.8009864893845164]


test_answer_acc:0.7598152424942263	iter_cnt_mean:1.8937644341801385
test_code_acc:[0.6079593564775614, 0.7840812870448772, 0.7840812870448772]
test_judgement_acc:[0.6799322607959356, 0.834038950042337, 0.834038950042337]


epoch:13,	loss_g:28.95797348022461	loss_d:10.050118207931519
train_code_acc:[0.5974694402745014, 0.7765387089856316, 0.8183572807205661]
train_judgement_acc:[0.6800343126742441, 0.8114947458717564, 0.8286510829937809]


test_answer_acc:0.7875288683602771	iter_cnt_mean:1.863741339491917
test_code_acc:[0.6062658763759525, 0.8001693480101609, 0.8060965283657917]
test_judgement_acc:[0.6985605419136325, 0.8687552921253175, 0.859441151566469]


epoch:14,	loss_g:27.654592037200928	loss_d:9.923677206039429
train_code_acc:[0.6045464293373365, 0.7836156980484666, 0.8310100793480591]
train_judgement_acc:[0.675101865751662, 0.8226463650010722, 0.8383015226249195]


test_answer_acc:0.7736720554272517	iter_cnt_mean:1.8729792147806004
test_code_acc:[0.6079593564775614, 0.7993226079593565, 0.8001693480101609]
test_judgement_acc:[0.6867061812023709, 0.859441151566469, 0.8577476714648603]


epoch:15,	loss_g:26.727533102035522	loss_d:9.362425088882446
train_code_acc:[0.6148402316105511, 0.8031310315247695, 0.8475230538280077]
train_judgement_acc:[0.6879691185931803, 0.840017156337122, 0.8599613982414754]


test_answer_acc:0.74364896073903	iter_cnt_mean:1.879907621247113
test_code_acc:[0.6181202370872142, 0.7679932260795935, 0.768839966130398]
test_judgement_acc:[0.6892464013547841, 0.834038950042337, 0.8331922099915327]


epoch:16,	loss_g:26.164557933807373	loss_d:9.236966967582703
train_code_acc:[0.6309242976624491, 0.8224319107870469, 0.8623203945957538]
train_judgement_acc:[0.6978340124383444, 0.8468796911859318, 0.8563156766030452]


test_answer_acc:0.7621247113163973	iter_cnt_mean:1.8706697459584296
test_code_acc:[0.632514817950889, 0.7993226079593565, 0.8018628281117697]
test_judgement_acc:[0.7053344623200677, 0.8619813717188823, 0.8619813717188823]


epoch:17,	loss_g:25.02336287498474	loss_d:8.898863315582275
train_code_acc:[0.6395024662234613, 0.8299378082779326, 0.8715419257988419]
train_judgement_acc:[0.6909714775895346, 0.8550289513188934, 0.8754021016512974]


test_answer_acc:0.7875288683602771	iter_cnt_mean:1.7829099307159353
test_code_acc:[0.6494496189669772, 0.8069432684165961, 0.8120237087214225]
test_judgement_acc:[0.7265029635901779, 0.8441998306519899, 0.8416596104995766]


epoch:18,	loss_g:24.43580412864685	loss_d:8.733027219772339
train_code_acc:[0.6467939095003217, 0.8453785116877547, 0.8837658159982844]
train_judgement_acc:[0.701050825648724, 0.865966116234184, 0.8745442847951962]


test_answer_acc:0.8060046189376443	iter_cnt_mean:1.766743648960739
test_code_acc:[0.663844199830652, 0.8187976291278577, 0.821337849280271]
test_judgement_acc:[0.7434377646062659, 0.8780694326841659, 0.8806096528365792]


epoch:19,	loss_g:23.2989501953125	loss_d:8.798038244247437
train_code_acc:[0.6472228179283723, 0.8462363285438559, 0.8833369075702338]
train_judgement_acc:[0.6965472871541926, 0.8623203945957538, 0.8826935449281579]


test_answer_acc:0.7990762124711316	iter_cnt_mean:1.8406466512702078
test_code_acc:[0.6359017781541066, 0.8094834885690093, 0.8120237087214225]
test_judgement_acc:[0.724809483488569, 0.8738357324301439, 0.8772226926333616]


epoch:20,	loss_g:22.98113465309143	loss_d:8.204785823822021
train_code_acc:[0.6594467081278147, 0.8565301308170705, 0.8942740724855244]
train_judgement_acc:[0.7130602616341412, 0.8816212738580314, 0.9049967831867897]


test_answer_acc:0.76905311778291	iter_cnt_mean:1.7829099307159353
test_code_acc:[0.663844199830652, 0.8027095681625741, 0.8044030482641829]
test_judgement_acc:[0.720575783234547, 0.8526672311600338, 0.8458933107535986]


epoch:21,	loss_g:22.195145845413208	loss_d:7.959286093711853
train_code_acc:[0.6658803345485739, 0.8668239330902853, 0.9039245121166631]
train_judgement_acc:[0.7269997855457859, 0.8859103581385375, 0.9004932446922582]


test_answer_acc:0.7967667436489607	iter_cnt_mean:1.766743648960739
test_code_acc:[0.6604572396274344, 0.8111769686706182, 0.8154106689246401]
test_judgement_acc:[0.7408975444538527, 0.869602032176122, 0.8738357324301439]


epoch:22,	loss_g:21.213953971862793	loss_d:8.015466094017029
train_code_acc:[0.6791764958181429, 0.8672528415183358, 0.9086425048252198]
train_judgement_acc:[0.72635642290371, 0.8788333690757023, 0.902423332618486]


test_answer_acc:0.8198614318706697	iter_cnt_mean:1.745958429561201
test_code_acc:[0.6629974597798476, 0.8306519898391194, 0.8323454699407282]
test_judgement_acc:[0.7468247248094835, 0.8619813717188823, 0.8628281117696867]


epoch:23,	loss_g:20.833019733428955	loss_d:7.751740515232086
train_code_acc:[0.6823933090285225, 0.8781900064336264, 0.9133604975337766]
train_judgement_acc:[0.7209950675530774, 0.8852669954964615, 0.9105725927514475]


test_answer_acc:0.7829099307159353	iter_cnt_mean:1.7644341801385681
test_code_acc:[0.668077900084674, 0.8154106689246401, 0.8162574089754445]
test_judgement_acc:[0.7214225232853514, 0.8509737510584251, 0.8433530906011855]


epoch:24,	loss_g:19.617212533950806	loss_d:7.359247863292694
train_code_acc:[0.6817499463864465, 0.8852669954964615, 0.9225820287368647]
train_judgement_acc:[0.7190649796268497, 0.9007076989062835, 0.920008578168561]


test_answer_acc:0.8429561200923787	iter_cnt_mean:1.7136258660508084
test_code_acc:[0.6697713801862828, 0.8416596104995766, 0.8450465707027942]
test_judgement_acc:[0.720575783234547, 0.8856900931414056, 0.8729889923793396]


epoch:25,	loss_g:19.299333095550537	loss_d:7.304553747177124
train_code_acc:[0.6965472871541926, 0.886339266566588, 0.9232253913789406]
train_judgement_acc:[0.7325755951104439, 0.896847523053828, 0.9232253913789406]


test_answer_acc:0.8221709006928406	iter_cnt_mean:1.748267898383372
test_code_acc:[0.6697713801862828, 0.8238780694326842, 0.8298052497883149]
test_judgement_acc:[0.745977984758679, 0.8738357324301439, 0.8780694326841659]


epoch:26,	loss_g:18.35296893119812	loss_d:7.064692199230194
train_code_acc:[0.7072699978554579, 0.8953463435556509, 0.935449281578383]
train_judgement_acc:[0.7392236757452284, 0.9049967831867897, 0.9279433840874973]


test_answer_acc:0.8545034642032333	iter_cnt_mean:1.6812933025404158
test_code_acc:[0.6782387806943269, 0.8314987298899238, 0.838272650296359]
test_judgement_acc:[0.7138018628281118, 0.8721422523285352, 0.8636748518204911]


epoch:27,	loss_g:18.557482481002808	loss_d:6.867166340351105
train_code_acc:[0.705983272571306, 0.9009221531203088, 0.9369504610765601]
train_judgement_acc:[0.7366502251769247, 0.9092858674672958, 0.9273000214454215]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.6882217090069285
test_code_acc:[0.6714648602878917, 0.8450465707027942, 0.8543607112616427]
test_judgement_acc:[0.7104149026248942, 0.8789161727349704, 0.8780694326841659]


epoch:28,	loss_g:18.126241445541382	loss_d:7.025070071220398
train_code_acc:[0.6999785545785975, 0.897490885695904, 0.9330902852241046]
train_judgement_acc:[0.72635642290371, 0.8992065194081064, 0.9285867467295732]


test_answer_acc:0.8637413394919169	iter_cnt_mean:1.71824480369515
test_code_acc:[0.6655376799322608, 0.8408128704487722, 0.8475867908552075]
test_judgement_acc:[0.7451312447078747, 0.8755292125317528, 0.88653683319221]


epoch:29,	loss_g:17.535406827926636	loss_d:6.52910989522934
train_code_acc:[0.708771177353635, 0.9133604975337766, 0.9483165344199014]
train_judgement_acc:[0.7332189577525199, 0.9202230323825863, 0.9418829079991422]


test_answer_acc:0.8521939953810623	iter_cnt_mean:1.699769053117783
test_code_acc:[0.676545300592718, 0.8450465707027942, 0.8492802709568162]
test_judgement_acc:[0.7214225232853514, 0.8839966130397968, 0.8848433530906011]


epoch:30,	loss_g:17.153348207473755	loss_d:6.579080104827881
train_code_acc:[0.7167059832725713, 0.9114304096075488, 0.9487454428479519]
train_judgement_acc:[0.7383658588891272, 0.9152905854600043, 0.9442419043534206]


test_answer_acc:0.859122401847575	iter_cnt_mean:1.6374133949191685
test_code_acc:[0.6994072819644369, 0.8374259102455546, 0.8458933107535986]
test_judgement_acc:[0.7764606265876376, 0.8890770533446232, 0.8941574936494496]


epoch:31,	loss_g:16.748453855514526	loss_d:6.480879724025726
train_code_acc:[0.7160626206304954, 0.9163628565301308, 0.9493888054900279]
train_judgement_acc:[0.7381514046751019, 0.920651940810637, 0.9395239116448638]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.6351039260969977
test_code_acc:[0.6917866215071973, 0.8611346316680779, 0.8619813717188823]
test_judgement_acc:[0.7383573243014394, 0.8899237933954276, 0.8746824724809483]


epoch:32,	loss_g:15.852792739868164	loss_d:6.099820613861084
train_code_acc:[0.7276431481878619, 0.922153120308814, 0.9553935234827364]
train_judgement_acc:[0.7465151190220888, 0.9255843877332189, 0.9556079776967618]


test_answer_acc:0.8568129330254042	iter_cnt_mean:1.6766743648960738
test_code_acc:[0.6850127011007621, 0.8416596104995766, 0.8475867908552075]
test_judgement_acc:[0.7569856054191363, 0.8721422523285352, 0.8839966130397968]


epoch:33,	loss_g:15.853934049606323	loss_d:6.26701807975769
train_code_acc:[0.7338623203945958, 0.9178640360283079, 0.9543212524126099]
train_judgement_acc:[0.7538065622989492, 0.920651940810637, 0.9425262706412181]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.6789838337182448
test_code_acc:[0.6799322607959356, 0.8679085520745131, 0.869602032176122]
test_judgement_acc:[0.7485182049110923, 0.8831498729889924, 0.8916172734970365]


epoch:34,	loss_g:15.376885294914246	loss_d:6.011554539203644
train_code_acc:[0.7252841518335835, 0.9307312888698263, 0.9633283294016728]
train_judgement_acc:[0.7535921080849238, 0.929873472013725, 0.9517478018443063]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.584295612009238
test_code_acc:[0.7197290431837426, 0.8577476714648603, 0.8619813717188823]
test_judgement_acc:[0.7620660457239627, 0.8704487722269263, 0.8797629127857748]


epoch:35,	loss_g:15.457756757736206	loss_d:5.711815297603607
train_code_acc:[0.741797126313532, 0.930516834655801, 0.9620416041175209]
train_judgement_acc:[0.7619558224319107, 0.9309457430838516, 0.9592536993351919]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.6166281755196306
test_code_acc:[0.7070279424216765, 0.8645215918712955, 0.8721422523285352]
test_judgement_acc:[0.7637595258255715, 0.8899237933954276, 0.8890770533446232]


epoch:36,	loss_g:15.108476638793945	loss_d:5.763082563877106
train_code_acc:[0.7420115805275573, 0.9328758310100793, 0.9665451426120524]
train_judgement_acc:[0.7591679176495818, 0.9303023804417757, 0.9566802487668883]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.6073903002309469
test_code_acc:[0.7011007620660458, 0.8636748518204911, 0.8679085520745131]
test_judgement_acc:[0.7637595258255715, 0.903471634208298, 0.9000846740050804]


epoch:37,	loss_g:14.835168838500977	loss_d:5.565700054168701
train_code_acc:[0.75788119236543, 0.9315891057259276, 0.9644006004717993]
train_judgement_acc:[0.7799699764100364, 0.9320180141539781, 0.9551790692687111]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.6073903002309469
test_code_acc:[0.7027942421676545, 0.8611346316680779, 0.8662150719729044]
test_judgement_acc:[0.7603725656223539, 0.8899237933954276, 0.8924640135478408]


epoch:38,	loss_g:14.55578327178955	loss_d:5.568056344985962
train_code_acc:[0.7463006648080635, 0.9390950032168132, 0.9665451426120524]
train_judgement_acc:[0.7630280935020373, 0.9365215526485096, 0.9590392451211667]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.5889145496535797
test_code_acc:[0.7163420829805249, 0.8518204911092294, 0.859441151566469]
test_judgement_acc:[0.7696867061812024, 0.8958509737510584, 0.890770533446232]


epoch:39,	loss_g:14.729599952697754	loss_d:5.507736146450043
train_code_acc:[0.760669097147759, 0.9350203731503324, 0.9671885052541283]
train_judgement_acc:[0.7814711559082136, 0.938237186360712, 0.9648295088998499]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.5889145496535797
test_code_acc:[0.7214225232853514, 0.8611346316680779, 0.8670618120237087]
test_judgement_acc:[0.768839966130398, 0.88653683319221, 0.8882303132938189]


epoch:40,	loss_g:13.9019855260849	loss_d:5.695146322250366
train_code_acc:[0.7525198370147973, 0.9384516405747373, 0.969118593180356]
train_judgement_acc:[0.7720351704911002, 0.935449281578383, 0.9611837872614197]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5750577367205543
test_code_acc:[0.720575783234547, 0.8628281117696867, 0.8670618120237087]
test_judgement_acc:[0.7747671464860287, 0.903471634208298, 0.9017781541066893]


epoch:41,	loss_g:13.567736506462097	loss_d:5.256078362464905
train_code_acc:[0.7610980055758095, 0.9440274501393953, 0.9699764100364572]
train_judgement_acc:[0.7791121595539352, 0.9401672742869397, 0.9628994209736221]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.556581986143187
test_code_acc:[0.7281964436917866, 0.8636748518204911, 0.8679085520745131]
test_judgement_acc:[0.7679932260795935, 0.882303132938188, 0.8848433530906011]


epoch:42,	loss_g:13.66901683807373	loss_d:5.168355107307434
train_code_acc:[0.778254342697834, 0.9453141754235471, 0.9731932232468368]
train_judgement_acc:[0.7904782328972765, 0.9463864464936736, 0.9678318678962041]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5612009237875288
test_code_acc:[0.7239627434377646, 0.8619813717188823, 0.8679085520745131]
test_judgement_acc:[0.7671464860287892, 0.890770533446232, 0.8933107535986452]


epoch:43,	loss_g:13.10148799419403	loss_d:5.444677233695984
train_code_acc:[0.7553077417971263, 0.9435985417113446, 0.974694402745014]
train_judgement_acc:[0.7701050825648724, 0.9431696332832941, 0.9674029594681536]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.5866050808314087
test_code_acc:[0.7214225232853514, 0.8645215918712955, 0.8704487722269263]
test_judgement_acc:[0.777307366638442, 0.8966977138018628, 0.8933107535986452]


epoch:44,	loss_g:13.327823400497437	loss_d:5.014250814914703
train_code_acc:[0.7666738151404675, 0.9493888054900279, 0.9759811280291658]
train_judgement_acc:[0.7849024233326185, 0.9485309886339267, 0.9665451426120524]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5242494226327945
test_code_acc:[0.7417442845046571, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7620660457239627, 0.882303132938188, 0.88653683319221]


epoch:45,	loss_g:12.71802306175232	loss_d:5.227149844169617
train_code_acc:[0.7767531631996569, 0.9493888054900279, 0.9764100364572164]
train_judgement_acc:[0.7874758739009221, 0.9500321681321038, 0.9701908642504825]


test_answer_acc:0.9030023094688222	iter_cnt_mean:1.5496535796766744
test_code_acc:[0.7239627434377646, 0.8721422523285352, 0.8755292125317528]
test_judgement_acc:[0.7679932260795935, 0.8848433530906011, 0.8873835732430144]


epoch:46,	loss_g:13.052856683731079	loss_d:5.163172602653503
train_code_acc:[0.7651726356422903, 0.9504610765601544, 0.9751233111730645]
train_judgement_acc:[0.7765387089856316, 0.9502466223461291, 0.9665451426120524]


test_answer_acc:0.9030023094688222	iter_cnt_mean:1.5473441108545034
test_code_acc:[0.7273497036409822, 0.8738357324301439, 0.8772226926333616]
test_judgement_acc:[0.7874682472480948, 0.9051651143099069, 0.9085520745131245]


epoch:47,	loss_g:12.583457231521606	loss_d:4.974725902080536
train_code_acc:[0.7784687969118593, 0.9519622560583315, 0.9798413038816213]
train_judgement_acc:[0.7906926871113017, 0.9517478018443063, 0.9725498606047609]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.53810623556582
test_code_acc:[0.7375105842506351, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.7646062658763759, 0.8899237933954276, 0.8873835732430144]


epoch:48,	loss_g:12.240620017051697	loss_d:4.924866139888763
train_code_acc:[0.778254342697834, 0.9545357066266352, 0.9798413038816213]
train_judgement_acc:[0.7866180570448209, 0.953034527128458, 0.9753377653870898]


test_answer_acc:0.9030023094688222	iter_cnt_mean:1.5404157043879907
test_code_acc:[0.7332768839966131, 0.8772226926333616, 0.8806096528365792]
test_judgement_acc:[0.781541066892464, 0.8958509737510584, 0.8975444538526672]


epoch:49,	loss_g:12.642580270767212	loss_d:4.534386456012726
train_code_acc:[0.7864036028307956, 0.9553935234827364, 0.9774823075273429]
train_judgement_acc:[0.804203302594896, 0.953677889770534, 0.9729787690328114]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5242494226327945
test_code_acc:[0.7392040643522438, 0.8636748518204911, 0.8670618120237087]
test_judgement_acc:[0.7917019475021169, 0.8890770533446232, 0.8983911939034717]


epoch:50,	loss_g:11.796358942985535	loss_d:4.602977931499481
train_code_acc:[0.7934805918936307, 0.9583958824790907, 0.9828436628779755]
train_judgement_acc:[0.8018443062406176, 0.9558224319107871, 0.9781256701694189]


test_answer_acc:0.9030023094688222	iter_cnt_mean:1.510392609699769
test_code_acc:[0.745977984758679, 0.8789161727349704, 0.8831498729889924]
test_judgement_acc:[0.781541066892464, 0.8916172734970365, 0.8924640135478408]


epoch:51,	loss_g:12.340591669082642	loss_d:4.590210258960724
train_code_acc:[0.790907141325327, 0.9566802487668883, 0.9813424833797985]
train_judgement_acc:[0.8027021230967188, 0.9523911644863822, 0.9798413038816213]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5496535796766744
test_code_acc:[0.7341236240474175, 0.8628281117696867, 0.8645215918712955]
test_judgement_acc:[0.7832345469940728, 0.8882303132938189, 0.8797629127857748]


epoch:52,	loss_g:12.062565803527832	loss_d:4.7558382749557495
train_code_acc:[0.7911215955393524, 0.9538923439845592, 0.9785545785974694]
train_judgement_acc:[0.801415397812567, 0.9547501608406606, 0.9738365858889128]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.5265588914549653
test_code_acc:[0.7392040643522438, 0.8585944115156647, 0.8619813717188823]
test_judgement_acc:[0.790008467400508, 0.8966977138018628, 0.8983911939034717]


epoch:53,	loss_g:11.766467452049255	loss_d:4.558099985122681
train_code_acc:[0.7896204160411752, 0.9622560583315463, 0.9819858460218743]
train_judgement_acc:[0.8037743941668454, 0.9568947029809136, 0.9736221316748874]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5519630484988454
test_code_acc:[0.7332768839966131, 0.8704487722269263, 0.8755292125317528]
test_judgement_acc:[0.7798475867908552, 0.8839966130397968, 0.8839966130397968]


epoch:54,	loss_g:11.538969874382019	loss_d:4.706374168395996
train_code_acc:[0.7864036028307956, 0.9609693330473944, 0.9826292086639502]
train_judgement_acc:[0.8007720351704911, 0.9583958824790907, 0.9766244906712417]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.5196304849884525
test_code_acc:[0.7510584250635055, 0.8653683319220999, 0.869602032176122]
test_judgement_acc:[0.781541066892464, 0.8814563928873835, 0.8839966130397968]


epoch:55,	loss_g:10.324697732925415	loss_d:4.2897117137908936
train_code_acc:[0.7958395882479091, 0.9648295088998499, 0.9882050182286082]
train_judgement_acc:[0.8072056615912503, 0.964186146257774, 0.9832725713060262]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5473441108545034
test_code_acc:[0.7324301439458086, 0.8679085520745131, 0.8721422523285352]
test_judgement_acc:[0.7747671464860287, 0.8848433530906011, 0.8890770533446232]


epoch:56,	loss_g:11.264827370643616	loss_d:4.22208434343338
train_code_acc:[0.8050611194509972, 0.9684752305382801, 0.9875616555865323]
train_judgement_acc:[0.8157838301522625, 0.9667595968260776, 0.9839159339481021]


test_answer_acc:0.9006928406466512	iter_cnt_mean:1.5057736720554273
test_code_acc:[0.7485182049110923, 0.8780694326841659, 0.8814563928873835]
test_judgement_acc:[0.7823878069432684, 0.8924640135478408, 0.8958509737510584]


epoch:57,	loss_g:11.078458786010742	loss_d:4.27406769990921
train_code_acc:[0.7992708556723139, 0.9583958824790907, 0.9837014797340767]
train_judgement_acc:[0.8157838301522625, 0.9588247909071413, 0.9826292086639502]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7442845046570703, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7790008467400508, 0.8848433530906011, 0.8890770533446232]


epoch:58,	loss_g:11.648255109786987	loss_d:4.217871934175491
train_code_acc:[0.8089212953034527, 0.9637572378297233, 0.9834870255200515]
train_judgement_acc:[0.8166416470083637, 0.9618271499034956, 0.979626849667596]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.5011547344110854
test_code_acc:[0.7578323454699407, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7849280270956817, 0.8831498729889924, 0.88653683319221]


epoch:59,	loss_g:11.047682881355286	loss_d:4.076765179634094
train_code_acc:[0.8022732146686682, 0.9682607763242548, 0.9858460218743298]
train_judgement_acc:[0.8166416470083637, 0.9701908642504825, 0.9828436628779755]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5150115473441108
test_code_acc:[0.7485182049110923, 0.8746824724809483, 0.8772226926333616]
test_judgement_acc:[0.7874682472480948, 0.8933107535986452, 0.8958509737510584]


epoch:60,	loss_g:11.03858482837677	loss_d:4.040937423706055
train_code_acc:[0.8112802916577311, 0.9665451426120524, 0.9864893845164058]
train_judgement_acc:[0.8228608192150976, 0.9656873257559511, 0.9809135749517478]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5265588914549653
test_code_acc:[0.7442845046570703, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7832345469940728, 0.8831498729889924, 0.8873835732430144]


epoch:61,	loss_g:9.703933238983154	loss_d:4.13849413394928
train_code_acc:[0.8112802916577311, 0.9609693330473944, 0.9884194724426335]
train_judgement_acc:[0.8228608192150976, 0.9601115161912932, 0.9862749303023804]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.5057736720554273
test_code_acc:[0.7544453852667231, 0.8662150719729044, 0.8687552921253175]
test_judgement_acc:[0.781541066892464, 0.8746824724809483, 0.8772226926333616]


epoch:62,	loss_g:10.99076771736145	loss_d:4.197547137737274
train_code_acc:[0.811923654299807, 0.9659017799699764, 0.984559296590178]
train_judgement_acc:[0.8162127385803131, 0.9652584173279005, 0.9822003002358997]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5173210161662818
test_code_acc:[0.7502116850127011, 0.8687552921253175, 0.8729889923793396]
test_judgement_acc:[0.7823878069432684, 0.8763759525825572, 0.8806096528365792]


epoch:63,	loss_g:10.288203477859497	loss_d:3.9568371176719666
train_code_acc:[0.8044177568089212, 0.9682607763242548, 0.9884194724426335]
train_judgement_acc:[0.8177139180784903, 0.9650439631138752, 0.9849882050182286]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.5242494226327945
test_code_acc:[0.7417442845046571, 0.8636748518204911, 0.8679085520745131]
test_judgement_acc:[0.7747671464860287, 0.8780694326841659, 0.882303132938188]


epoch:64,	loss_g:10.262629747390747	loss_d:3.908725470304489
train_code_acc:[0.8149260132961613, 0.9721209521767102, 0.9903495603688612]
train_judgement_acc:[0.825219815569376, 0.9701908642504825, 0.9884194724426335]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7519051651143099, 0.8679085520745131, 0.8729889923793396]
test_judgement_acc:[0.7823878069432684, 0.882303132938188, 0.8873835732430144]


epoch:65,	loss_g:9.778183400630951	loss_d:3.916138708591461
train_code_acc:[0.8149260132961613, 0.9693330473943813, 0.9882050182286082]
train_judgement_acc:[0.8224319107870469, 0.9680463221102295, 0.9858460218743298]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5196304849884525
test_code_acc:[0.7493649449618967, 0.8712955122777307, 0.8755292125317528]
test_judgement_acc:[0.7840812870448772, 0.8814563928873835, 0.8856900931414056]


epoch:66,	loss_g:10.654359579086304	loss_d:3.8284881114959717
train_code_acc:[0.8207162770748445, 0.9667595968260776, 0.9860604760883551]
train_judgement_acc:[0.8290799914218314, 0.9637572378297233, 0.9830581170920009]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7578323454699407, 0.8772226926333616, 0.8831498729889924]
test_judgement_acc:[0.7823878069432684, 0.8831498729889924, 0.8890770533446232]


epoch:67,	loss_g:10.56287395954132	loss_d:3.734406918287277
train_code_acc:[0.8241475444992494, 0.9661162341840017, 0.9854171134462792]
train_judgement_acc:[0.8346558009864894, 0.9652584173279005, 0.982414754449925]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7612193056731583, 0.8763759525825572, 0.882303132938188]
test_judgement_acc:[0.7781541066892464, 0.8797629127857748, 0.8848433530906011]


epoch:68,	loss_g:9.13427609205246	loss_d:3.822090059518814
train_code_acc:[0.8295088998498821, 0.9708342268925585, 0.9905640145828866]
train_judgement_acc:[0.8327257130602617, 0.9676174136821789, 0.9869182929444563]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7578323454699407, 0.8721422523285352, 0.8789161727349704]
test_judgement_acc:[0.7823878069432684, 0.882303132938188, 0.8873835732430144]


epoch:69,	loss_g:10.97870659828186	loss_d:3.6506557762622833
train_code_acc:[0.8310100793480591, 0.969761955822432, 0.9858460218743298]
train_judgement_acc:[0.8395882479090714, 0.9699764100364572, 0.9854171134462792]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7485182049110923, 0.8729889923793396, 0.8755292125317528]
test_judgement_acc:[0.7883149872988993, 0.8899237933954276, 0.8924640135478408]


epoch:70,	loss_g:10.081946790218353	loss_d:3.6714022159576416
train_code_acc:[0.8241475444992494, 0.9719064979626849, 0.9879905640145829]
train_judgement_acc:[0.8310100793480591, 0.9714775895346344, 0.9849882050182286]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7552921253175275, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.7917019475021169, 0.8780694326841659, 0.8797629127857748]


epoch:71,	loss_g:10.069298267364502	loss_d:3.666435956954956
train_code_acc:[0.8290799914218314, 0.9676174136821789, 0.9877761098005576]
train_judgement_acc:[0.837229251554793, 0.9693330473943813, 0.9860604760883551]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7603725656223539, 0.8738357324301439, 0.8780694326841659]
test_judgement_acc:[0.7891617273497037, 0.8780694326841659, 0.882303132938188]


epoch:72,	loss_g:9.451534688472748	loss_d:3.843530833721161
train_code_acc:[0.8256487239974265, 0.9680463221102295, 0.9888483808706842]
train_judgement_acc:[0.83508470941454, 0.9654728715419258, 0.9849882050182286]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7578323454699407, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7840812870448772, 0.8839966130397968, 0.8873835732430144]


epoch:73,	loss_g:8.973475575447083	loss_d:3.7883989810943604
train_code_acc:[0.8202873686467939, 0.9710486811065837, 0.9897061977267854]
train_judgement_acc:[0.8277932661376796, 0.9706197726785332, 0.9856315676603046]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7519051651143099, 0.8729889923793396, 0.8789161727349704]
test_judgement_acc:[0.7866215071972904, 0.8924640135478408, 0.8966977138018628]


epoch:74,	loss_g:9.669487357139587	loss_d:3.729050099849701
train_code_acc:[0.825219815569376, 0.9676174136821789, 0.9867038387304311]
train_judgement_acc:[0.8337979841303882, 0.966330688398027, 0.9849882050182286]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7629127857747672, 0.8721422523285352, 0.8780694326841659]
test_judgement_acc:[0.7950889077053345, 0.8814563928873835, 0.8873835732430144]


epoch:75,	loss_g:10.01649284362793	loss_d:3.5433758199214935
train_code_acc:[0.8348702552005147, 0.9716920437486597, 0.9892772892987347]
train_judgement_acc:[0.8398027021230967, 0.9719064979626849, 0.9864893845164058]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7620660457239627, 0.8746824724809483, 0.8806096528365792]
test_judgement_acc:[0.8001693480101609, 0.8839966130397968, 0.890770533446232]


epoch:76,	loss_g:9.456624865531921	loss_d:3.610791176557541
train_code_acc:[0.8344413467724641, 0.9674029594681536, 0.987347201372507]
train_judgement_acc:[0.8385159768389449, 0.9667595968260776, 0.9852026592322539]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4965357967667436
test_code_acc:[0.7552921253175275, 0.8746824724809483, 0.8780694326841659]
test_judgement_acc:[0.7874682472480948, 0.8899237933954276, 0.8933107535986452]


epoch:77,	loss_g:9.158859133720398	loss_d:3.4761248528957367
train_code_acc:[0.8327257130602617, 0.9714775895346344, 0.9892772892987347]
train_judgement_acc:[0.8447351490456787, 0.9706197726785332, 0.9862749303023804]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4942263279445727
test_code_acc:[0.7595258255715496, 0.8704487722269263, 0.8746824724809483]
test_judgement_acc:[0.7959356477561389, 0.8848433530906011, 0.8890770533446232]


epoch:78,	loss_g:9.391880512237549	loss_d:3.600645065307617
train_code_acc:[0.8346558009864894, 0.9706197726785332, 0.98949174351276]
train_judgement_acc:[0.8415183358352991, 0.9693330473943813, 0.9862749303023804]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.7654530059271804, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.785774767146486, 0.8806096528365792, 0.8873835732430144]


epoch:79,	loss_g:8.910828053951263	loss_d:3.585334539413452
train_code_acc:[0.8333690757023375, 0.971263135320609, 0.9897061977267854]
train_judgement_acc:[0.8410894274072486, 0.9710486811065837, 0.9882050182286082]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7646062658763759, 0.8763759525825572, 0.8814563928873835]
test_judgement_acc:[0.7967823878069432, 0.8890770533446232, 0.8941574936494496]


epoch:80,	loss_g:9.000062584877014	loss_d:3.37417334318161
train_code_acc:[0.8385159768389449, 0.9710486811065837, 0.9892772892987347]
train_judgement_acc:[0.8485953248981343, 0.9693330473943813, 0.9871327471584816]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7662997459779848, 0.8797629127857748, 0.8848433530906011]
test_judgement_acc:[0.7933954276037256, 0.890770533446232, 0.8958509737510584]


epoch:81,	loss_g:8.765013337135315	loss_d:3.3624464571475983
train_code_acc:[0.8387304310529702, 0.9755522196011152, 0.992279648295089]
train_judgement_acc:[0.8500965043963113, 0.9753377653870898, 0.9892772892987347]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7705334462320068, 0.8806096528365792, 0.8848433530906011]
test_judgement_acc:[0.7883149872988993, 0.8848433530906011, 0.8899237933954276]


epoch:82,	loss_g:9.17664361000061	loss_d:3.5789264142513275
train_code_acc:[0.8335835299163629, 0.9682607763242548, 0.9888483808706842]
train_judgement_acc:[0.8438773321895775, 0.9674029594681536, 0.9871327471584816]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4849884526558892
test_code_acc:[0.7629127857747672, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.7917019475021169, 0.8814563928873835, 0.8856900931414056]


epoch:83,	loss_g:8.70486569404602	loss_d:3.3458797931671143
train_code_acc:[0.8357280720566159, 0.9716920437486597, 0.9897061977267854]
train_judgement_acc:[0.8460218743298306, 0.9708342268925585, 0.9879905640145829]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7654530059271804, 0.8814563928873835, 0.8856900931414056]
test_judgement_acc:[0.7950889077053345, 0.8873835732430144, 0.8899237933954276]


epoch:84,	loss_g:8.93240749835968	loss_d:3.4448162317276
train_code_acc:[0.8292944456358567, 0.9734076774608621, 0.9909929230109371]
train_judgement_acc:[0.8436628779755522, 0.9721209521767102, 0.9882050182286082]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.4526558891454966
test_code_acc:[0.7739204064352244, 0.8831498729889924, 0.8856900931414056]
test_judgement_acc:[0.7933954276037256, 0.88653683319221, 0.8873835732430144]


epoch:85,	loss_g:8.571038603782654	loss_d:3.4250441789627075
train_code_acc:[0.832940167274287, 0.9706197726785332, 0.9905640145828866]
train_judgement_acc:[0.8421616984773751, 0.9704053184645078, 0.9892772892987347]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.466512702078522
test_code_acc:[0.7705334462320068, 0.8789161727349704, 0.8831498729889924]
test_judgement_acc:[0.7959356477561389, 0.8882303132938189, 0.8916172734970365]


epoch:86,	loss_g:8.701910018920898	loss_d:3.350790023803711
train_code_acc:[0.8402316105511474, 0.9738365858889128, 0.9914218314389878]
train_judgement_acc:[0.8492386875402101, 0.9738365858889128, 0.9892772892987347]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7637595258255715, 0.8738357324301439, 0.8772226926333616]
test_judgement_acc:[0.7933954276037256, 0.8797629127857748, 0.8839966130397968]


epoch:87,	loss_g:8.689478635787964	loss_d:3.3938114047050476
train_code_acc:[0.8376581599828437, 0.9721209521767102, 0.9892772892987347]
train_judgement_acc:[0.8488097791121596, 0.971263135320609, 0.987347201372507]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.5034642032332564
test_code_acc:[0.7620660457239627, 0.869602032176122, 0.8738357324301439]
test_judgement_acc:[0.7976291278577476, 0.8873835732430144, 0.8899237933954276]


epoch:88,	loss_g:9.019081592559814	loss_d:3.3742988407611847
train_code_acc:[0.8430195153334763, 0.9721209521767102, 0.9888483808706842]
train_judgement_acc:[0.8500965043963113, 0.9727643148187862, 0.9875616555865323]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7739204064352244, 0.8763759525825572, 0.882303132938188]
test_judgement_acc:[0.7976291278577476, 0.8933107535986452, 0.8975444538526672]


epoch:89,	loss_g:9.33717167377472	loss_d:3.2644881904125214
train_code_acc:[0.8460218743298306, 0.9753377653870898, 0.9897061977267854]
train_judgement_acc:[0.850525412824362, 0.9753377653870898, 0.9877761098005576]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7739204064352244, 0.8797629127857748, 0.8839966130397968]
test_judgement_acc:[0.7925486875529213, 0.882303132938188, 0.88653683319221]


epoch:90,	loss_g:8.229572474956512	loss_d:3.27377188205719
train_code_acc:[0.8440917864036028, 0.9755522196011152, 0.992279648295089]
train_judgement_acc:[0.8533133176066909, 0.974694402745014, 0.9905640145828866]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7662997459779848, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.7917019475021169, 0.8797629127857748, 0.8839966130397968]


epoch:91,	loss_g:8.821420907974243	loss_d:3.317947030067444
train_code_acc:[0.8402316105511474, 0.974051040102938, 0.9914218314389878]
train_judgement_acc:[0.8436628779755522, 0.9744799485309886, 0.9888483808706842]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.7629127857747672, 0.8738357324301439, 0.8780694326841659]
test_judgement_acc:[0.7908552074513124, 0.8924640135478408, 0.8924640135478408]


epoch:92,	loss_g:8.157774150371552	loss_d:3.2773323953151703
train_code_acc:[0.8402316105511474, 0.9710486811065837, 0.9916362856530131]
train_judgement_acc:[0.8526699549646151, 0.9714775895346344, 0.98949174351276]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.768839966130398, 0.8755292125317528, 0.8814563928873835]
test_judgement_acc:[0.7967823878069432, 0.8856900931414056, 0.8916172734970365]


epoch:93,	loss_g:9.281560897827148	loss_d:3.19268599152565
train_code_acc:[0.8520265923225392, 0.9744799485309886, 0.9909929230109371]
train_judgement_acc:[0.8558867681749946, 0.974051040102938, 0.9886339266566588]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7679932260795935, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.785774767146486, 0.8772226926333616, 0.882303132938188]


epoch:94,	loss_g:7.843582093715668	loss_d:3.132547050714493
train_code_acc:[0.8507398670383873, 0.9753377653870898, 0.992923010937165]
train_judgement_acc:[0.8586746729573236, 0.9751233111730645, 0.9916362856530131]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.489607390300231
test_code_acc:[0.7696867061812024, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.790008467400508, 0.8797629127857748, 0.8839966130397968]


epoch:95,	loss_g:8.394605100154877	loss_d:3.2412951290607452
train_code_acc:[0.844949603259704, 0.9736221316748874, 0.9927085567231396]
train_judgement_acc:[0.8524555007505897, 0.9723354063907356, 0.9901351061548359]


test_answer_acc:0.8775981524249422	iter_cnt_mean:1.491916859122402
test_code_acc:[0.7679932260795935, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.790008467400508, 0.882303132938188, 0.88653683319221]


epoch:96,	loss_g:8.046306550502777	loss_d:3.1998530328273773
train_code_acc:[0.8473085996139824, 0.9742654943169633, 0.992279648295089]
train_judgement_acc:[0.8546000428908428, 0.9731932232468368, 0.9907784687969119]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.48729792147806
test_code_acc:[0.7671464860287892, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.7925486875529213, 0.8848433530906011, 0.8882303132938189]


epoch:97,	loss_g:8.594018697738647	loss_d:3.2638068795204163
train_code_acc:[0.8421616984773751, 0.9701908642504825, 0.98949174351276]
train_judgement_acc:[0.8477375080420331, 0.969761955822432, 0.9886339266566588]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7696867061812024, 0.8772226926333616, 0.8814563928873835]
test_judgement_acc:[0.7883149872988993, 0.8873835732430144, 0.890770533446232]


epoch:98,	loss_g:8.624423265457153	loss_d:3.192913055419922
train_code_acc:[0.8406605189791979, 0.9738365858889128, 0.992279648295089]
train_judgement_acc:[0.8498820501822861, 0.9729787690328114, 0.9905640145828866]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.7713801862828111, 0.8780694326841659, 0.882303132938188]
test_judgement_acc:[0.7993226079593565, 0.8882303132938189, 0.8916172734970365]


epoch:99,	loss_g:7.938385546207428	loss_d:3.2688727974891663
train_code_acc:[0.8432339695475016, 0.9742654943169633, 0.992279648295089]
train_judgement_acc:[0.8498820501822861, 0.9729787690328114, 0.9899206519408107]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.466512702078522
test_code_acc:[0.7722269263336156, 0.8772226926333616, 0.8814563928873835]
test_judgement_acc:[0.7976291278577476, 0.8856900931414056, 0.8890770533446232]


epoch:100,	loss_g:8.276371002197266	loss_d:3.268936038017273
train_code_acc:[0.8445206948316535, 0.9716920437486597, 0.9907784687969119]
train_judgement_acc:[0.8494531417542355, 0.9708342268925585, 0.9882050182286082]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.464203233256351
test_code_acc:[0.77307366638442, 0.8755292125317528, 0.8806096528365792]
test_judgement_acc:[0.7976291278577476, 0.8899237933954276, 0.8941574936494496]


epoch:101,	loss_g:7.797686517238617	loss_d:3.1724328100681305
train_code_acc:[0.8470941453999571, 0.9742654943169633, 0.992923010937165]
train_judgement_acc:[0.8535277718207163, 0.974694402745014, 0.9909929230109371]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.77307366638442, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.79424216765453, 0.8856900931414056, 0.8899237933954276]


epoch:102,	loss_g:7.5568259954452515	loss_d:3.078101873397827
train_code_acc:[0.8520265923225392, 0.974051040102938, 0.992923010937165]
train_judgement_acc:[0.858245764529273, 0.9725498606047609, 0.9920651940810636]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.464203233256351
test_code_acc:[0.7756138865368332, 0.8763759525825572, 0.8814563928873835]
test_judgement_acc:[0.7959356477561389, 0.8856900931414056, 0.8899237933954276]


epoch:103,	loss_g:8.57018357515335	loss_d:3.2838855981826782
train_code_acc:[0.8423761526914004, 0.971263135320609, 0.9907784687969119]
train_judgement_acc:[0.8524555007505897, 0.9719064979626849, 0.9890628350847094]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.77307366638442, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7933954276037256, 0.882303132938188, 0.8873835732430144]


epoch:104,	loss_g:8.03188806772232	loss_d:3.1057217717170715
train_code_acc:[0.8494531417542355, 0.9759811280291658, 0.9916362856530131]
train_judgement_acc:[0.8522410465365644, 0.974694402745014, 0.9888483808706842]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7722269263336156, 0.8746824724809483, 0.8789161727349704]
test_judgement_acc:[0.7950889077053345, 0.8839966130397968, 0.8873835732430144]


epoch:105,	loss_g:8.526796579360962	loss_d:3.027109593153
train_code_acc:[0.8500965043963113, 0.9776967617413682, 0.9931374651511902]
train_judgement_acc:[0.8571734934591465, 0.9770533990992923, 0.9918507398670384]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7696867061812024, 0.8746824724809483, 0.8780694326841659]
test_judgement_acc:[0.8001693480101609, 0.8856900931414056, 0.8882303132938189]


epoch:106,	loss_g:8.163846254348755	loss_d:3.0031895339488983
train_code_acc:[0.8509543212524127, 0.9751233111730645, 0.9916362856530131]
train_judgement_acc:[0.8578168561012224, 0.974051040102938, 0.9905640145828866]


test_answer_acc:0.8799076212471132	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.7679932260795935, 0.8729889923793396, 0.8763759525825572]
test_judgement_acc:[0.7908552074513124, 0.8831498729889924, 0.8856900931414056]


epoch:107,	loss_g:9.074562728404999	loss_d:3.1115193963050842
train_code_acc:[0.8500965043963113, 0.9731932232468368, 0.9897061977267854]
train_judgement_acc:[0.8571734934591465, 0.9721209521767102, 0.9888483808706842]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7696867061812024, 0.8738357324301439, 0.8780694326841659]
test_judgement_acc:[0.7917019475021169, 0.8839966130397968, 0.8873835732430144]


epoch:108,	loss_g:8.270938396453857	loss_d:3.1220177710056305
train_code_acc:[0.8530988633926657, 0.974051040102938, 0.9901351061548359]
train_judgement_acc:[0.8569590392451212, 0.9731932232468368, 0.9892772892987347]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7705334462320068, 0.8746824724809483, 0.8789161727349704]
test_judgement_acc:[0.7967823878069432, 0.88653683319221, 0.8899237933954276]


epoch:109,	loss_g:7.814378142356873	loss_d:3.154697895050049
train_code_acc:[0.848380870684109, 0.9731932232468368, 0.9920651940810636]
train_judgement_acc:[0.8558867681749946, 0.9708342268925585, 0.9899206519408107]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.7705334462320068, 0.8729889923793396, 0.8772226926333616]
test_judgement_acc:[0.79424216765453, 0.8814563928873835, 0.88653683319221]


epoch:110,	loss_g:8.538010358810425	loss_d:3.1086984276771545
train_code_acc:[0.8481664164700836, 0.9755522196011152, 0.9909929230109371]
train_judgement_acc:[0.8526699549646151, 0.9742654943169633, 0.9901351061548359]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.7696867061812024, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7908552074513124, 0.8806096528365792, 0.88653683319221]


epoch:111,	loss_g:8.121905446052551	loss_d:3.0049255192279816
train_code_acc:[0.8556723139609693, 0.9738365858889128, 0.9920651940810636]
train_judgement_acc:[0.8606047608835513, 0.9721209521767102, 0.9907784687969119]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7705334462320068, 0.8755292125317528, 0.8806096528365792]
test_judgement_acc:[0.7950889077053345, 0.8890770533446232, 0.8941574936494496]


epoch:112,	loss_g:7.254442274570465	loss_d:3.0180277228355408
train_code_acc:[0.8475230538280077, 0.9714775895346344, 0.9935663735792408]
train_judgement_acc:[0.8569590392451212, 0.9710486811065837, 0.9916362856530131]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4688221709006928
test_code_acc:[0.7696867061812024, 0.8729889923793396, 0.8780694326841659]
test_judgement_acc:[0.7908552074513124, 0.8873835732430144, 0.8924640135478408]


epoch:113,	loss_g:8.078317880630493	loss_d:3.0638033151626587
train_code_acc:[0.8507398670383873, 0.9714775895346344, 0.9918507398670384]
train_judgement_acc:[0.8601758524555008, 0.9714775895346344, 0.9905640145828866]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4711316397228638
test_code_acc:[0.7696867061812024, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7917019475021169, 0.8873835732430144, 0.8933107535986452]


epoch:114,	loss_g:8.43841964006424	loss_d:3.168674111366272
train_code_acc:[0.8440917864036028, 0.9744799485309886, 0.9903495603688612]
train_judgement_acc:[0.8460218743298306, 0.9742654943169633, 0.9877761098005576]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4757505773672055
test_code_acc:[0.7696867061812024, 0.8738357324301439, 0.8789161727349704]
test_judgement_acc:[0.7950889077053345, 0.8882303132938189, 0.8933107535986452]


epoch:115,	loss_g:8.794149160385132	loss_d:3.204102486371994
train_code_acc:[0.844949603259704, 0.971263135320609, 0.9897061977267854]
train_judgement_acc:[0.8548144971048681, 0.9689041389663307, 0.9871327471584816]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7671464860287892, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.79424216765453, 0.8839966130397968, 0.8882303132938189]


epoch:116,	loss_g:8.91945195198059	loss_d:3.1244200468063354
train_code_acc:[0.8481664164700836, 0.9734076774608621, 0.9903495603688612]
train_judgement_acc:[0.8599613982414754, 0.9742654943169633, 0.9886339266566588]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.7671464860287892, 0.8763759525825572, 0.8806096528365792]
test_judgement_acc:[0.7950889077053345, 0.8848433530906011, 0.8890770533446232]


epoch:117,	loss_g:8.596908688545227	loss_d:3.2159197628498077
train_code_acc:[0.844949603259704, 0.9704053184645078, 0.98949174351276]
train_judgement_acc:[0.850525412824362, 0.9706197726785332, 0.9886339266566588]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7671464860287892, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.79424216765453, 0.8839966130397968, 0.8882303132938189]


epoch:118,	loss_g:8.128817200660706	loss_d:2.9376633167266846
train_code_acc:[0.8498820501822861, 0.9772678533133176, 0.9931374651511902]
train_judgement_acc:[0.8563156766030452, 0.9753377653870898, 0.992279648295089]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7671464860287892, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.7950889077053345, 0.8831498729889924, 0.8882303132938189]


epoch:119,	loss_g:8.21521008014679	loss_d:3.0637530386447906
train_code_acc:[0.8522410465365644, 0.9753377653870898, 0.992279648295089]
train_judgement_acc:[0.8546000428908428, 0.9736221316748874, 0.9905640145828866]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4826789838337182
test_code_acc:[0.7671464860287892, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.7917019475021169, 0.8839966130397968, 0.8882303132938189]


epoch:120,	loss_g:8.158047199249268	loss_d:3.069163531064987
train_code_acc:[0.8473085996139824, 0.9753377653870898, 0.9920651940810636]
train_judgement_acc:[0.8537422260347416, 0.9738365858889128, 0.98949174351276]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.768839966130398, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.7908552074513124, 0.8839966130397968, 0.8882303132938189]


epoch:121,	loss_g:8.237450361251831	loss_d:3.035603255033493
train_code_acc:[0.8509543212524127, 0.9736221316748874, 0.9918507398670384]
train_judgement_acc:[0.8593180355993996, 0.9731932232468368, 0.9890628350847094]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.7696867061812024, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.7925486875529213, 0.8848433530906011, 0.8890770533446232]


epoch:122,	loss_g:7.523115903139114	loss_d:2.9996960759162903
train_code_acc:[0.8535277718207163, 0.9753377653870898, 0.992279648295089]
train_judgement_acc:[0.8629637572378297, 0.974694402745014, 0.9920651940810636]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7696867061812024, 0.8763759525825572, 0.8806096528365792]
test_judgement_acc:[0.7908552074513124, 0.8839966130397968, 0.8882303132938189]


epoch:123,	loss_g:7.7490280866622925	loss_d:3.0368748903274536
train_code_acc:[0.8513832296804632, 0.9764100364572164, 0.992923010937165]
train_judgement_acc:[0.8563156766030452, 0.974694402745014, 0.9916362856530131]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7705334462320068, 0.8763759525825572, 0.8806096528365792]
test_judgement_acc:[0.7917019475021169, 0.8839966130397968, 0.8882303132938189]


epoch:124,	loss_g:7.881646156311035	loss_d:3.0159197747707367
train_code_acc:[0.8492386875402101, 0.9772678533133176, 0.9920651940810636]
train_judgement_acc:[0.8591035813853742, 0.976838944885267, 0.9905640145828866]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7705334462320068, 0.8763759525825572, 0.8806096528365792]
test_judgement_acc:[0.7908552074513124, 0.8831498729889924, 0.8873835732430144]


epoch:125,	loss_g:8.278380930423737	loss_d:2.863944172859192
train_code_acc:[0.8584602187432983, 0.9772678533133176, 0.992923010937165]
train_judgement_acc:[0.8670383873043105, 0.9770533990992923, 0.992923010937165]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.4734411085450347
test_code_acc:[0.7705334462320068, 0.8763759525825572, 0.8806096528365792]
test_judgement_acc:[0.7908552074513124, 0.8839966130397968, 0.8873835732430144]


epoch:126,	loss_g:7.064280033111572	loss_d:2.958825021982193
train_code_acc:[0.8546000428908428, 0.9764100364572164, 0.9937808277932662]
train_judgement_acc:[0.8603903066695261, 0.9766244906712417, 0.992279648295089]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4780600461893765
test_code_acc:[0.7696867061812024, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.790008467400508, 0.8831498729889924, 0.88653683319221]


epoch:127,	loss_g:8.540237307548523	loss_d:3.1193349063396454
train_code_acc:[0.8498820501822861, 0.9723354063907356, 0.9903495603688612]
train_judgement_acc:[0.8539566802487669, 0.9710486811065837, 0.9890628350847094]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.768839966130398, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.790008467400508, 0.8831498729889924, 0.88653683319221]


epoch:128,	loss_g:7.977261602878571	loss_d:3.1200257539749146
train_code_acc:[0.8511687754664379, 0.9751233111730645, 0.9931374651511902]
train_judgement_acc:[0.8543855886768175, 0.9731932232468368, 0.9920651940810636]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.768839966130398, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.790008467400508, 0.8831498729889924, 0.88653683319221]


epoch:129,	loss_g:7.955636739730835	loss_d:3.1323264241218567
train_code_acc:[0.843448423761527, 0.9723354063907356, 0.9907784687969119]
train_judgement_acc:[0.8524555007505897, 0.9731932232468368, 0.9907784687969119]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.4803695150115475
test_code_acc:[0.768839966130398, 0.8755292125317528, 0.8797629127857748]
test_judgement_acc:[0.790008467400508, 0.8831498729889924, 0.88653683319221]
after process dataset len: 433
total passed: 0
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 143076.92it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 186308.33it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss_g:53.93393135070801	loss_d:16.40540885925293
train_code_acc:[0.05018228608192151, 0.10401029380227321, 0.1537636714561441]
train_judgement_acc:[0.4790907141325327, 0.46922582028736864, 0.4649367360068625]


test_answer_acc:0.06697459584295612	iter_cnt_mean:2.928406466512702
test_code_acc:[0.12531752751905165, 0.1397121083827265, 0.14055884843353092]
test_judgement_acc:[0.7180355630821338, 0.712108382726503, 0.7129551227773073]
save best model to ./output/test/best_model, best acc is:0.06697459584295612 
after process dataset len: 433
total passed: 0
Traceback (most recent call last):
  File "train_0.py", line 68, in <module>
    f.write(json.dumps(args_dict, ensure_ascii=False, indent=2))
  File "/data/zhyma/Justc/MAWPS/src/Train.py", line 155, in train
    loss_g, loss_d, code_pred_list, judgement_pred_list, discriminator_label_list = model(input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids, num_positions=num_positions, tgt_ids=tgt_ids, tgt_mask=tgt_mask,problem_id=problem_id)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 838, in forward
    judgement_pred = self.discriminator(tgt=decoder_inputs, memory=problem_embeddings, tgt_key_padding_mask=~(tgt_mask.bool()), memory_key_padding_mask=~(input_mask.bool()))
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/Justc/MAWPS/src/Models.py", line 741, in forward
    output = self.decoder(tgt, memory, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 333, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 652, in forward
    x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 669, in _mha_block
    x = self.multihead_attn(x, mem, mem,
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 5046, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/data/zhyma/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 4745, in _in_projection_packed
    return (linear(q, w_q, b_q),) + linear(k, w_kv, b_kv).chunk(2, dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 39.45 GiB total capacity; 21.67 GiB already allocated; 51.31 MiB free; 21.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 90404.62it/s]
get dev data loader...
after process dataset len: 1730
total passed: 0
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 177443.44it/s]
define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

>>>>>>>>>>>>>>>>>>>start train......


epoch:0,	loss_g:53.93393278121948	loss_d:16.405407428741455
train_code_acc:[0.05018228608192151, 0.10401029380227321, 0.1537636714561441]
train_judgement_acc:[0.4790907141325327, 0.46922582028736864, 0.4649367360068625]


test_answer_acc:0.06697459584295612	iter_cnt_mean:2.928406466512702
test_code_acc:[0.12531752751905165, 0.1397121083827265, 0.14055884843353092]
test_judgement_acc:[0.7180355630821338, 0.712108382726503, 0.7129551227773073]
save best model to ./output/test/best_model, best acc is:0.06697459584295612 


epoch:1,	loss_g:50.6705527305603	loss_d:13.48455274105072
train_code_acc:[0.13918078490242333, 0.24061762813639287, 0.3186789620416041]
train_judgement_acc:[0.734720137250697, 0.662449067124169, 0.6021874329830581]


test_answer_acc:0.26096997690531176	iter_cnt_mean:2.5057736720554273
test_code_acc:[0.3386960203217612, 0.3386960203217612, 0.3386960203217612]
test_judgement_acc:[0.6613039796782387, 0.6613039796782387, 0.6613039796782387]
save best model to ./output/test/best_model, best acc is:0.26096997690531176 


epoch:2,	loss_g:46.412243366241455	loss_d:16.938047170639038
train_code_acc:[0.2980913574951748, 0.4250482521981557, 0.49624705125455715]
train_judgement_acc:[0.6946171992279648, 0.5736650225176925, 0.5018228608192151]


test_answer_acc:0.2586605080831409	iter_cnt_mean:2.5219399538106235
test_code_acc:[0.3437764606265876, 0.3556308213378493, 0.3556308213378493]
test_judgement_acc:[0.6570702794242168, 0.6452159187129551, 0.6452159187129551]


epoch:3,	loss_g:41.69740867614746	loss_d:15.24332571029663
train_code_acc:[0.31095861033669314, 0.4649367360068625, 0.5399957109157195]
train_judgement_acc:[0.5766673815140467, 0.5507184216169848, 0.5447137036242762]


test_answer_acc:0.26558891454965355	iter_cnt_mean:2.503464203233256
test_code_acc:[0.3598645215918713, 0.37087214225232856, 0.37087214225232856]
test_judgement_acc:[0.36833192209991533, 0.3793395427603726, 0.3810330228619814]
save best model to ./output/test/best_model, best acc is:0.26558891454965355 


epoch:4,	loss_g:38.31528091430664	loss_d:14.818852424621582
train_code_acc:[0.29980699120737725, 0.4657945528629638, 0.5513617842590607]
train_judgement_acc:[0.6114089641861462, 0.5869611837872614, 0.5663735792408321]


test_answer_acc:0.3187066974595843	iter_cnt_mean:2.5427251732101617
test_code_acc:[0.3573243014394581, 0.40474174428450466, 0.40474174428450466]
test_judgement_acc:[0.7095681625740897, 0.7256562235393734, 0.7256562235393734]
save best model to ./output/test/best_model, best acc is:0.3187066974595843 


epoch:5,	loss_g:36.82509136199951	loss_d:14.226408958435059
train_code_acc:[0.32296804632211024, 0.4835942526270641, 0.58245764529273]
train_judgement_acc:[0.6433626420759168, 0.6141968689684753, 0.5884623632854385]


test_answer_acc:0.4665127020785219	iter_cnt_mean:2.3117782909930717
test_code_acc:[0.4623200677392041, 0.5749364944961897, 0.584250635055038]
test_judgement_acc:[0.6104995766299746, 0.655376799322608, 0.6528365791701948]
save best model to ./output/test/best_model, best acc is:0.4665127020785219 


epoch:6,	loss_g:35.815897941589355	loss_d:13.738807439804077
train_code_acc:[0.3647866180570448, 0.5419257988419472, 0.6307098434484237]
train_judgement_acc:[0.6159125026806777, 0.6324254771606262, 0.6356422903710058]


test_answer_acc:0.4942263279445728	iter_cnt_mean:2.260969976905312
test_code_acc:[0.4970364098221846, 0.6011854360711262, 0.6079593564775614]
test_judgement_acc:[0.6790855207451313, 0.6960203217612193, 0.6926333615580017]
save best model to ./output/test/best_model, best acc is:0.4942263279445728 


epoch:7,	loss_g:34.448678970336914	loss_d:13.221423029899597
train_code_acc:[0.4372721423975981, 0.6030452498391593, 0.6950461076560155]
train_judgement_acc:[0.6013296161269569, 0.6697405104010293, 0.6965472871541926]


test_answer_acc:0.535796766743649	iter_cnt_mean:2.1939953810623556
test_code_acc:[0.4961896697713802, 0.6172734970364098, 0.6215071972904318]
test_judgement_acc:[0.668077900084674, 0.7129551227773073, 0.7188823031329382]
save best model to ./output/test/best_model, best acc is:0.535796766743649 


epoch:8,	loss_g:32.56758213043213	loss_d:12.362092852592468
train_code_acc:[0.49624705125455715, 0.6656658803345485, 0.7385803131031525]
train_judgement_acc:[0.6152691400386018, 0.7201372506969762, 0.7415826720995068]


test_answer_acc:0.6789838337182448	iter_cnt_mean:2.0115473441108547
test_code_acc:[0.5707027942421676, 0.7256562235393734, 0.7256562235393734]
test_judgement_acc:[0.6824724809483489, 0.785774767146486, 0.7874682472480948]
save best model to ./output/test/best_model, best acc is:0.6789838337182448 


epoch:9,	loss_g:31.412521839141846	loss_d:11.44789969921112
train_code_acc:[0.5440703409822003, 0.7100579026377868, 0.7709628994209736]
train_judgement_acc:[0.6461505468582458, 0.7632425477160626, 0.7778254342697835]


test_answer_acc:0.6928406466512702	iter_cnt_mean:1.9930715935334873
test_code_acc:[0.5800169348010161, 0.7281964436917866, 0.7281964436917866]
test_judgement_acc:[0.6883996613039797, 0.817104149026249, 0.817104149026249]
save best model to ./output/test/best_model, best acc is:0.6928406466512702 


epoch:10,	loss_g:29.821216583251953	loss_d:10.832025170326233
train_code_acc:[0.5794552862963758, 0.7520909285867468, 0.8048466652369719]
train_judgement_acc:[0.6705983272571306, 0.7788977053399099, 0.7973407677460862]


test_answer_acc:0.7205542725173211	iter_cnt_mean:1.9145496535796767
test_code_acc:[0.6011854360711262, 0.745977984758679, 0.745977984758679]
test_judgement_acc:[0.6917866215071973, 0.8221845893310754, 0.8221845893310754]
save best model to ./output/test/best_model, best acc is:0.7205542725173211 


epoch:11,	loss_g:29.05505871772766	loss_d:10.094439387321472
train_code_acc:[0.600042890842805, 0.7746086210594039, 0.821788548144971]
train_judgement_acc:[0.6744585031095861, 0.8129959253699335, 0.8297233540639074]


test_answer_acc:0.74364896073903	iter_cnt_mean:1.909930715935335
test_code_acc:[0.6096528365791702, 0.7806943268416596, 0.781541066892464]
test_judgement_acc:[0.6909398814563928, 0.842506350550381, 0.8416596104995766]
save best model to ./output/test/best_model, best acc is:0.74364896073903 


epoch:12,	loss_g:27.993207931518555	loss_d:9.754936575889587
train_code_acc:[0.6017585245550076, 0.7896204160411752, 0.837229251554793]
train_judgement_acc:[0.6787475873900922, 0.827364357709629, 0.8398027021230967]


test_answer_acc:0.7829099307159353	iter_cnt_mean:1.838337182448037
test_code_acc:[0.6215071972904318, 0.8018628281117697, 0.8018628281117697]
test_judgement_acc:[0.6917866215071973, 0.8636748518204911, 0.8628281117696867]
save best model to ./output/test/best_model, best acc is:0.7829099307159353 


epoch:13,	loss_g:27.253533840179443	loss_d:9.178893566131592
train_code_acc:[0.6255629423118164, 0.8110658374437058, 0.8503109586103367]
train_judgement_acc:[0.6965472871541926, 0.8413038816212739, 0.857602401887197]


test_answer_acc:0.7829099307159353	iter_cnt_mean:1.8175519630484989
test_code_acc:[0.6392887383573242, 0.8128704487722269, 0.8145639288738358]
test_judgement_acc:[0.7112616426756986, 0.8662150719729044, 0.8653683319220999]
save best model to ./output/test/best_model, best acc is:0.7829099307159353 


epoch:14,	loss_g:26.171570777893066	loss_d:9.28694486618042
train_code_acc:[0.6281363928801201, 0.8192150975766673, 0.8593180355993996]
train_judgement_acc:[0.6922582028736864, 0.8475230538280077, 0.8563156766030452]


test_answer_acc:0.7875288683602771	iter_cnt_mean:1.8475750577367205
test_code_acc:[0.6299745977984759, 0.8111769686706182, 0.8145639288738358]
test_judgement_acc:[0.7036409822184589, 0.8704487722269263, 0.8704487722269263]
save best model to ./output/test/best_model, best acc is:0.7875288683602771 


epoch:15,	loss_g:24.997588396072388	loss_d:8.678674817085266
train_code_acc:[0.6452927300021445, 0.8402316105511474, 0.8799056401458288]
train_judgement_acc:[0.701050825648724, 0.8597469440274501, 0.881406819644006]


test_answer_acc:0.7713625866050808	iter_cnt_mean:1.7990762124711317
test_code_acc:[0.6528365791701948, 0.7883149872988993, 0.7908552074513124]
test_judgement_acc:[0.7256562235393734, 0.8577476714648603, 0.8585944115156647]


epoch:16,	loss_g:24.48218536376953	loss_d:8.485067129135132
train_code_acc:[0.6560154407034098, 0.8500965043963113, 0.8876259918507399]
train_judgement_acc:[0.7074844520694832, 0.8685395668024877, 0.8874115376367145]


test_answer_acc:0.7806004618937644	iter_cnt_mean:1.8429561200923787
test_code_acc:[0.6418289585097375, 0.7984758679085521, 0.8027095681625741]
test_judgement_acc:[0.7104149026248942, 0.8509737510584251, 0.8560541913632514]


epoch:17,	loss_g:23.399613618850708	loss_d:8.371639132499695
train_code_acc:[0.6639502466223461, 0.8558867681749946, 0.8929873472013725]
train_judgement_acc:[0.7051254557152048, 0.8726141968689685, 0.8910572592751448]


test_answer_acc:0.7852193995381063	iter_cnt_mean:1.833718244803695
test_code_acc:[0.6469093988145639, 0.8069432684165961, 0.8111769686706182]
test_judgement_acc:[0.7307366638441999, 0.8636748518204911, 0.8687552921253175]


epoch:18,	loss_g:22.75552272796631	loss_d:8.002937316894531
train_code_acc:[0.6639502466223461, 0.8715419257988419, 0.9067124168989921]
train_judgement_acc:[0.7113446279219386, 0.886982629208664, 0.896847523053828]


test_answer_acc:0.7990762124711316	iter_cnt_mean:1.766743648960739
test_code_acc:[0.65961049957663, 0.8111769686706182, 0.8120237087214225]
test_judgement_acc:[0.7408975444538527, 0.8712955122777307, 0.8738357324301439]
save best model to ./output/test/best_model, best acc is:0.7990762124711316 


epoch:19,	loss_g:21.746773719787598	loss_d:8.121114611625671
train_code_acc:[0.6682393309028523, 0.8646793909500322, 0.9022088784044606]
train_judgement_acc:[0.7145614411323182, 0.8805490027879048, 0.9009221531203088]


test_answer_acc:0.8013856812933026	iter_cnt_mean:1.8198614318706698
test_code_acc:[0.6384419983065199, 0.8103302286198137, 0.8154106689246401]
test_judgement_acc:[0.7315834038950042, 0.8738357324301439, 0.8789161727349704]
save best model to ./output/test/best_model, best acc is:0.8013856812933026 


epoch:20,	loss_g:21.416017532348633	loss_d:7.862886667251587
train_code_acc:[0.6785331331760669, 0.8661805704482093, 0.9062835084709414]
train_judgement_acc:[0.7259275144756594, 0.8882693544928157, 0.9082135963971693]


test_answer_acc:0.7782909930715936	iter_cnt_mean:1.7852193995381063
test_code_acc:[0.6731583403895004, 0.8094834885690093, 0.8137171888230313]
test_judgement_acc:[0.7138018628281118, 0.8535139712108383, 0.8492802709568162]


epoch:21,	loss_g:20.554555654525757	loss_d:7.4140788316726685
train_code_acc:[0.6849667595968261, 0.8831224533562084, 0.92279648295089]
train_judgement_acc:[0.7274286939738366, 0.8951318893416256, 0.9185073986703839]


test_answer_acc:0.7736720554272517	iter_cnt_mean:1.7690531177829099
test_code_acc:[0.6773920406435224, 0.8111769686706182, 0.8145639288738358]
test_judgement_acc:[0.7392040643522438, 0.8552074513124471, 0.859441151566469]


epoch:22,	loss_g:20.173471689224243	loss_d:7.475221872329712
train_code_acc:[0.6976195582243191, 0.8846236328543856, 0.9204374865966116]
train_judgement_acc:[0.7315033240403174, 0.8932018014153978, 0.9146472228179283]


test_answer_acc:0.8568129330254042	iter_cnt_mean:1.7090069284064666
test_code_acc:[0.6697713801862828, 0.8374259102455546, 0.8441998306519899]
test_judgement_acc:[0.7383573243014394, 0.8780694326841659, 0.8831498729889924]
save best model to ./output/test/best_model, best acc is:0.8568129330254042 


epoch:23,	loss_g:19.49086284637451	loss_d:7.4251638650894165
train_code_acc:[0.6937593823718636, 0.8925584387733219, 0.9260132961612696]
train_judgement_acc:[0.7248552434055329, 0.8962041604117521, 0.9185073986703839]


test_answer_acc:0.8244803695150116	iter_cnt_mean:1.7782909930715936
test_code_acc:[0.6511430990685859, 0.8272650296359018, 0.8323454699407282]
test_judgement_acc:[0.6977138018628282, 0.8662150719729044, 0.8670618120237087]


epoch:24,	loss_g:19.222339868545532	loss_d:6.950515031814575
train_code_acc:[0.6974051040102938, 0.897490885695904, 0.9337336478661805]
train_judgement_acc:[0.7246407891915077, 0.9069268711130174, 0.9326613767960541]


test_answer_acc:0.7990762124711316	iter_cnt_mean:1.7413394919168592
test_code_acc:[0.672311600338696, 0.8103302286198137, 0.817104149026249]
test_judgement_acc:[0.7061812023708721, 0.8492802709568162, 0.8458933107535986]


epoch:25,	loss_g:18.578103065490723	loss_d:6.965806186199188
train_code_acc:[0.7001930087926228, 0.8942740724855244, 0.9335191936521553]
train_judgement_acc:[0.734720137250697, 0.9028522410465366, 0.9288012009435985]


test_answer_acc:0.8452655889145496	iter_cnt_mean:1.7228637413394918
test_code_acc:[0.6697713801862828, 0.8281117696867062, 0.8365791701947503]
test_judgement_acc:[0.7535986452159187, 0.8712955122777307, 0.8780694326841659]


epoch:26,	loss_g:18.16046380996704	loss_d:6.741041660308838
train_code_acc:[0.7119879905640146, 0.9075702337550933, 0.9435985417113446]
train_judgement_acc:[0.7387947673171777, 0.9131460433197512, 0.9320180141539781]


test_answer_acc:0.859122401847575	iter_cnt_mean:1.6327944572748267
test_code_acc:[0.6960203217612193, 0.8374259102455546, 0.8399661303979679]
test_judgement_acc:[0.7349703640982218, 0.8746824724809483, 0.8679085520745131]
save best model to ./output/test/best_model, best acc is:0.859122401847575 


epoch:27,	loss_g:18.335054397583008	loss_d:6.596835136413574
train_code_acc:[0.7154192579884194, 0.9056401458288655, 0.9431696332832941]
train_judgement_acc:[0.7437272142397598, 0.9127171348917006, 0.9399528200729145]


test_answer_acc:0.8314087759815243	iter_cnt_mean:1.7297921478060045
test_code_acc:[0.6706181202370872, 0.8264182895850973, 0.8314987298899238]
test_judgement_acc:[0.712108382726503, 0.8602878916172735, 0.8560541913632514]


epoch:28,	loss_g:17.781696319580078	loss_d:6.643752992153168
train_code_acc:[0.7072699978554579, 0.9082135963971693, 0.9433840874973193]
train_judgement_acc:[0.7385803131031525, 0.9092858674672958, 0.9345914647222818]


test_answer_acc:0.8683602771362586	iter_cnt_mean:1.6905311778290992
test_code_acc:[0.6782387806943269, 0.8450465707027942, 0.8518204911092294]
test_judgement_acc:[0.7231160033869602, 0.8839966130397968, 0.8738357324301439]
save best model to ./output/test/best_model, best acc is:0.8683602771362586 


epoch:29,	loss_g:17.18481695652008	loss_d:6.309898316860199
train_code_acc:[0.7220673386232039, 0.92279648295089, 0.9534634355565087]
train_judgement_acc:[0.7443705768818357, 0.9260132961612696, 0.9476731717778254]


test_answer_acc:0.8452655889145496	iter_cnt_mean:1.6789838337182448
test_code_acc:[0.6900931414055885, 0.8365791701947503, 0.838272650296359]
test_judgement_acc:[0.7400508044030483, 0.8814563928873835, 0.8814563928873835]


epoch:30,	loss_g:16.82398819923401	loss_d:6.188265740871429
train_code_acc:[0.718636071198799, 0.922153120308814, 0.9571091571949388]
train_judgement_acc:[0.7396525841732791, 0.9273000214454215, 0.950889984988205]


test_answer_acc:0.8545034642032333	iter_cnt_mean:1.6466512702078522
test_code_acc:[0.6985605419136325, 0.8416596104995766, 0.8450465707027942]
test_judgement_acc:[0.7620660457239627, 0.8806096528365792, 0.882303132938188]


epoch:31,	loss_g:16.30943512916565	loss_d:6.365679204463959
train_code_acc:[0.7267853313317607, 0.9197941239545357, 0.9541067981985846]
train_judgement_acc:[0.7428693973836585, 0.9245121166630924, 0.9416684537851169]


test_answer_acc:0.8637413394919169	iter_cnt_mean:1.6581986143187066
test_code_acc:[0.6960203217612193, 0.8518204911092294, 0.8526672311600338]
test_judgement_acc:[0.7383573243014394, 0.8797629127857748, 0.8738357324301439]


epoch:32,	loss_g:15.686847925186157	loss_d:5.889167606830597
train_code_acc:[0.7402959468153549, 0.9253699335191936, 0.9575380656229895]
train_judgement_acc:[0.7570233755093287, 0.928372292515548, 0.9553935234827364]


test_answer_acc:0.8568129330254042	iter_cnt_mean:1.6466512702078522
test_code_acc:[0.6968670618120237, 0.842506350550381, 0.8458933107535986]
test_judgement_acc:[0.7569856054191363, 0.882303132938188, 0.8738357324301439]


epoch:33,	loss_g:15.786614894866943	loss_d:6.050091028213501
train_code_acc:[0.7308599613982415, 0.9247265708771177, 0.9616126956894703]
train_judgement_acc:[0.749517478018443, 0.9245121166630924, 0.9496032597040532]


test_answer_acc:0.8660508083140878	iter_cnt_mean:1.651270207852194
test_code_acc:[0.6977138018628282, 0.8552074513124471, 0.859441151566469]
test_judgement_acc:[0.7468247248094835, 0.8933107535986452, 0.8882303132938189]


epoch:34,	loss_g:15.670037508010864	loss_d:6.159220039844513
train_code_acc:[0.7229251554793051, 0.9251554793051684, 0.9581814282650654]
train_judgement_acc:[0.7503752948745442, 0.9255843877332189, 0.9489598970619773]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.625866050808314
test_code_acc:[0.7019475021168501, 0.8509737510584251, 0.8543607112616427]
test_judgement_acc:[0.7527519051651143, 0.8814563928873835, 0.8831498729889924]
save best model to ./output/test/best_model, best acc is:0.8752886836027713 


epoch:35,	loss_g:16.145899772644043	loss_d:5.887987375259399
train_code_acc:[0.7351490456787476, 0.930516834655801, 0.9598970619772679]
train_judgement_acc:[0.7580956465794553, 0.9339481020802058, 0.9573236114089642]


test_answer_acc:0.8568129330254042	iter_cnt_mean:1.6628175519630486
test_code_acc:[0.7002540220152413, 0.8484335309060118, 0.8518204911092294]
test_judgement_acc:[0.756138865368332, 0.8797629127857748, 0.8814563928873835]


epoch:36,	loss_g:15.091521739959717	loss_d:5.791376709938049
train_code_acc:[0.7390092215312031, 0.9324469225820288, 0.9665451426120524]
train_judgement_acc:[0.755093287583101, 0.9337336478661805, 0.9598970619772679]


test_answer_acc:0.8752886836027713	iter_cnt_mean:1.6235565819861433
test_code_acc:[0.7011007620660458, 0.8560541913632514, 0.859441151566469]
test_judgement_acc:[0.7425910245554614, 0.8882303132938189, 0.8755292125317528]
save best model to ./output/test/best_model, best acc is:0.8752886836027713 


epoch:37,	loss_g:14.8660249710083	loss_d:5.485480010509491
train_code_acc:[0.7555221960111517, 0.9365215526485096, 0.9667595968260776]
train_judgement_acc:[0.7761098005575809, 0.935449281578383, 0.9556079776967618]


test_answer_acc:0.8729792147806005	iter_cnt_mean:1.6166281755196306
test_code_acc:[0.7146486028789162, 0.8577476714648603, 0.8619813717188823]
test_judgement_acc:[0.7535986452159187, 0.8890770533446232, 0.8916172734970365]


epoch:38,	loss_g:14.40670645236969	loss_d:5.485662758350372
train_code_acc:[0.7454428479519623, 0.9431696332832941, 0.9686896847523054]
train_judgement_acc:[0.7619558224319107, 0.9345914647222818, 0.9592536993351919]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5889145496535797
test_code_acc:[0.7171888230313294, 0.8653683319220999, 0.8679085520745131]
test_judgement_acc:[0.7679932260795935, 0.9017781541066893, 0.8890770533446232]
save best model to ./output/test/best_model, best acc is:0.8914549653579676 


epoch:39,	loss_g:14.864989638328552	loss_d:5.647064208984375
train_code_acc:[0.7486596611623418, 0.93330473943813, 0.9684752305382801]
train_judgement_acc:[0.7696761741368218, 0.9363070984344842, 0.9618271499034956]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.581986143187067
test_code_acc:[0.7180355630821338, 0.8653683319220999, 0.869602032176122]
test_judgement_acc:[0.7646062658763759, 0.9009314140558848, 0.8992379339542761]


epoch:40,	loss_g:13.993147850036621	loss_d:5.609443426132202
train_code_acc:[0.7557366502251769, 0.9356637357924084, 0.9665451426120524]
train_judgement_acc:[0.7713918078490243, 0.9356637357924084, 0.9573236114089642]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5773672055427252
test_code_acc:[0.7214225232853514, 0.8670618120237087, 0.8704487722269263]
test_judgement_acc:[0.7739204064352244, 0.9017781541066893, 0.8950042337002541]
save best model to ./output/test/best_model, best acc is:0.8937644341801386 


epoch:41,	loss_g:13.875779271125793	loss_d:5.365275502204895
train_code_acc:[0.7583101007934806, 0.9416684537851169, 0.9693330473943813]
train_judgement_acc:[0.7739652584173279, 0.9405961827149903, 0.9592536993351919]


test_answer_acc:0.9006928406466512	iter_cnt_mean:1.5750577367205543
test_code_acc:[0.724809483488569, 0.8712955122777307, 0.8763759525825572]
test_judgement_acc:[0.7671464860287892, 0.8983911939034717, 0.8899237933954276]
save best model to ./output/test/best_model, best acc is:0.9006928406466512 


epoch:42,	loss_g:14.034512162208557	loss_d:5.514577150344849
train_code_acc:[0.7615269140038602, 0.935449281578383, 0.9695475016084066]
train_judgement_acc:[0.7773965258417328, 0.9380227321466866, 0.9633283294016728]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.556581986143187
test_code_acc:[0.729043183742591, 0.8679085520745131, 0.8721422523285352]
test_judgement_acc:[0.77307366638442, 0.9060118543607113, 0.8975444538526672]


epoch:43,	loss_g:13.802747368812561	loss_d:5.3691131472587585
train_code_acc:[0.7593823718636071, 0.9427407248552434, 0.9725498606047609]
train_judgement_acc:[0.7801844306240617, 0.9457430838515977, 0.9686896847523054]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5681293302540416
test_code_acc:[0.7256562235393734, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.7705334462320068, 0.9009314140558848, 0.890770533446232]


epoch:44,	loss_g:13.696797490119934	loss_d:5.01252281665802
train_code_acc:[0.7632425477160626, 0.948102080205876, 0.9744799485309886]
train_judgement_acc:[0.7810422474801629, 0.9485309886339267, 0.9665451426120524]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5681293302540416
test_code_acc:[0.7273497036409822, 0.8662150719729044, 0.8704487722269263]
test_judgement_acc:[0.777307366638442, 0.9043183742591024, 0.8983911939034717]


epoch:45,	loss_g:13.588561773300171	loss_d:5.19258052110672
train_code_acc:[0.7658159982843663, 0.9502466223461291, 0.9770533990992923]
train_judgement_acc:[0.7827578811923654, 0.948102080205876, 0.9674029594681536]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.5750577367205543
test_code_acc:[0.7231160033869602, 0.8602878916172735, 0.8636748518204911]
test_judgement_acc:[0.7705334462320068, 0.8873835732430144, 0.8856900931414056]


epoch:46,	loss_g:13.464724779129028	loss_d:5.235848307609558
train_code_acc:[0.7662449067124169, 0.9433840874973193, 0.9725498606047609]
train_judgement_acc:[0.7816856101222389, 0.941025091143041, 0.9678318678962041]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5542725173210161
test_code_acc:[0.7324301439458086, 0.8687552921253175, 0.8738357324301439]
test_judgement_acc:[0.7840812870448772, 0.9000846740050804, 0.8983911939034717]


epoch:47,	loss_g:12.823210000991821	loss_d:5.145549476146698
train_code_acc:[0.762813639288012, 0.9502466223461291, 0.9776967617413682]
train_judgement_acc:[0.7799699764100364, 0.9487454428479519, 0.969118593180356]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5473441108545034
test_code_acc:[0.729043183742591, 0.8670618120237087, 0.8704487722269263]
test_judgement_acc:[0.7713801862828111, 0.8950042337002541, 0.8899237933954276]


epoch:48,	loss_g:12.86033546924591	loss_d:5.1330646276474
train_code_acc:[0.778254342697834, 0.9491743512760026, 0.9776967617413682]
train_judgement_acc:[0.7861891486167704, 0.9474587175638002, 0.9714775895346344]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.556581986143187
test_code_acc:[0.7281964436917866, 0.8653683319220999, 0.8729889923793396]
test_judgement_acc:[0.7705334462320068, 0.8966977138018628, 0.8941574936494496]


epoch:49,	loss_g:13.24207866191864	loss_d:4.745265543460846
train_code_acc:[0.7724640789191508, 0.9526056187004075, 0.9785545785974694]
train_judgement_acc:[0.7891915076131246, 0.9502466223461291, 0.974051040102938]


test_answer_acc:0.8983833718244804	iter_cnt_mean:1.5519630484988454
test_code_acc:[0.7315834038950042, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7764606265876376, 0.8966977138018628, 0.8983911939034717]


epoch:50,	loss_g:12.468196272850037	loss_d:4.973368465900421
train_code_acc:[0.772678533133176, 0.9483165344199014, 0.9794123954535706]
train_judgement_acc:[0.7889770533990993, 0.9461719922796483, 0.9725498606047609]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5450346420323327
test_code_acc:[0.7324301439458086, 0.8628281117696867, 0.8670618120237087]
test_judgement_acc:[0.7840812870448772, 0.8958509737510584, 0.890770533446232]


epoch:51,	loss_g:13.189439535140991	loss_d:4.999846518039703
train_code_acc:[0.7769676174136821, 0.9496032597040532, 0.9772678533133176]
train_judgement_acc:[0.7945528629637573, 0.9461719922796483, 0.9725498606047609]


test_answer_acc:0.8845265588914549	iter_cnt_mean:1.5612009237875288
test_code_acc:[0.7265029635901779, 0.8619813717188823, 0.8645215918712955]
test_judgement_acc:[0.7705334462320068, 0.890770533446232, 0.8882303132938189]


epoch:52,	loss_g:12.63272774219513	loss_d:4.9664114117622375
train_code_acc:[0.7750375294874544, 0.9526056187004075, 0.9794123954535706]
train_judgement_acc:[0.7868325112588462, 0.953034527128458, 0.9734076774608621]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.53810623556582
test_code_acc:[0.7324301439458086, 0.8619813717188823, 0.8670618120237087]
test_judgement_acc:[0.777307366638442, 0.8873835732430144, 0.8899237933954276]


epoch:53,	loss_g:12.414980173110962	loss_d:4.948795795440674
train_code_acc:[0.7784687969118593, 0.9528200729144327, 0.9776967617413682]
train_judgement_acc:[0.7966974051040103, 0.9502466223461291, 0.9704053184645078]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.5588914549653579
test_code_acc:[0.729043183742591, 0.8636748518204911, 0.8687552921253175]
test_judgement_acc:[0.7781541066892464, 0.8882303132938189, 0.8933107535986452]


epoch:54,	loss_g:12.710320830345154	loss_d:4.879091918468475
train_code_acc:[0.7739652584173279, 0.9551790692687111, 0.9804846665236971]
train_judgement_acc:[0.791550503967403, 0.950889984988205, 0.9744799485309886]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5473441108545034
test_code_acc:[0.7315834038950042, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.7747671464860287, 0.890770533446232, 0.8933107535986452]


epoch:55,	loss_g:12.070566773414612	loss_d:4.663081347942352
train_code_acc:[0.7842590606905425, 0.9590392451211667, 0.9828436628779755]
train_judgement_acc:[0.7949817713918078, 0.958610336693116, 0.9759811280291658]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5404157043879907
test_code_acc:[0.7358171041490262, 0.8662150719729044, 0.8679085520745131]
test_judgement_acc:[0.7713801862828111, 0.8839966130397968, 0.8856900931414056]


epoch:56,	loss_g:12.35390043258667	loss_d:4.778637886047363
train_code_acc:[0.7829723354063908, 0.9596826077632425, 0.982414754449925]
train_judgement_acc:[0.791550503967403, 0.9583958824790907, 0.9766244906712417]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5173210161662818
test_code_acc:[0.7451312447078747, 0.869602032176122, 0.8729889923793396]
test_judgement_acc:[0.7925486875529213, 0.8916172734970365, 0.8916172734970365]


epoch:57,	loss_g:11.906557202339172	loss_d:4.85991358757019
train_code_acc:[0.7829723354063908, 0.9506755307741798, 0.9819858460218743]
train_judgement_acc:[0.7962684966759597, 0.9521767102723568, 0.9774823075273429]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.533487297921478
test_code_acc:[0.7400508044030483, 0.8653683319220999, 0.8704487722269263]
test_judgement_acc:[0.7806943268416596, 0.8890770533446232, 0.890770533446232]


epoch:58,	loss_g:12.291354656219482	loss_d:4.652624309062958
train_code_acc:[0.7883336907570234, 0.9545357066266352, 0.9800557580956466]
train_judgement_acc:[0.8003431267424405, 0.956465794552863, 0.974694402745014]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7383573243014394, 0.8645215918712955, 0.8687552921253175]
test_judgement_acc:[0.7832345469940728, 0.8941574936494496, 0.8916172734970365]


epoch:59,	loss_g:12.288074016571045	loss_d:4.566039443016052
train_code_acc:[0.7883336907570234, 0.9547501608406606, 0.9785545785974694]
train_judgement_acc:[0.8067767531631996, 0.9583958824790907, 0.9749088569590393]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.535796766743649
test_code_acc:[0.7392040643522438, 0.8704487722269263, 0.8721422523285352]
test_judgement_acc:[0.790008467400508, 0.8916172734970365, 0.8924640135478408]


epoch:60,	loss_g:12.141695141792297	loss_d:4.6671701073646545
train_code_acc:[0.7868325112588462, 0.9568947029809136, 0.9804846665236971]
train_judgement_acc:[0.8027021230967188, 0.9551790692687111, 0.9725498606047609]


test_answer_acc:0.8822170900692841	iter_cnt_mean:1.5542725173210161
test_code_acc:[0.729043183742591, 0.8602878916172735, 0.8628281117696867]
test_judgement_acc:[0.7756138865368332, 0.88653683319221, 0.882303132938188]


epoch:61,	loss_g:11.089412808418274	loss_d:4.775941908359528
train_code_acc:[0.7808277932661377, 0.9545357066266352, 0.9815569375938237]
train_judgement_acc:[0.7911215955393524, 0.9493888054900279, 0.9738365858889128]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5242494226327945
test_code_acc:[0.7408975444538527, 0.8670618120237087, 0.8704487722269263]
test_judgement_acc:[0.7764606265876376, 0.8899237933954276, 0.890770533446232]


epoch:62,	loss_g:11.77433705329895	loss_d:4.868578374385834
train_code_acc:[0.7806133390521124, 0.9523911644863822, 0.9794123954535706]
train_judgement_acc:[0.7881192365429981, 0.9513188934162556, 0.9755522196011152]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.5196304849884525
test_code_acc:[0.7451312447078747, 0.8712955122777307, 0.8738357324301439]
test_judgement_acc:[0.7806943268416596, 0.8848433530906011, 0.8933107535986452]


epoch:63,	loss_g:11.415655374526978	loss_d:4.60746955871582
train_code_acc:[0.7891915076131246, 0.9598970619772679, 0.9837014797340767]
train_judgement_acc:[0.8024876688826935, 0.9556079776967618, 0.9753377653870898]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5311778290993072
test_code_acc:[0.7375105842506351, 0.8687552921253175, 0.8721422523285352]
test_judgement_acc:[0.7823878069432684, 0.8814563928873835, 0.8916172734970365]


epoch:64,	loss_g:11.072629690170288	loss_d:4.673411786556244
train_code_acc:[0.7844735149045678, 0.9556079776967618, 0.9841303881621274]
train_judgement_acc:[0.7949817713918078, 0.9541067981985846, 0.9806991207377225]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.535796766743649
test_code_acc:[0.7324301439458086, 0.8653683319220999, 0.8687552921253175]
test_judgement_acc:[0.7713801862828111, 0.8839966130397968, 0.8814563928873835]


epoch:65,	loss_g:10.713540315628052	loss_d:4.538196682929993
train_code_acc:[0.7956251340338838, 0.9592536993351919, 0.9856315676603046]
train_judgement_acc:[0.8039888483808707, 0.9579669740510401, 0.9791979412395454]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.533487297921478
test_code_acc:[0.7332768839966131, 0.8611346316680779, 0.8653683319220999]
test_judgement_acc:[0.7705334462320068, 0.8789161727349704, 0.8763759525825572]


epoch:66,	loss_g:11.851409673690796	loss_d:4.657773494720459
train_code_acc:[0.7941239545357066, 0.9534634355565087, 0.982414754449925]
train_judgement_acc:[0.8059189363070984, 0.9534634355565087, 0.9770533990992923]


test_answer_acc:0.8868360277136259	iter_cnt_mean:1.53810623556582
test_code_acc:[0.7341236240474175, 0.8645215918712955, 0.8670618120237087]
test_judgement_acc:[0.7747671464860287, 0.8806096528365792, 0.8839966130397968]


epoch:67,	loss_g:11.827910304069519	loss_d:4.544274806976318
train_code_acc:[0.7906926871113017, 0.9543212524126099, 0.9813424833797985]
train_judgement_acc:[0.8050611194509972, 0.9541067981985846, 0.9751233111730645]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.535796766743649
test_code_acc:[0.7375105842506351, 0.8662150719729044, 0.8687552921253175]
test_judgement_acc:[0.7832345469940728, 0.8848433530906011, 0.8873835732430144]


epoch:68,	loss_g:10.68876576423645	loss_d:4.386273801326752
train_code_acc:[0.7966974051040103, 0.9618271499034956, 0.9860604760883551]
train_judgement_acc:[0.8076345700193008, 0.958610336693116, 0.9791979412395454]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5265588914549653
test_code_acc:[0.7408975444538527, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.7747671464860287, 0.8831498729889924, 0.8856900931414056]


epoch:69,	loss_g:11.365813970565796	loss_d:4.429824709892273
train_code_acc:[0.8037743941668454, 0.9607548788333691, 0.984559296590178]
train_judgement_acc:[0.8102080205876045, 0.9573236114089642, 0.9791979412395454]


test_answer_acc:0.8937644341801386	iter_cnt_mean:1.51270207852194
test_code_acc:[0.7434377646062659, 0.8679085520745131, 0.8704487722269263]
test_judgement_acc:[0.7713801862828111, 0.8797629127857748, 0.882303132938188]


epoch:70,	loss_g:11.805724501609802	loss_d:4.6800901889801025
train_code_acc:[0.7943384087497319, 0.9575380656229895, 0.9832725713060262]
train_judgement_acc:[0.8022732146686682, 0.9566802487668883, 0.9787690328114947]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5150115473441108
test_code_acc:[0.745977984758679, 0.8679085520745131, 0.8704487722269263]
test_judgement_acc:[0.77307366638442, 0.8789161727349704, 0.8814563928873835]


epoch:71,	loss_g:11.67127251625061	loss_d:4.657283127307892
train_code_acc:[0.7928372292515548, 0.9575380656229895, 0.9809135749517478]
train_judgement_acc:[0.8009864893845164, 0.953677889770534, 0.976195582243191]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5150115473441108
test_code_acc:[0.7485182049110923, 0.8704487722269263, 0.8738357324301439]
test_judgement_acc:[0.7790008467400508, 0.882303132938188, 0.8856900931414056]


epoch:72,	loss_g:12.210187673568726	loss_d:4.751516938209534
train_code_acc:[0.788762599185074, 0.9541067981985846, 0.9802702123096719]
train_judgement_acc:[0.7969118593180357, 0.9485309886339267, 0.976195582243191]


test_answer_acc:0.8891454965357968	iter_cnt_mean:1.5265588914549653
test_code_acc:[0.7425910245554614, 0.8670618120237087, 0.8704487722269263]
test_judgement_acc:[0.7764606265876376, 0.8797629127857748, 0.8831498729889924]


epoch:73,	loss_g:10.689140558242798	loss_d:4.4478097558021545
train_code_acc:[0.8007720351704911, 0.9609693330473944, 0.9867038387304311]
train_judgement_acc:[0.8117092000857817, 0.9596826077632425, 0.9806991207377225]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7408975444538527, 0.8687552921253175, 0.8721422523285352]
test_judgement_acc:[0.7790008467400508, 0.8856900931414056, 0.8890770533446232]


epoch:74,	loss_g:11.360838174819946	loss_d:4.498609900474548
train_code_acc:[0.8022732146686682, 0.9611837872614197, 0.9852026592322539]
train_judgement_acc:[0.8112802916577311, 0.9596826077632425, 0.979626849667596]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7408975444538527, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.777307366638442, 0.8848433530906011, 0.8882303132938189]


epoch:75,	loss_g:11.552037835121155	loss_d:4.492345929145813
train_code_acc:[0.7926227750375295, 0.956465794552863, 0.9830581170920009]
train_judgement_acc:[0.8037743941668454, 0.953677889770534, 0.9794123954535706]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7408975444538527, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.777307366638442, 0.8856900931414056, 0.8882303132938189]


epoch:76,	loss_g:11.352404475212097	loss_d:4.5702595710754395
train_code_acc:[0.7960540424619343, 0.9575380656229895, 0.981771391807849]
train_judgement_acc:[0.8031310315247695, 0.9545357066266352, 0.9785545785974694]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7408975444538527, 0.8679085520745131, 0.8712955122777307]
test_judgement_acc:[0.777307366638442, 0.8856900931414056, 0.8882303132938189]


epoch:77,	loss_g:11.354696989059448	loss_d:4.5040987730026245
train_code_acc:[0.7973407677460862, 0.9596826077632425, 0.9839159339481021]
train_judgement_acc:[0.8076345700193008, 0.9577525198370148, 0.9791979412395454]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7400508044030483, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.77307366638442, 0.8848433530906011, 0.88653683319221]


epoch:78,	loss_g:10.889223456382751	loss_d:4.529948115348816
train_code_acc:[0.7962684966759597, 0.9611837872614197, 0.9854171134462792]
train_judgement_acc:[0.8076345700193008, 0.9571091571949388, 0.9794123954535706]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7400508044030483, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.77307366638442, 0.8839966130397968, 0.88653683319221]


epoch:79,	loss_g:10.993185997009277	loss_d:4.62057363986969
train_code_acc:[0.7936950461076561, 0.9601115161912932, 0.9843448423761527]
train_judgement_acc:[0.8057044820930731, 0.956465794552863, 0.979626849667596]


test_answer_acc:0.8914549653579676	iter_cnt_mean:1.5288683602771362
test_code_acc:[0.7400508044030483, 0.8670618120237087, 0.869602032176122]
test_judgement_acc:[0.77307366638442, 0.8839966130397968, 0.88653683319221]



Final_test
test_answer_acc:0.9006928406466512	iter_cnt_mean:1.5750577367205543
test_code_acc:[0.724809483488569, 0.8712955122777307, 0.8763759525825572]
test_judgement_acc:[0.7671464860287892, 0.8983911939034717, 0.8899237933954276]
after process dataset len: 433
total passed: 0
