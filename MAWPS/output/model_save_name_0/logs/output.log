2023-07-07 16:06:27,555 - get train data loader...
2023-07-07 16:06:27,733 - get dev data loader...
2023-07-07 16:06:27,775 - define model...
2023-07-07 16:06:52,133 - define optimizer...
2023-07-07 16:06:52,139 - ===========================train setting parameters=========================
2023-07-07 16:06:52,141 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 16:06:52,141 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 16:06:52,141 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 16:06:52,142 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,142 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,143 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,144 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,144 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,144 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,145 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,146 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,147 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,147 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,148 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,154 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,154 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,155 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,155 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,156 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,156 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,156 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,156 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,162 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,163 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,163 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,163 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,163 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,164 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,165 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,165 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,165 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,165 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,165 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,165 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 16:06:52,165 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 16:06:52,165 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,166 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 16:06:52,167 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 16:06:52,168 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 16:06:52,168 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 16:06:52,168 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 16:06:52,168 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 16:06:52,168 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 16:06:52,168 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 16:06:52,168 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 16:06:52,168 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 16:06:52,168 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 16:06:52,169 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 16:06:52,169 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 16:06:52,169 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 16:06:52,169 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 16:06:52,169 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 16:06:52,169 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 16:06:52,169 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 16:06:52,169 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 16:06:52,169 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 16:06:52,169 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 16:06:52,169 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 16:06:52,169 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 16:06:52,169 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 16:06:52,169 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 16:06:52,169 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 16:06:52,177 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 16:06:52,177 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 16:06:52,177 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 16:06:52,177 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 16:06:52,189 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 16:07:11,118 - 


2023-07-07 16:07:11,124 - epoch:0,	loss:1.93722003698349
2023-07-07 16:07:14,404 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 16:07:14,405 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 16:07:14,405 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 16:07:14,407 - save best model to ./output/test/best_model
2023-07-07 16:07:36,883 - 


2023-07-07 16:07:36,883 - epoch:1,	loss:1.2210435029119253
2023-07-07 16:07:40,041 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 16:07:40,041 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 16:07:40,041 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 16:07:51,377 - 


2023-07-07 16:07:51,377 - epoch:2,	loss:0.9560508746653795
2023-07-07 16:07:54,620 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 16:07:54,620 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 16:07:54,626 - wrong_be_tree_count:432	wrong_total:433	 wrong be tree ACC: 0.9976905311778291
2023-07-07 16:08:06,111 - 


2023-07-07 16:08:06,111 - epoch:3,	loss:0.8729819413274527
2023-07-07 16:08:09,392 - right_count:7	total:433	 Answer ACC: 0.016166281755196306
2023-07-07 16:08:09,392 - right_codes_count:1	total:433	 Code ACC: 0.0023094688221709007
2023-07-07 16:08:09,392 - wrong_be_tree_count:341	wrong_total:426	 wrong be tree ACC: 0.8004694835680751
2023-07-07 16:08:09,398 - save best model to ./output/test/best_model
2023-07-07 16:08:29,303 - 


2023-07-07 16:08:29,303 - epoch:4,	loss:0.8312085755169392
2023-07-07 16:08:32,456 - right_count:27	total:433	 Answer ACC: 0.06235565819861432
2023-07-07 16:08:32,456 - right_codes_count:10	total:433	 Code ACC: 0.023094688221709007
2023-07-07 16:08:32,456 - wrong_be_tree_count:267	wrong_total:406	 wrong be tree ACC: 0.6576354679802956
2023-07-07 16:08:32,458 - save best model to ./output/test/best_model
2023-07-07 16:08:50,649 - 


2023-07-07 16:08:50,649 - epoch:5,	loss:0.7774491822347045
2023-07-07 16:08:53,941 - right_count:90	total:433	 Answer ACC: 0.20785219399538107
2023-07-07 16:08:53,941 - right_codes_count:62	total:433	 Code ACC: 0.14318706697459585
2023-07-07 16:08:53,941 - wrong_be_tree_count:190	wrong_total:343	 wrong be tree ACC: 0.5539358600583091
2023-07-07 16:08:53,943 - save best model to ./output/test/best_model
2023-07-07 16:09:10,686 - 


2023-07-07 16:09:10,686 - epoch:6,	loss:0.7170977080240846
2023-07-07 16:09:13,880 - right_count:103	total:433	 Answer ACC: 0.23787528868360278
2023-07-07 16:09:13,880 - right_codes_count:76	total:433	 Code ACC: 0.17551963048498845
2023-07-07 16:09:13,880 - wrong_be_tree_count:109	wrong_total:330	 wrong be tree ACC: 0.3303030303030303
2023-07-07 16:09:13,883 - save best model to ./output/test/best_model
2023-07-07 16:09:31,971 - 


2023-07-07 16:09:31,972 - epoch:7,	loss:0.6597112752497196
2023-07-07 16:09:35,247 - right_count:146	total:433	 Answer ACC: 0.3371824480369515
2023-07-07 16:09:35,247 - right_codes_count:115	total:433	 Code ACC: 0.26558891454965355
2023-07-07 16:09:35,247 - wrong_be_tree_count:72	wrong_total:287	 wrong be tree ACC: 0.2508710801393728
2023-07-07 16:09:35,249 - save best model to ./output/test/best_model
2023-07-07 16:09:55,246 - 


2023-07-07 16:09:55,246 - epoch:8,	loss:0.6083915559574962
2023-07-07 16:09:58,574 - right_count:163	total:433	 Answer ACC: 0.37644341801385683
2023-07-07 16:09:58,574 - right_codes_count:134	total:433	 Code ACC: 0.3094688221709007
2023-07-07 16:09:58,574 - wrong_be_tree_count:51	wrong_total:270	 wrong be tree ACC: 0.18888888888888888
2023-07-07 16:09:58,577 - save best model to ./output/test/best_model
2023-07-07 16:10:19,710 - 


2023-07-07 16:10:19,710 - epoch:9,	loss:0.556087389588356
2023-07-07 16:10:22,787 - right_count:189	total:433	 Answer ACC: 0.43648960739030024
2023-07-07 16:10:22,787 - right_codes_count:154	total:433	 Code ACC: 0.3556581986143187
2023-07-07 16:10:22,787 - wrong_be_tree_count:38	wrong_total:244	 wrong be tree ACC: 0.1557377049180328
2023-07-07 16:10:22,789 - save best model to ./output/test/best_model
2023-07-07 16:10:44,037 - 


2023-07-07 16:10:44,037 - epoch:10,	loss:0.5088585601188242
2023-07-07 16:10:47,298 - right_count:213	total:433	 Answer ACC: 0.49191685912240185
2023-07-07 16:10:47,298 - right_codes_count:179	total:433	 Code ACC: 0.4133949191685912
2023-07-07 16:10:47,298 - wrong_be_tree_count:58	wrong_total:220	 wrong be tree ACC: 0.2636363636363636
2023-07-07 16:10:47,300 - save best model to ./output/test/best_model
2023-07-07 16:11:08,252 - 


2023-07-07 16:11:08,252 - epoch:11,	loss:0.46613616961985826
2023-07-07 16:11:11,555 - right_count:223	total:433	 Answer ACC: 0.5150115473441108
2023-07-07 16:11:11,555 - right_codes_count:193	total:433	 Code ACC: 0.4457274826789838
2023-07-07 16:11:11,555 - wrong_be_tree_count:69	wrong_total:210	 wrong be tree ACC: 0.32857142857142857
2023-07-07 16:11:11,557 - save best model to ./output/test/best_model
2023-07-07 16:11:37,959 - 


2023-07-07 16:11:37,969 - epoch:12,	loss:0.4201028570532799
2023-07-07 16:11:41,160 - right_count:246	total:433	 Answer ACC: 0.5681293302540416
2023-07-07 16:11:41,160 - right_codes_count:218	total:433	 Code ACC: 0.5034642032332564
2023-07-07 16:11:41,160 - wrong_be_tree_count:83	wrong_total:187	 wrong be tree ACC: 0.44385026737967914
2023-07-07 16:11:41,162 - save best model to ./output/test/best_model
2023-07-07 16:12:14,424 - 


2023-07-07 16:12:14,424 - epoch:13,	loss:0.38029321702197194
2023-07-07 16:12:17,611 - right_count:260	total:433	 Answer ACC: 0.6004618937644342
2023-07-07 16:12:17,612 - right_codes_count:233	total:433	 Code ACC: 0.5381062355658198
2023-07-07 16:12:17,612 - wrong_be_tree_count:81	wrong_total:173	 wrong be tree ACC: 0.4682080924855491
2023-07-07 16:12:17,623 - save best model to ./output/test/best_model
2023-07-07 16:12:46,375 - 


2023-07-07 16:12:46,375 - epoch:14,	loss:0.34414549893699586
2023-07-07 16:12:49,828 - right_count:283	total:433	 Answer ACC: 0.6535796766743649
2023-07-07 16:12:49,828 - right_codes_count:261	total:433	 Code ACC: 0.6027713625866051
2023-07-07 16:12:49,828 - wrong_be_tree_count:69	wrong_total:150	 wrong be tree ACC: 0.46
2023-07-07 16:12:49,830 - save best model to ./output/test/best_model
2023-07-07 16:13:20,378 - 


2023-07-07 16:13:20,378 - epoch:15,	loss:0.3213688733521849
2023-07-07 16:13:24,363 - right_count:288	total:433	 Answer ACC: 0.6651270207852193
2023-07-07 16:13:24,364 - right_codes_count:265	total:433	 Code ACC: 0.6120092378752887
2023-07-07 16:13:24,364 - wrong_be_tree_count:57	wrong_total:145	 wrong be tree ACC: 0.3931034482758621
2023-07-07 16:13:24,373 - save best model to ./output/test/best_model
2023-07-07 16:13:43,824 - 


2023-07-07 16:13:43,824 - epoch:16,	loss:0.30410903971642256
2023-07-07 16:13:47,202 - right_count:301	total:433	 Answer ACC: 0.6951501154734411
2023-07-07 16:13:47,203 - right_codes_count:278	total:433	 Code ACC: 0.6420323325635104
2023-07-07 16:13:47,203 - wrong_be_tree_count:49	wrong_total:132	 wrong be tree ACC: 0.3712121212121212
2023-07-07 16:13:47,205 - save best model to ./output/test/best_model
2023-07-07 16:14:05,766 - 


2023-07-07 16:14:05,766 - epoch:17,	loss:0.2821542979218066
2023-07-07 16:14:09,120 - right_count:303	total:433	 Answer ACC: 0.6997690531177829
2023-07-07 16:14:09,121 - right_codes_count:279	total:433	 Code ACC: 0.6443418013856813
2023-07-07 16:14:09,121 - wrong_be_tree_count:51	wrong_total:130	 wrong be tree ACC: 0.3923076923076923
2023-07-07 16:14:09,123 - save best model to ./output/test/best_model
2023-07-07 16:14:29,172 - 


2023-07-07 16:14:29,172 - epoch:18,	loss:0.27043105009943247
2023-07-07 16:14:32,464 - right_count:302	total:433	 Answer ACC: 0.6974595842956121
2023-07-07 16:14:32,465 - right_codes_count:284	total:433	 Code ACC: 0.6558891454965358
2023-07-07 16:14:32,465 - wrong_be_tree_count:55	wrong_total:131	 wrong be tree ACC: 0.4198473282442748
2023-07-07 16:14:44,212 - 


2023-07-07 16:14:44,212 - epoch:19,	loss:0.24519148492254317
2023-07-07 16:14:47,457 - right_count:307	total:433	 Answer ACC: 0.7090069284064665
2023-07-07 16:14:47,458 - right_codes_count:286	total:433	 Code ACC: 0.6605080831408776
2023-07-07 16:14:47,458 - wrong_be_tree_count:55	wrong_total:126	 wrong be tree ACC: 0.4365079365079365
2023-07-07 16:14:47,467 - save best model to ./output/test/best_model
2023-07-07 16:15:08,501 - 


2023-07-07 16:15:08,501 - epoch:20,	loss:0.2314369457308203
2023-07-07 16:15:11,716 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-07 16:15:11,716 - right_codes_count:297	total:433	 Code ACC: 0.6859122401847575
2023-07-07 16:15:11,716 - wrong_be_tree_count:44	wrong_total:119	 wrong be tree ACC: 0.3697478991596639
2023-07-07 16:15:11,720 - save best model to ./output/test/best_model
2023-07-07 16:15:30,572 - 


2023-07-07 16:15:30,573 - epoch:21,	loss:0.21982875559478998
2023-07-07 16:15:33,721 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-07 16:15:33,721 - right_codes_count:298	total:433	 Code ACC: 0.6882217090069284
2023-07-07 16:15:33,721 - wrong_be_tree_count:42	wrong_total:117	 wrong be tree ACC: 0.358974358974359
2023-07-07 16:15:33,729 - save best model to ./output/test/best_model
2023-07-07 16:15:55,901 - 


2023-07-07 16:15:55,901 - epoch:22,	loss:0.20526675297878683
2023-07-07 16:15:59,092 - right_count:317	total:433	 Answer ACC: 0.7321016166281755
2023-07-07 16:15:59,092 - right_codes_count:299	total:433	 Code ACC: 0.6905311778290993
2023-07-07 16:15:59,092 - wrong_be_tree_count:43	wrong_total:116	 wrong be tree ACC: 0.3706896551724138
2023-07-07 16:15:59,104 - save best model to ./output/test/best_model
2023-07-07 16:16:23,272 - 


2023-07-07 16:16:23,272 - epoch:23,	loss:0.2013801058055833
2023-07-07 16:16:26,634 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 16:16:26,634 - right_codes_count:301	total:433	 Code ACC: 0.6951501154734411
2023-07-07 16:16:26,634 - wrong_be_tree_count:41	wrong_total:111	 wrong be tree ACC: 0.36936936936936937
2023-07-07 16:16:26,637 - save best model to ./output/test/best_model
2023-07-07 16:16:52,067 - 


2023-07-07 16:16:52,068 - epoch:24,	loss:0.19289343687705696
2023-07-07 16:16:55,330 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-07 16:16:55,331 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-07 16:16:55,331 - wrong_be_tree_count:40	wrong_total:114	 wrong be tree ACC: 0.3508771929824561
2023-07-07 16:17:11,246 - 


2023-07-07 16:17:11,246 - epoch:25,	loss:0.18114392855204642
2023-07-07 16:17:14,436 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 16:17:14,436 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-07 16:17:14,436 - wrong_be_tree_count:41	wrong_total:112	 wrong be tree ACC: 0.36607142857142855
2023-07-07 16:17:29,661 - 


2023-07-07 16:17:29,661 - epoch:26,	loss:0.17790582356974483
2023-07-07 16:17:32,848 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:17:32,848 - right_codes_count:308	total:433	 Code ACC: 0.7113163972286374
2023-07-07 16:17:32,848 - wrong_be_tree_count:37	wrong_total:105	 wrong be tree ACC: 0.3523809523809524
2023-07-07 16:17:32,850 - save best model to ./output/test/best_model
2023-07-07 16:17:56,239 - 


2023-07-07 16:17:56,239 - epoch:27,	loss:0.176194301340729
2023-07-07 16:17:59,449 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 16:17:59,449 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 16:17:59,449 - wrong_be_tree_count:34	wrong_total:112	 wrong be tree ACC: 0.30357142857142855
2023-07-07 16:18:11,763 - 


2023-07-07 16:18:11,763 - epoch:28,	loss:0.16434376826509833
2023-07-07 16:18:15,358 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 16:18:15,358 - right_codes_count:305	total:433	 Code ACC: 0.7043879907621247
2023-07-07 16:18:15,358 - wrong_be_tree_count:40	wrong_total:109	 wrong be tree ACC: 0.3669724770642202
2023-07-07 16:18:28,891 - 


2023-07-07 16:18:28,891 - epoch:29,	loss:0.16439226875081658
2023-07-07 16:18:32,104 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 16:18:32,104 - right_codes_count:307	total:433	 Code ACC: 0.7090069284064665
2023-07-07 16:18:32,104 - wrong_be_tree_count:37	wrong_total:112	 wrong be tree ACC: 0.33035714285714285
2023-07-07 16:18:47,269 - 


2023-07-07 16:18:47,269 - epoch:30,	loss:0.162734056240879
2023-07-07 16:18:51,328 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 16:18:51,328 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 16:18:51,328 - wrong_be_tree_count:38	wrong_total:108	 wrong be tree ACC: 0.35185185185185186
2023-07-07 16:19:04,152 - 


2023-07-07 16:19:04,152 - epoch:31,	loss:0.15178991411812603
2023-07-07 16:19:07,364 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 16:19:07,364 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-07 16:19:07,364 - wrong_be_tree_count:34	wrong_total:111	 wrong be tree ACC: 0.3063063063063063
2023-07-07 16:19:20,618 - 


2023-07-07 16:19:20,618 - epoch:32,	loss:0.14738995872903615
2023-07-07 16:19:23,748 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 16:19:23,748 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 16:19:23,748 - wrong_be_tree_count:37	wrong_total:106	 wrong be tree ACC: 0.3490566037735849
2023-07-07 16:19:37,457 - 


2023-07-07 16:19:37,457 - epoch:33,	loss:0.14179722894914448
2023-07-07 16:19:40,834 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:19:40,834 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 16:19:40,834 - wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
2023-07-07 16:19:40,836 - save best model to ./output/test/best_model
2023-07-07 16:20:00,403 - 


2023-07-07 16:20:00,403 - epoch:34,	loss:0.14049719332251698
2023-07-07 16:20:03,830 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:20:03,830 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 16:20:03,830 - wrong_be_tree_count:32	wrong_total:104	 wrong be tree ACC: 0.3076923076923077
2023-07-07 16:20:17,639 - 


2023-07-07 16:20:17,639 - epoch:35,	loss:0.14038351422641426
2023-07-07 16:20:20,906 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 16:20:20,906 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:20:20,906 - wrong_be_tree_count:35	wrong_total:108	 wrong be tree ACC: 0.32407407407407407
2023-07-07 16:20:32,499 - 


2023-07-07 16:20:32,499 - epoch:36,	loss:0.13953421404585242
2023-07-07 16:20:35,781 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:20:35,781 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:20:35,781 - wrong_be_tree_count:36	wrong_total:102	 wrong be tree ACC: 0.35294117647058826
2023-07-07 16:20:46,931 - 


2023-07-07 16:20:46,931 - epoch:37,	loss:0.13298780441982672
2023-07-07 16:20:50,191 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:20:50,191 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 16:20:50,191 - wrong_be_tree_count:35	wrong_total:105	 wrong be tree ACC: 0.3333333333333333
2023-07-07 16:21:03,187 - 


2023-07-07 16:21:03,187 - epoch:38,	loss:0.1304018198279664
2023-07-07 16:21:06,459 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:21:06,459 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:21:06,459 - wrong_be_tree_count:38	wrong_total:100	 wrong be tree ACC: 0.38
2023-07-07 16:21:06,464 - save best model to ./output/test/best_model
2023-07-07 16:21:24,810 - 


2023-07-07 16:21:24,811 - epoch:39,	loss:0.1278692380292341
2023-07-07 16:21:28,105 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:21:28,105 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:21:28,105 - wrong_be_tree_count:45	wrong_total:102	 wrong be tree ACC: 0.4411764705882353
2023-07-07 16:21:39,887 - 


2023-07-07 16:21:39,887 - epoch:40,	loss:0.12971162586472929
2023-07-07 16:21:43,060 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:21:43,060 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:21:43,060 - wrong_be_tree_count:39	wrong_total:101	 wrong be tree ACC: 0.38613861386138615
2023-07-07 16:21:54,631 - 


2023-07-07 16:21:54,631 - epoch:41,	loss:0.12092199845938012
2023-07-07 16:21:57,903 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:21:57,904 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:21:57,904 - wrong_be_tree_count:39	wrong_total:102	 wrong be tree ACC: 0.38235294117647056
2023-07-07 16:22:09,359 - 


2023-07-07 16:22:09,359 - epoch:42,	loss:0.11873060470679775
2023-07-07 16:22:12,504 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:22:12,504 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 16:22:12,505 - wrong_be_tree_count:42	wrong_total:104	 wrong be tree ACC: 0.40384615384615385
2023-07-07 16:22:23,747 - 


2023-07-07 16:22:23,747 - epoch:43,	loss:0.11642347014276311
2023-07-07 16:22:26,909 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:22:26,910 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:22:26,910 - wrong_be_tree_count:39	wrong_total:103	 wrong be tree ACC: 0.3786407766990291
2023-07-07 16:22:38,260 - 


2023-07-07 16:22:38,260 - epoch:44,	loss:0.11505602404940873
2023-07-07 16:22:41,522 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:22:41,523 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:22:41,523 - wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
2023-07-07 16:22:52,972 - 


2023-07-07 16:22:52,972 - epoch:45,	loss:0.11240657250164077
2023-07-07 16:22:56,256 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:22:56,256 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:22:56,256 - wrong_be_tree_count:43	wrong_total:103	 wrong be tree ACC: 0.4174757281553398
2023-07-07 16:23:07,451 - 


2023-07-07 16:23:07,451 - epoch:46,	loss:0.10778309870511293
2023-07-07 16:23:10,624 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:23:10,625 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:23:10,625 - wrong_be_tree_count:44	wrong_total:101	 wrong be tree ACC: 0.43564356435643564
2023-07-07 16:23:22,007 - 


2023-07-07 16:23:22,007 - epoch:47,	loss:0.11299526563379914
2023-07-07 16:23:25,192 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:23:25,192 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:23:25,192 - wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-07 16:23:36,656 - 


2023-07-07 16:23:36,656 - epoch:48,	loss:0.10573645553085953
2023-07-07 16:23:39,852 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:23:39,852 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:23:39,853 - wrong_be_tree_count:38	wrong_total:98	 wrong be tree ACC: 0.3877551020408163
2023-07-07 16:23:39,854 - save best model to ./output/test/best_model
2023-07-07 16:23:57,555 - 


2023-07-07 16:23:57,555 - epoch:49,	loss:0.10527157428441569
2023-07-07 16:24:00,741 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:24:00,741 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:24:00,741 - wrong_be_tree_count:39	wrong_total:101	 wrong be tree ACC: 0.38613861386138615
2023-07-07 16:24:12,173 - 


2023-07-07 16:24:12,173 - epoch:50,	loss:0.10204894994967617
2023-07-07 16:24:15,416 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:24:15,417 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:24:15,417 - wrong_be_tree_count:39	wrong_total:103	 wrong be tree ACC: 0.3786407766990291
2023-07-07 16:24:28,100 - 


2023-07-07 16:24:28,101 - epoch:51,	loss:0.10086207068525255
2023-07-07 16:24:31,318 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:24:31,318 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:24:31,318 - wrong_be_tree_count:37	wrong_total:100	 wrong be tree ACC: 0.37
2023-07-07 16:24:42,613 - 


2023-07-07 16:24:42,613 - epoch:52,	loss:0.10004372498951852
2023-07-07 16:24:45,866 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 16:24:45,866 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:24:45,866 - wrong_be_tree_count:37	wrong_total:99	 wrong be tree ACC: 0.37373737373737376
2023-07-07 16:24:57,119 - 


2023-07-07 16:24:57,119 - epoch:53,	loss:0.09826713474467397
2023-07-07 16:25:00,374 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:25:00,374 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:25:00,374 - wrong_be_tree_count:38	wrong_total:104	 wrong be tree ACC: 0.36538461538461536
2023-07-07 16:25:11,697 - 


2023-07-07 16:25:11,697 - epoch:54,	loss:0.09561943728476763
2023-07-07 16:25:15,066 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:25:15,066 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:25:15,066 - wrong_be_tree_count:34	wrong_total:105	 wrong be tree ACC: 0.3238095238095238
2023-07-07 16:25:27,263 - 


2023-07-07 16:25:27,264 - epoch:55,	loss:0.09396973467664793
2023-07-07 16:25:30,858 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:25:30,858 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 16:25:30,858 - wrong_be_tree_count:39	wrong_total:104	 wrong be tree ACC: 0.375
2023-07-07 16:25:43,170 - 


2023-07-07 16:25:43,170 - epoch:56,	loss:0.09501565562095493
2023-07-07 16:25:46,354 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:25:46,354 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:25:46,354 - wrong_be_tree_count:37	wrong_total:104	 wrong be tree ACC: 0.3557692307692308
2023-07-07 16:25:58,141 - 


2023-07-07 16:25:58,141 - epoch:57,	loss:0.09122404101071879
2023-07-07 16:26:01,386 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 16:26:01,386 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:26:01,386 - wrong_be_tree_count:41	wrong_total:108	 wrong be tree ACC: 0.37962962962962965
2023-07-07 16:26:13,435 - 


2023-07-07 16:26:13,435 - epoch:58,	loss:0.09139801329001784
2023-07-07 16:26:16,932 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:26:16,932 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:26:16,932 - wrong_be_tree_count:41	wrong_total:103	 wrong be tree ACC: 0.39805825242718446
2023-07-07 16:26:29,289 - 


2023-07-07 16:26:29,289 - epoch:59,	loss:0.0899558705277741
2023-07-07 16:26:32,584 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:26:32,584 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:26:32,584 - wrong_be_tree_count:40	wrong_total:102	 wrong be tree ACC: 0.39215686274509803
2023-07-07 16:26:44,163 - 


2023-07-07 16:26:44,163 - epoch:60,	loss:0.09115804132306948
2023-07-07 16:26:47,362 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:26:47,362 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:26:47,362 - wrong_be_tree_count:35	wrong_total:101	 wrong be tree ACC: 0.3465346534653465
2023-07-07 16:26:59,084 - 


2023-07-07 16:26:59,084 - epoch:61,	loss:0.08812963054515421
2023-07-07 16:27:02,336 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:27:02,336 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 16:27:02,336 - wrong_be_tree_count:38	wrong_total:105	 wrong be tree ACC: 0.3619047619047619
2023-07-07 16:27:15,603 - 


2023-07-07 16:27:15,603 - epoch:62,	loss:0.08649761084234342
2023-07-07 16:27:18,839 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:27:18,839 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:27:18,840 - wrong_be_tree_count:40	wrong_total:104	 wrong be tree ACC: 0.38461538461538464
2023-07-07 16:27:32,028 - 


2023-07-07 16:27:32,029 - epoch:63,	loss:0.08316599042154849
2023-07-07 16:27:35,262 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:27:35,263 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:27:35,263 - wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-07 16:27:47,005 - 


2023-07-07 16:27:47,005 - epoch:64,	loss:0.08288775372784585
2023-07-07 16:27:50,074 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:27:50,074 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:27:50,074 - wrong_be_tree_count:31	wrong_total:100	 wrong be tree ACC: 0.31
2023-07-07 16:28:02,091 - 


2023-07-07 16:28:02,092 - epoch:65,	loss:0.08264766121283174
2023-07-07 16:28:05,490 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:28:05,490 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:28:05,490 - wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-07 16:28:17,087 - 


2023-07-07 16:28:17,087 - epoch:66,	loss:0.08210896578384563
2023-07-07 16:28:20,183 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:28:20,183 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:28:20,183 - wrong_be_tree_count:42	wrong_total:102	 wrong be tree ACC: 0.4117647058823529
2023-07-07 16:28:32,088 - 


2023-07-07 16:28:32,088 - epoch:67,	loss:0.08033686081762426
2023-07-07 16:28:35,377 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:28:35,378 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:28:35,378 - wrong_be_tree_count:42	wrong_total:104	 wrong be tree ACC: 0.40384615384615385
2023-07-07 16:28:47,094 - 


2023-07-07 16:28:47,095 - epoch:68,	loss:0.0780323474900797
2023-07-07 16:28:50,343 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:28:50,343 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 16:28:50,343 - wrong_be_tree_count:40	wrong_total:105	 wrong be tree ACC: 0.38095238095238093
2023-07-07 16:29:01,980 - 


2023-07-07 16:29:01,980 - epoch:69,	loss:0.07787053525680676
2023-07-07 16:29:05,329 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 16:29:05,330 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:29:05,330 - wrong_be_tree_count:43	wrong_total:106	 wrong be tree ACC: 0.4056603773584906
2023-07-07 16:29:16,862 - 


2023-07-07 16:29:16,862 - epoch:70,	loss:0.07635372978984378
2023-07-07 16:29:20,689 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:29:20,689 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:29:20,689 - wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
2023-07-07 16:29:31,726 - 


2023-07-07 16:29:31,727 - epoch:71,	loss:0.07412000023759902
2023-07-07 16:29:35,565 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:29:35,565 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:29:35,568 - wrong_be_tree_count:34	wrong_total:103	 wrong be tree ACC: 0.3300970873786408
2023-07-07 16:29:46,433 - 


2023-07-07 16:29:46,433 - epoch:72,	loss:0.07503280614037067
2023-07-07 16:29:50,340 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:29:50,340 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:29:50,346 - wrong_be_tree_count:37	wrong_total:101	 wrong be tree ACC: 0.36633663366336633
2023-07-07 16:30:01,508 - 


2023-07-07 16:30:01,508 - epoch:73,	loss:0.07298400255967863
2023-07-07 16:30:05,483 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 16:30:05,483 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 16:30:05,498 - wrong_be_tree_count:39	wrong_total:106	 wrong be tree ACC: 0.36792452830188677
2023-07-07 16:30:16,534 - 


2023-07-07 16:30:16,535 - epoch:74,	loss:0.073134391248459
2023-07-07 16:30:20,079 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:30:20,079 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:30:20,080 - wrong_be_tree_count:40	wrong_total:104	 wrong be tree ACC: 0.38461538461538464
2023-07-07 16:30:31,842 - 


2023-07-07 16:30:31,842 - epoch:75,	loss:0.06949928915128112
2023-07-07 16:30:35,765 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 16:30:35,765 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:30:35,765 - wrong_be_tree_count:41	wrong_total:104	 wrong be tree ACC: 0.3942307692307692
2023-07-07 16:30:46,557 - 


2023-07-07 16:30:46,557 - epoch:76,	loss:0.0684566488780547
2023-07-07 16:30:50,518 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:30:50,518 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:30:50,518 - wrong_be_tree_count:40	wrong_total:101	 wrong be tree ACC: 0.39603960396039606
2023-07-07 16:31:01,579 - 


2023-07-07 16:31:01,579 - epoch:77,	loss:0.06795953717664815
2023-07-07 16:31:05,798 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 16:31:05,798 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:31:05,798 - wrong_be_tree_count:41	wrong_total:106	 wrong be tree ACC: 0.3867924528301887
2023-07-07 16:31:16,819 - 


2023-07-07 16:31:16,819 - epoch:78,	loss:0.06658283676370047
2023-07-07 16:31:19,979 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:31:19,979 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:31:19,979 - wrong_be_tree_count:39	wrong_total:102	 wrong be tree ACC: 0.38235294117647056
2023-07-07 16:31:31,873 - 


2023-07-07 16:31:31,873 - epoch:79,	loss:0.06787640516995452
2023-07-07 16:31:35,012 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:31:35,012 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:31:35,012 - wrong_be_tree_count:37	wrong_total:103	 wrong be tree ACC: 0.3592233009708738
2023-07-07 16:31:46,804 - 


2023-07-07 16:31:46,804 - epoch:80,	loss:0.06512763776117936
2023-07-07 16:31:50,083 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:31:50,083 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 16:31:50,083 - wrong_be_tree_count:37	wrong_total:105	 wrong be tree ACC: 0.3523809523809524
2023-07-07 16:32:02,065 - 


2023-07-07 16:32:02,066 - epoch:81,	loss:0.06665801504277624
2023-07-07 16:32:05,453 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 16:32:05,453 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 16:32:05,453 - wrong_be_tree_count:39	wrong_total:108	 wrong be tree ACC: 0.3611111111111111
2023-07-07 16:32:16,943 - 


2023-07-07 16:32:16,944 - epoch:82,	loss:0.0657203207956627
2023-07-07 16:32:20,119 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 16:32:20,119 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:32:20,119 - wrong_be_tree_count:41	wrong_total:107	 wrong be tree ACC: 0.38317757009345793
2023-07-07 16:32:31,625 - 


2023-07-07 16:32:31,625 - epoch:83,	loss:0.06880073726642877
2023-07-07 16:32:34,791 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:32:34,791 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:32:34,791 - wrong_be_tree_count:40	wrong_total:103	 wrong be tree ACC: 0.3883495145631068
2023-07-07 16:32:46,235 - 


2023-07-07 16:32:46,235 - epoch:84,	loss:0.062409307778580114
2023-07-07 16:32:49,639 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:32:49,639 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:32:49,639 - wrong_be_tree_count:34	wrong_total:102	 wrong be tree ACC: 0.3333333333333333
2023-07-07 16:33:00,673 - 


2023-07-07 16:33:00,674 - epoch:85,	loss:0.06199650021153502
2023-07-07 16:33:03,992 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 16:33:03,992 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 16:33:03,992 - wrong_be_tree_count:41	wrong_total:105	 wrong be tree ACC: 0.3904761904761905
2023-07-07 16:33:15,124 - 


2023-07-07 16:33:15,124 - epoch:86,	loss:0.06294505437836051
2023-07-07 16:33:18,333 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:33:18,333 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:33:18,333 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:33:30,202 - 


2023-07-07 16:33:30,202 - epoch:87,	loss:0.062278938363306224
2023-07-07 16:33:33,576 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:33:33,576 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 16:33:33,576 - wrong_be_tree_count:43	wrong_total:103	 wrong be tree ACC: 0.4174757281553398
2023-07-07 16:33:44,571 - 


2023-07-07 16:33:44,572 - epoch:88,	loss:0.062139447953086346
2023-07-07 16:33:47,762 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:33:47,762 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:33:47,762 - wrong_be_tree_count:38	wrong_total:102	 wrong be tree ACC: 0.37254901960784315
2023-07-07 16:33:59,095 - 


2023-07-07 16:33:59,095 - epoch:89,	loss:0.06156477838521823
2023-07-07 16:34:02,644 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 16:34:02,645 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 16:34:02,645 - wrong_be_tree_count:37	wrong_total:99	 wrong be tree ACC: 0.37373737373737376
2023-07-07 16:34:18,146 - 


2023-07-07 16:34:18,146 - epoch:90,	loss:0.060565645864699036
2023-07-07 16:34:21,721 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:34:21,721 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:34:21,722 - wrong_be_tree_count:42	wrong_total:100	 wrong be tree ACC: 0.42
2023-07-07 16:34:36,788 - 


2023-07-07 16:34:36,788 - epoch:91,	loss:0.06030749890487641
2023-07-07 16:34:40,018 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:34:40,018 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 16:34:40,018 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-07 16:34:51,870 - 


2023-07-07 16:34:51,870 - epoch:92,	loss:0.05978675413643941
2023-07-07 16:34:55,140 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:34:55,140 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:34:55,140 - wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
2023-07-07 16:35:06,705 - 


2023-07-07 16:35:06,705 - epoch:93,	loss:0.060246667824685574
2023-07-07 16:35:10,182 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 16:35:10,182 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 16:35:10,182 - wrong_be_tree_count:37	wrong_total:97	 wrong be tree ACC: 0.38144329896907214
2023-07-07 16:35:10,184 - save best model to ./output/test/best_model
2023-07-07 16:35:26,738 - 


2023-07-07 16:35:26,738 - epoch:94,	loss:0.058826392763876356
2023-07-07 16:35:29,978 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:35:29,978 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:35:29,978 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:35:43,187 - 


2023-07-07 16:35:43,187 - epoch:95,	loss:0.059780508949188516
2023-07-07 16:35:46,523 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 16:35:46,523 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 16:35:46,530 - wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-07 16:35:58,194 - 


2023-07-07 16:35:58,194 - epoch:96,	loss:0.05865449205157347
2023-07-07 16:36:01,830 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:36:01,831 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:36:01,831 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 16:36:12,850 - 


2023-07-07 16:36:12,851 - epoch:97,	loss:0.05785741392173804
2023-07-07 16:36:16,125 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:36:16,125 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:36:16,125 - wrong_be_tree_count:42	wrong_total:98	 wrong be tree ACC: 0.42857142857142855
2023-07-07 16:36:26,932 - 


2023-07-07 16:36:26,932 - epoch:98,	loss:0.05823084953590296
2023-07-07 16:36:30,265 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:36:30,265 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:36:30,266 - wrong_be_tree_count:43	wrong_total:101	 wrong be tree ACC: 0.42574257425742573
2023-07-07 16:36:41,835 - 


2023-07-07 16:36:41,835 - epoch:99,	loss:0.057291851699119434
2023-07-07 16:36:45,199 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:36:45,199 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:36:45,199 - wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
2023-07-07 16:36:57,371 - 


2023-07-07 16:36:57,371 - epoch:100,	loss:0.057266796473413706
2023-07-07 16:37:00,675 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 16:37:00,675 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 16:37:00,675 - wrong_be_tree_count:44	wrong_total:103	 wrong be tree ACC: 0.42718446601941745
2023-07-07 16:37:13,989 - 


2023-07-07 16:37:13,989 - epoch:101,	loss:0.05661530769430101
2023-07-07 16:37:17,433 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:37:17,433 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:37:17,433 - wrong_be_tree_count:42	wrong_total:100	 wrong be tree ACC: 0.42
2023-07-07 16:37:32,411 - 


2023-07-07 16:37:32,411 - epoch:102,	loss:0.05898605435504578
2023-07-07 16:37:35,767 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:37:35,767 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 16:37:35,767 - wrong_be_tree_count:44	wrong_total:98	 wrong be tree ACC: 0.4489795918367347
2023-07-07 16:37:57,366 - 


2023-07-07 16:37:57,366 - epoch:103,	loss:0.057357063808012754
2023-07-07 16:38:00,661 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 16:38:00,661 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 16:38:00,661 - wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-07 16:38:20,853 - 


2023-07-07 16:38:20,853 - epoch:104,	loss:0.060553938790690154
2023-07-07 16:38:24,019 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:38:24,020 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:38:24,020 - wrong_be_tree_count:45	wrong_total:100	 wrong be tree ACC: 0.45
2023-07-07 16:38:43,188 - 


2023-07-07 16:38:43,188 - epoch:105,	loss:0.05678787166834809
2023-07-07 16:38:46,324 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:38:46,324 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:38:46,324 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 16:39:07,013 - 


2023-07-07 16:39:07,013 - epoch:106,	loss:0.056482033571228385
2023-07-07 16:39:10,246 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:39:10,247 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:39:10,247 - wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
2023-07-07 16:39:28,075 - 


2023-07-07 16:39:28,075 - epoch:107,	loss:0.05696161088417284
2023-07-07 16:39:31,322 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:39:31,322 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:39:31,322 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:39:45,498 - 


2023-07-07 16:39:45,498 - epoch:108,	loss:0.05564448190853
2023-07-07 16:39:48,752 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:39:48,752 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:39:48,752 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:40:01,999 - 


2023-07-07 16:40:01,999 - epoch:109,	loss:0.05551907225162722
2023-07-07 16:40:05,478 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 16:40:05,478 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 16:40:05,478 - wrong_be_tree_count:40	wrong_total:96	 wrong be tree ACC: 0.4166666666666667
2023-07-07 16:40:05,481 - save best model to ./output/test/best_model
2023-07-07 16:40:24,376 - 


2023-07-07 16:40:24,377 - epoch:110,	loss:0.05507177338586189
2023-07-07 16:40:27,904 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 16:40:27,904 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 16:40:27,904 - wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-07 16:40:39,919 - 


2023-07-07 16:40:39,919 - epoch:111,	loss:0.05480067506141495
2023-07-07 16:40:43,436 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:40:43,436 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:40:43,436 - wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
2023-07-07 16:40:54,901 - 


2023-07-07 16:40:54,901 - epoch:112,	loss:0.05879915569676086
2023-07-07 16:40:58,222 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 16:40:58,223 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 16:40:58,223 - wrong_be_tree_count:43	wrong_total:102	 wrong be tree ACC: 0.4215686274509804
2023-07-07 16:41:10,774 - 


2023-07-07 16:41:10,774 - epoch:113,	loss:0.05509884451748803
2023-07-07 16:41:14,501 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:41:14,502 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 16:41:14,502 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 16:41:26,727 - 


2023-07-07 16:41:26,727 - epoch:114,	loss:0.05415878845087718
2023-07-07 16:41:30,073 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:41:30,074 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:41:30,074 - wrong_be_tree_count:42	wrong_total:100	 wrong be tree ACC: 0.42
2023-07-07 16:41:42,553 - 


2023-07-07 16:41:42,553 - epoch:115,	loss:0.05516197715769522
2023-07-07 16:41:45,709 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:41:45,710 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 16:41:45,710 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-07 16:41:57,780 - 


2023-07-07 16:41:57,780 - epoch:116,	loss:0.054641924070892856
2023-07-07 16:42:01,001 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:42:01,001 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 16:42:01,001 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-07 16:42:13,201 - 


2023-07-07 16:42:13,201 - epoch:117,	loss:0.057273949088994414
2023-07-07 16:42:16,366 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 16:42:16,366 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 16:42:16,366 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-07 16:42:26,596 - 


2023-07-07 16:42:26,596 - epoch:118,	loss:0.05438351398333907
2023-07-07 16:42:29,691 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:42:29,691 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:42:29,691 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 16:42:39,799 - 


2023-07-07 16:42:39,799 - epoch:119,	loss:0.05445343552855775
2023-07-07 16:42:43,279 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:42:43,279 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:42:43,279 - wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
2023-07-07 16:42:53,569 - 


2023-07-07 16:42:53,569 - epoch:120,	loss:0.055429710482712835
2023-07-07 16:42:56,812 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:42:56,812 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:42:56,812 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 16:43:07,151 - 


2023-07-07 16:43:07,152 - epoch:121,	loss:0.05525841671624221
2023-07-07 16:43:10,352 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:43:10,353 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:43:10,353 - wrong_be_tree_count:40	wrong_total:101	 wrong be tree ACC: 0.39603960396039606
2023-07-07 16:43:20,698 - 


2023-07-07 16:43:20,698 - epoch:122,	loss:0.05632359909941442
2023-07-07 16:43:23,833 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:43:23,833 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:43:23,833 - wrong_be_tree_count:40	wrong_total:101	 wrong be tree ACC: 0.39603960396039606
2023-07-07 16:43:34,402 - 


2023-07-07 16:43:34,402 - epoch:123,	loss:0.05411119322525337
2023-07-07 16:43:37,718 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:43:37,718 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:43:37,718 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:43:48,501 - 


2023-07-07 16:43:48,501 - epoch:124,	loss:0.054728925897507
2023-07-07 16:43:51,588 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:43:51,588 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:43:51,588 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:44:02,624 - 


2023-07-07 16:44:02,624 - epoch:125,	loss:0.05599562174757011
2023-07-07 16:44:05,677 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:44:05,677 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:44:05,677 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:44:16,494 - 


2023-07-07 16:44:16,495 - epoch:126,	loss:0.05480119519052096
2023-07-07 16:44:19,746 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 16:44:19,746 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 16:44:19,746 - wrong_be_tree_count:40	wrong_total:101	 wrong be tree ACC: 0.39603960396039606
2023-07-07 16:44:31,396 - 


2023-07-07 16:44:31,396 - epoch:127,	loss:0.05487448288477026
2023-07-07 16:44:34,648 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:44:34,648 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:44:34,649 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:44:45,853 - 


2023-07-07 16:44:45,853 - epoch:128,	loss:0.055013567267451435
2023-07-07 16:44:49,172 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:44:49,172 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:44:49,172 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 16:44:59,614 - 


2023-07-07 16:44:59,614 - epoch:129,	loss:0.056160307954996824
2023-07-07 16:45:02,811 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 16:45:02,811 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 16:45:02,811 - wrong_be_tree_count:40	wrong_total:100	 wrong be tree ACC: 0.4
2023-07-07 17:44:31,053 - get train data loader...
2023-07-07 17:44:31,145 - get dev data loader...
2023-07-07 17:44:31,205 - define model...
2023-07-07 17:44:36,972 - define optimizer...
2023-07-07 17:44:36,973 - ===========================train setting parameters=========================
2023-07-07 17:44:36,974 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 17:44:36,974 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 17:44:36,974 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 17:44:36,974 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,974 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,974 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,974 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,975 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,977 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,977 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,977 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,977 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,977 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,977 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,977 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,977 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,979 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,980 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,981 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,982 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,982 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,983 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,984 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,984 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,984 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,984 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,984 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,984 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,984 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,984 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,984 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,985 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,986 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,986 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,987 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,988 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,989 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,989 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,990 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,991 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,991 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,991 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,991 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,992 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,992 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,992 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,992 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,993 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,993 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,994 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,995 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,995 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,995 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,996 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,996 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,996 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,996 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,996 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,996 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,996 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:36,997 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:36,998 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:36,998 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,998 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:36,998 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:36,998 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:44:36,998 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:44:36,999 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 17:44:37,000 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:44:37,001 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:44:37,001 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 17:44:37,001 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 17:44:37,001 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 17:44:37,001 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 17:44:37,001 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 17:44:37,002 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 17:44:37,002 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 17:44:37,002 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 17:44:37,002 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 17:44:37,002 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 17:44:37,002 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 17:44:37,003 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 17:44:37,003 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 17:44:37,003 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 17:44:37,003 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 17:44:37,003 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 17:44:37,003 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 17:44:37,003 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 17:44:37,003 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 17:44:37,003 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 17:44:37,003 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 17:44:37,003 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 17:44:37,004 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 17:44:37,004 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 17:44:37,005 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 17:44:42,706 - 


2023-07-07 17:44:42,706 - epoch:0,	loss:27.720148980617523
2023-07-07 17:44:45,887 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-07 17:44:45,887 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:44:45,887 - wrong_be_tree_count:414	wrong_total:432	 wrong be tree ACC: 0.9583333333333334
2023-07-07 17:44:45,889 - save best model to ./output/test/best_model
2023-07-07 17:45:01,119 - 


2023-07-07 17:45:01,119 - epoch:1,	loss:5.365400407463312
2023-07-07 17:45:04,244 - right_count:3	total:433	 Answer ACC: 0.006928406466512702
2023-07-07 17:45:04,244 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:45:04,244 - wrong_be_tree_count:427	wrong_total:430	 wrong be tree ACC: 0.9930232558139535
2023-07-07 17:45:04,246 - save best model to ./output/test/best_model
2023-07-07 17:45:19,816 - 


2023-07-07 17:45:19,817 - epoch:2,	loss:1.7383414842188358
2023-07-07 17:45:22,927 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-07 17:45:22,928 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:45:22,928 - wrong_be_tree_count:430	wrong_total:432	 wrong be tree ACC: 0.9953703703703703
2023-07-07 17:45:35,847 - 


2023-07-07 17:45:35,848 - epoch:3,	loss:1.2701822016388178
2023-07-07 17:45:39,012 - right_count:9	total:433	 Answer ACC: 0.020785219399538105
2023-07-07 17:45:39,012 - right_codes_count:1	total:433	 Code ACC: 0.0023094688221709007
2023-07-07 17:45:39,012 - wrong_be_tree_count:324	wrong_total:424	 wrong be tree ACC: 0.7641509433962265
2023-07-07 17:45:39,015 - save best model to ./output/test/best_model
2023-07-07 17:45:54,252 - 


2023-07-07 17:45:54,252 - epoch:4,	loss:1.1207787543535233
2023-07-07 17:45:57,480 - right_count:12	total:433	 Answer ACC: 0.02771362586605081
2023-07-07 17:45:57,480 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:45:57,480 - wrong_be_tree_count:304	wrong_total:421	 wrong be tree ACC: 0.7220902612826603
2023-07-07 17:45:57,483 - save best model to ./output/test/best_model
2023-07-07 17:46:13,062 - 


2023-07-07 17:46:13,062 - epoch:5,	loss:1.0266541261225939
2023-07-07 17:46:16,235 - right_count:28	total:433	 Answer ACC: 0.06466512702078522
2023-07-07 17:46:16,235 - right_codes_count:11	total:433	 Code ACC: 0.025404157043879907
2023-07-07 17:46:16,235 - wrong_be_tree_count:208	wrong_total:405	 wrong be tree ACC: 0.5135802469135803
2023-07-07 17:46:16,237 - save best model to ./output/test/best_model
2023-07-07 17:46:31,667 - 


2023-07-07 17:46:31,667 - epoch:6,	loss:0.9723202455788851
2023-07-07 17:46:34,853 - right_count:33	total:433	 Answer ACC: 0.07621247113163972
2023-07-07 17:46:34,853 - right_codes_count:16	total:433	 Code ACC: 0.03695150115473441
2023-07-07 17:46:34,853 - wrong_be_tree_count:244	wrong_total:400	 wrong be tree ACC: 0.61
2023-07-07 17:46:34,855 - save best model to ./output/test/best_model
2023-07-07 17:46:50,051 - 


2023-07-07 17:46:50,051 - epoch:7,	loss:0.9235092233866453
2023-07-07 17:46:53,303 - right_count:49	total:433	 Answer ACC: 0.11316397228637413
2023-07-07 17:46:53,303 - right_codes_count:33	total:433	 Code ACC: 0.07621247113163972
2023-07-07 17:46:53,303 - wrong_be_tree_count:255	wrong_total:384	 wrong be tree ACC: 0.6640625
2023-07-07 17:46:53,305 - save best model to ./output/test/best_model
2023-07-07 17:47:12,958 - 


2023-07-07 17:47:12,958 - epoch:8,	loss:0.882167523726821
2023-07-07 17:47:16,127 - right_count:91	total:433	 Answer ACC: 0.21016166281755197
2023-07-07 17:47:16,127 - right_codes_count:63	total:433	 Code ACC: 0.14549653579676675
2023-07-07 17:47:16,127 - wrong_be_tree_count:131	wrong_total:342	 wrong be tree ACC: 0.3830409356725146
2023-07-07 17:47:16,129 - save best model to ./output/test/best_model
2023-07-07 17:47:31,435 - 


2023-07-07 17:47:31,435 - epoch:9,	loss:0.8355464842170477
2023-07-07 17:47:34,586 - right_count:106	total:433	 Answer ACC: 0.24480369515011546
2023-07-07 17:47:34,586 - right_codes_count:76	total:433	 Code ACC: 0.17551963048498845
2023-07-07 17:47:34,586 - wrong_be_tree_count:98	wrong_total:327	 wrong be tree ACC: 0.2996941896024465
2023-07-07 17:47:34,589 - save best model to ./output/test/best_model
2023-07-07 17:47:50,127 - 


2023-07-07 17:47:50,128 - epoch:10,	loss:0.7848282782360911
2023-07-07 17:47:53,234 - right_count:122	total:433	 Answer ACC: 0.2817551963048499
2023-07-07 17:47:53,234 - right_codes_count:93	total:433	 Code ACC: 0.21478060046189376
2023-07-07 17:47:53,234 - wrong_be_tree_count:94	wrong_total:311	 wrong be tree ACC: 0.3022508038585209
2023-07-07 17:47:53,237 - save best model to ./output/test/best_model
2023-07-07 17:48:08,456 - 


2023-07-07 17:48:08,457 - epoch:11,	loss:0.7385142398998141
2023-07-07 17:48:11,654 - right_count:138	total:433	 Answer ACC: 0.3187066974595843
2023-07-07 17:48:11,654 - right_codes_count:111	total:433	 Code ACC: 0.25635103926096997
2023-07-07 17:48:11,654 - wrong_be_tree_count:60	wrong_total:295	 wrong be tree ACC: 0.2033898305084746
2023-07-07 17:48:11,656 - save best model to ./output/test/best_model
2023-07-07 17:48:26,917 - 


2023-07-07 17:48:26,917 - epoch:12,	loss:0.6937872124835849
2023-07-07 17:48:30,135 - right_count:153	total:433	 Answer ACC: 0.3533487297921478
2023-07-07 17:48:30,135 - right_codes_count:127	total:433	 Code ACC: 0.29330254041570436
2023-07-07 17:48:30,135 - wrong_be_tree_count:51	wrong_total:280	 wrong be tree ACC: 0.18214285714285713
2023-07-07 17:48:30,138 - save best model to ./output/test/best_model
2023-07-07 17:48:49,125 - 


2023-07-07 17:48:49,126 - epoch:13,	loss:0.6611379031091928
2023-07-07 17:48:52,255 - right_count:157	total:433	 Answer ACC: 0.3625866050808314
2023-07-07 17:48:52,255 - right_codes_count:128	total:433	 Code ACC: 0.2956120092378753
2023-07-07 17:48:52,255 - wrong_be_tree_count:60	wrong_total:276	 wrong be tree ACC: 0.21739130434782608
2023-07-07 17:48:52,257 - save best model to ./output/test/best_model
2023-07-07 17:49:07,266 - 


2023-07-07 17:49:07,266 - epoch:14,	loss:0.6285194428637624
2023-07-07 17:49:10,454 - right_count:169	total:433	 Answer ACC: 0.3903002309468822
2023-07-07 17:49:10,454 - right_codes_count:141	total:433	 Code ACC: 0.325635103926097
2023-07-07 17:49:10,454 - wrong_be_tree_count:46	wrong_total:264	 wrong be tree ACC: 0.17424242424242425
2023-07-07 17:49:10,456 - save best model to ./output/test/best_model
2023-07-07 17:49:25,382 - 


2023-07-07 17:49:25,382 - epoch:15,	loss:0.593063679523766
2023-07-07 17:49:28,625 - right_count:178	total:433	 Answer ACC: 0.4110854503464203
2023-07-07 17:49:28,626 - right_codes_count:144	total:433	 Code ACC: 0.3325635103926097
2023-07-07 17:49:28,626 - wrong_be_tree_count:49	wrong_total:255	 wrong be tree ACC: 0.19215686274509805
2023-07-07 17:49:28,628 - save best model to ./output/test/best_model
2023-07-07 17:49:45,069 - 


2023-07-07 17:49:45,069 - epoch:16,	loss:0.5595936896279454
2023-07-07 17:49:48,327 - right_count:188	total:433	 Answer ACC: 0.4341801385681293
2023-07-07 17:49:48,327 - right_codes_count:156	total:433	 Code ACC: 0.36027713625866054
2023-07-07 17:49:48,328 - wrong_be_tree_count:56	wrong_total:245	 wrong be tree ACC: 0.22857142857142856
2023-07-07 17:49:48,330 - save best model to ./output/test/best_model
2023-07-07 17:50:03,644 - 


2023-07-07 17:50:03,644 - epoch:17,	loss:0.5314176105894148
2023-07-07 17:50:06,786 - right_count:221	total:433	 Answer ACC: 0.5103926096997691
2023-07-07 17:50:06,786 - right_codes_count:186	total:433	 Code ACC: 0.4295612009237875
2023-07-07 17:50:06,786 - wrong_be_tree_count:63	wrong_total:212	 wrong be tree ACC: 0.2971698113207547
2023-07-07 17:50:06,789 - save best model to ./output/test/best_model
2023-07-07 17:50:27,589 - 


2023-07-07 17:50:27,589 - epoch:18,	loss:0.5094674741849303
2023-07-07 17:50:30,765 - right_count:242	total:433	 Answer ACC: 0.558891454965358
2023-07-07 17:50:30,765 - right_codes_count:199	total:433	 Code ACC: 0.45958429561200925
2023-07-07 17:50:30,765 - wrong_be_tree_count:52	wrong_total:191	 wrong be tree ACC: 0.27225130890052357
2023-07-07 17:50:30,767 - save best model to ./output/test/best_model
2023-07-07 17:50:45,876 - 


2023-07-07 17:50:45,876 - epoch:19,	loss:0.4805130837485194
2023-07-07 17:50:49,160 - right_count:243	total:433	 Answer ACC: 0.5612009237875288
2023-07-07 17:50:49,160 - right_codes_count:203	total:433	 Code ACC: 0.46882217090069284
2023-07-07 17:50:49,160 - wrong_be_tree_count:60	wrong_total:190	 wrong be tree ACC: 0.3157894736842105
2023-07-07 17:50:49,162 - save best model to ./output/test/best_model
2023-07-07 17:51:04,547 - 


2023-07-07 17:51:04,547 - epoch:20,	loss:0.4541113371960819
2023-07-07 17:51:07,682 - right_count:259	total:433	 Answer ACC: 0.5981524249422633
2023-07-07 17:51:07,682 - right_codes_count:219	total:433	 Code ACC: 0.5057736720554272
2023-07-07 17:51:07,682 - wrong_be_tree_count:68	wrong_total:174	 wrong be tree ACC: 0.39080459770114945
2023-07-07 17:51:07,684 - save best model to ./output/test/best_model
2023-07-07 17:51:22,812 - 


2023-07-07 17:51:22,812 - epoch:21,	loss:0.42933979257941246
2023-07-07 17:51:25,993 - right_count:267	total:433	 Answer ACC: 0.6166281755196305
2023-07-07 17:51:25,994 - right_codes_count:228	total:433	 Code ACC: 0.5265588914549654
2023-07-07 17:51:25,994 - wrong_be_tree_count:52	wrong_total:166	 wrong be tree ACC: 0.3132530120481928
2023-07-07 17:51:25,996 - save best model to ./output/test/best_model
2023-07-07 17:51:41,149 - 


2023-07-07 17:51:41,149 - epoch:22,	loss:0.41038250317797065
2023-07-07 17:51:44,324 - right_count:279	total:433	 Answer ACC: 0.6443418013856813
2023-07-07 17:51:44,324 - right_codes_count:241	total:433	 Code ACC: 0.5565819861431871
2023-07-07 17:51:44,324 - wrong_be_tree_count:57	wrong_total:154	 wrong be tree ACC: 0.37012987012987014
2023-07-07 17:51:44,327 - save best model to ./output/test/best_model
2023-07-07 17:52:02,951 - 


2023-07-07 17:52:02,951 - epoch:23,	loss:0.39706104109063745
2023-07-07 17:52:06,141 - right_count:283	total:433	 Answer ACC: 0.6535796766743649
2023-07-07 17:52:06,141 - right_codes_count:242	total:433	 Code ACC: 0.558891454965358
2023-07-07 17:52:06,141 - wrong_be_tree_count:50	wrong_total:150	 wrong be tree ACC: 0.3333333333333333
2023-07-07 17:52:06,144 - save best model to ./output/test/best_model
2023-07-07 17:52:21,196 - 


2023-07-07 17:52:21,196 - epoch:24,	loss:0.36854800721630454
2023-07-07 17:52:24,347 - right_count:291	total:433	 Answer ACC: 0.6720554272517321
2023-07-07 17:52:24,347 - right_codes_count:256	total:433	 Code ACC: 0.5912240184757506
2023-07-07 17:52:24,347 - wrong_be_tree_count:50	wrong_total:142	 wrong be tree ACC: 0.352112676056338
2023-07-07 17:52:24,351 - save best model to ./output/test/best_model
2023-07-07 17:52:39,628 - 


2023-07-07 17:52:39,628 - epoch:25,	loss:0.3567523309029639
2023-07-07 17:52:42,789 - right_count:303	total:433	 Answer ACC: 0.6997690531177829
2023-07-07 17:52:42,789 - right_codes_count:270	total:433	 Code ACC: 0.6235565819861432
2023-07-07 17:52:42,789 - wrong_be_tree_count:48	wrong_total:130	 wrong be tree ACC: 0.36923076923076925
2023-07-07 17:52:42,791 - save best model to ./output/test/best_model
2023-07-07 17:52:57,942 - 


2023-07-07 17:52:57,943 - epoch:26,	loss:0.33790709218010306
2023-07-07 17:53:01,161 - right_count:310	total:433	 Answer ACC: 0.7159353348729792
2023-07-07 17:53:01,161 - right_codes_count:276	total:433	 Code ACC: 0.6374133949191686
2023-07-07 17:53:01,161 - wrong_be_tree_count:41	wrong_total:123	 wrong be tree ACC: 0.3333333333333333
2023-07-07 17:53:01,163 - save best model to ./output/test/best_model
2023-07-07 17:53:16,331 - 


2023-07-07 17:53:16,331 - epoch:27,	loss:0.3264663387089968
2023-07-07 17:53:19,572 - right_count:305	total:433	 Answer ACC: 0.7043879907621247
2023-07-07 17:53:19,572 - right_codes_count:274	total:433	 Code ACC: 0.6327944572748267
2023-07-07 17:53:19,572 - wrong_be_tree_count:49	wrong_total:128	 wrong be tree ACC: 0.3828125
2023-07-07 17:53:32,395 - 


2023-07-07 17:53:32,395 - epoch:28,	loss:0.3101033251732588
2023-07-07 17:53:35,651 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-07 17:53:35,651 - right_codes_count:286	total:433	 Code ACC: 0.6605080831408776
2023-07-07 17:53:35,651 - wrong_be_tree_count:45	wrong_total:117	 wrong be tree ACC: 0.38461538461538464
2023-07-07 17:53:35,653 - save best model to ./output/test/best_model
2023-07-07 17:53:50,701 - 


2023-07-07 17:53:50,701 - epoch:29,	loss:0.3037996394559741
2023-07-07 17:53:53,939 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-07 17:53:53,939 - right_codes_count:289	total:433	 Code ACC: 0.6674364896073903
2023-07-07 17:53:53,939 - wrong_be_tree_count:45	wrong_total:113	 wrong be tree ACC: 0.39823008849557523
2023-07-07 17:53:53,942 - save best model to ./output/test/best_model
2023-07-07 17:54:09,598 - 


2023-07-07 17:54:09,599 - epoch:30,	loss:0.29203424509614706
2023-07-07 17:54:12,741 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 17:54:12,741 - right_codes_count:296	total:433	 Code ACC: 0.6836027713625866
2023-07-07 17:54:12,741 - wrong_be_tree_count:42	wrong_total:111	 wrong be tree ACC: 0.3783783783783784
2023-07-07 17:54:12,743 - save best model to ./output/test/best_model
2023-07-07 17:54:27,759 - 


2023-07-07 17:54:27,759 - epoch:31,	loss:0.27816195227205753
2023-07-07 17:54:30,902 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-07 17:54:30,902 - right_codes_count:296	total:433	 Code ACC: 0.6836027713625866
2023-07-07 17:54:30,902 - wrong_be_tree_count:42	wrong_total:110	 wrong be tree ACC: 0.38181818181818183
2023-07-07 17:54:30,905 - save best model to ./output/test/best_model
2023-07-07 17:54:46,132 - 


2023-07-07 17:54:46,133 - epoch:32,	loss:0.27030043094418943
2023-07-07 17:54:49,272 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 17:54:49,272 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-07 17:54:49,272 - wrong_be_tree_count:35	wrong_total:105	 wrong be tree ACC: 0.3333333333333333
2023-07-07 17:54:49,276 - save best model to ./output/test/best_model
2023-07-07 17:55:09,367 - 


2023-07-07 17:55:09,367 - epoch:33,	loss:0.25687641045078635
2023-07-07 17:55:12,569 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 17:55:12,569 - right_codes_count:295	total:433	 Code ACC: 0.6812933025404158
2023-07-07 17:55:12,569 - wrong_be_tree_count:38	wrong_total:111	 wrong be tree ACC: 0.34234234234234234
2023-07-07 17:55:22,801 - 


2023-07-07 17:55:22,802 - epoch:34,	loss:0.25302560278214514
2023-07-07 17:55:25,926 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-07 17:55:25,927 - right_codes_count:295	total:433	 Code ACC: 0.6812933025404158
2023-07-07 17:55:25,927 - wrong_be_tree_count:35	wrong_total:113	 wrong be tree ACC: 0.30973451327433627
2023-07-07 17:55:35,853 - 


2023-07-07 17:55:35,853 - epoch:35,	loss:0.24326171609573066
2023-07-07 17:55:39,017 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-07 17:55:39,017 - right_codes_count:292	total:433	 Code ACC: 0.674364896073903
2023-07-07 17:55:39,017 - wrong_be_tree_count:37	wrong_total:119	 wrong be tree ACC: 0.31092436974789917
2023-07-07 17:55:48,984 - 


2023-07-07 17:55:48,984 - epoch:36,	loss:0.23721798020415008
2023-07-07 17:55:52,098 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-07 17:55:52,098 - right_codes_count:297	total:433	 Code ACC: 0.6859122401847575
2023-07-07 17:55:52,098 - wrong_be_tree_count:32	wrong_total:110	 wrong be tree ACC: 0.2909090909090909
2023-07-07 17:56:02,084 - 


2023-07-07 17:56:02,084 - epoch:37,	loss:0.22748378349933773
2023-07-07 17:56:05,236 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-07 17:56:05,236 - right_codes_count:292	total:433	 Code ACC: 0.674364896073903
2023-07-07 17:56:05,236 - wrong_be_tree_count:30	wrong_total:113	 wrong be tree ACC: 0.26548672566371684
2023-07-07 17:56:15,701 - 


2023-07-07 17:56:15,701 - epoch:38,	loss:0.22304741037078202
2023-07-07 17:56:18,867 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 17:56:18,867 - right_codes_count:299	total:433	 Code ACC: 0.6905311778290993
2023-07-07 17:56:18,867 - wrong_be_tree_count:33	wrong_total:112	 wrong be tree ACC: 0.29464285714285715
2023-07-07 17:56:31,404 - 


2023-07-07 17:56:31,404 - epoch:39,	loss:0.2187914839014411
2023-07-07 17:56:34,581 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 17:56:34,581 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-07 17:56:34,581 - wrong_be_tree_count:33	wrong_total:109	 wrong be tree ACC: 0.30275229357798167
2023-07-07 17:56:44,515 - 


2023-07-07 17:56:44,515 - epoch:40,	loss:0.21299801440909505
2023-07-07 17:56:47,715 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-07 17:56:47,715 - right_codes_count:297	total:433	 Code ACC: 0.6859122401847575
2023-07-07 17:56:47,715 - wrong_be_tree_count:30	wrong_total:114	 wrong be tree ACC: 0.2631578947368421
2023-07-07 17:56:58,018 - 


2023-07-07 17:56:58,019 - epoch:41,	loss:0.20548623404465616
2023-07-07 17:57:01,178 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 17:57:01,179 - right_codes_count:302	total:433	 Code ACC: 0.6974595842956121
2023-07-07 17:57:01,179 - wrong_be_tree_count:31	wrong_total:108	 wrong be tree ACC: 0.28703703703703703
2023-07-07 17:57:12,236 - 


2023-07-07 17:57:12,236 - epoch:42,	loss:0.2024312315043062
2023-07-07 17:57:15,458 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-07 17:57:15,458 - right_codes_count:297	total:433	 Code ACC: 0.6859122401847575
2023-07-07 17:57:15,458 - wrong_be_tree_count:36	wrong_total:113	 wrong be tree ACC: 0.3185840707964602
2023-07-07 17:57:25,562 - 


2023-07-07 17:57:25,562 - epoch:43,	loss:0.20031667686998844
2023-07-07 17:57:28,715 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 17:57:28,715 - right_codes_count:305	total:433	 Code ACC: 0.7043879907621247
2023-07-07 17:57:28,715 - wrong_be_tree_count:33	wrong_total:109	 wrong be tree ACC: 0.30275229357798167
2023-07-07 17:57:38,778 - 


2023-07-07 17:57:38,778 - epoch:44,	loss:0.19583963206969202
2023-07-07 17:57:41,926 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-07 17:57:41,926 - right_codes_count:298	total:433	 Code ACC: 0.6882217090069284
2023-07-07 17:57:41,926 - wrong_be_tree_count:37	wrong_total:117	 wrong be tree ACC: 0.3162393162393162
2023-07-07 17:57:53,613 - 


2023-07-07 17:57:53,614 - epoch:45,	loss:0.1905506970360875
2023-07-07 17:57:56,796 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 17:57:56,796 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-07 17:57:56,796 - wrong_be_tree_count:32	wrong_total:108	 wrong be tree ACC: 0.2962962962962963
2023-07-07 17:58:09,038 - 


2023-07-07 17:58:09,038 - epoch:46,	loss:0.18421968386974186
2023-07-07 17:58:12,310 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 17:58:12,310 - right_codes_count:308	total:433	 Code ACC: 0.7113163972286374
2023-07-07 17:58:12,310 - wrong_be_tree_count:33	wrong_total:107	 wrong be tree ACC: 0.308411214953271
2023-07-07 17:58:22,924 - 


2023-07-07 17:58:22,925 - epoch:47,	loss:0.18364023917820305
2023-07-07 17:58:26,257 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:58:26,257 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 17:58:26,257 - wrong_be_tree_count:32	wrong_total:104	 wrong be tree ACC: 0.3076923076923077
2023-07-07 17:58:26,259 - save best model to ./output/test/best_model
2023-07-07 17:58:41,825 - 


2023-07-07 17:58:41,825 - epoch:48,	loss:0.1776506695896387
2023-07-07 17:58:45,133 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 17:58:45,133 - right_codes_count:308	total:433	 Code ACC: 0.7113163972286374
2023-07-07 17:58:45,133 - wrong_be_tree_count:33	wrong_total:106	 wrong be tree ACC: 0.3113207547169811
2023-07-07 17:58:55,187 - 


2023-07-07 17:58:55,187 - epoch:49,	loss:0.1740993153071031
2023-07-07 17:58:58,445 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-07 17:58:58,445 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 17:58:58,445 - wrong_be_tree_count:38	wrong_total:110	 wrong be tree ACC: 0.34545454545454546
2023-07-07 17:59:08,389 - 


2023-07-07 17:59:08,389 - epoch:50,	loss:0.1676749202888459
2023-07-07 17:59:11,714 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 17:59:11,714 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 17:59:11,714 - wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-07 17:59:21,680 - 


2023-07-07 17:59:21,680 - epoch:51,	loss:0.1662775642471388
2023-07-07 17:59:24,971 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:59:24,971 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 17:59:24,971 - wrong_be_tree_count:34	wrong_total:104	 wrong be tree ACC: 0.3269230769230769
2023-07-07 17:59:37,690 - 


2023-07-07 17:59:37,690 - epoch:52,	loss:0.16236144490540028
2023-07-07 17:59:41,188 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:59:41,188 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 17:59:41,188 - wrong_be_tree_count:35	wrong_total:104	 wrong be tree ACC: 0.33653846153846156
2023-07-07 17:59:51,863 - 


2023-07-07 17:59:51,863 - epoch:53,	loss:0.1612252553459257
2023-07-07 17:59:55,146 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 17:59:55,147 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 17:59:55,147 - wrong_be_tree_count:35	wrong_total:103	 wrong be tree ACC: 0.33980582524271846
2023-07-07 17:59:55,149 - save best model to ./output/test/best_model
2023-07-07 18:00:10,882 - 


2023-07-07 18:00:10,883 - epoch:54,	loss:0.1557168388972059
2023-07-07 18:00:14,188 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:00:14,189 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:00:14,189 - wrong_be_tree_count:34	wrong_total:105	 wrong be tree ACC: 0.3238095238095238
2023-07-07 18:00:24,217 - 


2023-07-07 18:00:24,217 - epoch:55,	loss:0.1556144873611629
2023-07-07 18:00:27,488 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 18:00:27,489 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:00:27,489 - wrong_be_tree_count:29	wrong_total:97	 wrong be tree ACC: 0.29896907216494845
2023-07-07 18:00:27,492 - save best model to ./output/test/best_model
2023-07-07 18:00:42,834 - 


2023-07-07 18:00:42,835 - epoch:56,	loss:0.1552577727707103
2023-07-07 18:00:46,215 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:00:46,215 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:00:46,215 - wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-07 18:00:57,826 - 


2023-07-07 18:00:57,826 - epoch:57,	loss:0.15080846974160522
2023-07-07 18:01:01,068 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:01:01,068 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:01:01,068 - wrong_be_tree_count:25	wrong_total:103	 wrong be tree ACC: 0.24271844660194175
2023-07-07 18:01:14,964 - 


2023-07-07 18:01:14,964 - epoch:58,	loss:0.1482559395954013
2023-07-07 18:01:18,216 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:01:18,216 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:01:18,216 - wrong_be_tree_count:28	wrong_total:103	 wrong be tree ACC: 0.27184466019417475
2023-07-07 18:01:28,232 - 


2023-07-07 18:01:28,232 - epoch:59,	loss:0.14725988055579364
2023-07-07 18:01:31,513 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:01:31,513 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:01:31,513 - wrong_be_tree_count:34	wrong_total:105	 wrong be tree ACC: 0.3238095238095238
2023-07-07 18:01:41,608 - 


2023-07-07 18:01:41,608 - epoch:60,	loss:0.1471973954467103
2023-07-07 18:01:45,072 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 18:01:45,072 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 18:01:45,072 - wrong_be_tree_count:39	wrong_total:108	 wrong be tree ACC: 0.3611111111111111
2023-07-07 18:01:55,129 - 


2023-07-07 18:01:55,130 - epoch:61,	loss:0.1440999370533973
2023-07-07 18:01:58,419 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:01:58,419 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:01:58,419 - wrong_be_tree_count:36	wrong_total:107	 wrong be tree ACC: 0.3364485981308411
2023-07-07 18:02:08,698 - 


2023-07-07 18:02:08,699 - epoch:62,	loss:0.13931934325955808
2023-07-07 18:02:11,864 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:02:11,865 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:02:11,865 - wrong_be_tree_count:29	wrong_total:103	 wrong be tree ACC: 0.2815533980582524
2023-07-07 18:02:22,006 - 


2023-07-07 18:02:22,006 - epoch:63,	loss:0.1388905413914472
2023-07-07 18:02:25,155 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:02:25,155 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:02:25,155 - wrong_be_tree_count:29	wrong_total:105	 wrong be tree ACC: 0.2761904761904762
2023-07-07 18:02:36,845 - 


2023-07-07 18:02:36,846 - epoch:64,	loss:0.13652996532619
2023-07-07 18:02:40,124 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:02:40,124 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:02:40,124 - wrong_be_tree_count:39	wrong_total:107	 wrong be tree ACC: 0.3644859813084112
2023-07-07 18:02:50,130 - 


2023-07-07 18:02:50,130 - epoch:65,	loss:0.1351269098231569
2023-07-07 18:02:53,450 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:02:53,450 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:02:53,450 - wrong_be_tree_count:28	wrong_total:103	 wrong be tree ACC: 0.27184466019417475
2023-07-07 18:03:03,459 - 


2023-07-07 18:03:03,460 - epoch:66,	loss:0.1323700798675418
2023-07-07 18:03:06,716 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 18:03:06,717 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:03:06,717 - wrong_be_tree_count:34	wrong_total:100	 wrong be tree ACC: 0.34
2023-07-07 18:03:16,781 - 


2023-07-07 18:03:16,782 - epoch:67,	loss:0.13109278003685176
2023-07-07 18:03:20,079 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:03:20,079 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:03:20,079 - wrong_be_tree_count:32	wrong_total:103	 wrong be tree ACC: 0.3106796116504854
2023-07-07 18:03:30,380 - 


2023-07-07 18:03:30,380 - epoch:68,	loss:0.130059173097834
2023-07-07 18:03:33,560 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:03:33,560 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:03:33,560 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 18:03:44,200 - 


2023-07-07 18:03:44,201 - epoch:69,	loss:0.12619090860243887
2023-07-07 18:03:47,471 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:03:47,472 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:03:47,472 - wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-07 18:04:00,036 - 


2023-07-07 18:04:00,037 - epoch:70,	loss:0.12465539324330166
2023-07-07 18:04:03,389 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:04:03,390 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:04:03,390 - wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-07 18:04:13,801 - 


2023-07-07 18:04:13,802 - epoch:71,	loss:0.12372860382311046
2023-07-07 18:04:17,091 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:04:17,091 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:04:17,091 - wrong_be_tree_count:33	wrong_total:106	 wrong be tree ACC: 0.3113207547169811
2023-07-07 18:04:27,235 - 


2023-07-07 18:04:27,236 - epoch:72,	loss:0.12381758040282875
2023-07-07 18:04:30,439 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:04:30,440 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:04:30,440 - wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-07 18:04:40,429 - 


2023-07-07 18:04:40,430 - epoch:73,	loss:0.1195546054514125
2023-07-07 18:04:43,646 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:04:43,646 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:04:43,646 - wrong_be_tree_count:29	wrong_total:107	 wrong be tree ACC: 0.27102803738317754
2023-07-07 18:04:53,686 - 


2023-07-07 18:04:53,686 - epoch:74,	loss:0.12288924551103264
2023-07-07 18:04:56,854 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:04:56,854 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:04:56,854 - wrong_be_tree_count:36	wrong_total:103	 wrong be tree ACC: 0.34951456310679613
2023-07-07 18:05:06,784 - 


2023-07-07 18:05:06,784 - epoch:75,	loss:0.11514996341429651
2023-07-07 18:05:10,057 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:05:10,057 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:05:10,057 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:05:23,262 - 


2023-07-07 18:05:23,263 - epoch:76,	loss:0.11717325437348336
2023-07-07 18:05:26,550 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:05:26,550 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:05:26,550 - wrong_be_tree_count:28	wrong_total:107	 wrong be tree ACC: 0.2616822429906542
2023-07-07 18:05:36,706 - 


2023-07-07 18:05:36,707 - epoch:77,	loss:0.11992833961267024
2023-07-07 18:05:39,953 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:05:39,953 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:05:39,953 - wrong_be_tree_count:36	wrong_total:107	 wrong be tree ACC: 0.3364485981308411
2023-07-07 18:17:51,979 - 


2023-07-07 18:17:51,979 - epoch:78,	loss:0.1169226304627955
2023-07-07 18:17:55,231 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:17:55,231 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 18:17:55,231 - wrong_be_tree_count:37	wrong_total:107	 wrong be tree ACC: 0.34579439252336447
2023-07-07 18:18:05,096 - 


2023-07-07 18:18:05,096 - epoch:79,	loss:0.11680753249675035
2023-07-07 18:18:08,213 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 18:18:08,213 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:18:08,213 - wrong_be_tree_count:35	wrong_total:109	 wrong be tree ACC: 0.3211009174311927
2023-07-07 18:18:18,197 - 


2023-07-07 18:18:18,198 - epoch:80,	loss:0.11468320374842733
2023-07-07 18:18:21,341 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:18:21,341 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:18:21,341 - wrong_be_tree_count:34	wrong_total:105	 wrong be tree ACC: 0.3238095238095238
2023-07-07 18:18:31,499 - 


2023-07-07 18:18:31,500 - epoch:81,	loss:0.11133100261213258
2023-07-07 18:18:34,654 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 18:18:34,654 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:18:34,654 - wrong_be_tree_count:34	wrong_total:104	 wrong be tree ACC: 0.3269230769230769
2023-07-07 18:18:44,901 - 


2023-07-07 18:18:44,901 - epoch:82,	loss:0.11485084856394678
2023-07-07 18:18:48,055 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:18:48,055 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:18:48,055 - wrong_be_tree_count:33	wrong_total:106	 wrong be tree ACC: 0.3113207547169811
2023-07-07 18:18:58,062 - 


2023-07-07 18:18:58,062 - epoch:83,	loss:0.11598824086831883
2023-07-07 18:19:01,216 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 18:19:01,216 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:19:01,216 - wrong_be_tree_count:34	wrong_total:101	 wrong be tree ACC: 0.33663366336633666
2023-07-07 18:19:11,255 - 


2023-07-07 18:19:11,255 - epoch:84,	loss:0.10824951040558517
2023-07-07 18:19:14,543 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:19:14,543 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:19:14,543 - wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-07 18:19:24,681 - 


2023-07-07 18:19:24,681 - epoch:85,	loss:0.10793459485284984
2023-07-07 18:19:28,188 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 18:19:28,188 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:19:28,188 - wrong_be_tree_count:32	wrong_total:104	 wrong be tree ACC: 0.3076923076923077
2023-07-07 18:19:38,531 - 


2023-07-07 18:19:38,531 - epoch:86,	loss:0.11018175166100264
2023-07-07 18:19:41,782 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:19:41,782 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:19:41,782 - wrong_be_tree_count:36	wrong_total:105	 wrong be tree ACC: 0.34285714285714286
2023-07-07 18:19:51,744 - 


2023-07-07 18:19:51,744 - epoch:87,	loss:0.10728412627940997
2023-07-07 18:19:54,931 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 18:19:54,932 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:19:54,932 - wrong_be_tree_count:32	wrong_total:105	 wrong be tree ACC: 0.3047619047619048
2023-07-07 18:20:05,083 - 


2023-07-07 18:20:05,083 - epoch:88,	loss:0.10846504871733487
2023-07-07 18:20:08,297 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:20:08,297 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:20:08,297 - wrong_be_tree_count:35	wrong_total:106	 wrong be tree ACC: 0.330188679245283
2023-07-07 18:20:18,446 - 


2023-07-07 18:20:18,446 - epoch:89,	loss:0.1047016930533573
2023-07-07 18:20:21,682 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 18:20:21,682 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:20:21,682 - wrong_be_tree_count:31	wrong_total:104	 wrong be tree ACC: 0.2980769230769231
2023-07-07 18:20:31,858 - 


2023-07-07 18:20:31,858 - epoch:90,	loss:0.10411932080751285
2023-07-07 18:20:35,083 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 18:20:35,084 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:20:35,084 - wrong_be_tree_count:34	wrong_total:108	 wrong be tree ACC: 0.3148148148148148
2023-07-07 18:20:44,999 - 


2023-07-07 18:20:44,999 - epoch:91,	loss:0.1044753939495422
2023-07-07 18:20:48,201 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 18:20:48,201 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 18:20:48,201 - wrong_be_tree_count:32	wrong_total:106	 wrong be tree ACC: 0.3018867924528302
2023-07-07 18:20:58,044 - 


2023-07-07 18:20:58,045 - epoch:92,	loss:0.10275945195462555
2023-07-07 18:21:01,272 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 18:21:01,272 - right_codes_count:310	total:433	 Code ACC: 0.7159353348729792
2023-07-07 18:21:01,272 - wrong_be_tree_count:34	wrong_total:108	 wrong be tree ACC: 0.3148148148148148
2023-07-07 18:21:11,249 - 


2023-07-07 18:21:11,249 - epoch:93,	loss:0.10211960755987093
2023-07-07 18:21:14,443 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:21:14,443 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 18:21:14,444 - wrong_be_tree_count:29	wrong_total:103	 wrong be tree ACC: 0.2815533980582524
2023-07-07 18:21:24,554 - 


2023-07-07 18:21:24,554 - epoch:94,	loss:0.09983924249536358
2023-07-07 18:21:27,824 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 18:21:27,824 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 18:21:27,824 - wrong_be_tree_count:38	wrong_total:107	 wrong be tree ACC: 0.35514018691588783
2023-07-07 18:21:38,022 - 


2023-07-07 18:21:38,023 - epoch:95,	loss:0.10167556203668937
2023-07-07 18:21:41,245 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:21:41,245 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:21:41,245 - wrong_be_tree_count:29	wrong_total:103	 wrong be tree ACC: 0.2815533980582524
2023-07-07 18:21:51,203 - 


2023-07-07 18:21:51,203 - epoch:96,	loss:0.10250774113228545
2023-07-07 18:21:54,392 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:21:54,392 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:21:54,392 - wrong_be_tree_count:32	wrong_total:103	 wrong be tree ACC: 0.3106796116504854
2023-07-07 18:22:04,222 - 


2023-07-07 18:22:04,222 - epoch:97,	loss:0.10190628271084279
2023-07-07 18:22:07,697 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:22:07,697 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:22:07,697 - wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
2023-07-07 18:22:17,882 - 


2023-07-07 18:22:17,882 - epoch:98,	loss:0.0984803230385296
2023-07-07 18:22:21,162 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 18:22:21,163 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:22:21,163 - wrong_be_tree_count:33	wrong_total:104	 wrong be tree ACC: 0.3173076923076923
2023-07-07 18:22:31,319 - 


2023-07-07 18:22:31,319 - epoch:99,	loss:0.09908528497908264
2023-07-07 18:22:34,798 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 18:22:34,798 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 18:22:34,798 - wrong_be_tree_count:34	wrong_total:99	 wrong be tree ACC: 0.3434343434343434
2023-07-07 18:22:44,891 - 


2023-07-07 18:22:44,891 - epoch:100,	loss:0.0963644910370931
2023-07-07 18:22:48,255 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:22:48,255 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:22:48,255 - wrong_be_tree_count:35	wrong_total:103	 wrong be tree ACC: 0.33980582524271846
2023-07-07 18:22:58,420 - 


2023-07-07 18:22:58,420 - epoch:101,	loss:0.09708574978867546
2023-07-07 18:23:01,627 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:23:01,627 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:23:01,627 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 18:23:11,549 - 


2023-07-07 18:23:11,549 - epoch:102,	loss:0.0984720223932527
2023-07-07 18:23:14,694 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:23:14,695 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 18:23:14,695 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 18:23:24,654 - 


2023-07-07 18:23:24,655 - epoch:103,	loss:0.09920104558113962
2023-07-07 18:23:27,878 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:23:27,878 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 18:23:27,878 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 18:23:37,845 - 


2023-07-07 18:23:37,845 - epoch:104,	loss:0.10032063396647573
2023-07-07 18:23:41,031 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:23:41,031 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:23:41,031 - wrong_be_tree_count:31	wrong_total:103	 wrong be tree ACC: 0.30097087378640774
2023-07-07 18:23:50,931 - 


2023-07-07 18:23:50,932 - epoch:105,	loss:0.09813005989417434
2023-07-07 18:23:54,380 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:23:54,380 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 18:23:54,380 - wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
2023-07-07 18:24:04,343 - 


2023-07-07 18:24:04,343 - epoch:106,	loss:0.09554274810943753
2023-07-07 18:24:07,557 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:24:07,557 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:24:07,557 - wrong_be_tree_count:34	wrong_total:103	 wrong be tree ACC: 0.3300970873786408
2023-07-07 18:24:17,548 - 


2023-07-07 18:24:17,548 - epoch:107,	loss:0.09603409498231485
2023-07-07 18:24:20,699 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:24:20,699 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 18:24:20,699 - wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
2023-07-07 18:24:30,633 - 


2023-07-07 18:24:30,633 - epoch:108,	loss:0.094701282447204
2023-07-07 18:24:33,878 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:24:33,878 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:24:33,878 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:24:43,836 - 


2023-07-07 18:24:43,837 - epoch:109,	loss:0.0924784584203735
2023-07-07 18:24:47,047 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:24:47,048 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:24:47,048 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:24:57,519 - 


2023-07-07 18:24:57,520 - epoch:110,	loss:0.09483242995338514
2023-07-07 18:25:00,797 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:25:00,797 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:25:00,797 - wrong_be_tree_count:32	wrong_total:103	 wrong be tree ACC: 0.3106796116504854
2023-07-07 18:25:10,780 - 


2023-07-07 18:25:10,781 - epoch:111,	loss:0.09280637808842584
2023-07-07 18:25:14,444 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:25:14,444 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:25:14,444 - wrong_be_tree_count:34	wrong_total:103	 wrong be tree ACC: 0.3300970873786408
2023-07-07 18:25:24,541 - 


2023-07-07 18:25:24,541 - epoch:112,	loss:0.09753960353555158
2023-07-07 18:25:27,725 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:25:27,725 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 18:25:27,725 - wrong_be_tree_count:34	wrong_total:103	 wrong be tree ACC: 0.3300970873786408
2023-07-07 18:25:37,594 - 


2023-07-07 18:25:37,594 - epoch:113,	loss:0.09367444016970694
2023-07-07 18:25:40,726 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:25:40,726 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:25:40,726 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:25:50,744 - 


2023-07-07 18:25:50,745 - epoch:114,	loss:0.09244561300147325
2023-07-07 18:25:54,030 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:25:54,031 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:25:54,031 - wrong_be_tree_count:34	wrong_total:103	 wrong be tree ACC: 0.3300970873786408
2023-07-07 18:26:03,987 - 


2023-07-07 18:26:03,987 - epoch:115,	loss:0.09183465663227253
2023-07-07 18:26:07,323 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:26:07,323 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:26:07,323 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:26:17,396 - 


2023-07-07 18:26:17,397 - epoch:116,	loss:0.09443118941271678
2023-07-07 18:26:20,565 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:26:20,566 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:26:20,566 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:26:30,500 - 


2023-07-07 18:26:30,501 - epoch:117,	loss:0.09723862400278449
2023-07-07 18:26:33,723 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:26:33,723 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:26:33,723 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:26:43,798 - 


2023-07-07 18:26:43,799 - epoch:118,	loss:0.0922049903892912
2023-07-07 18:26:46,974 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 18:26:46,975 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 18:26:46,975 - wrong_be_tree_count:33	wrong_total:102	 wrong be tree ACC: 0.3235294117647059
2023-07-07 18:26:57,623 - 


2023-07-07 18:26:57,623 - epoch:119,	loss:0.09148652839940041
2023-07-07 18:27:00,865 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:27:00,865 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:27:00,865 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:27:10,813 - 


2023-07-07 18:27:10,813 - epoch:120,	loss:0.09378045698394999
2023-07-07 18:27:13,962 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:27:13,962 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:27:13,962 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:27:24,012 - 


2023-07-07 18:27:24,012 - epoch:121,	loss:0.09331529756309465
2023-07-07 18:27:27,168 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:27:27,168 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:27:27,168 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:27:37,109 - 


2023-07-07 18:27:37,109 - epoch:122,	loss:0.09408116660779342
2023-07-07 18:27:40,380 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:27:40,380 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:27:40,380 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:27:50,477 - 


2023-07-07 18:27:50,477 - epoch:123,	loss:0.09372458601137623
2023-07-07 18:27:53,752 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:27:53,753 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:27:53,753 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:28:03,637 - 


2023-07-07 18:28:03,637 - epoch:124,	loss:0.09028399683302268
2023-07-07 18:28:06,775 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:28:06,775 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:28:06,775 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:28:16,806 - 


2023-07-07 18:28:16,807 - epoch:125,	loss:0.09277523431228474
2023-07-07 18:28:19,973 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:28:19,974 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:28:19,974 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:28:29,918 - 


2023-07-07 18:28:29,918 - epoch:126,	loss:0.09341112710535526
2023-07-07 18:28:33,142 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:28:33,143 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:28:33,143 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:28:43,158 - 


2023-07-07 18:28:43,158 - epoch:127,	loss:0.09109844890190288
2023-07-07 18:28:46,323 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:28:46,323 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:28:46,323 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:28:56,612 - 


2023-07-07 18:28:56,612 - epoch:128,	loss:0.09024306014180183
2023-07-07 18:28:59,789 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:28:59,789 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:28:59,789 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:29:10,065 - 


2023-07-07 18:29:10,066 - epoch:129,	loss:0.09220867260592058
2023-07-07 18:29:13,390 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 18:29:13,390 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:29:13,390 - wrong_be_tree_count:33	wrong_total:103	 wrong be tree ACC: 0.32038834951456313
2023-07-07 18:29:18,454 - 


2023-07-07 18:29:18,454 - final_test
2023-07-07 18:29:22,252 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 18:29:22,253 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 18:29:22,253 - wrong_be_tree_count:36	wrong_total:104	 wrong be tree ACC: 0.34615384615384615
2023-07-07 19:16:44,982 - get train data loader...
2023-07-07 19:16:45,066 - get dev data loader...
2023-07-07 19:16:45,088 - define model...
2023-07-07 19:16:51,770 - define optimizer...
2023-07-07 19:16:51,771 - ===========================train setting parameters=========================
2023-07-07 19:16:51,771 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:16:51,772 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:16:51,772 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:16:51,772 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,772 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,772 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,772 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,772 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,772 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,773 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,773 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,773 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,773 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,773 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,774 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,774 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,774 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,775 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,776 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,776 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,776 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,776 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,776 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,777 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,777 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,778 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,779 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,779 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,780 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,780 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,780 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,783 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,783 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,784 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,785 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,787 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,787 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,787 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,787 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,788 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,788 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,788 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,790 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,790 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,791 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,791 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,791 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,791 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,792 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,792 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,792 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,793 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,793 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,793 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,794 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,794 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,795 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,796 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,796 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,796 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,796 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,796 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,796 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,796 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:16:51,797 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:16:51,798 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:16:51,798 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:16:51,798 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:16:51,798 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:16:51,798 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:16:51,798 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:16:51,799 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:16:51,799 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:16:51,799 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:16:51,799 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:16:51,799 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:16:51,799 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:16:51,800 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:16:51,800 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:16:51,800 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:16:51,800 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:16:51,800 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:16:51,800 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:16:51,802 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:16:51,802 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:16:51,802 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:16:51,802 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:16:51,802 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:16:51,802 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:16:51,803 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:16:51,803 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:16:51,803 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:16:51,803 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:16:51,805 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 19:16:58,248 - 


2023-07-07 19:16:58,249 - epoch:0,	loss:1.9495259579271078
2023-07-07 19:17:01,467 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 19:17:01,467 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:17:01,467 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 19:17:01,469 - save best model to ./output/test/best_model
2023-07-07 19:26:26,181 - get train data loader...
2023-07-07 19:26:26,627 - get dev data loader...
2023-07-07 19:26:26,797 - define model...
2023-07-07 19:26:31,288 - define optimizer...
2023-07-07 19:26:31,291 - ===========================train setting parameters=========================
2023-07-07 19:26:31,291 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:26:31,291 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:26:31,292 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:26:31,292 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,292 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,293 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,293 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,293 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,293 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,294 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,295 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,295 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,295 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,295 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,296 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,296 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,296 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,297 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,297 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,297 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,298 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,299 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,300 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,300 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,301 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,301 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,301 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,301 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,301 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,302 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,303 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,303 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,303 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,305 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,305 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,305 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,306 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,306 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,307 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,307 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,307 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,308 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,308 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,309 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,309 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,309 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,310 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,310 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,310 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,310 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,310 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,311 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,311 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,311 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,311 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,312 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,312 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,312 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,313 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,313 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,313 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,314 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,314 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,315 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,315 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,315 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,315 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,315 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,316 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,317 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,317 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,318 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,318 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,318 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,319 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,319 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,320 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,320 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,321 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,321 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,321 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,321 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,322 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,322 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,323 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,324 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,324 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,324 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,325 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,325 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,325 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,326 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,326 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,326 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,327 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,327 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,327 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,328 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,328 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,329 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,329 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,329 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,330 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,330 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,330 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,330 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,331 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,331 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,331 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,332 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,333 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,333 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,333 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,333 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,334 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,334 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,335 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,335 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,335 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,336 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,337 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,337 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,337 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,338 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,338 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:26:31,338 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:26:31,339 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:26:31,339 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:26:31,340 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:26:31,340 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:26:31,340 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,342 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,342 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,342 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,342 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:26:31,343 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:26:31,343 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:26:31,343 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:26:31,343 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:26:31,344 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:26:31,344 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:26:31,344 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:26:31,344 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:26:31,344 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:26:31,344 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:26:31,344 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:26:31,345 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:26:31,345 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:26:31,345 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:26:31,346 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:26:31,346 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:26:31,346 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:26:31,347 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:26:31,347 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:26:31,347 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:26:31,348 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:26:31,348 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:26:31,348 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:26:31,349 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:26:31,349 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:26:31,349 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:26:31,350 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:26:31,350 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:26:31,350 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:27:00,443 - get train data loader...
2023-07-07 19:27:00,540 - get dev data loader...
2023-07-07 19:27:00,564 - define model...
2023-07-07 19:27:04,671 - define optimizer...
2023-07-07 19:27:04,672 - ===========================train setting parameters=========================
2023-07-07 19:27:04,672 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:27:04,672 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:27:04,672 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:27:04,672 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,673 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,673 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,673 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,674 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,674 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,674 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,674 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,674 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,675 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,675 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,675 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,675 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,675 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,676 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,676 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,676 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,676 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,676 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,677 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,678 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,678 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,678 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,678 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,678 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,679 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,680 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,680 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,680 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,680 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,680 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,681 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,681 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,681 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,681 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,682 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,683 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,683 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,685 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,686 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,686 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,686 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,686 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,686 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,686 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,686 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,686 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,687 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,688 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,689 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,689 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,689 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,689 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,689 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,689 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,689 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,689 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,689 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,690 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,690 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,690 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,690 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,690 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,691 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,691 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,691 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,692 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,692 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,692 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,692 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,692 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,692 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,693 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,694 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,695 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,696 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,696 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,696 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,696 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,696 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,696 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,696 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,697 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,698 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,698 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,699 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:27:04,700 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:27:04,701 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:27:04,701 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:27:04,701 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:27:04,701 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:27:04,701 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:27:04,701 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:27:04,701 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:27:04,701 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:27:04,701 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:27:04,701 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:27:04,701 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:27:04,701 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:27:04,701 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:27:04,701 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:27:04,701 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:27:04,701 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:27:04,701 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:27:04,701 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:27:04,702 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:27:04,702 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:27:04,702 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:27:04,702 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:27:04,702 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:27:04,702 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:27:04,702 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:27:04,702 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:27:04,706 - 


2023-07-07 19:27:04,706 - final_test
2023-07-07 19:27:08,979 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-07 19:27:08,979 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:27:08,979 - wrong_be_tree_count:419	wrong_total:432	 wrong be tree ACC: 0.9699074074074074
2023-07-07 19:31:26,068 - get train data loader...
2023-07-07 19:31:26,153 - get dev data loader...
2023-07-07 19:31:26,180 - define model...
2023-07-07 19:31:30,078 - define optimizer...
2023-07-07 19:31:30,079 - ===========================train setting parameters=========================
2023-07-07 19:31:30,079 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:31:30,079 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:31:30,079 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:31:30,079 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,079 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,079 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,079 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,079 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,083 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,084 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,084 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,084 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,084 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,084 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,085 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,085 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,085 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,085 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,086 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,086 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,086 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,087 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,087 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,087 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,088 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,088 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,088 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,088 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,089 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,089 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,089 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,089 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,089 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,089 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,090 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,090 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,090 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,090 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,091 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,092 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,092 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,092 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,092 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,093 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,093 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,093 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,093 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,093 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,094 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,095 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,095 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,095 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,095 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,096 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,096 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,097 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,097 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,097 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,097 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,098 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,099 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,099 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,099 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,099 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,099 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,099 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,099 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,099 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,099 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,099 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,100 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,100 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,100 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,100 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,100 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,101 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,101 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,101 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,102 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,102 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,102 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,103 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,103 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,104 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,104 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,104 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,104 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,105 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,105 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,105 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,105 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,106 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,106 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,106 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,106 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,106 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,108 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,108 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,108 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,108 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,109 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,109 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,109 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,109 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,110 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,110 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,110 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,110 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,110 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,112 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,112 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,112 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,112 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,112 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,112 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,112 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,113 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,113 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,113 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,113 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,113 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,114 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,115 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,115 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,115 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,116 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,116 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,116 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,117 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,117 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,117 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,117 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,117 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,118 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,118 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,119 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,120 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,120 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:31:30,120 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:31:30,121 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:31:30,121 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:31:30,121 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:31:30,121 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:31:30,122 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,122 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,122 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,122 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,122 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:31:30,123 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:31:30,123 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:31:30,123 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:31:30,123 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:31:30,123 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:31:30,124 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:31:30,124 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:31:30,124 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:31:30,124 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:31:30,125 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:31:30,125 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:31:30,126 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:31:30,126 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:31:30,126 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:31:30,126 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:31:30,126 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:31:30,126 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:31:30,126 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:31:30,127 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:31:30,127 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:31:30,127 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:31:30,127 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:31:30,127 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:31:30,127 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:31:30,127 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:31:30,127 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:31:30,128 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:31:30,128 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:31:30,128 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:31:30,131 - 


2023-07-07 19:31:30,131 - final_test
2023-07-07 19:31:34,848 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-07 19:31:34,848 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:31:34,848 - wrong_be_tree_count:419	wrong_total:432	 wrong be tree ACC: 0.9699074074074074
2023-07-07 19:32:14,002 - get train data loader...
2023-07-07 19:32:14,097 - get dev data loader...
2023-07-07 19:32:14,124 - define model...
2023-07-07 19:32:18,278 - define optimizer...
2023-07-07 19:32:18,279 - ===========================train setting parameters=========================
2023-07-07 19:32:18,284 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:32:18,284 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:32:18,284 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:32:18,284 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,284 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,284 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,285 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,286 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,286 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,287 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,287 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,288 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,289 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,289 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,290 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,291 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,292 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,292 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,293 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,294 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,296 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,296 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,296 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,296 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,298 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,299 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,299 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,299 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,299 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,299 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,299 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,299 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,299 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,299 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,300 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,300 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,301 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,302 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,303 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,303 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:32:18,304 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:32:18,304 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:32:18,305 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:32:18,305 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:32:18,305 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:32:18,305 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:32:18,305 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:32:18,305 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:32:18,305 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:32:18,305 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:32:18,305 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:32:18,305 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:32:18,305 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:32:18,305 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:32:18,305 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:32:18,305 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:32:18,305 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:32:18,305 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:32:18,305 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:32:18,305 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:32:18,305 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:32:18,307 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:32:18,307 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:32:18,307 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:32:18,307 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:32:18,309 - 


2023-07-07 19:32:18,309 - final_test
2023-07-07 19:32:23,027 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 19:32:23,027 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:32:23,027 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 19:33:48,273 - get train data loader...
2023-07-07 19:33:48,425 - get dev data loader...
2023-07-07 19:33:48,467 - define model...
2023-07-07 19:33:52,657 - define optimizer...
2023-07-07 19:33:52,657 - ===========================train setting parameters=========================
2023-07-07 19:33:52,658 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:33:52,658 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:33:52,658 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:33:52,658 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,658 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,658 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,658 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,659 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,660 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,660 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,660 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,660 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,660 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,660 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,660 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,660 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,661 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,661 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,661 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,661 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,661 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,662 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,662 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,662 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,663 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,663 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,663 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,663 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,663 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,663 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,663 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,663 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,664 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,665 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,665 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,665 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,665 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,665 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,666 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,667 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,667 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,668 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,669 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,669 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,669 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,669 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,669 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,669 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,669 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,670 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,671 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,672 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,672 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,672 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,672 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,673 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,675 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,675 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,676 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,676 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,677 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,678 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,678 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,678 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,678 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,679 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,679 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,679 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,679 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,680 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:33:52,681 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:33:52,681 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:33:52,681 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:33:52,682 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:33:52,682 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:33:52,682 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:33:52,682 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:33:52,682 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:33:52,682 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:33:52,682 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:33:52,682 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:33:52,682 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:33:52,682 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:33:52,682 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:33:52,682 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:33:52,682 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:33:52,682 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:33:52,683 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:33:52,683 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:33:52,683 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:33:52,683 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:33:52,683 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:33:52,683 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:33:52,683 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:33:52,683 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:33:52,687 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 19:33:58,807 - 


2023-07-07 19:33:58,808 - epoch:0,	loss:2.0519168376922607
2023-07-07 19:34:02,805 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 19:34:02,806 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:34:02,806 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 19:34:02,808 - save best model to ./output/test/best_model
2023-07-07 19:34:18,380 - 


2023-07-07 19:34:18,381 - epoch:1,	loss:1.2165446728467941
2023-07-07 19:34:22,171 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 19:34:22,172 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 19:34:22,172 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 19:34:32,399 - 


2023-07-07 19:34:32,399 - epoch:2,	loss:0.9445097204297781
2023-07-07 19:34:35,929 - right_count:3	total:433	 Answer ACC: 0.006928406466512702
2023-07-07 19:34:35,930 - right_codes_count:1	total:433	 Code ACC: 0.0023094688221709007
2023-07-07 19:34:35,931 - wrong_be_tree_count:407	wrong_total:430	 wrong be tree ACC: 0.9465116279069767
2023-07-07 19:34:35,934 - save best model to ./output/test/best_model
2023-07-07 19:34:51,352 - 


2023-07-07 19:34:51,353 - epoch:3,	loss:0.8726440165191889
2023-07-07 19:34:54,975 - right_count:16	total:433	 Answer ACC: 0.03695150115473441
2023-07-07 19:34:54,976 - right_codes_count:6	total:433	 Code ACC: 0.013856812933025405
2023-07-07 19:34:54,976 - wrong_be_tree_count:298	wrong_total:417	 wrong be tree ACC: 0.7146282973621103
2023-07-07 19:34:54,978 - save best model to ./output/test/best_model
2023-07-07 19:35:10,333 - 


2023-07-07 19:35:10,333 - epoch:4,	loss:0.8309638071805239
2023-07-07 19:35:14,236 - right_count:38	total:433	 Answer ACC: 0.08775981524249422
2023-07-07 19:35:14,237 - right_codes_count:17	total:433	 Code ACC: 0.03926096997690531
2023-07-07 19:35:14,237 - wrong_be_tree_count:274	wrong_total:395	 wrong be tree ACC: 0.6936708860759494
2023-07-07 19:35:14,242 - save best model to ./output/test/best_model
2023-07-07 19:35:29,550 - 


2023-07-07 19:35:29,550 - epoch:5,	loss:0.7833625329658389
2023-07-07 19:35:33,537 - right_count:89	total:433	 Answer ACC: 0.20554272517321015
2023-07-07 19:35:33,537 - right_codes_count:62	total:433	 Code ACC: 0.14318706697459585
2023-07-07 19:35:33,537 - wrong_be_tree_count:174	wrong_total:344	 wrong be tree ACC: 0.5058139534883721
2023-07-07 19:35:33,539 - save best model to ./output/test/best_model
2023-07-07 19:35:48,771 - 


2023-07-07 19:35:48,772 - epoch:6,	loss:0.7147971233353019
2023-07-07 19:35:52,705 - right_count:101	total:433	 Answer ACC: 0.23325635103926096
2023-07-07 19:35:52,705 - right_codes_count:76	total:433	 Code ACC: 0.17551963048498845
2023-07-07 19:35:52,705 - wrong_be_tree_count:88	wrong_total:332	 wrong be tree ACC: 0.26506024096385544
2023-07-07 19:35:52,708 - save best model to ./output/test/best_model
2023-07-07 19:36:10,448 - 


2023-07-07 19:36:10,449 - epoch:7,	loss:0.6582977436482906
2023-07-07 19:36:14,136 - right_count:143	total:433	 Answer ACC: 0.3302540415704388
2023-07-07 19:36:14,136 - right_codes_count:113	total:433	 Code ACC: 0.26096997690531176
2023-07-07 19:36:14,136 - wrong_be_tree_count:58	wrong_total:290	 wrong be tree ACC: 0.2
2023-07-07 19:36:14,138 - save best model to ./output/test/best_model
2023-07-07 19:36:30,354 - 


2023-07-07 19:36:30,354 - epoch:8,	loss:0.6172377234324813
2023-07-07 19:36:34,098 - right_count:165	total:433	 Answer ACC: 0.3810623556581986
2023-07-07 19:36:34,098 - right_codes_count:133	total:433	 Code ACC: 0.3071593533487298
2023-07-07 19:36:34,098 - wrong_be_tree_count:45	wrong_total:268	 wrong be tree ACC: 0.16791044776119404
2023-07-07 19:36:34,100 - save best model to ./output/test/best_model
2023-07-07 19:36:51,390 - 


2023-07-07 19:36:51,390 - epoch:9,	loss:0.5681507019326091
2023-07-07 19:36:55,196 - right_count:181	total:433	 Answer ACC: 0.418013856812933
2023-07-07 19:36:55,196 - right_codes_count:147	total:433	 Code ACC: 0.3394919168591224
2023-07-07 19:36:55,196 - wrong_be_tree_count:43	wrong_total:252	 wrong be tree ACC: 0.17063492063492064
2023-07-07 19:36:55,198 - save best model to ./output/test/best_model
2023-07-07 19:37:10,738 - 


2023-07-07 19:37:10,739 - epoch:10,	loss:0.5249695698730648
2023-07-07 19:37:14,493 - right_count:213	total:433	 Answer ACC: 0.49191685912240185
2023-07-07 19:37:14,493 - right_codes_count:174	total:433	 Code ACC: 0.4018475750577367
2023-07-07 19:37:14,493 - wrong_be_tree_count:43	wrong_total:220	 wrong be tree ACC: 0.19545454545454546
2023-07-07 19:37:14,496 - save best model to ./output/test/best_model
2023-07-07 19:37:29,876 - 


2023-07-07 19:37:29,876 - epoch:11,	loss:0.4772184635512531
2023-07-07 19:37:33,883 - right_count:223	total:433	 Answer ACC: 0.5150115473441108
2023-07-07 19:37:33,883 - right_codes_count:186	total:433	 Code ACC: 0.4295612009237875
2023-07-07 19:37:33,884 - wrong_be_tree_count:53	wrong_total:210	 wrong be tree ACC: 0.2523809523809524
2023-07-07 19:37:33,886 - save best model to ./output/test/best_model
2023-07-07 19:37:49,192 - 


2023-07-07 19:37:49,192 - epoch:12,	loss:0.43800947442650795
2023-07-07 19:37:52,747 - right_count:246	total:433	 Answer ACC: 0.5681293302540416
2023-07-07 19:37:52,747 - right_codes_count:214	total:433	 Code ACC: 0.4942263279445728
2023-07-07 19:37:52,747 - wrong_be_tree_count:62	wrong_total:187	 wrong be tree ACC: 0.3315508021390374
2023-07-07 19:37:52,750 - save best model to ./output/test/best_model
2023-07-07 19:38:09,180 - 


2023-07-07 19:38:09,181 - epoch:13,	loss:0.3986371294595301
2023-07-07 19:38:12,742 - right_count:252	total:433	 Answer ACC: 0.581986143187067
2023-07-07 19:38:12,742 - right_codes_count:219	total:433	 Code ACC: 0.5057736720554272
2023-07-07 19:38:12,742 - wrong_be_tree_count:64	wrong_total:181	 wrong be tree ACC: 0.35359116022099446
2023-07-07 19:38:12,744 - save best model to ./output/test/best_model
2023-07-07 19:38:28,118 - 


2023-07-07 19:38:28,118 - epoch:14,	loss:0.36370793893001974
2023-07-07 19:38:31,645 - right_count:261	total:433	 Answer ACC: 0.6027713625866051
2023-07-07 19:38:31,645 - right_codes_count:231	total:433	 Code ACC: 0.5334872979214781
2023-07-07 19:38:31,645 - wrong_be_tree_count:64	wrong_total:172	 wrong be tree ACC: 0.37209302325581395
2023-07-07 19:38:31,647 - save best model to ./output/test/best_model
2023-07-07 19:38:47,344 - 


2023-07-07 19:38:47,344 - epoch:15,	loss:0.3405845477245748
2023-07-07 19:38:50,701 - right_count:283	total:433	 Answer ACC: 0.6535796766743649
2023-07-07 19:38:50,701 - right_codes_count:254	total:433	 Code ACC: 0.5866050808314087
2023-07-07 19:38:50,701 - wrong_be_tree_count:56	wrong_total:150	 wrong be tree ACC: 0.37333333333333335
2023-07-07 19:38:50,704 - save best model to ./output/test/best_model
2023-07-07 19:39:05,924 - 


2023-07-07 19:39:05,924 - epoch:16,	loss:0.32082445034757257
2023-07-07 19:39:09,173 - right_count:287	total:433	 Answer ACC: 0.6628175519630485
2023-07-07 19:39:09,173 - right_codes_count:262	total:433	 Code ACC: 0.605080831408776
2023-07-07 19:39:09,173 - wrong_be_tree_count:53	wrong_total:146	 wrong be tree ACC: 0.363013698630137
2023-07-07 19:39:09,175 - save best model to ./output/test/best_model
2023-07-07 19:39:24,456 - 


2023-07-07 19:39:24,456 - epoch:17,	loss:0.29763356293551624
2023-07-07 19:39:27,668 - right_count:295	total:433	 Answer ACC: 0.6812933025404158
2023-07-07 19:39:27,668 - right_codes_count:266	total:433	 Code ACC: 0.6143187066974596
2023-07-07 19:39:27,668 - wrong_be_tree_count:50	wrong_total:138	 wrong be tree ACC: 0.36231884057971014
2023-07-07 19:39:27,671 - save best model to ./output/test/best_model
2023-07-07 19:39:43,070 - 


2023-07-07 19:39:43,071 - epoch:18,	loss:0.2859751204960048
2023-07-07 19:39:46,254 - right_count:306	total:433	 Answer ACC: 0.7066974595842956
2023-07-07 19:39:46,254 - right_codes_count:276	total:433	 Code ACC: 0.6374133949191686
2023-07-07 19:39:46,254 - wrong_be_tree_count:49	wrong_total:127	 wrong be tree ACC: 0.3858267716535433
2023-07-07 19:39:46,256 - save best model to ./output/test/best_model
2023-07-07 19:40:01,497 - 


2023-07-07 19:40:01,498 - epoch:19,	loss:0.2583670390304178
2023-07-07 19:40:04,669 - right_count:310	total:433	 Answer ACC: 0.7159353348729792
2023-07-07 19:40:04,670 - right_codes_count:285	total:433	 Code ACC: 0.6581986143187067
2023-07-07 19:40:04,670 - wrong_be_tree_count:52	wrong_total:123	 wrong be tree ACC: 0.42276422764227645
2023-07-07 19:40:04,673 - save best model to ./output/test/best_model
2023-07-07 19:40:19,848 - 


2023-07-07 19:40:19,848 - epoch:20,	loss:0.24294447572901845
2023-07-07 19:40:23,047 - right_count:313	total:433	 Answer ACC: 0.7228637413394919
2023-07-07 19:40:23,047 - right_codes_count:287	total:433	 Code ACC: 0.6628175519630485
2023-07-07 19:40:23,048 - wrong_be_tree_count:49	wrong_total:120	 wrong be tree ACC: 0.4083333333333333
2023-07-07 19:40:23,051 - save best model to ./output/test/best_model
2023-07-07 19:40:38,393 - 


2023-07-07 19:40:38,394 - epoch:21,	loss:0.23250635946169496
2023-07-07 19:40:41,506 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 19:40:41,506 - right_codes_count:292	total:433	 Code ACC: 0.674364896073903
2023-07-07 19:40:41,506 - wrong_be_tree_count:44	wrong_total:112	 wrong be tree ACC: 0.39285714285714285
2023-07-07 19:40:41,509 - save best model to ./output/test/best_model
2023-07-07 19:40:56,686 - 


2023-07-07 19:40:56,687 - epoch:22,	loss:0.22407180489972234
2023-07-07 19:41:00,129 - right_count:310	total:433	 Answer ACC: 0.7159353348729792
2023-07-07 19:41:00,130 - right_codes_count:290	total:433	 Code ACC: 0.6697459584295612
2023-07-07 19:41:00,130 - wrong_be_tree_count:50	wrong_total:123	 wrong be tree ACC: 0.4065040650406504
2023-07-07 19:41:10,065 - 


2023-07-07 19:41:10,065 - epoch:23,	loss:0.21392290573567152
2023-07-07 19:41:13,205 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-07 19:41:13,206 - right_codes_count:290	total:433	 Code ACC: 0.6697459584295612
2023-07-07 19:41:13,206 - wrong_be_tree_count:44	wrong_total:119	 wrong be tree ACC: 0.3697478991596639
2023-07-07 19:41:23,440 - 


2023-07-07 19:41:23,440 - epoch:24,	loss:0.19688142545055598
2023-07-07 19:41:26,771 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 19:41:26,771 - right_codes_count:295	total:433	 Code ACC: 0.6812933025404158
2023-07-07 19:41:26,771 - wrong_be_tree_count:39	wrong_total:111	 wrong be tree ACC: 0.35135135135135137
2023-07-07 19:41:26,774 - save best model to ./output/test/best_model
2023-07-07 19:41:41,814 - 


2023-07-07 19:41:41,814 - epoch:25,	loss:0.19083242170745507
2023-07-07 19:41:45,156 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-07 19:41:45,156 - right_codes_count:299	total:433	 Code ACC: 0.6905311778290993
2023-07-07 19:41:45,156 - wrong_be_tree_count:41	wrong_total:114	 wrong be tree ACC: 0.35964912280701755
2023-07-07 19:41:55,157 - 


2023-07-07 19:41:55,157 - epoch:26,	loss:0.18387456017080694
2023-07-07 19:41:58,313 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-07 19:41:58,313 - right_codes_count:298	total:433	 Code ACC: 0.6882217090069284
2023-07-07 19:41:58,313 - wrong_be_tree_count:38	wrong_total:114	 wrong be tree ACC: 0.3333333333333333
2023-07-07 19:42:08,485 - 


2023-07-07 19:42:08,486 - epoch:27,	loss:0.1787454665172845
2023-07-07 19:42:11,720 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-07 19:42:11,720 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-07 19:42:11,720 - wrong_be_tree_count:40	wrong_total:113	 wrong be tree ACC: 0.35398230088495575
2023-07-07 19:42:21,964 - 


2023-07-07 19:42:21,964 - epoch:28,	loss:0.17146770062390715
2023-07-07 19:42:25,220 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-07 19:42:25,220 - right_codes_count:303	total:433	 Code ACC: 0.6997690531177829
2023-07-07 19:42:25,220 - wrong_be_tree_count:38	wrong_total:111	 wrong be tree ACC: 0.34234234234234234
2023-07-07 19:42:35,258 - 


2023-07-07 19:42:35,258 - epoch:29,	loss:0.17082448676228523
2023-07-07 19:42:38,395 - right_count:321	total:433	 Answer ACC: 0.7413394919168591
2023-07-07 19:42:38,396 - right_codes_count:301	total:433	 Code ACC: 0.6951501154734411
2023-07-07 19:42:38,396 - wrong_be_tree_count:32	wrong_total:112	 wrong be tree ACC: 0.2857142857142857
2023-07-07 19:42:46,818 - get train data loader...
2023-07-07 19:42:46,903 - get dev data loader...
2023-07-07 19:42:46,971 - define model...
2023-07-07 19:42:48,505 - 


2023-07-07 19:42:48,505 - epoch:30,	loss:0.16978819447103888
2023-07-07 19:42:51,146 - define optimizer...
2023-07-07 19:42:51,147 - ===========================train setting parameters=========================
2023-07-07 19:42:51,149 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:42:51,149 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:42:51,149 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:42:51,149 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,149 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,149 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,150 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,150 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,151 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,152 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,153 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,153 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,155 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,156 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,156 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,158 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,159 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,160 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,160 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,160 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,160 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,160 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,160 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,160 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,161 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,162 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,162 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,162 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,162 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,162 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,162 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,162 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,162 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,162 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,162 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,163 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,163 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,164 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,165 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,166 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,166 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,166 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,166 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,167 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,168 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,168 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,168 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,168 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,169 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,169 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,170 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:42:51,171 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:42:51,172 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:42:51,172 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:42:51,172 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:42:51,172 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:42:51,172 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:42:51,172 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:42:51,172 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:42:51,173 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:42:51,173 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:42:51,173 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:42:51,173 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:42:51,173 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:42:51,173 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:42:51,173 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:42:51,174 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:42:51,174 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:42:51,174 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:42:51,174 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:42:51,174 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:42:51,174 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:42:51,174 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:42:51,175 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:42:51,175 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:42:51,175 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:42:51,738 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-07 19:42:51,738 - right_codes_count:301	total:433	 Code ACC: 0.6951501154734411
2023-07-07 19:42:51,738 - wrong_be_tree_count:36	wrong_total:114	 wrong be tree ACC: 0.3157894736842105
2023-07-07 19:43:01,854 - 


2023-07-07 19:43:01,855 - epoch:31,	loss:0.15827414084924385
2023-07-07 19:43:05,157 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-07 19:43:05,157 - right_codes_count:302	total:433	 Code ACC: 0.6974595842956121
2023-07-07 19:43:05,157 - wrong_be_tree_count:29	wrong_total:110	 wrong be tree ACC: 0.2636363636363636
2023-07-07 19:43:05,159 - save best model to ./output/test/best_model
2023-07-07 19:43:20,255 - 


2023-07-07 19:43:20,255 - epoch:32,	loss:0.15356056671589613
2023-07-07 19:43:23,518 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 19:43:23,518 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-07 19:43:23,518 - wrong_be_tree_count:27	wrong_total:109	 wrong be tree ACC: 0.24770642201834864
2023-07-07 19:43:23,521 - save best model to ./output/test/best_model
2023-07-07 19:43:39,324 - 


2023-07-07 19:43:39,325 - epoch:33,	loss:0.14902539970353246
2023-07-07 19:43:42,750 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 19:43:42,750 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-07 19:43:42,750 - wrong_be_tree_count:36	wrong_total:106	 wrong be tree ACC: 0.33962264150943394
2023-07-07 19:43:42,753 - save best model to ./output/test/best_model
2023-07-07 19:43:57,832 - 


2023-07-07 19:43:57,832 - epoch:34,	loss:0.14754657173762098
2023-07-07 19:44:01,099 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 19:44:01,099 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 19:44:01,099 - wrong_be_tree_count:35	wrong_total:108	 wrong be tree ACC: 0.32407407407407407
2023-07-07 19:44:11,130 - 


2023-07-07 19:44:11,130 - epoch:35,	loss:0.14238854823634028
2023-07-07 19:44:14,425 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 19:44:14,425 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 19:44:14,425 - wrong_be_tree_count:33	wrong_total:108	 wrong be tree ACC: 0.3055555555555556
2023-07-07 19:44:24,653 - 


2023-07-07 19:44:24,654 - epoch:36,	loss:0.13948303018696606
2023-07-07 19:44:27,828 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 19:44:27,828 - right_codes_count:307	total:433	 Code ACC: 0.7090069284064665
2023-07-07 19:44:27,828 - wrong_be_tree_count:38	wrong_total:105	 wrong be tree ACC: 0.3619047619047619
2023-07-07 19:44:27,831 - save best model to ./output/test/best_model
2023-07-07 19:44:43,096 - 


2023-07-07 19:44:43,097 - epoch:37,	loss:0.13556845107814297
2023-07-07 19:44:46,304 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:44:46,304 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 19:44:46,304 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 19:44:46,306 - save best model to ./output/test/best_model
2023-07-07 19:45:01,266 - 


2023-07-07 19:45:01,267 - epoch:38,	loss:0.1325716214487329
2023-07-07 19:45:04,462 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 19:45:04,462 - right_codes_count:307	total:433	 Code ACC: 0.7090069284064665
2023-07-07 19:45:04,462 - wrong_be_tree_count:37	wrong_total:105	 wrong be tree ACC: 0.3523809523809524
2023-07-07 19:45:14,892 - 


2023-07-07 19:45:14,892 - epoch:39,	loss:0.1324873857665807
2023-07-07 19:45:18,104 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 19:45:18,105 - right_codes_count:307	total:433	 Code ACC: 0.7090069284064665
2023-07-07 19:45:18,105 - wrong_be_tree_count:39	wrong_total:104	 wrong be tree ACC: 0.375
2023-07-07 19:45:28,106 - 


2023-07-07 19:45:28,106 - epoch:40,	loss:0.12953970930539072
2023-07-07 19:45:31,303 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 19:45:31,303 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 19:45:31,303 - wrong_be_tree_count:39	wrong_total:106	 wrong be tree ACC: 0.36792452830188677
2023-07-07 19:45:41,399 - 


2023-07-07 19:45:41,399 - epoch:41,	loss:0.12475967028876767
2023-07-07 19:45:44,697 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-07 19:45:44,697 - right_codes_count:305	total:433	 Code ACC: 0.7043879907621247
2023-07-07 19:45:44,697 - wrong_be_tree_count:38	wrong_total:108	 wrong be tree ACC: 0.35185185185185186
2023-07-07 19:45:54,792 - 


2023-07-07 19:45:54,792 - epoch:42,	loss:0.127818544046022
2023-07-07 19:45:58,032 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 19:45:58,032 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 19:45:58,032 - wrong_be_tree_count:38	wrong_total:103	 wrong be tree ACC: 0.36893203883495146
2023-07-07 19:46:07,930 - 


2023-07-07 19:46:07,930 - epoch:43,	loss:0.12276539241429418
2023-07-07 19:46:11,181 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:46:11,182 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 19:46:11,182 - wrong_be_tree_count:34	wrong_total:102	 wrong be tree ACC: 0.3333333333333333
2023-07-07 19:46:21,444 - 


2023-07-07 19:46:21,444 - epoch:44,	loss:0.11700977146392688
2023-07-07 19:46:24,759 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:46:24,759 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 19:46:24,759 - wrong_be_tree_count:44	wrong_total:102	 wrong be tree ACC: 0.43137254901960786
2023-07-07 19:46:34,959 - 


2023-07-07 19:46:34,959 - epoch:45,	loss:0.11815006501274183
2023-07-07 19:46:38,285 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 19:46:38,286 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-07 19:46:38,286 - wrong_be_tree_count:35	wrong_total:103	 wrong be tree ACC: 0.33980582524271846
2023-07-07 19:46:48,371 - 


2023-07-07 19:46:48,372 - epoch:46,	loss:0.11535027844365686
2023-07-07 19:46:51,912 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:46:51,912 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 19:46:51,912 - wrong_be_tree_count:42	wrong_total:102	 wrong be tree ACC: 0.4117647058823529
2023-07-07 19:47:02,120 - 


2023-07-07 19:47:02,120 - epoch:47,	loss:0.11691989831160754
2023-07-07 19:47:05,864 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 19:47:05,864 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 19:47:05,865 - wrong_be_tree_count:38	wrong_total:105	 wrong be tree ACC: 0.3619047619047619
2023-07-07 19:47:16,077 - 


2023-07-07 19:47:16,077 - epoch:48,	loss:0.11137629637960345
2023-07-07 19:47:19,268 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:47:19,268 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:47:19,268 - wrong_be_tree_count:33	wrong_total:100	 wrong be tree ACC: 0.33
2023-07-07 19:47:19,270 - save best model to ./output/test/best_model
2023-07-07 19:47:30,339 - get train data loader...
2023-07-07 19:47:30,465 - get dev data loader...
2023-07-07 19:47:30,556 - define model...
2023-07-07 19:47:34,738 - 


2023-07-07 19:47:34,738 - epoch:49,	loss:0.10999876371352002
2023-07-07 19:47:35,378 - define optimizer...
2023-07-07 19:47:35,378 - ===========================train setting parameters=========================
2023-07-07 19:47:35,379 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:47:35,379 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:47:35,379 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:47:35,379 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,379 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,379 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,379 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,379 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,380 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,381 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,382 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,382 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,382 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,382 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,382 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,383 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,383 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,383 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,383 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,383 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,384 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,385 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,385 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,385 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,386 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,387 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,387 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,387 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,387 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,388 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,388 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,389 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,406 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,406 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,406 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,406 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,419 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,419 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,419 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,421 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,425 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,425 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,425 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,425 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,425 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,426 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,426 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,426 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,427 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,428 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,428 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,428 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,428 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,428 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,428 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,428 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,428 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,429 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,431 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,431 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,431 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,431 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,431 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,431 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,432 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,433 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,434 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,434 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,435 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,435 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,435 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,435 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,436 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,436 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,436 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,437 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,437 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,437 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,437 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:47:35,437 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:47:35,437 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:47:35,437 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:47:35,437 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:47:35,438 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:47:35,439 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:47:35,439 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:47:35,439 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:47:35,439 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:47:35,439 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:47:35,439 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:47:35,440 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:47:35,440 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:47:35,440 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:47:35,440 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:47:35,440 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:47:35,440 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:47:35,440 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:47:35,441 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:47:35,442 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:47:35,442 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:47:35,442 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:47:35,442 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:47:35,442 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:47:35,442 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:47:35,443 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:47:35,443 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:47:35,443 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:47:35,443 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:47:35,443 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:47:35,443 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:47:35,443 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:47:35,443 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:47:38,906 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-07 19:47:38,906 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 19:47:38,906 - wrong_be_tree_count:39	wrong_total:106	 wrong be tree ACC: 0.36792452830188677
2023-07-07 19:47:49,385 - 


2023-07-07 19:47:49,385 - epoch:50,	loss:0.10595832581748255
2023-07-07 19:47:52,682 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:47:52,682 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:47:52,682 - wrong_be_tree_count:37	wrong_total:101	 wrong be tree ACC: 0.36633663366336633
2023-07-07 19:48:02,799 - 


2023-07-07 19:48:02,799 - epoch:51,	loss:0.10426564863882959
2023-07-07 19:48:06,950 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 19:48:06,950 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 19:48:06,950 - wrong_be_tree_count:38	wrong_total:103	 wrong be tree ACC: 0.36893203883495146
2023-07-07 19:48:17,216 - 


2023-07-07 19:48:17,217 - epoch:52,	loss:0.10264708334580064
2023-07-07 19:48:21,273 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:48:21,273 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:48:21,273 - wrong_be_tree_count:36	wrong_total:100	 wrong be tree ACC: 0.36
2023-07-07 19:48:31,570 - 


2023-07-07 19:48:31,571 - epoch:53,	loss:0.10362558154156432
2023-07-07 19:48:34,931 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:48:34,931 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 19:48:34,931 - wrong_be_tree_count:38	wrong_total:98	 wrong be tree ACC: 0.3877551020408163
2023-07-07 19:48:34,933 - save best model to ./output/test/best_model
2023-07-07 19:48:51,925 - 


2023-07-07 19:48:51,926 - epoch:54,	loss:0.10025476309238002
2023-07-07 19:48:55,029 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:48:55,029 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:48:55,029 - wrong_be_tree_count:36	wrong_total:99	 wrong be tree ACC: 0.36363636363636365
2023-07-07 19:49:05,084 - 


2023-07-07 19:49:05,084 - epoch:55,	loss:0.09929108951473609
2023-07-07 19:49:08,206 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:49:08,206 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:49:08,206 - wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
2023-07-07 19:49:08,231 - save best model to ./output/test/best_model
2023-07-07 19:49:34,278 - 


2023-07-07 19:49:34,293 - epoch:56,	loss:0.09991729212924838
2023-07-07 19:49:37,367 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:49:37,368 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:49:37,368 - wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
2023-07-07 19:49:56,511 - 


2023-07-07 19:49:56,511 - epoch:57,	loss:0.09480209252797067
2023-07-07 19:49:59,556 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:49:59,556 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:49:59,556 - wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
2023-07-07 19:50:14,954 - 


2023-07-07 19:50:14,955 - epoch:58,	loss:0.09629334032069892
2023-07-07 19:50:17,981 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:50:17,981 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:50:17,981 - wrong_be_tree_count:39	wrong_total:101	 wrong be tree ACC: 0.38613861386138615
2023-07-07 19:50:30,455 - 


2023-07-07 19:50:30,455 - epoch:59,	loss:0.09342200082028285
2023-07-07 19:50:33,909 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:50:33,909 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 19:50:33,909 - wrong_be_tree_count:38	wrong_total:101	 wrong be tree ACC: 0.37623762376237624
2023-07-07 19:50:44,983 - 


2023-07-07 19:50:44,983 - epoch:60,	loss:0.09612503444077447
2023-07-07 19:50:48,798 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:50:48,798 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 19:50:48,798 - wrong_be_tree_count:35	wrong_total:98	 wrong be tree ACC: 0.35714285714285715
2023-07-07 19:50:55,636 - get train data loader...
2023-07-07 19:50:55,728 - get dev data loader...
2023-07-07 19:50:55,806 - define model...
2023-07-07 19:50:59,194 - 


2023-07-07 19:50:59,194 - epoch:61,	loss:0.09342715347884223
2023-07-07 19:51:00,172 - define optimizer...
2023-07-07 19:51:00,174 - ===========================train setting parameters=========================
2023-07-07 19:51:00,174 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:51:00,174 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:51:00,174 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:51:00,174 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,174 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,174 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,175 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,175 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,175 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,178 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,178 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,179 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,179 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,179 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,183 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,183 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,183 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,185 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,185 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,185 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,185 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,189 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,189 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,192 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,192 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,192 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,193 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,193 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,193 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,194 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,194 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,194 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,195 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,195 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,195 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,198 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,198 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,198 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,198 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,201 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,202 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,202 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,203 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,203 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,206 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,206 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,207 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,207 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,207 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,210 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,210 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,210 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,211 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,211 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,221 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,221 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,221 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,221 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,221 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,228 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,228 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,238 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,238 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,239 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,239 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,239 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,240 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,243 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,246 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,247 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,247 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,247 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,247 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,247 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,255 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,264 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,267 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,267 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,271 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,274 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,274 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,288 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,296 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,296 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,311 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,311 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,312 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,312 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,312 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,315 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,318 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,318 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,320 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,320 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,320 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,329 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,329 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,329 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,329 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,329 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,336 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,336 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,336 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,336 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,337 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,339 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,342 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,342 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,342 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,342 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,342 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,343 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,343 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,343 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:00,343 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:00,344 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:00,344 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:00,344 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:00,344 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:00,344 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,346 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:00,351 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:00,351 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:00,351 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:51:00,352 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:51:00,352 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:51:00,352 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:51:00,352 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:51:00,353 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:51:00,353 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:51:00,353 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:51:00,353 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:51:00,353 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:51:00,353 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:51:00,353 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:51:00,353 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:51:00,353 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:51:00,353 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:51:00,353 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:51:00,353 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:51:00,354 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:51:00,354 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:51:00,354 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:51:00,354 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:51:00,355 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:51:00,355 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:51:03,486 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:51:03,486 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:51:03,486 - wrong_be_tree_count:38	wrong_total:98	 wrong be tree ACC: 0.3877551020408163
2023-07-07 19:51:14,140 - 


2023-07-07 19:51:14,140 - epoch:62,	loss:0.09314388543134555
2023-07-07 19:51:17,736 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:51:17,736 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:51:17,736 - wrong_be_tree_count:35	wrong_total:96	 wrong be tree ACC: 0.3645833333333333
2023-07-07 19:51:27,954 - 


2023-07-07 19:51:27,954 - epoch:63,	loss:0.08827244030544534
2023-07-07 19:51:31,696 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 19:51:31,696 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:51:31,696 - wrong_be_tree_count:36	wrong_total:97	 wrong be tree ACC: 0.3711340206185567
2023-07-07 19:51:38,804 - get train data loader...
2023-07-07 19:51:38,933 - get dev data loader...
2023-07-07 19:51:39,077 - define model...
2023-07-07 19:51:42,053 - 


2023-07-07 19:51:42,054 - epoch:64,	loss:0.08594350359635428
2023-07-07 19:51:43,976 - define optimizer...
2023-07-07 19:51:43,977 - ===========================train setting parameters=========================
2023-07-07 19:51:43,978 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:51:43,978 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:51:43,979 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:51:43,979 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,979 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,979 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,979 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,979 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,980 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,981 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,981 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,982 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,982 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,983 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,983 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,983 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,983 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,984 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,985 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,985 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,985 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,985 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,986 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,986 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,986 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,986 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,987 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,987 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,987 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,987 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,987 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,988 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,988 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,988 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,989 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,990 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,991 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,991 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,991 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,991 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,991 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,992 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,992 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,992 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,992 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,992 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,992 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,993 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,993 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,993 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,993 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,994 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,995 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,995 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,995 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,995 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,995 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,996 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,996 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,996 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,996 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:43,997 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:43,998 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:51:43,998 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:43,998 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:43,998 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:43,999 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:43,999 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:43,999 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:43,999 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:43,999 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:44,000 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,000 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,000 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,000 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,001 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,001 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:44,001 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,002 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:44,003 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:44,003 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:44,003 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,003 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,004 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,004 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:44,004 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:44,004 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:44,005 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:44,005 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:44,005 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:44,005 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,005 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,006 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,006 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,006 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:44,006 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:44,006 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:44,007 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,007 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,008 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,008 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:44,008 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:44,008 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:44,008 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,009 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,009 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,009 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:51:44,009 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:51:44,009 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:51:44,009 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:51:44,010 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:51:44,010 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:51:44,010 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,010 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,010 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,011 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,011 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:51:44,011 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:51:44,011 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:51:44,012 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:51:44,012 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:51:44,012 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:51:44,012 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:51:44,013 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:51:44,013 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:51:44,013 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:51:44,013 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:51:44,013 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:51:44,014 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:51:44,014 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:51:44,014 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:51:44,015 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:51:44,015 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:51:44,015 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:51:44,015 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:51:44,016 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:51:44,016 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:51:44,016 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:51:44,016 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:51:44,016 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:51:44,017 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:51:44,017 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:51:44,017 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:51:44,017 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:51:44,017 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:51:44,018 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 19:51:46,112 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:51:46,112 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 19:51:46,112 - wrong_be_tree_count:35	wrong_total:96	 wrong be tree ACC: 0.3645833333333333
2023-07-07 19:51:56,835 - 


2023-07-07 19:51:56,835 - epoch:65,	loss:0.08732218173099682
2023-07-07 19:52:01,976 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:52:01,976 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 19:52:01,976 - wrong_be_tree_count:35	wrong_total:96	 wrong be tree ACC: 0.3645833333333333
2023-07-07 19:52:12,368 - 


2023-07-07 19:52:12,369 - epoch:66,	loss:0.08377638814272359
2023-07-07 19:52:15,967 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:52:15,968 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 19:52:15,968 - wrong_be_tree_count:41	wrong_total:100	 wrong be tree ACC: 0.41
2023-07-07 19:52:26,157 - 


2023-07-07 19:52:26,158 - epoch:67,	loss:0.08349973935401067
2023-07-07 19:52:30,632 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:52:30,632 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:52:30,632 - wrong_be_tree_count:35	wrong_total:102	 wrong be tree ACC: 0.3431372549019608
2023-07-07 19:52:41,229 - 


2023-07-07 19:52:41,229 - epoch:68,	loss:0.0828713407390751
2023-07-07 19:52:44,627 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:52:44,627 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:52:44,627 - wrong_be_tree_count:36	wrong_total:100	 wrong be tree ACC: 0.36
2023-07-07 19:52:55,686 - 


2023-07-07 19:52:55,686 - epoch:69,	loss:0.08086115005426109
2023-07-07 19:52:59,479 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:52:59,479 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 19:52:59,479 - wrong_be_tree_count:33	wrong_total:98	 wrong be tree ACC: 0.336734693877551
2023-07-07 19:53:10,355 - 


2023-07-07 19:53:10,356 - epoch:70,	loss:0.08035694636055268
2023-07-07 19:53:13,827 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:53:13,827 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:53:13,827 - wrong_be_tree_count:36	wrong_total:100	 wrong be tree ACC: 0.36
2023-07-07 19:53:24,144 - 


2023-07-07 19:53:24,144 - epoch:71,	loss:0.07946845726110041
2023-07-07 19:53:27,863 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:53:27,863 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:53:27,863 - wrong_be_tree_count:34	wrong_total:101	 wrong be tree ACC: 0.33663366336633666
2023-07-07 19:53:38,225 - 


2023-07-07 19:53:38,225 - epoch:72,	loss:0.07922233350109309
2023-07-07 19:53:41,781 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:53:41,781 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:53:41,781 - wrong_be_tree_count:39	wrong_total:99	 wrong be tree ACC: 0.3939393939393939
2023-07-07 19:53:52,175 - 


2023-07-07 19:53:52,176 - epoch:73,	loss:0.07733319030376151
2023-07-07 19:53:55,771 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:53:55,772 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 19:53:55,772 - wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
2023-07-07 19:54:05,919 - 


2023-07-07 19:54:05,920 - epoch:74,	loss:0.07763060863362625
2023-07-07 19:54:09,287 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:54:09,287 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:54:09,287 - wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
2023-07-07 19:54:19,396 - 


2023-07-07 19:54:19,396 - epoch:75,	loss:0.07559531246079132
2023-07-07 19:54:22,849 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 19:54:22,850 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:54:22,850 - wrong_be_tree_count:38	wrong_total:104	 wrong be tree ACC: 0.36538461538461536
2023-07-07 19:54:33,448 - 


2023-07-07 19:54:33,449 - epoch:76,	loss:0.07566534320358187
2023-07-07 19:54:38,029 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:54:38,029 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:54:38,029 - wrong_be_tree_count:39	wrong_total:102	 wrong be tree ACC: 0.38235294117647056
2023-07-07 19:54:48,405 - 


2023-07-07 19:54:48,405 - epoch:77,	loss:0.073867976636393
2023-07-07 19:54:52,078 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 19:54:52,078 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 19:54:52,078 - wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-07 19:55:02,330 - 


2023-07-07 19:55:02,330 - epoch:78,	loss:0.07273065089248121
2023-07-07 19:55:06,036 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:55:06,036 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:55:06,036 - wrong_be_tree_count:38	wrong_total:99	 wrong be tree ACC: 0.3838383838383838
2023-07-07 19:55:16,132 - 


2023-07-07 19:55:16,132 - epoch:79,	loss:0.07411862254957668
2023-07-07 19:55:19,621 - right_count:330	total:433	 Answer ACC: 0.7621247113163973
2023-07-07 19:55:19,621 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-07 19:55:19,621 - wrong_be_tree_count:40	wrong_total:103	 wrong be tree ACC: 0.3883495145631068
2023-07-07 19:55:29,638 - 


2023-07-07 19:55:29,638 - epoch:80,	loss:0.07046729544526897
2023-07-07 19:55:33,114 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:55:33,115 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 19:55:33,115 - wrong_be_tree_count:38	wrong_total:100	 wrong be tree ACC: 0.38
2023-07-07 19:55:43,223 - 


2023-07-07 19:55:43,223 - epoch:81,	loss:0.07211166311753914
2023-07-07 19:55:46,559 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:55:46,559 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:55:46,559 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-07 19:55:56,803 - 


2023-07-07 19:55:56,804 - epoch:82,	loss:0.07260659273015335
2023-07-07 19:56:00,334 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:56:00,335 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:56:00,335 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-07 19:56:10,909 - 


2023-07-07 19:56:10,909 - epoch:83,	loss:0.07379983167629689
2023-07-07 19:56:14,367 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:56:14,367 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:56:14,367 - wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
2023-07-07 19:56:24,879 - 


2023-07-07 19:56:24,880 - epoch:84,	loss:0.06828910270996857
2023-07-07 19:56:28,509 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:56:28,509 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:56:28,509 - wrong_be_tree_count:38	wrong_total:100	 wrong be tree ACC: 0.38
2023-07-07 19:56:38,771 - 


2023-07-07 19:56:38,771 - epoch:85,	loss:0.06814510430558585
2023-07-07 19:56:42,213 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 19:56:42,213 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-07 19:56:42,213 - wrong_be_tree_count:38	wrong_total:100	 wrong be tree ACC: 0.38
2023-07-07 19:56:52,329 - 


2023-07-07 19:56:52,330 - epoch:86,	loss:0.06741621275432408
2023-07-07 19:56:55,971 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:56:55,971 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 19:56:55,971 - wrong_be_tree_count:37	wrong_total:99	 wrong be tree ACC: 0.37373737373737376
2023-07-07 19:57:06,067 - 


2023-07-07 19:57:06,068 - epoch:87,	loss:0.06805274708312936
2023-07-07 19:57:09,455 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 19:57:09,455 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 19:57:09,455 - wrong_be_tree_count:39	wrong_total:101	 wrong be tree ACC: 0.38613861386138615
2023-07-07 19:57:19,722 - 


2023-07-07 19:57:19,723 - epoch:88,	loss:0.06720578420208767
2023-07-07 19:57:23,576 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:57:23,576 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 19:57:23,576 - wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
2023-07-07 19:57:33,818 - 


2023-07-07 19:57:33,818 - epoch:89,	loss:0.06488450121833012
2023-07-07 19:57:37,205 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 19:57:37,206 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 19:57:37,206 - wrong_be_tree_count:39	wrong_total:95	 wrong be tree ACC: 0.4105263157894737
2023-07-07 19:57:37,208 - save best model to ./output/test/best_model
2023-07-07 19:57:52,788 - 


2023-07-07 19:57:52,788 - epoch:90,	loss:0.06638540889252909
2023-07-07 19:57:56,452 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 19:57:56,452 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 19:57:56,452 - wrong_be_tree_count:37	wrong_total:99	 wrong be tree ACC: 0.37373737373737376
2023-07-07 19:58:06,657 - 


2023-07-07 19:58:06,657 - epoch:91,	loss:0.06421625366783701
2023-07-07 19:58:10,071 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 19:58:10,071 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 19:58:10,071 - wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
2023-07-07 19:58:20,107 - 


2023-07-07 19:58:20,107 - epoch:92,	loss:0.06517635160707869
2023-07-07 19:58:23,493 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:58:23,493 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 19:58:23,493 - wrong_be_tree_count:38	wrong_total:96	 wrong be tree ACC: 0.3958333333333333
2023-07-07 19:58:33,933 - 


2023-07-07 19:58:33,933 - epoch:93,	loss:0.0637500777374953
2023-07-07 19:58:37,464 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:58:37,464 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 19:58:37,464 - wrong_be_tree_count:38	wrong_total:96	 wrong be tree ACC: 0.3958333333333333
2023-07-07 19:58:47,645 - 


2023-07-07 19:58:47,645 - epoch:94,	loss:0.06336931425903458
2023-07-07 19:58:50,983 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 19:58:50,983 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 19:58:50,983 - wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-07 19:59:01,553 - 


2023-07-07 19:59:01,553 - epoch:95,	loss:0.06337087557767518
2023-07-07 19:59:04,976 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 19:59:04,976 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 19:59:04,976 - wrong_be_tree_count:35	wrong_total:97	 wrong be tree ACC: 0.36082474226804123
2023-07-07 19:59:15,826 - 


2023-07-07 19:59:15,826 - epoch:96,	loss:0.0653396401903592
2023-07-07 19:59:39,240 - get train data loader...
2023-07-07 19:59:39,523 - get dev data loader...
2023-07-07 19:59:39,662 - define model...
2023-07-07 19:59:43,896 - define optimizer...
2023-07-07 19:59:43,899 - ===========================train setting parameters=========================
2023-07-07 19:59:43,899 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 19:59:43,899 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 19:59:43,901 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 19:59:43,901 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,901 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,901 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,901 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,901 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,901 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,902 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,902 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,902 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,903 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,903 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,903 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,903 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,904 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,904 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,904 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,904 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,905 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,905 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,905 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,906 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,906 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,906 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,906 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,907 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,908 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,908 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,909 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,909 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,909 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,909 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,910 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,911 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,912 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,912 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,912 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,917 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,917 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,917 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,918 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,918 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,918 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,919 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,919 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,919 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,920 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,920 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,921 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,922 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,922 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,923 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,923 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,923 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,924 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,924 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,925 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,925 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,925 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,925 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,925 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,926 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,926 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,926 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,926 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,927 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,927 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,928 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,928 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,929 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,929 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,930 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,930 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,931 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,932 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,932 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,933 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,934 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,934 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,934 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,936 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,936 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,937 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,937 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,937 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,938 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,938 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,939 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,940 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,940 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,941 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,941 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,941 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,942 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,942 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,942 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,943 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,943 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,943 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,945 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,945 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,945 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,946 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,946 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,947 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,948 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,948 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,948 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,948 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,949 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,949 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,949 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,950 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,950 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,950 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,950 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,951 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,951 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,951 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,952 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,952 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,952 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,953 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,953 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,953 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,954 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,954 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,954 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,955 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,955 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,955 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,955 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,956 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,957 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,957 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,958 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,958 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,959 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,959 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,960 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,961 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,961 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,961 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,962 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,962 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,963 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,963 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 19:59:43,964 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 19:59:43,965 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 19:59:43,965 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 19:59:43,966 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 19:59:43,966 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 19:59:43,967 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,967 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,967 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,967 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,968 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 19:59:43,968 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 19:59:43,969 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 19:59:43,969 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 19:59:43,969 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 19:59:43,970 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 19:59:43,970 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 19:59:43,970 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 19:59:43,970 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 19:59:43,970 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 19:59:43,970 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 19:59:43,971 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 19:59:43,971 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 19:59:43,971 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 19:59:43,971 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 19:59:43,971 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 19:59:43,971 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 19:59:43,972 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 19:59:43,972 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 19:59:43,972 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 19:59:43,972 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 19:59:43,972 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 19:59:43,973 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 19:59:43,973 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 19:59:43,974 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 19:59:43,974 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 19:59:43,974 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 19:59:43,974 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 19:59:43,975 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 19:59:43,975 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 20:06:23,402 - get train data loader...
2023-07-07 20:06:23,543 - get dev data loader...
2023-07-07 20:06:23,629 - define model...
2023-07-07 20:06:28,399 - define optimizer...
2023-07-07 20:06:28,400 - ===========================train setting parameters=========================
2023-07-07 20:06:28,400 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 20:06:28,401 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 20:06:28,401 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 20:06:28,401 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,402 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,403 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,403 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,403 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,403 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,403 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,404 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,405 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,405 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,405 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,406 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,406 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,407 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,407 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,407 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,407 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,408 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,408 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,408 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,409 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,409 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,409 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,409 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,410 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,410 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,410 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,411 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,411 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,412 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,412 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,412 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,412 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,413 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,413 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,413 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,413 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,414 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,414 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,414 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,415 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,415 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,415 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,415 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,415 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,416 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,416 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,416 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,417 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,417 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,417 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,417 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,417 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,417 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,417 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,418 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,419 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,419 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,419 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,420 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,420 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,420 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,420 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,420 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,421 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,421 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,421 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,421 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,421 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,422 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,422 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,422 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,422 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,424 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,424 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,424 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,424 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,425 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,425 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,425 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,425 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,426 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,426 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,426 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,426 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,426 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,427 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,427 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,427 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,428 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,428 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,428 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,428 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,429 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,429 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,429 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,429 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,430 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,430 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,430 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,430 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,431 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,431 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,431 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,431 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,431 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,436 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,437 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,437 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,437 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,437 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,438 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,439 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,439 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,439 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,440 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,440 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,440 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,440 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,440 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,441 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,441 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,441 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,441 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,441 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:06:28,441 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 20:06:28,442 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:06:28,442 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 20:06:28,442 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:06:28,442 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 20:06:28,442 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:06:28,443 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:06:28,444 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 20:06:28,444 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:06:28,444 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:06:28,444 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 20:06:28,444 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 20:06:28,445 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 20:06:28,445 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 20:06:28,445 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 20:06:28,445 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 20:06:28,445 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 20:06:28,446 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 20:06:28,446 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 20:06:28,446 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 20:06:28,446 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 20:06:28,446 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 20:06:28,446 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 20:06:28,447 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 20:06:28,447 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 20:06:28,447 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 20:06:28,447 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 20:06:28,447 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 20:06:28,447 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 20:06:28,451 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 20:06:28,451 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 20:06:28,451 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 20:06:28,451 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 20:06:28,451 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 20:07:24,244 - get train data loader...
2023-07-07 20:07:24,371 - get dev data loader...
2023-07-07 20:07:24,464 - define model...
2023-07-07 20:07:28,442 - define optimizer...
2023-07-07 20:07:28,443 - ===========================train setting parameters=========================
2023-07-07 20:07:28,443 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 20:07:28,443 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 20:07:28,443 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 20:07:28,443 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,444 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,444 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,445 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,446 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,447 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,447 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,447 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,447 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,447 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,447 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,447 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,447 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,448 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,449 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,449 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,449 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,449 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,449 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,449 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,449 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,449 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,450 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,451 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,451 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,451 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,451 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,451 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,451 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,451 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,451 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,452 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,453 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,453 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,453 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,454 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,454 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,454 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,454 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,454 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,455 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,455 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,455 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,455 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,456 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,457 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,458 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,458 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,458 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,458 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,458 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,458 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,458 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,459 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,460 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,460 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,460 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,460 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,460 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,460 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,460 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,460 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,461 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,462 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,462 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,462 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 20:07:28,463 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,464 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,464 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,464 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,464 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:07:28,464 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:07:28,465 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:07:28,465 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 20:07:28,465 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:07:28,465 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:07:28,465 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 20:07:28,465 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 20:07:28,465 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 20:07:28,465 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 20:07:28,466 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 20:07:28,466 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 20:07:28,466 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 20:07:28,466 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 20:07:28,466 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 20:07:28,466 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 20:07:28,466 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 20:07:28,466 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 20:07:28,466 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 20:07:28,466 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 20:07:28,466 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 20:07:28,467 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 20:07:28,467 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 20:07:28,467 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 20:07:28,467 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 20:07:28,467 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 20:07:28,467 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 20:07:28,467 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 20:07:28,467 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 20:07:28,467 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 20:07:59,361 - get train data loader...
2023-07-07 20:07:59,743 - get dev data loader...
2023-07-07 20:07:59,905 - define model...
2023-07-07 20:08:04,303 - define optimizer...
2023-07-07 20:08:04,306 - ===========================train setting parameters=========================
2023-07-07 20:08:04,306 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 20:08:04,307 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 20:08:04,307 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 20:08:04,308 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,308 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,310 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,310 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,310 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,310 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,311 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,311 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,311 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,311 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,312 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,312 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,313 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,313 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,314 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,314 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,315 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,315 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,316 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,316 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,317 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,317 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,318 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,318 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,319 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,319 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,319 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,320 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,320 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,320 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,321 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,321 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,322 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,322 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,323 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,323 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,323 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,323 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,323 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,324 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,324 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,324 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,325 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,325 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,325 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,326 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,326 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,327 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,327 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,327 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,327 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,327 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,328 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,328 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,328 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,329 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,329 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,330 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,330 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,331 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,332 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,333 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,333 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,334 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,334 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,335 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,335 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,335 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,335 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,335 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,336 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,336 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,336 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,336 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,337 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,337 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,337 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,338 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,338 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,338 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,338 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,338 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,339 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,340 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,340 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,340 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,340 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,340 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,341 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,341 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,341 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,341 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,341 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,342 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,342 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,342 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,342 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,342 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,343 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,344 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,344 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,344 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,345 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,345 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,345 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,346 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,347 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,347 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,347 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,347 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,348 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,348 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,349 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,349 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,350 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,350 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,351 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,351 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,351 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,352 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,352 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,352 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,352 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,352 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,353 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,353 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,353 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,353 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,353 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,354 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,354 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,354 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,355 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,355 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,355 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,356 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,357 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,357 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,358 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,358 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,358 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,358 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,359 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,359 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,359 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,360 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,361 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,361 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,361 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 20:08:04,361 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 20:08:04,361 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 20:08:04,362 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 20:08:04,362 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 20:08:04,362 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 20:08:04,363 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,363 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,363 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,363 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,363 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 20:08:04,364 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 20:08:04,364 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 20:08:04,364 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 20:08:04,364 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 20:08:04,364 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 20:08:04,364 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 20:08:04,365 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 20:08:04,365 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 20:08:04,366 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 20:08:04,366 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 20:08:04,366 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 20:08:04,366 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 20:08:04,367 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 20:08:04,367 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 20:08:04,367 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 20:08:04,367 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 20:08:04,367 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 20:08:04,367 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 20:08:04,368 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 20:08:04,368 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 20:08:04,368 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 20:08:04,368 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 20:08:04,369 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 20:08:04,369 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 20:08:04,370 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 20:08:04,370 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 20:08:04,371 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 20:08:04,371 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 20:08:04,372 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 17:08:28,857 - get train data loader...
2023-07-07 17:08:29,247 - get dev data loader...
2023-07-07 17:08:29,451 - define model...
2023-07-07 17:11:08,134 - get train data loader...
2023-07-07 17:11:08,707 - get dev data loader...
2023-07-07 17:11:09,003 - define model...
2023-07-07 17:11:28,415 - define optimizer...
2023-07-07 17:11:28,424 - ===========================train setting parameters=========================
2023-07-07 17:11:28,424 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 17:11:28,426 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 17:11:28,429 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 17:11:28,430 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,430 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,430 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,430 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,431 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,431 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,432 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,432 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,433 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,433 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,433 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,433 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,435 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,435 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,435 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,435 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,435 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,436 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,437 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,437 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,437 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,437 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,437 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,438 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,438 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,439 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,439 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,439 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,439 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,448 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,448 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,448 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,449 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,449 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,449 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,449 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,458 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,459 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,459 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,459 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,459 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,459 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,465 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,465 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,466 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,471 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,471 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,471 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,471 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,472 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,472 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,472 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,472 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,472 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,477 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,477 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,478 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,478 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,478 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,478 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,478 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,478 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,478 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,478 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,479 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,481 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,482 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,483 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,483 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,484 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,484 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,484 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,484 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,484 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,484 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,484 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,486 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,487 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,489 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,489 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,489 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,489 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,490 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,490 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,490 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,490 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,492 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,494 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,494 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,494 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,494 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,494 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,495 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,495 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,495 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,497 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,498 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,499 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,500 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,500 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,500 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,500 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,501 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,502 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,502 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,502 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,503 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,503 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,503 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,503 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,503 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,505 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,505 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,505 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,505 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,505 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,505 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,505 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,507 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,507 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,507 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,507 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,508 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,508 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,508 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,510 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,510 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,510 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,510 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,510 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,510 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,510 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,510 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,512 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,512 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,512 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,512 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,513 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,513 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,513 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,513 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,515 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,515 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,515 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,515 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,515 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:11:28,515 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 17:11:28,515 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:11:28,515 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 17:11:28,517 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:11:28,517 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 17:11:28,517 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,517 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,518 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,518 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,518 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:11:28,518 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:11:28,520 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:11:28,520 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 17:11:28,520 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:11:28,520 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:11:28,520 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 17:11:28,520 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 17:11:28,520 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 17:11:28,520 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 17:11:28,522 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 17:11:28,522 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 17:11:28,523 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 17:11:28,523 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 17:11:28,523 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 17:11:28,523 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 17:11:28,523 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 17:11:28,523 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 17:11:28,523 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 17:11:28,523 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 17:11:28,523 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 17:11:28,525 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 17:11:28,525 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 17:11:28,526 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 17:11:28,526 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 17:11:28,526 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 17:11:28,526 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 17:11:28,526 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 17:11:28,526 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 17:11:28,526 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 17:11:28,540 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 17:11:45,402 - 


2023-07-07 17:11:45,402 - epoch:0,	loss:31.162674129009247
2023-07-07 17:11:54,889 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:11:54,890 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:11:54,890 - wrong_be_tree_count:412	wrong_total:433	 wrong be tree ACC: 0.9515011547344111
2023-07-07 17:11:54,900 - save best model to ./output/test/best_model
2023-07-07 17:12:13,779 - 


2023-07-07 17:12:13,780 - epoch:1,	loss:29.350705742836
2023-07-07 17:12:23,223 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:12:23,224 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:12:23,232 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:12:36,224 - 


2023-07-07 17:12:36,225 - epoch:2,	loss:24.162699162960052
2023-07-07 17:12:45,620 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:12:45,620 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:12:45,622 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:12:59,224 - 


2023-07-07 17:12:59,225 - epoch:3,	loss:11.067088253097609
2023-07-07 17:13:09,295 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:13:09,295 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:13:09,298 - wrong_be_tree_count:61	wrong_total:433	 wrong be tree ACC: 0.14087759815242495
2023-07-07 17:13:24,915 - 


2023-07-07 17:13:24,915 - epoch:4,	loss:-15.520586408674717
2023-07-07 17:13:34,663 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:13:34,664 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:13:34,665 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:13:47,799 - 


2023-07-07 17:13:47,799 - epoch:5,	loss:-57.393886148929596
2023-07-07 17:13:56,131 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:13:56,132 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:13:56,132 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:14:08,243 - 


2023-07-07 17:14:08,243 - epoch:6,	loss:-119.26179993152618
2023-07-07 17:14:16,457 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:14:16,457 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:14:16,457 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:14:29,438 - 


2023-07-07 17:14:29,438 - epoch:7,	loss:-208.5039403438568
2023-07-07 17:14:38,244 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:14:38,245 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:14:38,245 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:14:50,687 - 


2023-07-07 17:14:50,688 - epoch:8,	loss:-333.35989809036255
2023-07-07 17:14:59,199 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:14:59,199 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:14:59,199 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:15:13,168 - 


2023-07-07 17:15:13,169 - epoch:9,	loss:-505.0214891433716
2023-07-07 17:15:21,777 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:15:21,777 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:15:21,777 - wrong_be_tree_count:0	wrong_total:433	 wrong be tree ACC: 0.0
2023-07-07 17:15:34,558 - 


2023-07-07 17:15:34,558 - epoch:10,	loss:-735.3374710083008
2023-07-07 17:24:53,571 - get train data loader...
2023-07-07 17:24:53,897 - get dev data loader...
2023-07-07 17:24:54,076 - define model...
2023-07-07 17:24:58,833 - define optimizer...
2023-07-07 17:24:58,837 - ===========================train setting parameters=========================
2023-07-07 17:24:58,837 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 17:24:58,837 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 17:24:58,838 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 17:24:58,838 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,838 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,839 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,840 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,840 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,841 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,841 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,842 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,843 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,844 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,844 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,844 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,844 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,845 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,845 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,846 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,846 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,851 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,852 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,853 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,853 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,854 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,855 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,856 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,856 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,857 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,857 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,858 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,859 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,860 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,860 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,861 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,861 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,862 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,862 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,863 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,864 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,865 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,865 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,866 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,867 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,868 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,868 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,869 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,869 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,871 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,871 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,872 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,872 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,873 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,874 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,875 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,875 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,876 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,877 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,878 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,878 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,879 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,880 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,881 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,881 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,882 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,883 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,884 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,884 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,885 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,885 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,887 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,887 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,888 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,888 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,889 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,890 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,891 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,891 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,893 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,893 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,894 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,894 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,895 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,896 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,897 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,897 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,898 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,898 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,899 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,900 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,901 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,901 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,902 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,902 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,904 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,904 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,905 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,905 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,906 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,907 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,908 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,908 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,909 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,909 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,910 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,911 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,912 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,912 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,913 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,913 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,914 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,915 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,916 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,916 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,917 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,917 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,918 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,919 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,920 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,920 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,921 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,921 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,922 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,922 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,924 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,924 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,926 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,926 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,928 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,929 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,930 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,930 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,931 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,931 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,932 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,933 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,934 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,935 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,935 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,937 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,937 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,937 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,939 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,939 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,940 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,940 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,941 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,942 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,943 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,943 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,944 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,945 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,946 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,947 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,948 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,950 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,951 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,952 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,953 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,954 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,954 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,955 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,955 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,956 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,957 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,958 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,959 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,959 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,960 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,961 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,961 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,961 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,962 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,962 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,962 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,965 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,965 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,965 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,966 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,966 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,966 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,967 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:24:58,967 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 17:24:58,969 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:24:58,969 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 17:24:58,969 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:24:58,970 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 17:24:58,970 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,970 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,972 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,972 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,972 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:24:58,973 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:24:58,973 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:24:58,974 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 17:24:58,974 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:24:58,975 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:24:58,976 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 17:24:58,977 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 17:24:58,977 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 17:24:58,977 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 17:24:58,978 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 17:24:58,978 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 17:24:58,979 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 17:24:58,979 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 17:24:58,980 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 17:24:58,981 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 17:24:58,982 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 17:24:58,982 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 17:24:58,983 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 17:24:58,983 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 17:24:58,984 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 17:24:58,984 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 17:24:58,985 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 17:24:58,986 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 17:24:58,987 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 17:24:58,987 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 17:24:58,988 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 17:24:58,988 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 17:24:58,989 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 17:24:58,990 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 17:24:59,009 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 17:29:08,707 - get train data loader...
2023-07-07 17:29:09,049 - get dev data loader...
2023-07-07 17:29:09,209 - define model...
2023-07-07 17:29:13,526 - define optimizer...
2023-07-07 17:29:13,530 - ===========================train setting parameters=========================
2023-07-07 17:29:13,530 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-07 17:29:13,531 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-07 17:29:13,532 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-07 17:29:13,532 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,533 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,533 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,533 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,534 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,534 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,534 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,534 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,535 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,535 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,535 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,535 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,536 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,536 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,536 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,537 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,537 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,537 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,538 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,538 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,539 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,539 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,539 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,540 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,540 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,540 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,540 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,541 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,541 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,541 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,541 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,542 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,542 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,542 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,543 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,543 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,543 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,544 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,544 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,544 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,544 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,545 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,545 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,545 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,546 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,546 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,546 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,547 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,547 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,548 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,548 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,549 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,549 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,549 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,549 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,550 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,550 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,550 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,550 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,551 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,551 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,551 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,551 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,552 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,552 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,552 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,553 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,553 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,553 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,554 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,554 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,555 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,555 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,556 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,556 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,556 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,556 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,557 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,557 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,557 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,558 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,558 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,558 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,559 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,559 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,560 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,560 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,561 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,561 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,561 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,562 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,562 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,562 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,563 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,563 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,563 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,564 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,565 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,565 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,566 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,566 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,566 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,567 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,568 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,568 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,569 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,569 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,570 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,570 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,570 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,571 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,572 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,572 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,573 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,573 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,573 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,574 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,574 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,575 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,576 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,576 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,576 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,576 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,577 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,577 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,577 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,577 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,578 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,578 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,578 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,579 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,580 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,580 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,581 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,581 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,581 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,581 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,582 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,583 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,583 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,583 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,584 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,584 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,584 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,584 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,585 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,585 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,585 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,586 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,586 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,587 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,587 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,588 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,588 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,588 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,588 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,589 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,589 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,589 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,589 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,590 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,590 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,590 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,590 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,590 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,591 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,591 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,591 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,592 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,592 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,592 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,592 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,593 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,594 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,594 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,594 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,595 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,595 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,595 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-07 17:29:13,595 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-07 17:29:13,596 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-07 17:29:13,596 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-07 17:29:13,596 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-07 17:29:13,596 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-07 17:29:13,597 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,597 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,597 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,598 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,598 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-07 17:29:13,598 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-07 17:29:13,598 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-07 17:29:13,599 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-07 17:29:13,599 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-07 17:29:13,600 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-07 17:29:13,601 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-07 17:29:13,601 - bert.pooler.dense.bias-torch.Size([768])
2023-07-07 17:29:13,601 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-07 17:29:13,601 - fc.layer1.0.bias-torch.Size([2048])
2023-07-07 17:29:13,602 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-07 17:29:13,602 - fc.layer2.0.bias-torch.Size([1024])
2023-07-07 17:29:13,602 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-07 17:29:13,602 - fc.layer3.0.bias-torch.Size([28])
2023-07-07 17:29:13,603 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-07 17:29:13,603 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-07 17:29:13,603 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-07 17:29:13,603 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-07 17:29:13,604 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-07 17:29:13,604 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-07 17:29:13,604 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-07 17:29:13,605 - code_check.layer1.0.bias-torch.Size([768])
2023-07-07 17:29:13,606 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-07 17:29:13,606 - code_check.layer2.0.bias-torch.Size([384])
2023-07-07 17:29:13,607 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-07 17:29:13,607 - code_check.layer3.0.bias-torch.Size([2])
2023-07-07 17:29:13,607 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-07 17:29:13,608 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-07 17:29:13,608 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-07 17:29:13,608 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-07 17:29:13,622 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-07 17:29:21,695 - 


2023-07-07 17:29:21,695 - epoch:0,	loss:29.10623925924301
2023-07-07 17:29:29,741 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-07 17:29:29,741 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:29:29,741 - wrong_be_tree_count:26	wrong_total:432	 wrong be tree ACC: 0.06018518518518518
2023-07-07 17:29:29,746 - save best model to ./output/test/best_model
2023-07-07 17:29:50,308 - 


2023-07-07 17:29:50,309 - epoch:1,	loss:21.675853192806244
2023-07-07 17:29:58,010 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:29:58,010 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:29:58,010 - wrong_be_tree_count:432	wrong_total:433	 wrong be tree ACC: 0.9976905311778291
2023-07-07 17:30:11,050 - 


2023-07-07 17:30:11,051 - epoch:2,	loss:11.28910094499588
2023-07-07 17:30:18,596 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:30:18,596 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:30:18,597 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:30:30,854 - 


2023-07-07 17:30:30,854 - epoch:3,	loss:5.713678307831287
2023-07-07 17:30:38,356 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:30:38,356 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:30:38,356 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:30:50,849 - 


2023-07-07 17:30:50,849 - epoch:4,	loss:4.3039905577898026
2023-07-07 17:30:58,237 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:30:58,238 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:30:58,239 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:31:10,397 - 


2023-07-07 17:31:10,398 - epoch:5,	loss:3.4324928745627403
2023-07-07 17:31:18,219 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:31:18,219 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:31:18,219 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:31:32,901 - 


2023-07-07 17:31:32,902 - epoch:6,	loss:3.045180093497038
2023-07-07 17:31:40,615 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:31:40,615 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:31:40,615 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:31:53,419 - 


2023-07-07 17:31:53,419 - epoch:7,	loss:2.8958472535014153
2023-07-07 17:32:01,526 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-07 17:32:01,527 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-07 17:32:01,527 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-07 17:32:14,310 - 


2023-07-07 17:32:14,311 - epoch:8,	loss:2.794802762567997
2023-07-07 17:32:22,156 - right_count:35	total:433	 Answer ACC: 0.08083140877598152
2023-07-07 17:32:22,157 - right_codes_count:13	total:433	 Code ACC: 0.03002309468822171
2023-07-07 17:32:22,157 - wrong_be_tree_count:80	wrong_total:398	 wrong be tree ACC: 0.20100502512562815
2023-07-07 17:32:22,165 - save best model to ./output/test/best_model
2023-07-07 17:32:40,267 - 


2023-07-07 17:32:40,268 - epoch:9,	loss:2.675110161304474
2023-07-07 17:32:48,237 - right_count:95	total:433	 Answer ACC: 0.21939953810623555
2023-07-07 17:32:48,237 - right_codes_count:65	total:433	 Code ACC: 0.15011547344110854
2023-07-07 17:32:48,237 - wrong_be_tree_count:95	wrong_total:338	 wrong be tree ACC: 0.28106508875739644
2023-07-07 17:32:48,244 - save best model to ./output/test/best_model
2023-07-07 17:33:12,881 - 


2023-07-07 17:33:12,883 - epoch:10,	loss:2.420791696757078
2023-07-07 17:33:20,956 - right_count:97	total:433	 Answer ACC: 0.22401847575057737
2023-07-07 17:33:20,956 - right_codes_count:66	total:433	 Code ACC: 0.15242494226327943
2023-07-07 17:33:20,956 - wrong_be_tree_count:118	wrong_total:336	 wrong be tree ACC: 0.35119047619047616
2023-07-07 17:33:20,961 - save best model to ./output/test/best_model
2023-07-07 17:33:40,642 - 


2023-07-07 17:33:40,642 - epoch:11,	loss:2.0504341274499893
2023-07-07 17:33:48,907 - right_count:137	total:433	 Answer ACC: 0.3163972286374134
2023-07-07 17:33:48,907 - right_codes_count:110	total:433	 Code ACC: 0.2540415704387991
2023-07-07 17:33:48,907 - wrong_be_tree_count:30	wrong_total:296	 wrong be tree ACC: 0.10135135135135136
2023-07-07 17:33:48,912 - save best model to ./output/test/best_model
2023-07-07 17:34:06,970 - 


2023-07-07 17:34:06,970 - epoch:12,	loss:1.8224882036447525
2023-07-07 17:34:14,838 - right_count:212	total:433	 Answer ACC: 0.4896073903002309
2023-07-07 17:34:14,838 - right_codes_count:188	total:433	 Code ACC: 0.4341801385681293
2023-07-07 17:34:14,838 - wrong_be_tree_count:19	wrong_total:221	 wrong be tree ACC: 0.08597285067873303
2023-07-07 17:34:14,844 - save best model to ./output/test/best_model
2023-07-07 17:34:32,990 - 


2023-07-07 17:34:32,990 - epoch:13,	loss:1.6397493835538626
2023-07-07 17:34:41,000 - right_count:221	total:433	 Answer ACC: 0.5103926096997691
2023-07-07 17:34:41,001 - right_codes_count:203	total:433	 Code ACC: 0.46882217090069284
2023-07-07 17:34:41,001 - wrong_be_tree_count:33	wrong_total:212	 wrong be tree ACC: 0.15566037735849056
2023-07-07 17:34:41,006 - save best model to ./output/test/best_model
2023-07-07 17:35:08,255 - 


2023-07-07 17:35:08,256 - epoch:14,	loss:1.47284453548491
2023-07-07 17:35:16,589 - right_count:227	total:433	 Answer ACC: 0.5242494226327945
2023-07-07 17:35:16,589 - right_codes_count:210	total:433	 Code ACC: 0.48498845265588914
2023-07-07 17:35:16,589 - wrong_be_tree_count:20	wrong_total:206	 wrong be tree ACC: 0.0970873786407767
2023-07-07 17:35:16,596 - save best model to ./output/test/best_model
2023-07-07 17:35:35,305 - 


2023-07-07 17:35:35,305 - epoch:15,	loss:1.3494968973100185
2023-07-07 17:35:43,045 - right_count:240	total:433	 Answer ACC: 0.5542725173210161
2023-07-07 17:35:43,045 - right_codes_count:224	total:433	 Code ACC: 0.5173210161662818
2023-07-07 17:35:43,045 - wrong_be_tree_count:48	wrong_total:193	 wrong be tree ACC: 0.24870466321243523
2023-07-07 17:35:43,052 - save best model to ./output/test/best_model
2023-07-07 17:36:01,293 - 


2023-07-07 17:36:01,293 - epoch:16,	loss:1.2124132867902517
2023-07-07 17:36:09,503 - right_count:254	total:433	 Answer ACC: 0.5866050808314087
2023-07-07 17:36:09,504 - right_codes_count:235	total:433	 Code ACC: 0.5427251732101617
2023-07-07 17:36:09,504 - wrong_be_tree_count:61	wrong_total:179	 wrong be tree ACC: 0.3407821229050279
2023-07-07 17:36:09,509 - save best model to ./output/test/best_model
2023-07-07 17:36:27,588 - 


2023-07-07 17:36:27,589 - epoch:17,	loss:1.0798421744257212
2023-07-07 17:36:35,943 - right_count:271	total:433	 Answer ACC: 0.625866050808314
2023-07-07 17:36:35,943 - right_codes_count:254	total:433	 Code ACC: 0.5866050808314087
2023-07-07 17:36:35,945 - wrong_be_tree_count:82	wrong_total:162	 wrong be tree ACC: 0.5061728395061729
2023-07-07 17:36:35,953 - save best model to ./output/test/best_model
2023-07-07 17:36:56,534 - 


2023-07-07 17:36:56,534 - epoch:18,	loss:0.9785589352250099
2023-07-07 17:37:04,451 - right_count:282	total:433	 Answer ACC: 0.651270207852194
2023-07-07 17:37:04,452 - right_codes_count:269	total:433	 Code ACC: 0.6212471131639723
2023-07-07 17:37:04,452 - wrong_be_tree_count:87	wrong_total:151	 wrong be tree ACC: 0.5761589403973509
2023-07-07 17:37:04,459 - save best model to ./output/test/best_model
2023-07-07 17:37:22,436 - 


2023-07-07 17:37:22,437 - epoch:19,	loss:0.8253042502328753
2023-07-07 17:37:30,336 - right_count:302	total:433	 Answer ACC: 0.6974595842956121
2023-07-07 17:37:30,336 - right_codes_count:286	total:433	 Code ACC: 0.6605080831408776
2023-07-07 17:37:30,336 - wrong_be_tree_count:73	wrong_total:131	 wrong be tree ACC: 0.5572519083969466
2023-07-07 17:37:30,341 - save best model to ./output/test/best_model
2023-07-07 17:37:48,815 - 


2023-07-07 17:37:48,816 - epoch:20,	loss:0.77331374399364
2023-07-07 17:37:56,934 - right_count:298	total:433	 Answer ACC: 0.6882217090069284
2023-07-07 17:37:56,935 - right_codes_count:281	total:433	 Code ACC: 0.648960739030023
2023-07-07 17:37:56,935 - wrong_be_tree_count:64	wrong_total:135	 wrong be tree ACC: 0.4740740740740741
2023-07-07 17:38:10,466 - 


2023-07-07 17:38:10,467 - epoch:21,	loss:0.6898792372085154
2023-07-07 17:38:18,534 - right_count:317	total:433	 Answer ACC: 0.7321016166281755
2023-07-07 17:38:18,534 - right_codes_count:299	total:433	 Code ACC: 0.6905311778290993
2023-07-07 17:38:18,604 - wrong_be_tree_count:54	wrong_total:116	 wrong be tree ACC: 0.46551724137931033
2023-07-07 17:38:18,616 - save best model to ./output/test/best_model
2023-07-07 17:38:36,853 - 


2023-07-07 17:38:36,854 - epoch:22,	loss:0.6362611656077206
2023-07-07 17:38:44,886 - right_count:317	total:433	 Answer ACC: 0.7321016166281755
2023-07-07 17:38:44,886 - right_codes_count:303	total:433	 Code ACC: 0.6997690531177829
2023-07-07 17:38:44,887 - wrong_be_tree_count:59	wrong_total:116	 wrong be tree ACC: 0.5086206896551724
2023-07-07 17:38:57,550 - 


2023-07-07 17:38:57,550 - epoch:23,	loss:0.6183072323910892
2023-07-07 17:39:05,316 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-07 17:39:05,317 - right_codes_count:306	total:433	 Code ACC: 0.7066974595842956
2023-07-07 17:39:05,317 - wrong_be_tree_count:45	wrong_total:110	 wrong be tree ACC: 0.4090909090909091
2023-07-07 17:39:05,323 - save best model to ./output/test/best_model
2023-07-07 17:39:23,468 - 


2023-07-07 17:39:23,468 - epoch:24,	loss:0.5650867838412523
2023-07-07 17:39:31,015 - right_count:317	total:433	 Answer ACC: 0.7321016166281755
2023-07-07 17:39:31,015 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-07 17:39:31,015 - wrong_be_tree_count:46	wrong_total:116	 wrong be tree ACC: 0.39655172413793105
2023-07-07 17:39:43,723 - 


2023-07-07 17:39:43,723 - epoch:25,	loss:0.5322930798865855
2023-07-07 17:39:51,438 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:39:51,438 - right_codes_count:309	total:433	 Code ACC: 0.7136258660508084
2023-07-07 17:39:51,440 - wrong_be_tree_count:38	wrong_total:104	 wrong be tree ACC: 0.36538461538461536
2023-07-07 17:39:51,445 - save best model to ./output/test/best_model
2023-07-07 17:40:12,713 - 


2023-07-07 17:40:12,714 - epoch:26,	loss:0.49192396155558527
2023-07-07 17:40:20,283 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 17:40:20,283 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 17:40:20,283 - wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
2023-07-07 17:40:20,290 - save best model to ./output/test/best_model
2023-07-07 17:40:38,038 - 


2023-07-07 17:40:38,038 - epoch:27,	loss:0.48516618041321635
2023-07-07 17:40:45,755 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:40:45,755 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 17:40:45,755 - wrong_be_tree_count:35	wrong_total:104	 wrong be tree ACC: 0.33653846153846156
2023-07-07 17:40:58,463 - 


2023-07-07 17:40:58,463 - epoch:28,	loss:0.4707718282006681
2023-07-07 17:41:06,394 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-07 17:41:06,395 - right_codes_count:308	total:433	 Code ACC: 0.7113163972286374
2023-07-07 17:41:06,395 - wrong_be_tree_count:36	wrong_total:107	 wrong be tree ACC: 0.3364485981308411
2023-07-07 17:41:19,329 - 


2023-07-07 17:41:19,329 - epoch:29,	loss:0.4318398730829358
2023-07-07 17:41:27,163 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 17:41:27,163 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 17:41:27,163 - wrong_be_tree_count:37	wrong_total:100	 wrong be tree ACC: 0.37
2023-07-07 17:41:27,168 - save best model to ./output/test/best_model
2023-07-07 17:41:52,042 - 


2023-07-07 17:41:52,042 - epoch:30,	loss:0.40883160498924553
2023-07-07 17:41:59,948 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:41:59,949 - right_codes_count:313	total:433	 Code ACC: 0.7228637413394919
2023-07-07 17:41:59,949 - wrong_be_tree_count:38	wrong_total:104	 wrong be tree ACC: 0.36538461538461536
2023-07-07 17:42:12,916 - 


2023-07-07 17:42:12,916 - epoch:31,	loss:0.38079408439807594
2023-07-07 17:42:20,925 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:42:20,925 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:42:20,925 - wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-07 17:42:20,930 - save best model to ./output/test/best_model
2023-07-07 17:42:39,756 - 


2023-07-07 17:42:39,756 - epoch:32,	loss:0.36883946415036917
2023-07-07 17:42:47,552 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 17:42:47,552 - right_codes_count:314	total:433	 Code ACC: 0.7251732101616628
2023-07-07 17:42:47,552 - wrong_be_tree_count:33	wrong_total:99	 wrong be tree ACC: 0.3333333333333333
2023-07-07 17:43:00,286 - 


2023-07-07 17:43:00,286 - epoch:33,	loss:0.35231626383028924
2023-07-07 17:43:08,457 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 17:43:08,458 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 17:43:08,458 - wrong_be_tree_count:38	wrong_total:105	 wrong be tree ACC: 0.3619047619047619
2023-07-07 17:43:26,289 - 


2023-07-07 17:43:26,289 - epoch:34,	loss:0.34563117707148194
2023-07-07 17:43:34,217 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 17:43:34,217 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 17:43:34,218 - wrong_be_tree_count:45	wrong_total:100	 wrong be tree ACC: 0.45
2023-07-07 17:43:46,800 - 


2023-07-07 17:43:46,801 - epoch:35,	loss:0.33793614129535854
2023-07-07 17:43:54,986 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 17:43:54,986 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:43:54,986 - wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-07 17:44:07,732 - 


2023-07-07 17:44:07,733 - epoch:36,	loss:0.316502318251878
2023-07-07 17:44:15,832 - right_count:328	total:433	 Answer ACC: 0.7575057736720554
2023-07-07 17:44:15,832 - right_codes_count:315	total:433	 Code ACC: 0.7274826789838337
2023-07-07 17:44:15,832 - wrong_be_tree_count:42	wrong_total:105	 wrong be tree ACC: 0.4
2023-07-07 17:44:28,926 - 


2023-07-07 17:44:28,926 - epoch:37,	loss:0.30231247132178396
2023-07-07 17:44:37,440 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 17:44:37,441 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 17:44:37,441 - wrong_be_tree_count:46	wrong_total:100	 wrong be tree ACC: 0.46
2023-07-07 17:44:50,277 - 


2023-07-07 17:44:50,277 - epoch:38,	loss:0.29715866525657475
2023-07-07 17:44:58,144 - right_count:324	total:433	 Answer ACC: 0.7482678983833718
2023-07-07 17:44:58,145 - right_codes_count:312	total:433	 Code ACC: 0.7205542725173211
2023-07-07 17:44:58,145 - wrong_be_tree_count:43	wrong_total:109	 wrong be tree ACC: 0.3944954128440367
2023-07-07 17:45:10,978 - 


2023-07-07 17:45:10,978 - epoch:39,	loss:0.2891001895768568
2023-07-07 17:45:19,255 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 17:45:19,255 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:45:19,256 - wrong_be_tree_count:41	wrong_total:101	 wrong be tree ACC: 0.40594059405940597
2023-07-07 17:45:32,120 - 


2023-07-07 17:45:32,120 - epoch:40,	loss:0.27895879559218884
2023-07-07 17:45:40,168 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 17:45:40,168 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 17:45:40,168 - wrong_be_tree_count:37	wrong_total:95	 wrong be tree ACC: 0.3894736842105263
2023-07-07 17:45:40,174 - save best model to ./output/test/best_model
2023-07-07 17:45:58,413 - 


2023-07-07 17:45:58,413 - epoch:41,	loss:0.25655463978182524
2023-07-07 17:46:06,343 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:46:06,344 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-07 17:46:06,344 - wrong_be_tree_count:37	wrong_total:94	 wrong be tree ACC: 0.39361702127659576
2023-07-07 17:46:06,355 - save best model to ./output/test/best_model
2023-07-07 17:46:24,072 - 


2023-07-07 17:46:24,072 - epoch:42,	loss:0.270217256154865
2023-07-07 17:46:32,197 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 17:46:32,197 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 17:46:32,197 - wrong_be_tree_count:38	wrong_total:96	 wrong be tree ACC: 0.3958333333333333
2023-07-07 17:46:45,467 - 


2023-07-07 17:46:45,468 - epoch:43,	loss:0.2711399196414277
2023-07-07 17:46:53,451 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 17:46:53,452 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 17:46:53,452 - wrong_be_tree_count:42	wrong_total:93	 wrong be tree ACC: 0.45161290322580644
2023-07-07 17:46:53,459 - save best model to ./output/test/best_model
2023-07-07 17:47:11,768 - 


2023-07-07 17:47:11,769 - epoch:44,	loss:0.24574454530375078
2023-07-07 17:47:20,048 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 17:47:20,049 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 17:47:20,049 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-07 17:47:33,040 - 


2023-07-07 17:47:33,040 - epoch:45,	loss:0.2539208014495671
2023-07-07 17:47:40,624 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:47:40,624 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:47:40,624 - wrong_be_tree_count:47	wrong_total:97	 wrong be tree ACC: 0.4845360824742268
2023-07-07 17:47:52,885 - 


2023-07-07 17:47:52,885 - epoch:46,	loss:0.2371719086659141
2023-07-07 17:48:00,655 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 17:48:00,656 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 17:48:00,656 - wrong_be_tree_count:45	wrong_total:99	 wrong be tree ACC: 0.45454545454545453
2023-07-07 17:48:13,049 - 


2023-07-07 17:48:13,049 - epoch:47,	loss:0.237736752955243
2023-07-07 17:48:20,604 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 17:48:20,605 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 17:48:20,605 - wrong_be_tree_count:42	wrong_total:102	 wrong be tree ACC: 0.4117647058823529
2023-07-07 17:48:33,114 - 


2023-07-07 17:48:33,114 - epoch:48,	loss:0.21893557405564934
2023-07-07 17:48:41,464 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:48:41,465 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 17:48:41,465 - wrong_be_tree_count:39	wrong_total:94	 wrong be tree ACC: 0.4148936170212766
2023-07-07 17:48:53,990 - 


2023-07-07 17:48:53,991 - epoch:49,	loss:0.21284139389172196
2023-07-07 17:49:02,124 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 17:49:02,124 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-07 17:49:02,124 - wrong_be_tree_count:44	wrong_total:96	 wrong be tree ACC: 0.4583333333333333
2023-07-07 17:49:15,110 - 


2023-07-07 17:49:15,111 - epoch:50,	loss:0.1977079736534506
2023-07-07 17:49:23,806 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:49:23,806 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 17:49:23,806 - wrong_be_tree_count:43	wrong_total:104	 wrong be tree ACC: 0.41346153846153844
2023-07-07 17:49:37,067 - 


2023-07-07 17:49:37,068 - epoch:51,	loss:0.19328514399239793
2023-07-07 17:49:45,652 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-07 17:49:45,652 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-07 17:49:45,652 - wrong_be_tree_count:43	wrong_total:104	 wrong be tree ACC: 0.41346153846153844
2023-07-07 17:49:58,493 - 


2023-07-07 17:49:58,494 - epoch:52,	loss:0.18617806886322796
2023-07-07 17:50:06,940 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:50:06,941 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 17:50:06,941 - wrong_be_tree_count:43	wrong_total:97	 wrong be tree ACC: 0.44329896907216493
2023-07-07 17:50:19,681 - 


2023-07-07 17:50:19,682 - epoch:53,	loss:0.18854003550950438
2023-07-07 17:50:28,586 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 17:50:28,586 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 17:50:28,586 - wrong_be_tree_count:48	wrong_total:101	 wrong be tree ACC: 0.4752475247524752
2023-07-07 17:50:41,813 - 


2023-07-07 17:50:41,814 - epoch:54,	loss:0.17872437220648862
2023-07-07 17:50:50,251 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 17:50:50,252 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 17:50:50,252 - wrong_be_tree_count:49	wrong_total:99	 wrong be tree ACC: 0.494949494949495
2023-07-07 17:51:03,073 - 


2023-07-07 17:51:03,073 - epoch:55,	loss:0.17923930355755147
2023-07-07 17:51:11,637 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:51:11,637 - right_codes_count:332	total:433	 Code ACC: 0.766743648960739
2023-07-07 17:51:11,637 - wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-07 17:51:24,806 - 


2023-07-07 17:51:24,806 - epoch:56,	loss:0.17523030744632706
2023-07-07 17:51:33,256 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 17:51:33,257 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 17:51:33,257 - wrong_be_tree_count:42	wrong_total:100	 wrong be tree ACC: 0.42
2023-07-07 17:51:46,993 - 


2023-07-07 17:51:46,993 - epoch:57,	loss:0.1649986864067614
2023-07-07 17:51:55,557 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 17:51:55,557 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 17:51:55,557 - wrong_be_tree_count:51	wrong_total:102	 wrong be tree ACC: 0.5
2023-07-07 17:52:08,449 - 


2023-07-07 17:52:08,450 - epoch:58,	loss:0.16637300385627896
2023-07-07 17:52:17,619 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 17:52:17,619 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 17:52:17,619 - wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-07 17:52:17,627 - save best model to ./output/test/best_model
2023-07-07 17:52:38,366 - 


2023-07-07 17:52:38,366 - epoch:59,	loss:0.15940784651320428
2023-07-07 17:52:47,021 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 17:52:47,021 - right_codes_count:317	total:433	 Code ACC: 0.7321016166281755
2023-07-07 17:52:47,021 - wrong_be_tree_count:42	wrong_total:98	 wrong be tree ACC: 0.42857142857142855
2023-07-07 17:52:59,753 - 


2023-07-07 17:52:59,753 - epoch:60,	loss:0.1598698953166604
2023-07-07 17:53:08,362 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:53:08,362 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 17:53:08,362 - wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-07 17:53:21,683 - 


2023-07-07 17:53:21,683 - epoch:61,	loss:0.14901837435900234
2023-07-07 17:53:30,341 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:53:30,342 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 17:53:30,342 - wrong_be_tree_count:44	wrong_total:94	 wrong be tree ACC: 0.46808510638297873
2023-07-07 17:53:44,909 - 


2023-07-07 17:53:44,909 - epoch:62,	loss:0.15009576352895238
2023-07-07 17:53:53,615 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-07 17:53:53,616 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:53:53,616 - wrong_be_tree_count:48	wrong_total:102	 wrong be tree ACC: 0.47058823529411764
2023-07-07 17:54:06,566 - 


2023-07-07 17:54:06,566 - epoch:63,	loss:0.14255147316725925
2023-07-07 17:54:15,785 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-07 17:54:15,786 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-07 17:54:15,786 - wrong_be_tree_count:47	wrong_total:98	 wrong be tree ACC: 0.47959183673469385
2023-07-07 17:54:29,016 - 


2023-07-07 17:54:29,017 - epoch:64,	loss:0.14681382779963315
2023-07-07 17:54:37,280 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 17:54:37,280 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-07 17:54:37,280 - wrong_be_tree_count:47	wrong_total:99	 wrong be tree ACC: 0.47474747474747475
2023-07-07 17:54:50,197 - 


2023-07-07 17:54:50,198 - epoch:65,	loss:0.14561639371095225
2023-07-07 17:54:58,570 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-07 17:54:58,570 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-07 17:54:58,570 - wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-07 17:55:11,396 - 


2023-07-07 17:55:11,396 - epoch:66,	loss:0.14259861572645605
2023-07-07 17:55:19,690 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-07 17:55:19,691 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 17:55:19,691 - wrong_be_tree_count:45	wrong_total:101	 wrong be tree ACC: 0.44554455445544555
2023-07-07 17:55:32,768 - 


2023-07-07 17:55:32,769 - epoch:67,	loss:0.13914478913648054
2023-07-07 17:55:41,129 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:55:41,129 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 17:55:41,129 - wrong_be_tree_count:47	wrong_total:97	 wrong be tree ACC: 0.4845360824742268
2023-07-07 17:55:54,077 - 


2023-07-07 17:55:54,077 - epoch:68,	loss:0.12871624546824023
2023-07-07 17:56:05,990 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:56:05,990 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 17:56:06,025 - wrong_be_tree_count:45	wrong_total:94	 wrong be tree ACC: 0.4787234042553192
2023-07-07 17:56:21,138 - 


2023-07-07 17:56:21,138 - epoch:69,	loss:0.1285676684929058
2023-07-07 17:56:32,958 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 17:56:32,958 - right_codes_count:334	total:433	 Code ACC: 0.7713625866050808
2023-07-07 17:56:32,963 - wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-07 17:56:46,640 - 


2023-07-07 17:56:46,641 - epoch:70,	loss:0.12576675286982208
2023-07-07 17:56:58,098 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 17:56:58,098 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 17:56:58,114 - wrong_be_tree_count:43	wrong_total:96	 wrong be tree ACC: 0.4479166666666667
2023-07-07 17:57:12,173 - 


2023-07-07 17:57:12,174 - epoch:71,	loss:0.13050980618572794
2023-07-07 17:57:23,535 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 17:57:23,535 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 17:57:23,536 - wrong_be_tree_count:49	wrong_total:95	 wrong be tree ACC: 0.5157894736842106
2023-07-07 17:57:36,589 - 


2023-07-07 17:57:36,590 - epoch:72,	loss:0.12108738801907748
2023-07-07 17:57:48,228 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 17:57:48,229 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-07 17:57:48,235 - wrong_be_tree_count:48	wrong_total:96	 wrong be tree ACC: 0.5
2023-07-07 17:58:04,077 - 


2023-07-07 17:58:04,077 - epoch:73,	loss:0.12628572135872673
2023-07-07 17:58:15,182 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:58:15,183 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-07 17:58:15,186 - wrong_be_tree_count:48	wrong_total:97	 wrong be tree ACC: 0.4948453608247423
2023-07-07 17:58:28,598 - 


2023-07-07 17:58:28,598 - epoch:74,	loss:0.13407874206313863
2023-07-07 17:58:38,916 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 17:58:38,917 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 17:58:38,917 - wrong_be_tree_count:50	wrong_total:97	 wrong be tree ACC: 0.5154639175257731
2023-07-07 17:58:51,810 - 


2023-07-07 17:58:51,810 - epoch:75,	loss:0.12472458626143634
2023-07-07 17:59:02,899 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 17:59:02,899 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 17:59:02,899 - wrong_be_tree_count:45	wrong_total:94	 wrong be tree ACC: 0.4787234042553192
2023-07-07 17:59:16,525 - 


2023-07-07 17:59:16,525 - epoch:76,	loss:0.11859092398663051
2023-07-07 17:59:26,759 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 17:59:26,760 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 17:59:26,760 - wrong_be_tree_count:46	wrong_total:93	 wrong be tree ACC: 0.4946236559139785
2023-07-07 17:59:40,026 - 


2023-07-07 17:59:40,027 - epoch:77,	loss:0.11472695824340917
2023-07-07 17:59:48,049 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-07 17:59:48,052 - right_codes_count:334	total:433	 Code ACC: 0.7713625866050808
2023-07-07 17:59:48,057 - wrong_be_tree_count:48	wrong_total:90	 wrong be tree ACC: 0.5333333333333333
2023-07-07 17:59:48,063 - save best model to ./output/test/best_model
2023-07-07 18:00:06,949 - 


2023-07-07 18:00:06,952 - epoch:78,	loss:0.11788851773599163
2023-07-07 18:00:14,859 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:00:14,862 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:00:14,862 - wrong_be_tree_count:46	wrong_total:92	 wrong be tree ACC: 0.5
2023-07-07 18:00:28,893 - 


2023-07-07 18:00:28,896 - epoch:79,	loss:0.11662863905075938
2023-07-07 18:00:37,565 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 18:00:37,566 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-07 18:00:37,566 - wrong_be_tree_count:50	wrong_total:97	 wrong be tree ACC: 0.5154639175257731
2023-07-07 18:00:52,353 - 


2023-07-07 18:00:52,354 - epoch:80,	loss:0.11468634832999669
2023-07-07 18:01:00,805 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:01:00,805 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 18:01:00,806 - wrong_be_tree_count:42	wrong_total:93	 wrong be tree ACC: 0.45161290322580644
2023-07-07 18:01:14,079 - 


2023-07-07 18:01:14,079 - epoch:81,	loss:0.11471884991624393
2023-07-07 18:01:22,741 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-07 18:01:22,742 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:01:22,742 - wrong_be_tree_count:52	wrong_total:96	 wrong be tree ACC: 0.5416666666666666
2023-07-07 18:01:36,271 - 


2023-07-07 18:01:36,271 - epoch:82,	loss:0.11912023852346465
2023-07-07 18:01:45,152 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:01:45,152 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 18:01:45,152 - wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
2023-07-07 18:02:01,458 - 


2023-07-07 18:02:01,459 - epoch:83,	loss:0.11848042244673707
2023-07-07 18:02:09,649 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-07 18:02:09,649 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 18:02:09,649 - wrong_be_tree_count:52	wrong_total:97	 wrong be tree ACC: 0.5360824742268041
2023-07-07 18:02:23,361 - 


2023-07-07 18:02:23,361 - epoch:84,	loss:0.10319333581719548
2023-07-07 18:02:31,610 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-07 18:02:31,611 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:02:31,611 - wrong_be_tree_count:51	wrong_total:99	 wrong be tree ACC: 0.5151515151515151
2023-07-07 18:02:44,780 - 


2023-07-07 18:02:44,780 - epoch:85,	loss:0.10142608079331694
2023-07-07 18:02:53,670 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:02:53,670 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:02:53,670 - wrong_be_tree_count:45	wrong_total:94	 wrong be tree ACC: 0.4787234042553192
2023-07-07 18:03:08,618 - 


2023-07-07 18:03:08,618 - epoch:86,	loss:0.10605145071167499
2023-07-07 18:03:16,953 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:03:16,953 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:03:16,953 - wrong_be_tree_count:44	wrong_total:94	 wrong be tree ACC: 0.46808510638297873
2023-07-07 18:03:30,491 - 


2023-07-07 18:03:30,491 - epoch:87,	loss:0.10489417410281021
2023-07-07 18:03:38,387 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:03:38,387 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:03:38,387 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:03:51,875 - 


2023-07-07 18:03:51,876 - epoch:88,	loss:0.10473882986116223
2023-07-07 18:03:59,937 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:03:59,937 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-07 18:03:59,937 - wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-07 18:04:13,373 - 


2023-07-07 18:04:13,374 - epoch:89,	loss:0.10401267145061865
2023-07-07 18:04:21,496 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:04:21,496 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:04:21,496 - wrong_be_tree_count:46	wrong_total:92	 wrong be tree ACC: 0.5
2023-07-07 18:04:35,511 - 


2023-07-07 18:04:35,511 - epoch:90,	loss:0.10316156494081952
2023-07-07 18:04:44,816 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:04:44,816 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:04:44,816 - wrong_be_tree_count:47	wrong_total:95	 wrong be tree ACC: 0.49473684210526314
2023-07-07 18:04:59,583 - 


2023-07-07 18:04:59,583 - epoch:91,	loss:0.10198255442082882
2023-07-07 18:05:07,925 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:05:07,925 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:05:07,925 - wrong_be_tree_count:44	wrong_total:95	 wrong be tree ACC: 0.4631578947368421
2023-07-07 18:05:21,141 - 


2023-07-07 18:05:21,141 - epoch:92,	loss:0.09635775751667097
2023-07-07 18:05:29,592 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:05:29,593 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-07 18:05:29,593 - wrong_be_tree_count:43	wrong_total:95	 wrong be tree ACC: 0.45263157894736844
2023-07-07 18:05:43,385 - 


2023-07-07 18:05:43,385 - epoch:93,	loss:0.10471536705153994
2023-07-07 18:05:51,745 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:05:51,745 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:05:51,745 - wrong_be_tree_count:43	wrong_total:93	 wrong be tree ACC: 0.46236559139784944
2023-07-07 18:06:05,371 - 


2023-07-07 18:06:05,372 - epoch:94,	loss:0.09731951776120695
2023-07-07 18:06:13,826 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:06:13,826 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:06:13,827 - wrong_be_tree_count:46	wrong_total:93	 wrong be tree ACC: 0.4946236559139785
2023-07-07 18:06:26,988 - 


2023-07-07 18:06:26,988 - epoch:95,	loss:0.09609146279399283
2023-07-07 18:06:35,591 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:06:35,592 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:06:35,592 - wrong_be_tree_count:44	wrong_total:92	 wrong be tree ACC: 0.4782608695652174
2023-07-07 18:06:48,302 - 


2023-07-07 18:06:48,302 - epoch:96,	loss:0.09448013151268242
2023-07-07 18:06:56,198 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:06:56,198 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:06:56,198 - wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
2023-07-07 18:07:08,619 - 


2023-07-07 18:07:08,619 - epoch:97,	loss:0.09610712659195997
2023-07-07 18:07:16,369 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:07:16,369 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:07:16,369 - wrong_be_tree_count:44	wrong_total:94	 wrong be tree ACC: 0.46808510638297873
2023-07-07 18:07:28,877 - 


2023-07-07 18:07:28,877 - epoch:98,	loss:0.09684278216445819
2023-07-07 18:07:36,578 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:07:36,578 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:07:36,578 - wrong_be_tree_count:42	wrong_total:92	 wrong be tree ACC: 0.45652173913043476
2023-07-07 18:07:49,248 - 


2023-07-07 18:07:49,248 - epoch:99,	loss:0.09470716993382666
2023-07-07 18:07:58,287 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:07:58,287 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 18:07:58,291 - wrong_be_tree_count:48	wrong_total:95	 wrong be tree ACC: 0.5052631578947369
2023-07-07 18:08:10,906 - 


2023-07-07 18:08:10,906 - epoch:100,	loss:0.0961072706268169
2023-07-07 18:08:18,731 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:08:18,731 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:08:18,731 - wrong_be_tree_count:46	wrong_total:93	 wrong be tree ACC: 0.4946236559139785
2023-07-07 18:08:32,776 - 


2023-07-07 18:08:32,777 - epoch:101,	loss:0.0936816816101782
2023-07-07 18:08:40,888 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:08:40,888 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:08:40,888 - wrong_be_tree_count:45	wrong_total:93	 wrong be tree ACC: 0.4838709677419355
2023-07-07 18:08:54,449 - 


2023-07-07 18:08:54,449 - epoch:102,	loss:0.10083083534846082
2023-07-07 18:09:02,694 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:09:02,694 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:09:02,694 - wrong_be_tree_count:44	wrong_total:93	 wrong be tree ACC: 0.4731182795698925
2023-07-07 18:09:15,758 - 


2023-07-07 18:09:15,759 - epoch:103,	loss:0.09395816377946176
2023-07-07 18:09:24,052 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:09:24,052 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:09:24,052 - wrong_be_tree_count:45	wrong_total:93	 wrong be tree ACC: 0.4838709677419355
2023-07-07 18:09:37,149 - 


2023-07-07 18:09:37,150 - epoch:104,	loss:0.09698554392525693
2023-07-07 18:09:46,376 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:09:46,376 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:09:46,376 - wrong_be_tree_count:44	wrong_total:94	 wrong be tree ACC: 0.46808510638297873
2023-07-07 18:10:01,729 - 


2023-07-07 18:10:01,730 - epoch:105,	loss:0.09301977593713673
2023-07-07 18:10:10,317 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:10:10,318 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:10:10,318 - wrong_be_tree_count:45	wrong_total:95	 wrong be tree ACC: 0.47368421052631576
2023-07-07 18:10:23,726 - 


2023-07-07 18:10:23,726 - epoch:106,	loss:0.09278091732994653
2023-07-07 18:10:31,890 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:10:31,890 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:10:31,890 - wrong_be_tree_count:46	wrong_total:93	 wrong be tree ACC: 0.4946236559139785
2023-07-07 18:10:47,297 - 


2023-07-07 18:10:47,297 - epoch:107,	loss:0.0901549702975899
2023-07-07 18:10:55,732 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 18:10:55,732 - right_codes_count:332	total:433	 Code ACC: 0.766743648960739
2023-07-07 18:10:55,732 - wrong_be_tree_count:45	wrong_total:91	 wrong be tree ACC: 0.4945054945054945
2023-07-07 18:11:12,266 - 


2023-07-07 18:11:12,266 - epoch:108,	loss:0.08901349271764047
2023-07-07 18:11:21,611 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:11:21,611 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:11:21,615 - wrong_be_tree_count:45	wrong_total:93	 wrong be tree ACC: 0.4838709677419355
2023-07-07 18:11:34,912 - 


2023-07-07 18:11:34,912 - epoch:109,	loss:0.09499222628073767
2023-07-07 18:11:43,529 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:11:43,529 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:11:43,529 - wrong_be_tree_count:48	wrong_total:93	 wrong be tree ACC: 0.5161290322580645
2023-07-07 18:11:56,830 - 


2023-07-07 18:11:56,830 - epoch:110,	loss:0.09100961658987217
2023-07-07 18:12:05,422 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:12:05,422 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:12:05,422 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:12:22,473 - 


2023-07-07 18:12:22,473 - epoch:111,	loss:0.09191705659759464
2023-07-07 18:12:30,953 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 18:12:30,953 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-07 18:12:30,953 - wrong_be_tree_count:47	wrong_total:91	 wrong be tree ACC: 0.5164835164835165
2023-07-07 18:12:45,346 - 


2023-07-07 18:12:45,347 - epoch:112,	loss:0.09563016891479492
2023-07-07 18:12:54,278 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 18:12:54,278 - right_codes_count:333	total:433	 Code ACC: 0.76905311778291
2023-07-07 18:12:54,278 - wrong_be_tree_count:47	wrong_total:91	 wrong be tree ACC: 0.5164835164835165
2023-07-07 18:13:07,619 - 


2023-07-07 18:13:07,619 - epoch:113,	loss:0.08927972271339968
2023-07-07 18:13:16,205 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:13:16,206 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:13:16,223 - wrong_be_tree_count:47	wrong_total:92	 wrong be tree ACC: 0.5108695652173914
2023-07-07 18:13:38,504 - 


2023-07-07 18:13:38,504 - epoch:114,	loss:0.08924969279905781
2023-07-07 18:13:46,969 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-07 18:13:46,969 - right_codes_count:333	total:433	 Code ACC: 0.76905311778291
2023-07-07 18:13:46,969 - wrong_be_tree_count:47	wrong_total:91	 wrong be tree ACC: 0.5164835164835165
2023-07-07 18:14:08,834 - 


2023-07-07 18:14:08,835 - epoch:115,	loss:0.09352248565119226
2023-07-07 18:14:17,655 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-07 18:14:17,655 - right_codes_count:332	total:433	 Code ACC: 0.766743648960739
2023-07-07 18:14:17,655 - wrong_be_tree_count:48	wrong_total:92	 wrong be tree ACC: 0.5217391304347826
2023-07-07 18:14:34,301 - 


2023-07-07 18:14:34,302 - epoch:116,	loss:0.08832708057161653
2023-07-07 18:14:43,833 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:14:43,834 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-07 18:14:43,834 - wrong_be_tree_count:46	wrong_total:94	 wrong be tree ACC: 0.48936170212765956
2023-07-07 18:15:04,464 - 


2023-07-07 18:15:04,464 - epoch:117,	loss:0.09458435146370903
2023-07-07 18:15:12,986 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:15:12,986 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:15:12,986 - wrong_be_tree_count:46	wrong_total:94	 wrong be tree ACC: 0.48936170212765956
2023-07-07 18:15:27,663 - 


2023-07-07 18:15:27,663 - epoch:118,	loss:0.08968057346646674
2023-07-07 18:15:36,213 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:15:36,214 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-07 18:15:36,214 - wrong_be_tree_count:47	wrong_total:95	 wrong be tree ACC: 0.49473684210526314
2023-07-07 18:15:48,786 - 


2023-07-07 18:15:48,787 - epoch:119,	loss:0.08970488597697113
2023-07-07 18:15:57,300 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:15:57,300 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:15:57,300 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:16:09,984 - 


2023-07-07 18:16:09,984 - epoch:120,	loss:0.08987070320290513
2023-07-07 18:16:19,499 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:16:19,499 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:16:19,499 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:16:49,579 - 


2023-07-07 18:16:49,579 - epoch:121,	loss:0.09027066675480455
2023-07-07 18:16:58,430 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-07 18:16:58,464 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:16:58,465 - wrong_be_tree_count:46	wrong_total:95	 wrong be tree ACC: 0.4842105263157895
2023-07-07 18:17:20,497 - 


2023-07-07 18:17:20,536 - epoch:122,	loss:0.09176071165711619
2023-07-07 18:17:28,817 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:17:28,817 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:17:28,818 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:17:40,683 - 


2023-07-07 18:17:40,684 - epoch:123,	loss:0.09049018603400327
2023-07-07 18:17:49,249 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:17:49,250 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:17:49,250 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:18:15,552 - 


2023-07-07 18:18:15,553 - epoch:124,	loss:0.08838578595896251
2023-07-07 18:18:22,965 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-07 18:18:22,966 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-07 18:18:22,968 - wrong_be_tree_count:47	wrong_total:94	 wrong be tree ACC: 0.5
2023-07-07 18:18:41,829 - 


2023-07-07 18:18:41,858 - epoch:125,	loss:0.09279486248851754
2023-07-07 18:18:49,943 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:18:49,943 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:18:49,943 - wrong_be_tree_count:47	wrong_total:93	 wrong be tree ACC: 0.5053763440860215
2023-07-07 18:19:05,376 - 


2023-07-07 18:19:05,377 - epoch:126,	loss:0.09033320777234621
2023-07-07 18:19:13,916 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:19:13,917 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:19:13,917 - wrong_be_tree_count:47	wrong_total:93	 wrong be tree ACC: 0.5053763440860215
2023-07-07 18:19:32,541 - 


2023-07-07 18:19:32,542 - epoch:127,	loss:0.08742257664562203
2023-07-07 18:19:40,053 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:19:40,053 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:19:40,053 - wrong_be_tree_count:47	wrong_total:93	 wrong be tree ACC: 0.5053763440860215
2023-07-07 18:20:00,309 - 


2023-07-07 18:20:00,310 - epoch:128,	loss:0.08757971346494742
2023-07-07 18:20:08,075 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:20:08,076 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:20:08,076 - wrong_be_tree_count:47	wrong_total:93	 wrong be tree ACC: 0.5053763440860215
2023-07-07 18:20:31,310 - 


2023-07-07 18:20:31,311 - epoch:129,	loss:0.09215026638412382
2023-07-07 18:20:39,408 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-07 18:20:39,409 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-07 18:20:39,410 - wrong_be_tree_count:47	wrong_total:93	 wrong be tree ACC: 0.5053763440860215
2023-07-07 18:20:44,826 - 


2023-07-07 18:20:44,826 - final_test
2023-07-08 03:42:51,617 - get train data loader...
2023-07-08 03:42:51,714 - get dev data loader...
2023-07-08 03:42:51,808 - define model...
2023-07-08 03:42:56,353 - define optimizer...
2023-07-08 03:42:56,353 - ===========================train setting parameters=========================
2023-07-08 03:42:56,354 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 03:42:56,354 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 03:42:56,354 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 03:42:56,354 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,354 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,355 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,356 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,392 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,392 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,392 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,393 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,393 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,393 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,393 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,393 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,394 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,394 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,394 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,394 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,394 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,395 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,395 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,395 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,395 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,397 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,399 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,399 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,399 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,400 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,400 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,400 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,401 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,402 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,402 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,403 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,403 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,403 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,403 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,404 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,404 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,404 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,404 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,404 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,405 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,406 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,406 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,407 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,407 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,407 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,407 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,407 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,408 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,410 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,410 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,410 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,412 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,413 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,413 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,413 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,414 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,414 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,414 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,414 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,415 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,415 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,415 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,415 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,416 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,416 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,417 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,417 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,417 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,418 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,418 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,418 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,418 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,418 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,419 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,419 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,419 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,419 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,421 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,421 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,421 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,421 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,422 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,422 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,423 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,423 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,424 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,424 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,424 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,424 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,425 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,425 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,425 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,425 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,427 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,427 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,427 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,427 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,428 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,428 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,428 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,428 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,429 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,429 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,430 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,430 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,431 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,431 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,431 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,431 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,432 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,432 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,432 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,433 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,434 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,434 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,434 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,434 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,435 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,435 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,435 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,435 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,443 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,465 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,466 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,471 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,471 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,471 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,472 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,472 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,472 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:42:56,473 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 03:42:56,474 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:42:56,474 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 03:42:56,474 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:42:56,474 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 03:42:56,475 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,475 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,475 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,475 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,477 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:42:56,477 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:42:56,477 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:42:56,477 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 03:42:56,478 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:42:56,478 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:42:56,479 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 03:42:56,479 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 03:42:56,480 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 03:42:56,480 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 03:42:56,480 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 03:42:56,480 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 03:42:56,481 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 03:42:56,481 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 03:42:56,481 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 03:42:56,481 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 03:42:56,483 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 03:42:56,483 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 03:42:56,483 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 03:42:56,483 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 03:42:56,484 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 03:42:56,484 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 03:42:56,484 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 03:42:56,484 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 03:42:56,484 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 03:42:56,486 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 03:42:56,486 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 03:42:56,486 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 03:42:56,486 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 03:42:56,487 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 03:51:15,622 - get train data loader...
2023-07-08 03:51:15,741 - get dev data loader...
2023-07-08 03:51:15,861 - define model...
2023-07-08 03:51:20,288 - define optimizer...
2023-07-08 03:51:20,289 - ===========================train setting parameters=========================
2023-07-08 03:51:20,290 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 03:51:20,290 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 03:51:20,290 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 03:51:20,290 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,290 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,290 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,292 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,294 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,295 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,296 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,296 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,297 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,297 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,297 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,298 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,298 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,298 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,298 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,298 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,299 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,299 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,299 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,299 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,300 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,301 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,301 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,301 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,301 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,301 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,302 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,302 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,303 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,303 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,304 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,304 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,304 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,304 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,304 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,305 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,305 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,305 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,305 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,306 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,307 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,307 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,307 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,307 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,307 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,308 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,308 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,308 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,308 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,308 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,309 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,310 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,310 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,310 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,310 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,311 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,312 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,313 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,313 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,313 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,313 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,314 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,314 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,314 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,314 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,314 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,315 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,316 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,316 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,316 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,316 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,317 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,318 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,318 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,318 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,318 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,318 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,319 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,320 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,320 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,320 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,320 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,320 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,321 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,322 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,322 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,322 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,322 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,322 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,323 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,323 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,323 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,324 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,324 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,325 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,325 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,325 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,325 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,325 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,327 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,327 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,327 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,327 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,327 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,328 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,329 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,329 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,330 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,330 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,330 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,330 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,330 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,331 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,331 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,331 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,331 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,331 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,333 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,335 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,335 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,335 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,335 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,335 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,336 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 03:51:20,336 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 03:51:20,336 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 03:51:20,336 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,337 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,338 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 03:51:20,338 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 03:51:20,338 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 03:51:20,339 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 03:51:20,339 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 03:51:20,340 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 03:51:20,340 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 03:51:20,340 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 03:51:20,340 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 03:51:20,341 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 03:51:20,341 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 03:51:20,341 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 03:51:20,341 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 03:51:20,341 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 03:51:20,342 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 03:51:20,343 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 03:51:20,343 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 03:51:20,343 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 03:51:20,343 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 03:51:20,344 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 03:51:20,344 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 03:51:20,344 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 03:51:20,344 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 03:51:20,344 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 03:51:20,346 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 03:51:20,346 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 03:51:20,346 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 03:51:20,346 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 03:51:20,346 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 03:51:20,347 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 03:51:20,354 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-08 03:51:26,947 - 


2023-07-08 03:51:26,947 - epoch:0,	loss:16.160451777279377
2023-07-08 03:51:31,266 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 03:51:31,267 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:51:31,267 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 03:51:31,269 - save best model to ./output/test/best_model
2023-07-08 03:51:47,357 - 


2023-07-08 03:51:47,358 - epoch:1,	loss:3.741540912538767
2023-07-08 03:51:51,710 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 03:51:51,710 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:51:51,710 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 03:52:03,103 - 


2023-07-08 03:52:03,103 - epoch:2,	loss:2.959688790142536
2023-07-08 03:52:08,426 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 03:52:08,426 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:52:08,426 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 03:52:19,919 - 


2023-07-08 03:52:19,919 - epoch:3,	loss:2.8282162584364414
2023-07-08 03:52:24,488 - right_count:10	total:433	 Answer ACC: 0.023094688221709007
2023-07-08 03:52:24,488 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:52:24,488 - wrong_be_tree_count:367	wrong_total:423	 wrong be tree ACC: 0.8676122931442081
2023-07-08 03:52:24,490 - save best model to ./output/test/best_model
2023-07-08 03:52:41,460 - 


2023-07-08 03:52:41,461 - epoch:4,	loss:2.790547203272581
2023-07-08 03:52:47,019 - right_count:9	total:433	 Answer ACC: 0.020785219399538105
2023-07-08 03:52:47,019 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:52:47,019 - wrong_be_tree_count:384	wrong_total:424	 wrong be tree ACC: 0.9056603773584906
2023-07-08 03:52:58,719 - 


2023-07-08 03:52:58,720 - epoch:5,	loss:2.7705311812460423
2023-07-08 03:53:03,355 - right_count:11	total:433	 Answer ACC: 0.025404157043879907
2023-07-08 03:53:03,356 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:53:03,356 - wrong_be_tree_count:314	wrong_total:422	 wrong be tree ACC: 0.7440758293838863
2023-07-08 03:53:03,359 - save best model to ./output/test/best_model
2023-07-08 03:53:13,416 - 


2023-07-08 03:53:13,416 - final_test
2023-07-08 03:53:23,512 - right_count:11	total:433	 Answer ACC: 0.025404157043879907
2023-07-08 03:53:23,512 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 03:53:23,512 - wrong_be_tree_count:314	wrong_total:422	 wrong be tree ACC: 0.7440758293838863
2023-07-08 12:11:17,817 - get train data loader...
2023-07-08 12:11:17,900 - get dev data loader...
2023-07-08 12:11:17,978 - define model...
2023-07-08 12:11:21,779 - define optimizer...
2023-07-08 12:11:21,780 - ===========================train setting parameters=========================
2023-07-08 12:11:21,781 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 12:11:21,781 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 12:11:21,781 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 12:11:21,781 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,781 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,781 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,782 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,784 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,784 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,785 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,785 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,786 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,787 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,788 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,788 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,789 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,791 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,792 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,793 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,794 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,795 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,795 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 12:11:21,795 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 12:11:21,796 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 12:11:21,797 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 12:11:21,797 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 12:11:21,797 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 12:11:21,797 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 12:11:21,797 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 12:11:21,797 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 12:11:21,797 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 12:11:21,797 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 12:11:21,797 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 12:11:21,798 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 12:11:21,799 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 12:11:21,799 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 12:11:21,799 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 12:11:21,799 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 12:11:21,799 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 12:11:21,799 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 12:11:21,799 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 12:11:21,799 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 12:11:21,799 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 12:11:21,799 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 12:11:21,799 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 12:11:21,799 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 12:11:21,800 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 12:11:21,800 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 12:11:21,800 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 12:11:21,800 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 12:11:21,800 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 12:11:21,802 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-08 12:11:27,374 - 


2023-07-08 12:11:27,374 - epoch:0,	loss:29.8985276222229
2023-07-08 12:11:30,511 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-08 12:11:30,511 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:11:30,511 - wrong_be_tree_count:416	wrong_total:432	 wrong be tree ACC: 0.9629629629629629
2023-07-08 12:11:30,513 - save best model to ./output/test/best_model
2023-07-08 12:11:45,648 - 


2023-07-08 12:11:45,648 - epoch:1,	loss:22.602594524621964
2023-07-08 12:11:48,754 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:11:48,754 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:11:48,754 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:11:58,669 - 


2023-07-08 12:11:58,670 - epoch:2,	loss:11.903513595461845
2023-07-08 12:12:01,782 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:12:01,783 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:12:01,783 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:12:11,812 - 


2023-07-08 12:12:11,812 - epoch:3,	loss:5.943711072206497
2023-07-08 12:12:14,927 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:12:14,927 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:12:14,927 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:12:24,778 - 


2023-07-08 12:12:24,778 - epoch:4,	loss:4.531653881072998
2023-07-08 12:12:27,879 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:12:27,879 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:12:27,879 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:12:37,632 - 


2023-07-08 12:12:37,633 - epoch:5,	loss:3.830233722925186
2023-07-08 12:12:40,767 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:12:40,767 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:12:40,767 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:12:50,585 - 


2023-07-08 12:12:50,585 - epoch:6,	loss:3.161520853638649
2023-07-08 12:12:53,689 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:12:53,689 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:12:53,689 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:13:03,514 - 


2023-07-08 12:13:03,514 - epoch:7,	loss:2.9325198605656624
2023-07-08 12:13:06,616 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-08 12:13:06,616 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-08 12:13:06,616 - wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-08 12:13:16,396 - 


2023-07-08 12:13:16,397 - epoch:8,	loss:2.8153669461607933
2023-07-08 12:13:19,521 - right_count:38	total:433	 Answer ACC: 0.08775981524249422
2023-07-08 12:13:19,521 - right_codes_count:19	total:433	 Code ACC: 0.04387990762124711
2023-07-08 12:13:19,521 - wrong_be_tree_count:207	wrong_total:395	 wrong be tree ACC: 0.5240506329113924
2023-07-08 12:13:19,523 - save best model to ./output/test/best_model
2023-07-08 12:13:34,384 - 


2023-07-08 12:13:34,384 - epoch:9,	loss:2.689666088670492
2023-07-08 12:13:37,528 - right_count:82	total:433	 Answer ACC: 0.18937644341801385
2023-07-08 12:13:37,529 - right_codes_count:59	total:433	 Code ACC: 0.13625866050808313
2023-07-08 12:13:37,529 - wrong_be_tree_count:153	wrong_total:351	 wrong be tree ACC: 0.4358974358974359
2023-07-08 12:13:37,531 - save best model to ./output/test/best_model
2023-07-08 12:13:52,484 - 


2023-07-08 12:13:52,484 - epoch:10,	loss:2.4086277708411217
2023-07-08 12:13:55,641 - right_count:122	total:433	 Answer ACC: 0.2817551963048499
2023-07-08 12:13:55,641 - right_codes_count:93	total:433	 Code ACC: 0.21478060046189376
2023-07-08 12:13:55,641 - wrong_be_tree_count:31	wrong_total:311	 wrong be tree ACC: 0.09967845659163987
2023-07-08 12:13:55,643 - save best model to ./output/test/best_model
2023-07-08 12:14:10,627 - 


2023-07-08 12:14:10,627 - epoch:11,	loss:2.115438796579838
2023-07-08 12:14:13,798 - right_count:168	total:433	 Answer ACC: 0.38799076212471134
2023-07-08 12:14:13,798 - right_codes_count:135	total:433	 Code ACC: 0.3117782909930716
2023-07-08 12:14:13,798 - wrong_be_tree_count:22	wrong_total:265	 wrong be tree ACC: 0.0830188679245283
2023-07-08 12:14:13,800 - save best model to ./output/test/best_model
2023-07-08 12:14:28,861 - 


2023-07-08 12:14:28,861 - epoch:12,	loss:1.890639841556549
2023-07-08 12:14:32,016 - right_count:190	total:433	 Answer ACC: 0.4387990762124711
2023-07-08 12:14:32,016 - right_codes_count:157	total:433	 Code ACC: 0.3625866050808314
2023-07-08 12:14:32,016 - wrong_be_tree_count:21	wrong_total:243	 wrong be tree ACC: 0.08641975308641975
2023-07-08 12:14:32,018 - save best model to ./output/test/best_model
2023-07-08 12:14:47,171 - 


2023-07-08 12:14:47,171 - epoch:13,	loss:1.7157725431025028
2023-07-08 12:14:50,420 - right_count:214	total:433	 Answer ACC: 0.4942263279445728
2023-07-08 12:14:50,420 - right_codes_count:192	total:433	 Code ACC: 0.44341801385681295
2023-07-08 12:14:50,420 - wrong_be_tree_count:28	wrong_total:219	 wrong be tree ACC: 0.1278538812785388
2023-07-08 12:14:50,422 - save best model to ./output/test/best_model
2023-07-08 12:15:05,995 - 


2023-07-08 12:15:05,995 - epoch:14,	loss:1.558558490127325
2023-07-08 12:15:09,188 - right_count:228	total:433	 Answer ACC: 0.5265588914549654
2023-07-08 12:15:09,189 - right_codes_count:207	total:433	 Code ACC: 0.4780600461893764
2023-07-08 12:15:09,189 - wrong_be_tree_count:20	wrong_total:205	 wrong be tree ACC: 0.0975609756097561
2023-07-08 12:15:09,191 - save best model to ./output/test/best_model
2023-07-08 12:15:24,098 - 


2023-07-08 12:15:24,098 - epoch:15,	loss:1.4488160870969296
2023-07-08 12:15:27,261 - right_count:236	total:433	 Answer ACC: 0.5450346420323325
2023-07-08 12:15:27,261 - right_codes_count:221	total:433	 Code ACC: 0.5103926096997691
2023-07-08 12:15:27,261 - wrong_be_tree_count:14	wrong_total:197	 wrong be tree ACC: 0.07106598984771574
2023-07-08 12:15:27,264 - save best model to ./output/test/best_model
2023-07-08 12:15:42,824 - 


2023-07-08 12:15:42,824 - epoch:16,	loss:1.322403596714139
2023-07-08 12:15:46,065 - right_count:248	total:433	 Answer ACC: 0.5727482678983834
2023-07-08 12:15:46,065 - right_codes_count:231	total:433	 Code ACC: 0.5334872979214781
2023-07-08 12:15:46,065 - wrong_be_tree_count:53	wrong_total:185	 wrong be tree ACC: 0.2864864864864865
2023-07-08 12:15:46,067 - save best model to ./output/test/best_model
2023-07-08 12:16:00,995 - 


2023-07-08 12:16:00,995 - epoch:17,	loss:1.1968582011759281
2023-07-08 12:16:04,185 - right_count:259	total:433	 Answer ACC: 0.5981524249422633
2023-07-08 12:16:04,185 - right_codes_count:239	total:433	 Code ACC: 0.5519630484988453
2023-07-08 12:16:04,185 - wrong_be_tree_count:52	wrong_total:174	 wrong be tree ACC: 0.2988505747126437
2023-07-08 12:16:04,187 - save best model to ./output/test/best_model
2023-07-08 12:16:19,331 - 


2023-07-08 12:16:19,331 - epoch:18,	loss:1.1142162177711725
2023-07-08 12:16:22,499 - right_count:269	total:433	 Answer ACC: 0.6212471131639723
2023-07-08 12:16:22,499 - right_codes_count:252	total:433	 Code ACC: 0.581986143187067
2023-07-08 12:16:22,499 - wrong_be_tree_count:81	wrong_total:164	 wrong be tree ACC: 0.49390243902439024
2023-07-08 12:16:22,501 - save best model to ./output/test/best_model
2023-07-08 12:16:37,659 - 


2023-07-08 12:16:37,659 - epoch:19,	loss:0.9639395345002413
2023-07-08 12:16:40,883 - right_count:276	total:433	 Answer ACC: 0.6374133949191686
2023-07-08 12:16:40,883 - right_codes_count:262	total:433	 Code ACC: 0.605080831408776
2023-07-08 12:16:40,883 - wrong_be_tree_count:84	wrong_total:157	 wrong be tree ACC: 0.535031847133758
2023-07-08 12:16:40,885 - save best model to ./output/test/best_model
2023-07-08 12:16:58,149 - 


2023-07-08 12:16:58,149 - epoch:20,	loss:0.8963187308982015
2023-07-08 12:17:06,334 - right_count:308	total:433	 Answer ACC: 0.7113163972286374
2023-07-08 12:17:06,334 - right_codes_count:292	total:433	 Code ACC: 0.674364896073903
2023-07-08 12:17:06,334 - wrong_be_tree_count:65	wrong_total:125	 wrong be tree ACC: 0.52
2023-07-08 12:17:06,336 - save best model to ./output/test/best_model
2023-07-08 12:17:37,690 - 


2023-07-08 12:17:37,690 - epoch:21,	loss:0.8185673207044601
2023-07-08 12:18:00,123 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-08 12:18:00,123 - right_codes_count:298	total:433	 Code ACC: 0.6882217090069284
2023-07-08 12:18:00,124 - wrong_be_tree_count:57	wrong_total:117	 wrong be tree ACC: 0.48717948717948717
2023-07-08 12:18:00,126 - save best model to ./output/test/best_model
2023-07-08 12:18:47,509 - 


2023-07-08 12:18:47,509 - epoch:22,	loss:0.7442664708942175
2023-07-08 12:18:59,354 - right_count:312	total:433	 Answer ACC: 0.7205542725173211
2023-07-08 12:18:59,354 - right_codes_count:295	total:433	 Code ACC: 0.6812933025404158
2023-07-08 12:18:59,354 - wrong_be_tree_count:51	wrong_total:121	 wrong be tree ACC: 0.4214876033057851
2023-07-08 12:19:43,705 - 


2023-07-08 12:19:43,706 - epoch:23,	loss:0.6810887171886861
2023-07-08 12:19:52,961 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-08 12:19:52,962 - right_codes_count:300	total:433	 Code ACC: 0.6928406466512702
2023-07-08 12:19:52,962 - wrong_be_tree_count:52	wrong_total:114	 wrong be tree ACC: 0.45614035087719296
2023-07-08 12:19:52,964 - save best model to ./output/test/best_model
2023-07-08 12:20:39,107 - 


2023-07-08 12:20:39,107 - epoch:24,	loss:0.6154047334566712
2023-07-08 12:20:46,313 - right_count:322	total:433	 Answer ACC: 0.74364896073903
2023-07-08 12:20:46,313 - right_codes_count:304	total:433	 Code ACC: 0.7020785219399538
2023-07-08 12:20:46,313 - wrong_be_tree_count:43	wrong_total:111	 wrong be tree ACC: 0.38738738738738737
2023-07-08 12:20:46,315 - save best model to ./output/test/best_model
2023-07-08 12:21:29,917 - 


2023-07-08 12:21:29,917 - epoch:25,	loss:0.565348599338904
2023-07-08 12:21:41,410 - right_count:323	total:433	 Answer ACC: 0.745958429561201
2023-07-08 12:21:41,410 - right_codes_count:307	total:433	 Code ACC: 0.7090069284064665
2023-07-08 12:21:41,410 - wrong_be_tree_count:46	wrong_total:110	 wrong be tree ACC: 0.41818181818181815
2023-07-08 12:21:41,412 - save best model to ./output/test/best_model
2023-07-08 12:22:23,808 - 


2023-07-08 12:22:23,808 - epoch:26,	loss:0.5334661772940308
2023-07-08 12:22:30,529 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 12:22:30,529 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-08 12:22:30,529 - wrong_be_tree_count:39	wrong_total:97	 wrong be tree ACC: 0.4020618556701031
2023-07-08 12:22:30,531 - save best model to ./output/test/best_model
2023-07-08 12:23:30,052 - 


2023-07-08 12:23:30,052 - epoch:27,	loss:0.5222174837253988
2023-07-08 12:23:40,499 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-08 12:23:40,499 - right_codes_count:311	total:433	 Code ACC: 0.7182448036951501
2023-07-08 12:23:40,499 - wrong_be_tree_count:37	wrong_total:107	 wrong be tree ACC: 0.34579439252336447
2023-07-08 12:24:20,474 - 


2023-07-08 12:24:20,475 - epoch:28,	loss:0.4846936445683241
2023-07-08 12:24:36,799 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-08 12:24:36,800 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-08 12:24:36,800 - wrong_be_tree_count:46	wrong_total:100	 wrong be tree ACC: 0.46
2023-07-08 12:25:00,168 - 


2023-07-08 12:25:00,168 - epoch:29,	loss:0.46856265468522906
2023-07-08 12:25:03,385 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 12:25:03,386 - right_codes_count:318	total:433	 Code ACC: 0.7344110854503464
2023-07-08 12:25:03,386 - wrong_be_tree_count:34	wrong_total:97	 wrong be tree ACC: 0.35051546391752575
2023-07-08 12:25:45,834 - 


2023-07-08 12:25:45,834 - epoch:30,	loss:0.43640051409602165
2023-07-08 12:25:54,801 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:25:54,801 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-08 12:25:54,801 - wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-08 12:25:54,803 - save best model to ./output/test/best_model
2023-07-08 12:27:03,603 - 


2023-07-08 12:27:03,603 - epoch:31,	loss:0.41171019268222153
2023-07-08 12:27:12,499 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-08 12:27:12,499 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:27:12,499 - wrong_be_tree_count:33	wrong_total:90	 wrong be tree ACC: 0.36666666666666664
2023-07-08 12:27:12,501 - save best model to ./output/test/best_model
2023-07-08 12:28:16,737 - 


2023-07-08 12:28:16,737 - epoch:32,	loss:0.38942219875752926
2023-07-08 12:28:29,010 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 12:28:29,010 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 12:28:29,010 - wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
2023-07-08 12:28:55,520 - 


2023-07-08 12:28:55,520 - epoch:33,	loss:0.36964685493148863
2023-07-08 12:28:58,725 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 12:28:58,725 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-08 12:28:58,725 - wrong_be_tree_count:47	wrong_total:99	 wrong be tree ACC: 0.47474747474747475
2023-07-08 12:29:35,256 - 


2023-07-08 12:29:35,256 - epoch:34,	loss:0.3684661479201168
2023-07-08 12:29:43,378 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:29:43,378 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 12:29:43,379 - wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-08 12:30:13,852 - 


2023-07-08 12:30:13,852 - epoch:35,	loss:0.35948439221829176
2023-07-08 12:30:23,579 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:30:23,580 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-08 12:30:23,580 - wrong_be_tree_count:35	wrong_total:94	 wrong be tree ACC: 0.3723404255319149
2023-07-08 12:30:43,925 - 


2023-07-08 12:30:43,925 - epoch:36,	loss:0.3409419935196638
2023-07-08 12:30:54,940 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 12:30:54,940 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-08 12:30:54,940 - wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-08 12:31:20,820 - 


2023-07-08 12:31:20,821 - epoch:37,	loss:0.33866678189951926
2023-07-08 12:31:23,995 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-08 12:31:23,995 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:31:23,995 - wrong_be_tree_count:49	wrong_total:92	 wrong be tree ACC: 0.532608695652174
2023-07-08 12:31:57,666 - 


2023-07-08 12:31:57,666 - epoch:38,	loss:0.3143552648834884
2023-07-08 12:32:05,682 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:32:05,683 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 12:32:05,683 - wrong_be_tree_count:48	wrong_total:94	 wrong be tree ACC: 0.5106382978723404
2023-07-08 12:32:34,157 - 


2023-07-08 12:32:34,157 - epoch:39,	loss:0.3099656749982387
2023-07-08 12:32:39,278 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:32:39,278 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 12:32:39,278 - wrong_be_tree_count:42	wrong_total:91	 wrong be tree ACC: 0.46153846153846156
2023-07-08 12:33:08,659 - 


2023-07-08 12:33:08,659 - epoch:40,	loss:0.2941558165475726
2023-07-08 12:33:19,762 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:33:19,762 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-08 12:33:19,762 - wrong_be_tree_count:34	wrong_total:91	 wrong be tree ACC: 0.37362637362637363
2023-07-08 12:33:50,707 - 


2023-07-08 12:33:50,707 - epoch:41,	loss:0.27787858177907765
2023-07-08 12:33:53,891 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 12:33:53,891 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:33:53,891 - wrong_be_tree_count:37	wrong_total:95	 wrong be tree ACC: 0.3894736842105263
2023-07-08 12:34:29,584 - 


2023-07-08 12:34:29,584 - epoch:42,	loss:0.2762306636432186
2023-07-08 12:34:41,673 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-08 12:34:41,673 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:34:41,673 - wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-08 12:35:14,374 - 


2023-07-08 12:35:14,374 - epoch:43,	loss:0.2714262965018861
2023-07-08 12:35:29,668 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-08 12:35:29,668 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:35:29,668 - wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-08 12:35:44,738 - 


2023-07-08 12:35:44,868 - epoch:44,	loss:0.27103294164408
2023-07-08 12:35:52,949 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:35:52,949 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:35:52,949 - wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
2023-07-08 12:36:16,649 - 


2023-07-08 12:36:16,649 - epoch:45,	loss:0.2602749631041661
2023-07-08 12:36:29,348 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-08 12:36:29,348 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-08 12:36:29,348 - wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-08 12:36:29,350 - save best model to ./output/test/best_model
2023-07-08 12:36:51,222 - 


2023-07-08 12:36:51,222 - epoch:46,	loss:0.25127134763170034
2023-07-08 12:36:55,583 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-08 12:36:55,583 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-08 12:36:55,583 - wrong_be_tree_count:33	wrong_total:87	 wrong be tree ACC: 0.3793103448275862
2023-07-08 12:37:25,283 - 


2023-07-08 12:37:25,283 - epoch:47,	loss:0.2418369270162657
2023-07-08 12:37:38,803 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 12:37:38,803 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-08 12:37:38,803 - wrong_be_tree_count:39	wrong_total:93	 wrong be tree ACC: 0.41935483870967744
2023-07-08 12:37:59,781 - 


2023-07-08 12:37:59,781 - epoch:48,	loss:0.2311724149622023
2023-07-08 12:38:05,068 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:38:05,068 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:38:05,068 - wrong_be_tree_count:40	wrong_total:94	 wrong be tree ACC: 0.425531914893617
2023-07-08 12:38:31,144 - 


2023-07-08 12:38:31,144 - epoch:49,	loss:0.2283893983112648
2023-07-08 12:38:34,410 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:38:34,410 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-08 12:38:34,410 - wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-08 12:39:02,966 - 


2023-07-08 12:39:02,966 - epoch:50,	loss:0.21557977254269645
2023-07-08 12:39:10,516 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:39:10,516 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:39:10,516 - wrong_be_tree_count:47	wrong_total:96	 wrong be tree ACC: 0.4895833333333333
2023-07-08 12:39:41,920 - 


2023-07-08 12:39:41,920 - epoch:51,	loss:0.21571090765064582
2023-07-08 12:39:59,104 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-08 12:39:59,104 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-08 12:39:59,104 - wrong_be_tree_count:38	wrong_total:90	 wrong be tree ACC: 0.4222222222222222
2023-07-08 12:40:17,033 - 


2023-07-08 12:40:17,033 - epoch:52,	loss:0.20441914827097207
2023-07-08 12:40:20,679 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:40:20,679 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 12:40:20,679 - wrong_be_tree_count:43	wrong_total:96	 wrong be tree ACC: 0.4479166666666667
2023-07-08 12:40:52,361 - 


2023-07-08 12:40:52,361 - epoch:53,	loss:0.2017573966877535
2023-07-08 12:41:02,644 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 12:41:02,644 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-08 12:41:02,644 - wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
2023-07-08 12:41:24,077 - 


2023-07-08 12:41:24,077 - epoch:54,	loss:0.2009961794828996
2023-07-08 12:41:41,859 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-08 12:41:41,859 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-08 12:41:41,859 - wrong_be_tree_count:52	wrong_total:101	 wrong be tree ACC: 0.5148514851485149
2023-07-08 12:41:56,403 - 


2023-07-08 12:41:56,403 - epoch:55,	loss:0.18962430182727985
2023-07-08 12:42:00,185 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:42:00,186 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 12:42:00,186 - wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-08 12:42:34,845 - 


2023-07-08 12:42:34,845 - epoch:56,	loss:0.19183627696475014
2023-07-08 12:42:48,850 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:42:48,850 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 12:42:48,850 - wrong_be_tree_count:33	wrong_total:94	 wrong be tree ACC: 0.35106382978723405
2023-07-08 12:43:29,973 - 


2023-07-08 12:43:29,973 - epoch:57,	loss:0.1776288026594557
2023-07-08 12:43:44,103 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:43:44,103 - right_codes_count:316	total:433	 Code ACC: 0.7297921478060047
2023-07-08 12:43:44,103 - wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-08 12:44:23,399 - 


2023-07-08 12:44:23,399 - epoch:58,	loss:0.18237292143749073
2023-07-08 12:44:39,062 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-08 12:44:39,062 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-08 12:44:39,062 - wrong_be_tree_count:42	wrong_total:101	 wrong be tree ACC: 0.4158415841584158
2023-07-08 12:45:20,745 - 


2023-07-08 12:45:20,745 - epoch:59,	loss:0.17879030818585306
2023-07-08 12:45:34,226 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 12:45:34,226 - right_codes_count:319	total:433	 Code ACC: 0.7367205542725174
2023-07-08 12:45:34,226 - wrong_be_tree_count:46	wrong_total:99	 wrong be tree ACC: 0.46464646464646464
2023-07-08 12:46:15,370 - 


2023-07-08 12:46:15,370 - epoch:60,	loss:0.17967732896795496
2023-07-08 12:46:29,901 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 12:46:29,902 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:46:29,902 - wrong_be_tree_count:45	wrong_total:98	 wrong be tree ACC: 0.45918367346938777
2023-07-08 12:46:56,513 - 


2023-07-08 12:46:56,513 - epoch:61,	loss:0.165830330864992
2023-07-08 12:47:19,697 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-08 12:47:19,697 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 12:47:19,697 - wrong_be_tree_count:41	wrong_total:89	 wrong be tree ACC: 0.4606741573033708
2023-07-08 12:47:35,513 - 


2023-07-08 12:47:35,513 - epoch:62,	loss:0.1653649391955696
2023-07-08 12:47:38,661 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 12:47:38,661 - right_codes_count:320	total:433	 Code ACC: 0.7390300230946882
2023-07-08 12:47:38,661 - wrong_be_tree_count:45	wrong_total:99	 wrong be tree ACC: 0.45454545454545453
2023-07-08 12:48:12,092 - 


2023-07-08 12:48:12,092 - epoch:63,	loss:0.15534975723130628
2023-07-08 12:48:21,129 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-08 12:48:21,129 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-08 12:48:21,129 - wrong_be_tree_count:31	wrong_total:90	 wrong be tree ACC: 0.34444444444444444
2023-07-08 12:49:06,612 - 


2023-07-08 12:49:06,612 - epoch:64,	loss:0.1611539403675124
2023-07-08 12:49:16,647 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:49:16,648 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 12:49:16,648 - wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-08 12:50:04,482 - 


2023-07-08 12:50:04,482 - epoch:65,	loss:0.15735798189416528
2023-07-08 12:50:13,684 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:50:13,684 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 12:50:13,685 - wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-08 12:50:59,979 - 


2023-07-08 12:50:59,979 - epoch:66,	loss:0.15327074518427253
2023-07-08 12:51:10,002 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:51:10,002 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 12:51:10,002 - wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-08 12:51:53,325 - 


2023-07-08 12:51:53,325 - epoch:67,	loss:0.14593678509118035
2023-07-08 12:52:02,608 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 12:52:02,609 - right_codes_count:321	total:433	 Code ACC: 0.7413394919168591
2023-07-08 12:52:02,609 - wrong_be_tree_count:40	wrong_total:96	 wrong be tree ACC: 0.4166666666666667
2023-07-08 12:52:45,717 - 


2023-07-08 12:52:45,717 - epoch:68,	loss:0.13890635703864973
2023-07-08 12:52:58,297 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 12:52:58,297 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 12:52:58,297 - wrong_be_tree_count:39	wrong_total:95	 wrong be tree ACC: 0.4105263157894737
2023-07-08 12:53:37,344 - 


2023-07-08 12:53:37,344 - epoch:69,	loss:0.1395796273718588
2023-07-08 12:53:53,377 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 12:53:53,377 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:53:53,377 - wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
2023-07-08 12:54:20,135 - 


2023-07-08 12:54:20,135 - epoch:70,	loss:0.13647317269351333
2023-07-08 12:54:43,000 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 12:54:43,000 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:54:43,000 - wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-08 12:54:55,765 - 


2023-07-08 12:54:55,765 - epoch:71,	loss:0.1353360519860871
2023-07-08 12:54:58,938 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 12:54:58,938 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 12:54:58,938 - wrong_be_tree_count:40	wrong_total:93	 wrong be tree ACC: 0.43010752688172044
2023-07-08 12:55:35,015 - 


2023-07-08 12:55:35,015 - epoch:72,	loss:0.1342314725043252
2023-07-08 12:55:43,740 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:55:43,740 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-08 12:55:43,740 - wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-08 12:56:30,420 - 


2023-07-08 12:56:30,420 - epoch:73,	loss:0.13109204644570127
2023-07-08 12:56:39,471 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:56:39,471 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:56:39,471 - wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-08 12:57:22,980 - 


2023-07-08 12:57:22,980 - epoch:74,	loss:0.13096618533018045
2023-07-08 12:57:32,446 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-08 12:57:32,446 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 12:57:32,446 - wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-08 12:58:18,645 - 


2023-07-08 12:58:18,645 - epoch:75,	loss:0.12722158938413486
2023-07-08 12:58:28,430 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 12:58:28,430 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 12:58:28,430 - wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-08 12:59:15,498 - 


2023-07-08 12:59:15,498 - epoch:76,	loss:0.12041594975744374
2023-07-08 12:59:24,729 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 12:59:24,729 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 12:59:24,729 - wrong_be_tree_count:39	wrong_total:93	 wrong be tree ACC: 0.41935483870967744
2023-07-08 13:00:10,726 - 


2023-07-08 13:00:10,726 - epoch:77,	loss:0.12401728704571724
2023-07-08 13:00:18,895 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 13:00:18,895 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 13:00:18,895 - wrong_be_tree_count:39	wrong_total:93	 wrong be tree ACC: 0.41935483870967744
2023-07-08 13:01:06,276 - 


2023-07-08 13:01:06,276 - epoch:78,	loss:0.12445310055045411
2023-07-08 13:01:15,762 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-08 13:01:15,762 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-08 13:01:15,762 - wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-08 13:02:04,125 - 


2023-07-08 13:02:04,125 - epoch:79,	loss:0.12641959814936854
2023-07-08 13:02:13,277 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 13:02:13,277 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:02:13,277 - wrong_be_tree_count:34	wrong_total:93	 wrong be tree ACC: 0.3655913978494624
2023-07-08 13:03:01,967 - 


2023-07-08 13:03:01,967 - epoch:80,	loss:0.11541090067476034
2023-07-08 13:03:10,963 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:03:10,963 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:03:10,964 - wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-08 13:03:55,365 - 


2023-07-08 13:03:55,366 - epoch:81,	loss:0.1146625563269481
2023-07-08 13:04:03,771 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 13:04:03,771 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:04:03,771 - wrong_be_tree_count:35	wrong_total:94	 wrong be tree ACC: 0.3723404255319149
2023-07-08 13:04:51,741 - 


2023-07-08 13:04:51,741 - epoch:82,	loss:0.11953372287098318
2023-07-08 13:05:00,798 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 13:05:00,798 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:05:00,798 - wrong_be_tree_count:35	wrong_total:94	 wrong be tree ACC: 0.3723404255319149
2023-07-08 13:05:44,312 - 


2023-07-08 13:05:44,312 - epoch:83,	loss:0.12279956214479171
2023-07-08 13:05:58,820 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:05:58,821 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 13:05:58,821 - wrong_be_tree_count:43	wrong_total:97	 wrong be tree ACC: 0.44329896907216493
2023-07-08 13:06:39,801 - 


2023-07-08 13:06:39,801 - epoch:84,	loss:0.11087945472172578
2023-07-08 13:06:54,651 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:06:54,651 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 13:06:54,651 - wrong_be_tree_count:37	wrong_total:98	 wrong be tree ACC: 0.37755102040816324
2023-07-08 13:07:17,806 - 


2023-07-08 13:07:17,806 - epoch:85,	loss:0.10965782964194659
2023-07-08 13:07:33,013 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:07:33,013 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 13:07:33,013 - wrong_be_tree_count:35	wrong_total:97	 wrong be tree ACC: 0.36082474226804123
2023-07-08 13:07:51,390 - 


2023-07-08 13:07:51,390 - epoch:86,	loss:0.11085836365236901
2023-07-08 13:07:56,578 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 13:07:56,578 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 13:07:56,578 - wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
2023-07-08 13:08:42,714 - 


2023-07-08 13:08:42,714 - epoch:87,	loss:0.11247219186043367
2023-07-08 13:08:51,668 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:08:51,669 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 13:08:51,669 - wrong_be_tree_count:39	wrong_total:97	 wrong be tree ACC: 0.4020618556701031
2023-07-08 13:09:40,495 - 


2023-07-08 13:09:40,495 - epoch:88,	loss:0.1111859077209374
2023-07-08 13:09:50,420 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 13:09:50,420 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 13:09:50,420 - wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
2023-07-08 13:10:39,511 - 


2023-07-08 13:10:39,511 - epoch:89,	loss:0.10780126418103464
2023-07-08 13:10:48,629 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 13:10:48,629 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:10:48,629 - wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-08 13:11:36,160 - 


2023-07-08 13:11:36,161 - epoch:90,	loss:0.10826262034242973
2023-07-08 13:11:45,174 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-08 13:11:45,174 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:11:45,174 - wrong_be_tree_count:40	wrong_total:95	 wrong be tree ACC: 0.42105263157894735
2023-07-08 13:12:29,659 - 


2023-07-08 13:12:29,659 - epoch:91,	loss:0.10743067896692082
2023-07-08 13:12:38,936 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:12:38,936 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:12:38,936 - wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-08 13:13:23,638 - 


2023-07-08 13:13:23,638 - epoch:92,	loss:0.10642842785455287
2023-07-08 13:13:35,688 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:13:35,689 - right_codes_count:323	total:433	 Code ACC: 0.745958429561201
2023-07-08 13:13:35,689 - wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-08 13:14:19,428 - 


2023-07-08 13:14:19,428 - epoch:93,	loss:0.11041385875432752
2023-07-08 13:14:32,125 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-08 13:14:32,125 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:14:32,125 - wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
2023-07-08 13:15:15,659 - 


2023-07-08 13:15:15,659 - epoch:94,	loss:0.10228856054163771
2023-07-08 13:15:28,537 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 13:15:28,537 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:15:28,537 - wrong_be_tree_count:38	wrong_total:93	 wrong be tree ACC: 0.40860215053763443
2023-07-08 13:16:09,274 - 


2023-07-08 13:16:09,274 - epoch:95,	loss:0.10628320192336105
2023-07-08 13:16:24,334 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 13:16:24,334 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:16:24,334 - wrong_be_tree_count:37	wrong_total:93	 wrong be tree ACC: 0.3978494623655914
2023-07-08 13:16:46,744 - 


2023-07-08 13:16:46,744 - epoch:96,	loss:0.10640852585493121
2023-07-08 13:17:11,023 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-08 13:17:11,023 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-08 13:17:11,023 - wrong_be_tree_count:32	wrong_total:90	 wrong be tree ACC: 0.35555555555555557
2023-07-08 13:17:22,189 - 


2023-07-08 13:17:22,189 - epoch:97,	loss:0.10434562602313235
2023-07-08 13:17:25,381 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:17:25,381 - right_codes_count:322	total:433	 Code ACC: 0.74364896073903
2023-07-08 13:17:25,381 - wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
2023-07-08 13:18:05,282 - 


2023-07-08 13:18:05,282 - epoch:98,	loss:0.10519303957698867
2023-07-08 13:18:13,983 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:18:13,983 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:18:13,983 - wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-08 13:19:00,106 - 


2023-07-08 13:19:00,106 - epoch:99,	loss:0.1019369282585103
2023-07-08 13:19:09,739 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:19:09,739 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 13:19:09,739 - wrong_be_tree_count:43	wrong_total:96	 wrong be tree ACC: 0.4479166666666667
2023-07-08 13:19:52,539 - 


2023-07-08 13:19:52,539 - epoch:100,	loss:0.10003602199140005
2023-07-08 13:20:06,259 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:20:06,259 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:20:06,260 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-08 13:20:48,292 - 


2023-07-08 13:20:48,292 - epoch:101,	loss:0.10180819450761192
2023-07-08 13:21:02,044 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:21:02,044 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:21:02,044 - wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-08 13:21:38,936 - 


2023-07-08 13:21:38,936 - epoch:102,	loss:0.10572398759541102
2023-07-08 13:21:55,534 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:21:55,534 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:21:55,534 - wrong_be_tree_count:41	wrong_total:97	 wrong be tree ACC: 0.422680412371134
2023-07-08 13:22:19,413 - 


2023-07-08 13:22:19,413 - epoch:103,	loss:0.09653933899244294
2023-07-08 13:22:42,688 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:22:42,688 - right_codes_count:324	total:433	 Code ACC: 0.7482678983833718
2023-07-08 13:22:42,688 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-08 13:22:55,243 - 


2023-07-08 13:22:55,243 - epoch:104,	loss:0.10674812440993264
2023-07-08 13:22:58,454 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:22:58,455 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:22:58,455 - wrong_be_tree_count:44	wrong_total:98	 wrong be tree ACC: 0.4489795918367347
2023-07-08 13:23:42,909 - 


2023-07-08 13:23:42,909 - epoch:105,	loss:0.09801753130159341
2023-07-08 13:23:51,890 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:23:51,890 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:23:51,890 - wrong_be_tree_count:45	wrong_total:99	 wrong be tree ACC: 0.45454545454545453
2023-07-08 13:24:39,386 - 


2023-07-08 13:24:39,386 - epoch:106,	loss:0.09922095069487114
2023-07-08 13:24:48,200 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:24:48,200 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:24:48,200 - wrong_be_tree_count:43	wrong_total:97	 wrong be tree ACC: 0.44329896907216493
2023-07-08 13:25:32,954 - 


2023-07-08 13:25:32,954 - epoch:107,	loss:0.09820167110592593
2023-07-08 13:25:46,021 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:25:46,021 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:25:46,021 - wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-08 13:26:34,559 - 


2023-07-08 13:26:34,559 - epoch:108,	loss:0.09863212578056846
2023-07-08 13:26:43,978 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-08 13:26:43,978 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 13:26:43,978 - wrong_be_tree_count:40	wrong_total:94	 wrong be tree ACC: 0.425531914893617
2023-07-08 13:27:32,338 - 


2023-07-08 13:27:32,338 - epoch:109,	loss:0.09372627883567475
2023-07-08 13:27:41,328 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:27:41,328 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:27:41,328 - wrong_be_tree_count:39	wrong_total:98	 wrong be tree ACC: 0.3979591836734694
2023-07-08 13:28:28,845 - 


2023-07-08 13:28:28,846 - epoch:110,	loss:0.0944124358065892
2023-07-08 13:28:37,224 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:28:37,225 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:28:37,225 - wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-08 13:29:22,758 - 


2023-07-08 13:29:22,758 - epoch:111,	loss:0.09335401367934537
2023-07-08 13:29:32,442 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:29:32,442 - right_codes_count:325	total:433	 Code ACC: 0.7505773672055427
2023-07-08 13:29:32,442 - wrong_be_tree_count:43	wrong_total:99	 wrong be tree ACC: 0.43434343434343436
2023-07-08 13:30:20,882 - 


2023-07-08 13:30:20,882 - epoch:112,	loss:0.10297821188578382
2023-07-08 13:30:29,903 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:30:29,903 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:30:29,903 - wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-08 13:31:13,737 - 


2023-07-08 13:31:13,738 - epoch:113,	loss:0.09425314082182012
2023-07-08 13:31:23,272 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-08 13:31:23,272 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:31:23,272 - wrong_be_tree_count:41	wrong_total:97	 wrong be tree ACC: 0.422680412371134
2023-07-08 13:32:04,441 - 


2023-07-08 13:32:04,441 - epoch:114,	loss:0.09498515342420433
2023-07-08 13:32:18,771 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-08 13:32:18,771 - right_codes_count:331	total:433	 Code ACC: 0.7644341801385681
2023-07-08 13:32:18,771 - wrong_be_tree_count:42	wrong_total:93	 wrong be tree ACC: 0.45161290322580644
2023-07-08 13:32:42,155 - 


2023-07-08 13:32:42,155 - epoch:115,	loss:0.0927468476438662
2023-07-08 13:33:06,535 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-08 13:33:06,535 - right_codes_count:329	total:433	 Code ACC: 0.7598152424942263
2023-07-08 13:33:06,535 - wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-08 13:33:17,861 - 


2023-07-08 13:33:17,861 - epoch:116,	loss:0.09625496777880471
2023-07-08 13:33:21,063 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:33:21,064 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:33:21,064 - wrong_be_tree_count:44	wrong_total:99	 wrong be tree ACC: 0.4444444444444444
2023-07-08 13:34:01,085 - 


2023-07-08 13:34:01,085 - epoch:117,	loss:0.10231580192339607
2023-07-08 13:34:09,841 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:34:09,841 - right_codes_count:328	total:433	 Code ACC: 0.7575057736720554
2023-07-08 13:34:09,841 - wrong_be_tree_count:42	wrong_total:98	 wrong be tree ACC: 0.42857142857142855
2023-07-08 13:35:00,622 - 


2023-07-08 13:35:00,622 - epoch:118,	loss:0.09205237467540428
2023-07-08 13:35:09,277 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:35:09,278 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:35:09,278 - wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
2023-07-08 13:36:05,137 - 


2023-07-08 13:36:05,138 - epoch:119,	loss:0.09275242817238905
2023-07-08 13:36:15,275 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:36:15,276 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:36:15,276 - wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
2023-07-08 13:37:03,508 - 


2023-07-08 13:37:03,509 - epoch:120,	loss:0.0931289076252142
2023-07-08 13:37:13,084 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:37:13,084 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:37:13,084 - wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
2023-07-08 13:37:59,462 - 


2023-07-08 13:37:59,462 - epoch:121,	loss:0.09522807988105342
2023-07-08 13:38:10,590 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:38:10,590 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:38:10,590 - wrong_be_tree_count:43	wrong_total:99	 wrong be tree ACC: 0.43434343434343436
2023-07-08 13:38:55,925 - 


2023-07-08 13:38:55,925 - epoch:122,	loss:0.09113666907069273
2023-07-08 13:39:08,531 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:39:08,531 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:39:08,531 - wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
2023-07-08 13:39:29,424 - 


2023-07-08 13:39:29,424 - epoch:123,	loss:0.09332545881625265
2023-07-08 13:39:53,656 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-08 13:39:53,656 - right_codes_count:326	total:433	 Code ACC: 0.7528868360277137
2023-07-08 13:39:53,656 - wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-08 13:40:05,119 - 


2023-07-08 13:40:05,119 - epoch:124,	loss:0.0947623997926712
2023-07-08 13:40:08,321 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:40:08,321 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:40:08,321 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-08 13:40:48,166 - 


2023-07-08 13:40:48,167 - epoch:125,	loss:0.09645712218480185
2023-07-08 13:40:56,882 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:40:56,882 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:40:56,882 - wrong_be_tree_count:42	wrong_total:98	 wrong be tree ACC: 0.42857142857142855
2023-07-08 13:41:43,296 - 


2023-07-08 13:41:43,296 - epoch:126,	loss:0.09290479033370502
2023-07-08 13:41:51,681 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:41:51,682 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:41:51,682 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-08 13:42:33,646 - 


2023-07-08 13:42:33,646 - epoch:127,	loss:0.09274900631862693
2023-07-08 13:42:48,020 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:42:48,020 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:42:48,020 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-08 13:43:24,768 - 


2023-07-08 13:43:24,768 - epoch:128,	loss:0.092732618250011
2023-07-08 13:43:44,256 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:43:44,256 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:43:44,256 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-08 13:44:02,120 - 


2023-07-08 13:44:02,120 - epoch:129,	loss:0.09602221538079903
2023-07-08 13:44:05,427 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-08 13:44:05,428 - right_codes_count:327	total:433	 Code ACC: 0.7551963048498845
2023-07-08 13:44:05,428 - wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-08 13:44:12,262 - 


2023-07-08 13:44:12,262 - final_test
2023-07-08 13:44:35,921 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-08 13:44:35,921 - right_codes_count:330	total:433	 Code ACC: 0.7621247113163973
2023-07-08 13:44:35,921 - wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-08 14:44:14,523 - get train data loader...
2023-07-08 14:44:14,632 - get dev data loader...
2023-07-08 14:44:14,658 - define model...
2023-07-08 14:44:28,962 - define optimizer...
2023-07-08 14:44:28,963 - ===========================train setting parameters=========================
2023-07-08 14:44:28,964 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 14:44:28,964 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 14:44:28,964 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 14:44:28,964 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,964 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,964 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,965 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,965 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,966 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,967 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,968 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,968 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,969 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,969 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,969 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,969 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,970 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,970 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,971 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,971 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,972 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,973 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,973 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:44:28,974 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:44:28,975 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:44:28,975 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 14:44:28,976 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 14:44:28,976 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 14:44:28,976 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 14:44:28,976 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 14:44:28,976 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 14:44:28,976 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 14:44:28,976 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 14:44:28,976 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 14:44:28,976 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 14:44:28,976 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 14:44:28,976 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 14:44:28,976 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 14:44:28,977 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 14:44:28,977 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 14:44:28,977 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 14:44:28,977 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 14:44:28,977 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 14:44:28,977 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 14:44:28,977 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 14:44:28,977 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 14:44:28,977 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 14:44:28,977 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 14:44:28,977 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 14:51:02,622 - get train data loader...
2023-07-08 14:51:02,708 - get dev data loader...
2023-07-08 14:51:02,733 - define model...
2023-07-08 14:51:06,816 - define optimizer...
2023-07-08 14:51:06,817 - ===========================train setting parameters=========================
2023-07-08 14:51:06,818 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 14:51:06,818 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 14:51:06,818 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 14:51:06,818 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,818 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,818 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,819 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,819 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,821 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,822 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,823 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,824 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,824 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,824 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,825 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,825 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,826 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,826 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,826 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,827 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,827 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,828 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,828 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,829 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,830 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,830 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,830 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,830 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,830 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,830 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,830 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,830 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,830 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,830 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,831 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 14:51:06,832 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:06,833 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:06,833 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:06,833 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 14:51:06,833 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 14:51:06,833 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 14:51:06,833 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 14:51:06,833 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 14:51:06,833 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 14:51:06,833 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 14:51:06,833 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 14:51:06,833 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 14:51:06,834 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 14:51:06,834 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 14:51:06,834 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 14:51:06,834 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 14:51:06,834 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 14:51:06,834 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 14:51:06,834 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 14:51:06,834 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 14:51:06,834 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 14:51:06,834 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 14:51:06,835 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 14:51:06,835 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 14:51:06,835 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 14:51:06,835 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 14:51:26,443 - get train data loader...
2023-07-08 14:51:26,535 - get dev data loader...
2023-07-08 14:51:26,564 - define model...
2023-07-08 14:51:32,202 - define optimizer...
2023-07-08 14:51:32,202 - ===========================train setting parameters=========================
2023-07-08 14:51:32,205 - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-07-08 14:51:32,205 - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-07-08 14:51:32,205 - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-07-08 14:51:32,205 - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,205 - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,205 - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,205 - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,205 - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,205 - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,206 - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,207 - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,208 - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,209 - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,210 - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,210 - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,211 - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,212 - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,212 - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,212 - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,212 - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,212 - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,212 - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,212 - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,212 - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,213 - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,214 - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,214 - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,214 - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,215 - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,215 - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,216 - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,217 - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,217 - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,218 - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,218 - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,219 - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,227 - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,227 - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,227 - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,227 - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,227 - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,229 - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,230 - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-07-08 14:51:32,231 - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-07-08 14:51:32,232 - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-07-08 14:51:32,232 - bert.pooler.dense.weight-torch.Size([768, 768])
2023-07-08 14:51:32,232 - bert.pooler.dense.bias-torch.Size([768])
2023-07-08 14:51:32,233 - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-07-08 14:51:32,233 - fc.layer1.0.bias-torch.Size([2048])
2023-07-08 14:51:32,233 - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-07-08 14:51:32,233 - fc.layer2.0.bias-torch.Size([1024])
2023-07-08 14:51:32,233 - fc.layer3.0.weight-torch.Size([28, 1024])
2023-07-08 14:51:32,233 - fc.layer3.0.bias-torch.Size([28])
2023-07-08 14:51:32,233 - code_emb.layer1.0.weight-torch.Size([384, 28])
2023-07-08 14:51:32,233 - code_emb.layer1.0.bias-torch.Size([384])
2023-07-08 14:51:32,233 - code_emb.layer2.0.weight-torch.Size([768, 384])
2023-07-08 14:51:32,233 - code_emb.layer2.0.bias-torch.Size([768])
2023-07-08 14:51:32,234 - code_emb.layer3.0.weight-torch.Size([1536, 768])
2023-07-08 14:51:32,234 - code_emb.layer3.0.bias-torch.Size([1536])
2023-07-08 14:51:32,234 - code_check.layer1.0.weight-torch.Size([768, 1536])
2023-07-08 14:51:32,234 - code_check.layer1.0.bias-torch.Size([768])
2023-07-08 14:51:32,234 - code_check.layer2.0.weight-torch.Size([384, 768])
2023-07-08 14:51:32,234 - code_check.layer2.0.bias-torch.Size([384])
2023-07-08 14:51:32,234 - code_check.layer3.0.weight-torch.Size([2, 384])
2023-07-08 14:51:32,234 - code_check.layer3.0.bias-torch.Size([2])
2023-07-08 14:51:32,234 - dec_self_attn.W_Q.weight-torch.Size([1024, 1536])
2023-07-08 14:51:32,235 - dec_self_attn.W_K.weight-torch.Size([1024, 1536])
2023-07-08 14:51:32,235 - dec_self_attn.W_V.weight-torch.Size([1024, 1536])
2023-07-08 14:51:32,235 - dec_self_attn.fc.weight-torch.Size([1536, 1024])
2023-07-08 14:58:51,780 - get train data loader...
2023-07-08 14:58:52,064 - get dev data loader...
2023-07-08 14:58:52,190 - define model...
2023-07-08 15:01:49,735 - get train data loader...
2023-07-08 15:01:49,815 - get dev data loader...
2023-07-08 15:01:49,838 - define model...
2023-07-08 15:04:07,595 - get train data loader...
2023-07-08 15:04:07,685 - get dev data loader...
2023-07-08 15:04:07,707 - define model...
2023-07-08 15:05:33,356 - get train data loader...
2023-07-08 15:05:33,461 - get dev data loader...
2023-07-08 15:05:33,485 - define model...
2023-07-08 15:07:09,240 - get train data loader...
2023-07-08 15:07:09,325 - get dev data loader...
2023-07-08 15:07:09,349 - define model...
2023-07-08 15:08:10,017 - get train data loader...
2023-07-08 15:08:10,102 - get dev data loader...
2023-07-08 15:08:10,144 - define model...
2023-07-08 15:09:33,067 - get train data loader...
2023-07-08 15:09:33,196 - get dev data loader...
2023-07-08 15:09:33,221 - define model...
2023-07-08 15:12:44,288 - get train data loader...
2023-07-08 15:12:44,558 - get dev data loader...
2023-07-08 15:12:44,678 - define model...
2023-07-08 15:15:29,067 - get train data loader...
2023-07-08 15:15:29,332 - get dev data loader...
2023-07-08 15:15:29,453 - define model...
2023-07-08 15:18:18,349 - get train data loader...
2023-07-08 15:18:18,669 - get dev data loader...
2023-07-08 15:18:18,791 - define model...
2023-07-08 16:57:43,286 - get train data loader...
2023-07-08 16:57:43,653 - get dev data loader...
2023-07-08 16:57:43,791 - define model...
2023-07-08 17:00:29,674 - get train data loader...
2023-07-08 17:00:29,933 - get dev data loader...
2023-07-08 17:00:30,055 - define model...
2023-07-08 17:04:35,165 - get train data loader...
2023-07-08 17:04:35,507 - get dev data loader...
2023-07-08 17:04:35,650 - define model...
2023-07-08 17:05:22,014 - get train data loader...
2023-07-08 17:05:22,279 - get dev data loader...
2023-07-08 17:05:22,415 - define model...
2023-07-08 17:06:59,764 - get train data loader...
2023-07-08 17:07:00,033 - get dev data loader...
2023-07-08 17:07:00,156 - define model...
2023-07-08 17:09:24,478 - get train data loader...
2023-07-08 17:09:24,775 - get dev data loader...
2023-07-08 17:09:24,912 - define model...
2023-07-08 17:15:49,964 - get train data loader...
2023-07-08 17:15:50,224 - get dev data loader...
2023-07-08 17:15:50,353 - define model...
2023-07-08 17:23:57,519 - get train data loader...
2023-07-08 17:23:57,801 - get dev data loader...
2023-07-08 17:23:57,939 - define model...
2023-07-08 17:28:21,708 - get train data loader...
2023-07-08 17:28:21,989 - get dev data loader...
2023-07-08 17:28:22,128 - define model...
2023-07-08 17:32:26,704 - get train data loader...
2023-07-08 17:32:26,795 - get dev data loader...
2023-07-08 17:32:26,857 - define model...
2023-07-08 17:35:37,532 - get train data loader...
2023-07-08 17:35:37,807 - get dev data loader...
2023-07-08 17:35:37,939 - define model...
2023-07-08 17:40:33,562 - get train data loader...
2023-07-08 17:40:33,902 - get dev data loader...
2023-07-08 17:40:34,047 - define model...
2023-07-08 20:37:10,588 - 


2023-07-08 20:37:11,051 - get train data loader...
2023-07-08 20:37:11,199 - get dev data loader...
2023-07-08 20:37:11,240 - define model...
2023-07-08 20:45:28,282 - 


2023-07-08 20:45:30,206 - get train data loader...
2023-07-08 20:45:31,390 - get dev data loader...
2023-07-08 20:45:31,722 - define model...
2023-07-08 21:09:40,537 - 


2023-07-08 21:09:41,024 - get train data loader...
2023-07-08 21:09:41,166 - get dev data loader...
2023-07-08 21:09:41,248 - define model...
2023-07-08 21:11:37,588 - 


2023-07-08 21:11:38,061 - get train data loader...
2023-07-08 21:11:38,532 - get dev data loader...
2023-07-08 21:11:38,738 - define model...
2023-07-08 21:16:34,130 - 


2023-07-08 21:16:34,607 - get train data loader...
2023-07-08 21:16:34,760 - get dev data loader...
2023-07-08 21:16:34,861 - define model...
2023-07-08 21:20:36,472 - 


2023-07-08 21:20:36,940 - get train data loader...
2023-07-08 21:20:37,360 - get dev data loader...
2023-07-08 21:20:37,561 - define model...
2023-07-08 21:22:19,787 - 


2023-07-08 21:22:20,247 - get train data loader...
2023-07-08 21:22:20,389 - get dev data loader...
2023-07-08 21:22:20,478 - define model...
2023-07-08 21:30:09,838 - 


2023-07-08 21:30:10,679 - get train data loader...
2023-07-08 21:30:10,830 - get dev data loader...
2023-07-08 21:30:10,924 - define model...
2023-07-08 21:30:50,313 - 


2023-07-08 21:30:50,777 - get train data loader...
2023-07-08 21:30:51,245 - get dev data loader...
2023-07-08 21:30:51,459 - define model...
2023-07-08 21:33:04,227 - 


2023-07-08 21:33:04,681 - get train data loader...
2023-07-08 21:33:04,836 - get dev data loader...
2023-07-08 21:33:04,967 - define model...
2023-07-09 12:08:50,434 - 


2023-07-09 12:08:51,303 - get train data loader...
2023-07-09 12:08:51,739 - get dev data loader...
2023-07-09 12:08:51,949 - define model...
2023-07-09 21:36:41,034 - 


2023-07-09 21:36:41,584 - get train data loader...
2023-07-09 21:36:42,040 - get dev data loader...
2023-07-09 21:36:42,236 - define model...
2023-07-09 21:36:52,422 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:37:38,752 - 


2023-07-09 21:37:39,707 - get train data loader...
2023-07-09 21:37:40,190 - get dev data loader...
2023-07-09 21:37:40,439 - define model...
2023-07-09 21:37:49,401 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:46:32,390 - 


2023-07-09 21:46:32,865 - get train data loader...
2023-07-09 21:46:33,331 - get dev data loader...
2023-07-09 21:46:33,530 - define model...
2023-07-09 21:46:38,905 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:48:26,691 - 


2023-07-09 21:48:27,763 - get train data loader...
2023-07-09 21:48:28,271 - get dev data loader...
2023-07-09 21:48:28,528 - define model...
2023-07-09 21:48:33,477 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:51:05,445 - 


2023-07-09 21:51:05,933 - get train data loader...
2023-07-09 21:51:06,358 - get dev data loader...
2023-07-09 21:51:06,563 - define model...
2023-07-09 21:51:12,233 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:54:53,953 - 


2023-07-09 21:54:54,428 - get train data loader...
2023-07-09 21:54:54,918 - get dev data loader...
2023-07-09 21:54:55,108 - define model...
2023-07-09 21:54:59,930 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 21:58:38,995 - 


2023-07-09 21:58:39,465 - get train data loader...
2023-07-09 21:58:39,931 - get dev data loader...
2023-07-09 21:58:40,114 - define model...
2023-07-09 21:58:45,728 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:06:00,721 - save best refiner model to ./output/test/best_model
2023-07-09 22:06:01,061 - epoch:0,	loss:28.68044137954712
2023-07-09 22:06:12,737 - epoch:1,	loss:28.407694160938263
2023-07-09 22:06:25,170 - epoch:2,	loss:27.872223913669586
2023-07-09 22:06:37,035 - epoch:3,	loss:27.079622983932495
2023-07-09 22:06:49,037 - epoch:4,	loss:26.05875915288925
2023-07-09 22:07:01,150 - epoch:5,	loss:24.821426451206207
2023-07-09 22:07:13,131 - epoch:6,	loss:23.39795994758606
2023-07-09 22:07:24,795 - save best refiner model to ./output/test/best_model
2023-07-09 22:07:25,123 - epoch:7,	loss:21.804624050855637
2023-07-09 22:07:37,000 - save best refiner model to ./output/test/best_model
2023-07-09 22:07:37,320 - epoch:8,	loss:20.07244136929512
2023-07-09 22:07:49,487 - save best refiner model to ./output/test/best_model
2023-07-09 22:07:49,790 - epoch:9,	loss:18.22979924082756
2023-07-09 22:08:01,664 - save best refiner model to ./output/test/best_model
2023-07-09 22:08:01,878 - epoch:10,	loss:16.316939145326614
2023-07-09 22:08:14,031 - epoch:11,	loss:14.37646958231926
2023-07-09 22:08:26,158 - epoch:12,	loss:12.469615668058395
2023-07-09 22:08:38,132 - epoch:13,	loss:10.664051204919815
2023-07-09 22:08:50,410 - epoch:14,	loss:9.076821208000183
2023-07-09 22:09:02,408 - epoch:15,	loss:7.728821575641632
2023-07-09 22:18:32,880 - 


2023-07-09 22:18:33,362 - get train data loader...
2023-07-09 22:18:33,852 - get dev data loader...
2023-07-09 22:18:34,051 - define model...
2023-07-09 22:18:38,930 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:18:56,734 - save best refiner model to ./output/test/best_model
2023-07-09 22:19:38,993 - 


2023-07-09 22:19:39,468 - get train data loader...
2023-07-09 22:19:39,930 - get dev data loader...
2023-07-09 22:19:40,131 - define model...
2023-07-09 22:19:45,263 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:20:00,118 - save best refiner model to ./output/test/best_model
2023-07-09 22:20:00,451 - epoch:0,	loss:28.68044137954712
2023-07-09 22:20:13,351 - epoch:1,	loss:28.407694160938263
2023-07-09 22:20:25,591 - epoch:2,	loss:27.872223913669586
2023-07-09 22:20:38,993 - epoch:3,	loss:27.079622983932495
2023-07-09 22:20:51,794 - epoch:4,	loss:26.05875915288925
2023-07-09 22:21:04,317 - epoch:5,	loss:24.821426451206207
2023-07-09 22:21:16,431 - epoch:6,	loss:23.39795994758606
2023-07-09 22:21:29,413 - save best refiner model to ./output/test/best_model
2023-07-09 22:21:29,712 - epoch:7,	loss:21.804624050855637
2023-07-09 22:21:42,338 - save best refiner model to ./output/test/best_model
2023-07-09 22:21:42,685 - epoch:8,	loss:20.07244136929512
2023-07-09 22:21:54,478 - save best refiner model to ./output/test/best_model
2023-07-09 22:22:20,916 - epoch:9,	loss:18.22979924082756
2023-07-09 22:22:23,408 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:22:41,908 - 


2023-07-09 22:22:42,434 - get train data loader...
2023-07-09 22:22:42,914 - get dev data loader...
2023-07-09 22:22:43,089 - define model...
2023-07-09 22:22:48,083 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:23:05,198 - save best refiner model to ./output/test/best_model
2023-07-09 22:23:05,541 - epoch:0,	loss:28.68044137954712
2023-07-09 22:23:17,531 - epoch:1,	loss:28.407694160938263
2023-07-09 22:23:29,721 - epoch:2,	loss:27.872223913669586
2023-07-09 22:23:42,322 - epoch:3,	loss:27.079622983932495
2023-07-09 22:23:55,220 - epoch:4,	loss:26.05875915288925
2023-07-09 22:24:07,570 - epoch:5,	loss:24.821426451206207
2023-07-09 22:24:20,120 - epoch:6,	loss:23.39795994758606
2023-07-09 22:24:32,123 - save best refiner model to ./output/test/best_model
2023-07-09 22:24:32,438 - epoch:7,	loss:21.804624050855637
2023-07-09 22:24:44,169 - save best refiner model to ./output/test/best_model
2023-07-09 22:24:44,607 - epoch:8,	loss:20.07244136929512
2023-07-09 22:24:56,669 - save best refiner model to ./output/test/best_model
2023-07-09 22:27:15,808 - epoch:9,	loss:18.22979924082756
2023-07-09 22:27:48,629 - save best refiner model to ./output/test/best_model
2023-07-09 22:27:56,033 - epoch:10,	loss:16.316939145326614
2023-07-09 22:32:27,783 - 


2023-07-09 22:32:28,403 - get train data loader...
2023-07-09 22:32:28,909 - get dev data loader...
2023-07-09 22:32:29,146 - define model...
2023-07-09 22:32:34,921 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:33:18,885 - save best refiner model to ./output/test/best_model
2023-07-09 22:33:19,235 - epoch:0,	loss:28.68044137954712
2023-07-09 22:33:31,617 - save best refiner model to ./output/test/best_model
2023-07-09 22:34:55,659 - epoch:1,	loss:28.407694160938263
2023-07-09 22:39:32,827 - save best refiner model to ./output/test/best_model
2023-07-09 22:41:52,253 - 


2023-07-09 22:41:53,225 - get train data loader...
2023-07-09 22:41:53,705 - get dev data loader...
2023-07-09 22:41:53,896 - define model...
2023-07-09 22:41:59,133 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:47:16,476 - save best refiner model to ./output/test/best_model
2023-07-09 22:47:16,822 - epoch:0,	loss:28.68044137954712
2023-07-09 22:47:29,238 - save best refiner model to ./output/test/best_model
2023-07-09 22:47:57,130 - epoch:1,	loss:28.407694160938263
2023-07-09 22:50:51,187 - save best refiner model to ./output/test/best_model
2023-07-09 22:51:47,188 - 


2023-07-09 22:51:47,787 - get train data loader...
2023-07-09 22:51:48,257 - get dev data loader...
2023-07-09 22:51:48,449 - define model...
2023-07-09 22:51:53,087 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 22:57:57,498 - save best refiner model to ./output/test/best_model
2023-07-09 22:57:57,801 - epoch:0,	loss:28.68044137954712
2023-07-09 23:01:08,592 - save best refiner model to ./output/test/best_model
2023-07-09 23:01:20,718 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:01:20,718 - 


2023-07-09 23:01:20,718 - final_test
2023-07-09 23:01:32,567 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-09 23:01:32,567 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-09 23:01:32,568 - temp:73	temp1:34	wrong_total:86	
2023-07-09 23:19:03,594 - 


2023-07-09 23:19:04,575 - get train data loader...
2023-07-09 23:19:05,033 - get dev data loader...
2023-07-09 23:19:05,255 - define model...
2023-07-09 23:19:09,898 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:21:45,333 - save best refiner model to ./output/test/best_model
2023-07-09 23:21:45,669 - epoch:0,	loss:28.68044137954712
2023-07-09 23:21:57,850 - save best refiner model to ./output/test/best_model
2023-07-09 23:21:57,851 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:21:57,852 - 


2023-07-09 23:21:57,852 - final_test
2023-07-09 23:22:10,511 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-09 23:22:10,512 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-09 23:22:10,512 - temp:73	temp1:34	wrong_total:86	
2023-07-09 23:24:57,514 - 


2023-07-09 23:24:58,013 - get train data loader...
2023-07-09 23:24:58,462 - get dev data loader...
2023-07-09 23:24:58,662 - define model...
2023-07-09 23:25:03,523 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:35:19,319 - save best refiner model to ./output/test/best_model
2023-07-09 23:35:19,644 - epoch:0,	loss:28.68044137954712
2023-07-09 23:35:31,358 - save best refiner model to ./output/test/best_model
2023-07-09 23:35:31,359 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:35:31,359 - 


2023-07-09 23:35:31,360 - final_test
2023-07-09 23:35:42,242 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-09 23:35:42,243 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-09 23:35:42,244 - temp:73	temp1:34	wrong_total:86	
2023-07-09 23:36:02,079 - 


2023-07-09 23:36:02,969 - get train data loader...
2023-07-09 23:36:03,432 - get dev data loader...
2023-07-09 23:36:03,616 - define model...
2023-07-09 23:36:08,867 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:43:17,789 - 


2023-07-09 23:43:18,337 - get train data loader...
2023-07-09 23:43:18,784 - get dev data loader...
2023-07-09 23:43:18,978 - define model...
2023-07-09 23:43:24,074 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:43:40,012 - save best refiner model to ./output/test/best_model
2023-07-09 23:43:40,329 - epoch:0,	loss:28.68044137954712
2023-07-09 23:43:52,712 - save best refiner model to ./output/test/best_model
2023-07-09 23:43:52,713 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-09 23:43:52,713 - 


2023-07-09 23:43:52,722 - final_test
2023-07-09 23:44:04,035 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-09 23:44:04,035 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-09 23:44:04,037 - temp:73	temp1:34	wrong_total:86	
2023-07-09 23:45:46,671 - 


2023-07-09 23:45:47,529 - get train data loader...
2023-07-09 23:45:48,006 - get dev data loader...
2023-07-09 23:45:48,227 - define model...
2023-07-09 23:45:53,039 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 00:03:33,317 - 


2023-07-10 00:03:33,882 - get train data loader...
2023-07-10 00:03:34,338 - get dev data loader...
2023-07-10 00:03:34,555 - define model...
2023-07-10 00:03:39,363 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 00:04:17,585 - save best refiner model to ./output/test/best_model
2023-07-10 00:04:17,838 - epoch:0,	loss:28.811647295951843
2023-07-10 00:04:28,884 - epoch:1,	loss:28.567025899887085
2023-07-10 00:04:40,880 - epoch:2,	loss:28.06796282529831
2023-07-10 00:04:52,885 - epoch:3,	loss:27.331715643405914
2023-07-10 00:05:04,995 - epoch:4,	loss:26.392565488815308
2023-07-10 00:05:16,917 - epoch:5,	loss:25.249973595142365
2023-07-10 00:05:29,689 - epoch:6,	loss:23.94920724630356
2023-07-10 00:05:41,759 - epoch:7,	loss:22.502763241529465
2023-07-10 00:05:54,048 - epoch:8,	loss:20.94159233570099
2023-07-10 00:06:06,187 - epoch:9,	loss:19.37851482629776
2023-07-10 03:51:22,103 - 


2023-07-10 03:51:23,308 - get train data loader...
2023-07-10 03:51:23,828 - get dev data loader...
2023-07-10 03:51:24,067 - define model...
2023-07-10 03:53:27,943 - 


2023-07-10 03:53:28,638 - get train data loader...
2023-07-10 03:53:29,036 - get dev data loader...
2023-07-10 03:53:29,226 - define model...
2023-07-10 03:53:33,655 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 03:54:21,188 - save best refiner model to ./output/test/best_model
2023-07-10 03:54:21,435 - epoch:0,	loss:176.60658144950867
2023-07-10 03:54:37,066 - epoch:1,	loss:176.4635410308838
2023-07-10 03:54:51,767 - epoch:2,	loss:176.39600682258606
2023-07-10 03:55:07,293 - epoch:3,	loss:176.2498893737793
2023-07-10 03:55:22,822 - epoch:4,	loss:175.99332857131958
2023-07-10 03:55:38,207 - epoch:5,	loss:175.7311749458313
2023-07-10 03:55:53,499 - epoch:6,	loss:175.37137937545776
2023-07-10 03:56:09,032 - epoch:7,	loss:174.9500834941864
2023-07-10 03:56:24,135 - epoch:8,	loss:174.476087808609
2023-07-10 03:56:39,545 - epoch:9,	loss:173.83821153640747
2023-07-10 03:56:54,946 - epoch:10,	loss:173.27298951148987
2023-07-10 03:58:17,315 - 


2023-07-10 03:58:17,931 - get train data loader...
2023-07-10 03:58:18,321 - get dev data loader...
2023-07-10 03:58:18,490 - define model...
2023-07-10 03:58:23,190 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 03:58:40,488 - save best refiner model to ./output/test/best_model
2023-07-10 03:58:40,733 - epoch:0,	loss:176.14546418190002
2023-07-10 03:58:56,248 - epoch:1,	loss:173.13816666603088
2023-07-10 03:59:11,714 - epoch:2,	loss:166.60977959632874
2023-07-10 03:59:27,144 - save best refiner model to ./output/test/best_model
2023-07-10 03:59:27,389 - epoch:3,	loss:156.97362446784973
2023-07-10 03:59:42,632 - epoch:4,	loss:143.83380246162415
2023-07-10 03:59:57,766 - epoch:5,	loss:121.68549084663391
2023-07-10 04:00:13,005 - epoch:6,	loss:89.63381290435791
2023-07-10 04:00:28,215 - epoch:7,	loss:57.46110635995865
2023-07-10 04:00:42,898 - save best refiner model to ./output/test/best_model
2023-07-10 04:00:43,265 - epoch:8,	loss:36.76759722828865
2023-07-10 04:00:58,379 - save best refiner model to ./output/test/best_model
2023-07-10 04:00:58,637 - epoch:9,	loss:27.892618894577026
2023-07-10 04:01:14,228 - epoch:10,	loss:23.227624475955963
2023-07-10 04:01:29,778 - epoch:11,	loss:21.387170806527138
2023-07-10 04:01:44,992 - epoch:12,	loss:20.982056364417076
2023-07-10 04:01:59,942 - epoch:13,	loss:20.42980206012726
2023-07-10 04:02:14,638 - epoch:14,	loss:20.092499122023582
2023-07-10 04:02:29,380 - epoch:15,	loss:20.31398245692253
2023-07-10 04:02:44,655 - epoch:16,	loss:20.28337626159191
2023-07-10 04:02:59,980 - epoch:17,	loss:20.387072250247
2023-07-10 04:03:15,179 - epoch:18,	loss:20.005308836698532
2023-07-10 04:03:30,121 - epoch:19,	loss:19.677257776260376
2023-07-10 04:03:45,478 - epoch:20,	loss:19.529139146208763
2023-07-10 04:04:00,571 - epoch:21,	loss:20.24052445590496
2023-07-10 04:04:16,122 - epoch:22,	loss:20.232803270220757
2023-07-10 04:04:31,615 - epoch:23,	loss:19.644889131188393
2023-07-10 04:04:46,748 - epoch:24,	loss:19.75187596678734
2023-07-10 04:05:02,186 - epoch:25,	loss:19.21322436258197
2023-07-10 04:05:17,720 - epoch:26,	loss:19.17193052917719
2023-07-10 04:05:32,925 - epoch:27,	loss:19.712185472249985
2023-07-10 04:05:48,703 - epoch:28,	loss:19.588974490761757
2023-07-10 04:06:04,425 - epoch:29,	loss:19.15702410042286
2023-07-10 04:06:04,426 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 04:06:04,426 - 


2023-07-10 04:06:04,439 - final_test
2023-07-10 04:06:13,965 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 04:06:13,965 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 04:06:13,965 - temp:73	temp1:34	wrong_total:86	
2023-07-10 04:14:34,116 - 


2023-07-10 04:14:34,849 - get train data loader...
2023-07-10 04:14:35,227 - get dev data loader...
2023-07-10 04:14:35,419 - define model...
2023-07-10 04:14:39,535 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 04:14:56,560 - save best refiner model to ./output/test/best_model
2023-07-10 04:14:56,828 - epoch:0,	loss:82.20125937461853
2023-07-10 04:15:12,260 - epoch:1,	loss:80.79837203025818
2023-07-10 04:15:27,226 - epoch:2,	loss:77.75270998477936
2023-07-10 04:15:42,307 - save best refiner model to ./output/test/best_model
2023-07-10 04:15:42,540 - epoch:3,	loss:73.25630354881287
2023-07-10 04:15:58,267 - epoch:4,	loss:67.126189827919
2023-07-10 04:16:13,634 - epoch:5,	loss:56.79250741004944
2023-07-10 04:16:28,877 - epoch:6,	loss:41.838633835315704
2023-07-10 04:16:44,347 - epoch:7,	loss:26.830350011587143
2023-07-10 04:16:59,482 - save best refiner model to ./output/test/best_model
2023-07-10 04:16:59,834 - epoch:8,	loss:17.19147329032421
2023-07-10 04:17:14,694 - save best refiner model to ./output/test/best_model
2023-07-10 04:17:14,912 - epoch:9,	loss:13.057227835059166
2023-07-10 04:17:30,215 - epoch:10,	loss:10.84382227063179
2023-07-10 04:17:45,953 - epoch:11,	loss:9.978142686188221
2023-07-10 04:18:01,204 - epoch:12,	loss:9.784963123500347
2023-07-10 04:18:16,447 - epoch:13,	loss:9.525290615856647
2023-07-10 04:18:31,818 - epoch:14,	loss:9.371049843728542
2023-07-10 04:18:46,761 - epoch:15,	loss:9.470367133617401
2023-07-10 04:19:01,906 - epoch:16,	loss:9.456597093492746
2023-07-10 04:19:16,677 - epoch:17,	loss:9.504650630056858
2023-07-10 04:19:31,608 - epoch:18,	loss:9.326464459300041
2023-07-10 04:19:46,791 - epoch:19,	loss:9.167214520275593
2023-07-10 04:20:02,142 - save best refiner model to ./output/test/best_model
2023-07-10 04:20:02,395 - epoch:20,	loss:9.101064015179873
2023-07-10 04:20:17,841 - epoch:21,	loss:9.430764116346836
2023-07-10 04:20:33,189 - epoch:22,	loss:9.429268915206194
2023-07-10 04:20:48,296 - epoch:23,	loss:9.157742228358984
2023-07-10 04:21:02,874 - epoch:24,	loss:9.2072294652462
2023-07-10 04:21:18,259 - epoch:25,	loss:8.958644412457943
2023-07-10 04:21:34,135 - epoch:26,	loss:8.939562410116196
2023-07-10 04:21:51,099 - epoch:27,	loss:9.191635057330132
2023-07-10 04:22:06,341 - save best refiner model to ./output/test/best_model
2023-07-10 04:22:06,607 - epoch:28,	loss:9.13508216291666
2023-07-10 04:22:21,840 - epoch:29,	loss:8.932938493788242
2023-07-10 04:22:21,840 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 04:22:21,840 - 


2023-07-10 04:22:21,842 - final_test
2023-07-10 04:22:31,419 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 04:22:31,420 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 04:22:31,420 - temp:73	temp1:34	wrong_total:86	
2023-07-10 04:24:00,060 - 


2023-07-10 04:24:00,890 - get train data loader...
2023-07-10 04:24:01,264 - get dev data loader...
2023-07-10 04:24:01,453 - define model...
2023-07-10 04:24:05,715 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 04:24:22,314 - save best refiner model to ./output/test/best_model
2023-07-10 04:24:22,548 - epoch:0,	loss:68.63535058498383
2023-07-10 04:24:37,881 - epoch:1,	loss:65.32587683200836
2023-07-10 04:24:52,770 - epoch:2,	loss:58.45286405086517
2023-07-10 04:25:07,884 - epoch:3,	loss:45.82798969745636
2023-07-10 04:25:22,887 - save best refiner model to ./output/test/best_model
2023-07-10 04:25:23,120 - epoch:4,	loss:28.596271634101868
2023-07-10 04:25:38,554 - epoch:5,	loss:16.24406135082245
2023-07-10 04:25:53,406 - save best refiner model to ./output/test/best_model
2023-07-10 04:25:53,644 - epoch:6,	loss:11.365680694580078
2023-07-10 04:26:08,740 - save best refiner model to ./output/test/best_model
2023-07-10 04:26:08,989 - epoch:7,	loss:9.978295709937811
2023-07-10 04:26:24,237 - epoch:8,	loss:9.510499209165573
2023-07-10 04:26:40,211 - epoch:9,	loss:9.791751883924007
2023-07-10 04:26:55,463 - epoch:10,	loss:9.348133888095617
2023-07-10 04:27:10,454 - save best refiner model to ./output/test/best_model
2023-07-10 04:27:10,690 - epoch:11,	loss:9.114367369562387
2023-07-10 04:27:25,924 - epoch:12,	loss:9.252334631979465
2023-07-10 04:27:40,377 - epoch:13,	loss:9.125575054436922
2023-07-10 04:27:55,956 - save best refiner model to ./output/test/best_model
2023-07-10 04:27:56,195 - epoch:14,	loss:9.023276340216398
2023-07-10 04:28:12,471 - epoch:15,	loss:9.20623479038477
2023-07-10 04:28:27,744 - epoch:16,	loss:9.118049841374159
2023-07-10 04:28:42,765 - epoch:17,	loss:9.198390835896134
2023-07-10 04:28:57,625 - epoch:18,	loss:8.92841013520956
2023-07-10 04:29:13,092 - epoch:19,	loss:8.845621176064014
2023-07-10 04:29:27,672 - epoch:20,	loss:8.784604620188475
2023-07-10 04:29:43,454 - epoch:21,	loss:9.09438868239522
2023-07-10 04:29:59,569 - epoch:22,	loss:9.104207463562489
2023-07-10 04:30:14,789 - epoch:23,	loss:8.80222201347351
2023-07-10 04:30:30,037 - epoch:24,	loss:8.886507261544466
2023-07-10 04:30:44,549 - save best refiner model to ./output/test/best_model
2023-07-10 04:30:44,787 - epoch:25,	loss:8.584941275417805
2023-07-10 04:31:00,556 - epoch:26,	loss:8.569361113011837
2023-07-10 04:31:16,125 - epoch:27,	loss:8.823013663291931
2023-07-10 04:31:31,841 - epoch:28,	loss:8.729377605021
2023-07-10 04:31:46,716 - epoch:29,	loss:8.509476084262133
2023-07-10 04:32:02,004 - epoch:30,	loss:8.66548253595829
2023-07-10 04:32:17,565 - epoch:31,	loss:8.525529634207487
2023-07-10 04:32:32,996 - epoch:32,	loss:8.64734348654747
2023-07-10 04:32:48,219 - epoch:33,	loss:8.490040494129062
2023-07-10 04:33:03,630 - epoch:34,	loss:8.445062167942524
2023-07-10 04:33:18,544 - epoch:35,	loss:8.593618866056204
2023-07-10 04:33:33,684 - epoch:36,	loss:8.507872618734837
2023-07-10 04:33:48,149 - epoch:37,	loss:8.402364803478122
2023-07-10 04:34:03,311 - epoch:38,	loss:8.435520444065332
2023-07-10 04:34:18,737 - epoch:39,	loss:8.565341643989086
2023-07-10 04:34:34,276 - epoch:40,	loss:8.580661837011576
2023-07-10 04:34:49,578 - epoch:41,	loss:8.461628288030624
2023-07-10 04:35:04,971 - epoch:42,	loss:8.451545119285583
2023-07-10 04:35:20,096 - epoch:43,	loss:8.317955980077386
2023-07-10 04:35:35,003 - epoch:44,	loss:8.291177123785019
2023-07-10 04:35:50,262 - epoch:45,	loss:8.324856955558062
2023-07-10 04:36:04,678 - epoch:46,	loss:8.441720400005579
2023-07-10 04:36:19,982 - epoch:47,	loss:8.401514440774918
2023-07-10 04:36:35,399 - epoch:48,	loss:8.187069743871689
2023-07-10 04:36:50,850 - epoch:49,	loss:8.495294257998466
2023-07-10 04:37:05,814 - epoch:50,	loss:8.16877755150199
2023-07-10 04:37:21,064 - epoch:51,	loss:8.160728462040424
2023-07-10 04:37:36,214 - epoch:52,	loss:8.158816043287516
2023-07-10 04:37:51,270 - epoch:53,	loss:8.171458330005407
2023-07-10 04:38:06,371 - epoch:54,	loss:8.10511950403452
2023-07-10 04:38:21,761 - epoch:55,	loss:8.286436025053263
2023-07-10 04:38:36,902 - epoch:56,	loss:8.215725630521774
2023-07-10 04:38:52,129 - epoch:57,	loss:8.10395947098732
2023-07-10 04:39:07,427 - epoch:58,	loss:8.106975473463535
2023-07-10 04:39:22,760 - epoch:59,	loss:8.109586257487535
2023-07-10 04:39:38,055 - epoch:60,	loss:8.370298776775599
2023-07-10 04:39:53,205 - epoch:61,	loss:8.036028642207384
2023-07-10 04:40:08,339 - epoch:62,	loss:8.099194291979074
2023-07-10 04:40:23,662 - epoch:63,	loss:8.009358290582895
2023-07-10 04:40:39,143 - epoch:64,	loss:8.103357255458832
2023-07-10 04:40:54,163 - epoch:65,	loss:8.038560707122087
2023-07-10 04:41:09,711 - epoch:66,	loss:8.0352250225842
2023-07-10 04:41:24,739 - epoch:67,	loss:7.994968440383673
2023-07-10 04:41:39,330 - epoch:68,	loss:7.950620228424668
2023-07-10 04:41:53,921 - epoch:69,	loss:7.980349229648709
2023-07-10 04:42:09,047 - epoch:70,	loss:8.233371760696173
2023-07-10 04:42:24,816 - epoch:71,	loss:7.931745231151581
2023-07-10 04:42:40,224 - epoch:72,	loss:8.124160587787628
2023-07-10 04:42:54,690 - epoch:73,	loss:7.943557411432266
2023-07-10 04:43:09,131 - epoch:74,	loss:8.232312567532063
2023-07-10 04:43:09,131 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 04:43:09,131 - 


2023-07-10 04:43:09,131 - final_test
2023-07-10 04:43:18,192 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 04:43:18,192 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 04:43:18,192 - temp:73	temp1:34	wrong_total:86	
2023-07-10 20:59:41,338 - 


2023-07-10 20:59:42,508 - get train data loader...
2023-07-10 20:59:42,894 - get dev data loader...
2023-07-10 20:59:43,069 - define model...
2023-07-10 20:59:59,526 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:05:37,246 - 


2023-07-10 21:05:38,123 - get train data loader...
2023-07-10 21:05:38,451 - get dev data loader...
2023-07-10 21:05:38,574 - define model...
2023-07-10 21:05:42,012 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:06:45,253 - 


2023-07-10 21:06:45,773 - get train data loader...
2023-07-10 21:06:46,049 - get dev data loader...
2023-07-10 21:06:46,201 - define model...
2023-07-10 21:06:49,788 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:12:36,780 - 


2023-07-10 21:12:37,324 - get train data loader...
2023-07-10 21:12:37,587 - get dev data loader...
2023-07-10 21:12:37,715 - define model...
2023-07-10 21:12:41,097 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:15:21,914 - 


2023-07-10 21:15:22,780 - get train data loader...
2023-07-10 21:15:23,064 - get dev data loader...
2023-07-10 21:15:23,190 - define model...
2023-07-10 21:15:27,059 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:16:18,208 - 


2023-07-10 21:16:19,042 - get train data loader...
2023-07-10 21:16:19,299 - get dev data loader...
2023-07-10 21:16:19,445 - define model...
2023-07-10 21:16:22,732 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:17:12,195 - 


2023-07-10 21:17:12,729 - get train data loader...
2023-07-10 21:17:12,985 - get dev data loader...
2023-07-10 21:17:13,133 - define model...
2023-07-10 21:17:16,852 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:17:55,351 - 


2023-07-10 21:17:55,816 - get train data loader...
2023-07-10 21:17:56,071 - get dev data loader...
2023-07-10 21:17:56,197 - define model...
2023-07-10 21:17:59,416 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:22:47,388 - 


2023-07-10 21:22:47,836 - get train data loader...
2023-07-10 21:22:48,112 - get dev data loader...
2023-07-10 21:22:48,240 - define model...
2023-07-10 21:22:51,631 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:24:30,842 - 


2023-07-10 21:24:31,304 - get train data loader...
2023-07-10 21:24:31,563 - get dev data loader...
2023-07-10 21:24:31,700 - define model...
2023-07-10 21:24:35,170 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:26:34,850 - 


2023-07-10 21:26:35,461 - get train data loader...
2023-07-10 21:26:35,743 - get dev data loader...
2023-07-10 21:26:35,870 - define model...
2023-07-10 21:26:39,488 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:28:05,814 - 


2023-07-10 21:28:06,321 - get train data loader...
2023-07-10 21:28:06,618 - get dev data loader...
2023-07-10 21:28:06,747 - define model...
2023-07-10 21:28:12,115 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:34:35,991 - 


2023-07-10 21:34:36,509 - get train data loader...
2023-07-10 21:34:36,779 - get dev data loader...
2023-07-10 21:34:36,911 - define model...
2023-07-10 21:34:41,177 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:58:55,480 - 


2023-07-10 21:58:55,934 - get train data loader...
2023-07-10 21:58:56,195 - get dev data loader...
2023-07-10 21:58:56,322 - define model...
2023-07-10 21:58:59,901 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 21:59:05,898 - 

2023-07-10 21:59:05,898 - epoch:0,	loss:30.12815123796463
2023-07-10 22:01:01,517 - 


2023-07-10 22:01:02,049 - get train data loader...
2023-07-10 22:01:02,317 - get dev data loader...
2023-07-10 22:01:02,438 - define model...
2023-07-10 22:01:05,939 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:01:11,744 - 

2023-07-10 22:01:11,744 - epoch:0,	loss:30.12815123796463
2023-07-10 22:04:39,939 - 


2023-07-10 22:04:40,395 - get train data loader...
2023-07-10 22:04:40,663 - get dev data loader...
2023-07-10 22:04:40,794 - define model...
2023-07-10 22:04:44,202 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:04:50,030 - 

2023-07-10 22:04:50,030 - epoch:0,	loss:30.12815123796463
2023-07-10 22:05:30,261 - 


2023-07-10 22:05:31,368 - get train data loader...
2023-07-10 22:05:31,631 - get dev data loader...
2023-07-10 22:05:31,771 - define model...
2023-07-10 22:05:35,236 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:05:41,046 - 

2023-07-10 22:05:41,046 - epoch:0,	loss:30.12815123796463
2023-07-10 22:05:45,903 - right_count:2	total:433	 Answer ACC: 0.004618937644341801
2023-07-10 22:05:45,903 - right_codes_count:0	total:433	 Code ACC: 0.0
2023-07-10 22:05:45,903 - wrong_be_tree_count:412	wrong_total:431	 wrong be tree ACC: 0.9559164733178654
2023-07-10 22:08:55,255 - 


2023-07-10 22:08:55,786 - get train data loader...
2023-07-10 22:08:56,058 - get dev data loader...
2023-07-10 22:08:56,185 - define model...
2023-07-10 22:08:59,697 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:13:28,910 - 


2023-07-10 22:13:29,447 - get train data loader...
2023-07-10 22:13:29,711 - get dev data loader...
2023-07-10 22:13:29,846 - define model...
2023-07-10 22:13:33,872 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:13:45,222 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 22:13:45,222 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 22:13:45,222 - temp:73	temp1:34	wrong_total:86	
2023-07-10 22:13:45,223 - save best refiner model to ./output/test/best_model
2023-07-10 22:13:45,406 - epoch:0,	loss:70.28527760505676
2023-07-10 22:13:55,189 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 22:13:55,189 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 22:13:55,189 - temp:73	temp1:34	wrong_total:86	
2023-07-10 22:13:55,375 - epoch:1,	loss:nan
2023-07-10 22:14:05,104 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 22:14:05,104 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 22:14:05,104 - temp:73	temp1:34	wrong_total:86	
2023-07-10 22:14:05,303 - epoch:2,	loss:41.05486798286438
2023-07-10 22:14:15,059 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 22:14:15,059 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 22:14:15,059 - temp:73	temp1:34	wrong_total:86	
2023-07-10 22:14:15,243 - epoch:3,	loss:nan
2023-07-10 22:14:25,131 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-10 22:14:25,132 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-10 22:14:25,132 - temp:73	temp1:34	wrong_total:86	
2023-07-10 22:14:25,341 - epoch:4,	loss:16.75230999290943
2023-07-10 22:15:07,814 - 


2023-07-10 22:15:08,290 - get train data loader...
2023-07-10 22:15:08,621 - get dev data loader...
2023-07-10 22:15:08,774 - define model...
2023-07-10 22:15:12,444 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:15:24,091 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-10 22:15:24,091 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:117	wrong_total:117	 wrong be tree ACC: 1.0
2023-07-10 22:15:24,091 - temp:113	temp1:3	wrong_total:117	
2023-07-10 22:15:24,094 - save best refiner model to ./output/test/best_model
2023-07-10 22:15:24,278 - epoch:0,	loss:70.28527760505676
2023-07-10 22:15:34,292 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 22:15:34,292 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:41	wrong_total:96	 wrong be tree ACC: 0.4270833333333333
2023-07-10 22:15:34,292 - temp:20	temp1:8	wrong_total:96	
2023-07-10 22:15:34,294 - save best refiner model to ./output/test/best_model
2023-07-10 22:15:34,536 - epoch:1,	loss:nan
2023-07-10 22:15:44,392 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:15:44,392 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:15:44,392 - temp:0	temp1:24	wrong_total:101	
2023-07-10 22:15:44,590 - epoch:2,	loss:41.05486798286438
2023-07-10 22:15:54,496 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-10 22:15:54,497 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:44	wrong_total:99	 wrong be tree ACC: 0.4444444444444444
2023-07-10 22:15:54,497 - temp:11	temp1:16	wrong_total:99	
2023-07-10 22:15:54,681 - epoch:3,	loss:nan
2023-07-10 22:16:04,595 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 22:16:04,595 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:41	wrong_total:96	 wrong be tree ACC: 0.4270833333333333
2023-07-10 22:16:04,595 - temp:21	temp1:22	wrong_total:96	
2023-07-10 22:16:04,780 - epoch:4,	loss:16.75230999290943
2023-07-10 22:16:14,727 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 22:16:14,727 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-10 22:16:14,728 - temp:25	temp1:18	wrong_total:94	
2023-07-10 22:16:14,729 - save best refiner model to ./output/test/best_model
2023-07-10 22:16:14,907 - epoch:5,	loss:nan
2023-07-10 22:16:24,646 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:16:24,646 - right_codes_count:323	total:433	Code ACC: 0.745958429561201	wrong_be_tree_count:29	wrong_total:92	 wrong be tree ACC: 0.31521739130434784
2023-07-10 22:16:24,646 - temp:46	temp1:17	wrong_total:92	
2023-07-10 22:16:24,647 - save best refiner model to ./output/test/best_model
2023-07-10 22:16:24,831 - epoch:6,	loss:nan
2023-07-10 22:16:34,649 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-10 22:16:34,649 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:37	wrong_total:93	 wrong be tree ACC: 0.3978494623655914
2023-07-10 22:16:34,649 - temp:52	temp1:12	wrong_total:93	
2023-07-10 22:16:34,833 - epoch:7,	loss:nan
2023-07-10 22:16:44,739 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-10 22:16:44,739 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:48	wrong_total:93	 wrong be tree ACC: 0.5161290322580645
2023-07-10 22:16:44,739 - temp:61	temp1:17	wrong_total:93	
2023-07-10 22:16:45,066 - epoch:8,	loss:nan
2023-07-10 22:16:55,003 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:16:55,003 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:50	wrong_total:92	 wrong be tree ACC: 0.5434782608695652
2023-07-10 22:16:55,003 - temp:55	temp1:13	wrong_total:92	
2023-07-10 22:16:55,202 - epoch:9,	loss:-13.743223030818626
2023-07-10 22:17:05,240 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:17:05,240 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:49	wrong_total:92	 wrong be tree ACC: 0.532608695652174
2023-07-10 22:17:05,240 - temp:52	temp1:14	wrong_total:92	
2023-07-10 22:17:05,420 - epoch:10,	loss:nan
2023-07-10 22:26:08,844 - 


2023-07-10 22:26:09,393 - get train data loader...
2023-07-10 22:26:09,674 - get dev data loader...
2023-07-10 22:26:09,801 - define model...
2023-07-10 22:26:13,851 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:32:26,395 - 


2023-07-10 22:32:26,848 - get train data loader...
2023-07-10 22:32:27,116 - get dev data loader...
2023-07-10 22:32:27,238 - define model...
2023-07-10 22:32:30,732 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:32:47,782 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-10 22:32:47,782 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:117	wrong_total:117	 wrong be tree ACC: 1.0
2023-07-10 22:32:47,782 - temp:108	temp1:2	wrong_total:117	
2023-07-10 22:32:47,784 - save best refiner model to ./output/test/best_model
2023-07-10 22:32:47,966 - epoch:0,	loss:13967.977954864502
2023-07-10 22:32:57,639 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-10 22:32:57,639 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-10 22:32:57,639 - temp:14	temp1:10	wrong_total:99	
2023-07-10 22:32:57,821 - epoch:1,	loss:12704.036937713623
2023-07-10 22:33:07,345 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:33:07,345 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:33:07,345 - temp:0	temp1:24	wrong_total:101	
2023-07-10 22:33:07,531 - epoch:2,	loss:8392.159362792969
2023-07-10 22:33:17,606 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:33:17,606 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:33:17,606 - temp:0	temp1:29	wrong_total:101	
2023-07-10 22:33:17,793 - epoch:3,	loss:4141.8582553863525
2023-07-10 22:33:27,387 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-10 22:33:27,387 - right_codes_count:318	total:433	Code ACC: 0.7344110854503464	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-10 22:33:27,387 - temp:20	temp1:25	wrong_total:97	
2023-07-10 22:33:27,390 - save best refiner model to ./output/test/best_model
2023-07-10 22:33:27,571 - epoch:4,	loss:3419.669179916382
2023-07-10 22:33:37,033 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:33:37,034 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-10 22:33:37,034 - temp:23	temp1:22	wrong_total:95	
2023-07-10 22:33:37,036 - save best refiner model to ./output/test/best_model
2023-07-10 22:33:37,217 - epoch:5,	loss:3014.243230819702
2023-07-10 22:33:46,738 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:33:46,738 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:30	wrong_total:92	 wrong be tree ACC: 0.32608695652173914
2023-07-10 22:33:46,738 - temp:46	temp1:20	wrong_total:92	
2023-07-10 22:33:46,740 - save best refiner model to ./output/test/best_model
2023-07-10 22:33:46,922 - epoch:6,	loss:2557.0850434303284
2023-07-10 22:33:56,436 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 22:33:56,436 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-10 22:33:56,436 - temp:52	temp1:16	wrong_total:94	
2023-07-10 22:33:56,616 - epoch:7,	loss:1973.9257912635803
2023-07-10 22:34:06,072 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-10 22:34:06,072 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-10 22:34:06,073 - temp:54	temp1:17	wrong_total:91	
2023-07-10 22:34:06,335 - epoch:8,	loss:1160.7293195724487
2023-07-10 22:34:15,781 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-10 22:34:15,781 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:45	wrong_total:90	 wrong be tree ACC: 0.5
2023-07-10 22:34:15,781 - temp:51	temp1:11	wrong_total:90	
2023-07-10 22:34:15,962 - epoch:9,	loss:-386.93117332458496
2023-07-10 22:34:25,559 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-10 22:34:25,559 - right_codes_count:323	total:433	Code ACC: 0.745958429561201	wrong_be_tree_count:45	wrong_total:90	 wrong be tree ACC: 0.5
2023-07-10 22:34:25,559 - temp:51	temp1:12	wrong_total:90	
2023-07-10 22:34:25,560 - save best refiner model to ./output/test/best_model
2023-07-10 22:34:25,761 - epoch:10,	loss:-3624.9679622650146
2023-07-10 22:34:35,510 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-10 22:34:35,510 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:46	wrong_total:89	 wrong be tree ACC: 0.5168539325842697
2023-07-10 22:34:35,510 - temp:59	temp1:11	wrong_total:89	
2023-07-10 22:34:35,697 - epoch:11,	loss:-11479.105375289917
2023-07-10 22:40:18,641 - 


2023-07-10 22:40:19,194 - get train data loader...
2023-07-10 22:40:19,471 - get dev data loader...
2023-07-10 22:40:19,602 - define model...
2023-07-10 22:40:23,328 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:43:27,857 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-10 22:43:27,858 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:117	wrong_total:117	 wrong be tree ACC: 1.0
2023-07-10 22:43:27,858 - temp:108	temp1:2	wrong_total:117	
2023-07-10 22:43:27,859 - save best refiner model to ./output/test/best_model
2023-07-10 22:43:28,049 - epoch:0,	loss:13967.977954864502
2023-07-10 22:43:44,792 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-10 22:43:44,792 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-10 22:43:44,792 - temp:14	temp1:10	wrong_total:99	
2023-07-10 22:43:44,975 - epoch:1,	loss:12704.036937713623
2023-07-10 22:43:59,149 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:43:59,149 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:43:59,149 - temp:0	temp1:24	wrong_total:101	
2023-07-10 22:43:59,332 - epoch:2,	loss:8392.159362792969
2023-07-10 22:44:10,797 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:44:10,798 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:44:10,798 - temp:0	temp1:29	wrong_total:101	
2023-07-10 22:44:10,979 - epoch:3,	loss:4141.8582553863525
2023-07-10 22:44:23,576 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-10 22:44:23,576 - right_codes_count:318	total:433	Code ACC: 0.7344110854503464	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-10 22:44:23,576 - temp:20	temp1:25	wrong_total:97	
2023-07-10 22:44:23,578 - save best refiner model to ./output/test/best_model
2023-07-10 22:44:23,763 - epoch:4,	loss:3419.669179916382
2023-07-10 22:44:35,022 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:44:35,022 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-10 22:44:35,022 - temp:23	temp1:22	wrong_total:95	
2023-07-10 22:44:35,024 - save best refiner model to ./output/test/best_model
2023-07-10 22:44:35,203 - epoch:5,	loss:3014.243230819702
2023-07-10 22:44:46,966 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:44:46,967 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:30	wrong_total:92	 wrong be tree ACC: 0.32608695652173914
2023-07-10 22:44:46,967 - temp:46	temp1:20	wrong_total:92	
2023-07-10 22:44:46,968 - save best refiner model to ./output/test/best_model
2023-07-10 22:44:47,146 - epoch:6,	loss:2557.0850434303284
2023-07-10 22:45:02,556 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 22:45:02,557 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-10 22:45:02,557 - temp:52	temp1:16	wrong_total:94	
2023-07-10 22:45:02,747 - epoch:7,	loss:1973.9257912635803
2023-07-10 22:45:13,732 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-10 22:45:13,732 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-10 22:45:13,732 - temp:54	temp1:17	wrong_total:91	
2023-07-10 22:45:13,923 - epoch:8,	loss:1160.7293195724487
2023-07-10 22:45:34,143 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-10 22:45:34,144 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:45	wrong_total:90	 wrong be tree ACC: 0.5
2023-07-10 22:45:34,144 - temp:51	temp1:11	wrong_total:90	
2023-07-10 22:45:34,325 - epoch:9,	loss:-386.93117332458496
2023-07-10 22:48:08,767 - 


2023-07-10 22:48:09,292 - get train data loader...
2023-07-10 22:48:09,564 - get dev data loader...
2023-07-10 22:48:09,716 - define model...
2023-07-10 22:48:13,659 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:48:36,474 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-10 22:48:36,475 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:117	wrong_total:117	 wrong be tree ACC: 1.0
2023-07-10 22:48:36,475 - temp:108	temp1:2	wrong_total:117	
2023-07-10 22:48:36,476 - save best refiner model to ./output/test/best_model
2023-07-10 22:48:36,664 - epoch:0,	loss:13967.977954864502
2023-07-10 22:48:46,451 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-10 22:48:46,451 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-10 22:48:46,451 - temp:14	temp1:10	wrong_total:99	
2023-07-10 22:48:46,639 - epoch:1,	loss:12704.036937713623
2023-07-10 22:48:56,405 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:48:56,405 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:48:56,405 - temp:0	temp1:24	wrong_total:101	
2023-07-10 22:48:56,587 - epoch:2,	loss:8392.159362792969
2023-07-10 22:49:06,490 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-10 22:49:06,490 - right_codes_count:316	total:433	Code ACC: 0.7297921478060047	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-10 22:49:06,490 - temp:0	temp1:29	wrong_total:101	
2023-07-10 22:49:06,674 - epoch:3,	loss:4141.8582553863525
2023-07-10 22:49:16,531 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-10 22:49:16,531 - right_codes_count:318	total:433	Code ACC: 0.7344110854503464	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-10 22:49:16,532 - temp:20	temp1:25	wrong_total:97	
2023-07-10 22:49:16,533 - save best refiner model to ./output/test/best_model
2023-07-10 22:49:16,715 - epoch:4,	loss:3419.669179916382
2023-07-10 22:49:26,457 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:49:26,457 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-10 22:49:26,457 - temp:23	temp1:22	wrong_total:95	
2023-07-10 22:49:26,460 - save best refiner model to ./output/test/best_model
2023-07-10 22:49:26,641 - epoch:5,	loss:3014.243230819702
2023-07-10 22:49:36,698 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:49:36,698 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:30	wrong_total:92	 wrong be tree ACC: 0.32608695652173914
2023-07-10 22:49:36,698 - temp:46	temp1:20	wrong_total:92	
2023-07-10 22:49:36,700 - save best refiner model to ./output/test/best_model
2023-07-10 22:49:36,952 - epoch:6,	loss:2557.0850434303284
2023-07-10 22:49:46,840 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 22:49:46,840 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:36	wrong_total:94	 wrong be tree ACC: 0.3829787234042553
2023-07-10 22:49:46,840 - temp:52	temp1:16	wrong_total:94	
2023-07-10 22:49:47,026 - epoch:7,	loss:1973.9257912635803
2023-07-10 22:49:56,880 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-10 22:49:56,880 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-10 22:49:56,880 - temp:54	temp1:17	wrong_total:91	
2023-07-10 22:49:57,065 - epoch:8,	loss:1160.7293195724487
2023-07-10 22:50:06,958 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-10 22:50:06,959 - right_codes_count:322	total:433	Code ACC: 0.74364896073903	wrong_be_tree_count:45	wrong_total:90	 wrong be tree ACC: 0.5
2023-07-10 22:50:06,959 - temp:51	temp1:11	wrong_total:90	
2023-07-10 22:50:07,141 - epoch:9,	loss:-386.93117332458496
2023-07-10 22:50:17,000 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-10 22:50:17,001 - right_codes_count:323	total:433	Code ACC: 0.745958429561201	wrong_be_tree_count:45	wrong_total:90	 wrong be tree ACC: 0.5
2023-07-10 22:50:17,001 - temp:51	temp1:12	wrong_total:90	
2023-07-10 22:50:17,002 - save best refiner model to ./output/test/best_model
2023-07-10 22:50:17,183 - epoch:10,	loss:-3624.9679622650146
2023-07-10 22:50:27,172 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-10 22:50:27,173 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:46	wrong_total:89	 wrong be tree ACC: 0.5168539325842697
2023-07-10 22:50:27,173 - temp:59	temp1:11	wrong_total:89	
2023-07-10 22:50:27,355 - epoch:11,	loss:-11479.105375289917
2023-07-10 22:50:37,262 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-10 22:50:37,262 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:45	wrong_total:91	 wrong be tree ACC: 0.4945054945054945
2023-07-10 22:50:37,262 - temp:61	temp1:14	wrong_total:91	
2023-07-10 22:50:37,448 - epoch:12,	loss:-29910.35145163536
2023-07-10 22:50:47,392 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 22:50:47,392 - right_codes_count:321	total:433	Code ACC: 0.7413394919168591	wrong_be_tree_count:51	wrong_total:92	 wrong be tree ACC: 0.5543478260869565
2023-07-10 22:50:47,392 - temp:60	temp1:13	wrong_total:92	
2023-07-10 22:50:47,575 - epoch:13,	loss:-68713.69124126434
2023-07-10 22:50:57,509 - right_count:329	total:433	 Answer ACC: 0.7598152424942263
2023-07-10 22:50:57,509 - right_codes_count:320	total:433	Code ACC: 0.7390300230946882	wrong_be_tree_count:73	wrong_total:104	 wrong be tree ACC: 0.7019230769230769
2023-07-10 22:50:57,509 - temp:73	temp1:11	wrong_total:104	
2023-07-10 22:50:57,691 - epoch:14,	loss:-135628.74040603638
2023-07-10 22:54:20,837 - 


2023-07-10 22:54:21,303 - get train data loader...
2023-07-10 22:57:00,034 - 


2023-07-10 22:57:00,587 - get train data loader...
2023-07-10 22:57:00,988 - get dev data loader...
2023-07-10 22:57:01,141 - define model...
2023-07-10 22:57:05,086 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-10 22:57:17,264 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-10 22:57:17,264 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-10 22:57:17,265 - temp:101	temp1:0	wrong_total:107	
2023-07-10 22:57:17,267 - save best refiner model to ./output/test/best_model
2023-07-10 22:57:17,451 - epoch:0,	loss:11014.301326751709
2023-07-10 22:57:27,498 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:57:27,498 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:57:27,498 - temp:0	temp1:9	wrong_total:100	
2023-07-10 22:57:27,684 - epoch:1,	loss:10023.77460861206
2023-07-10 22:57:37,717 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:57:37,717 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:57:37,718 - temp:0	temp1:17	wrong_total:100	
2023-07-10 22:57:37,908 - epoch:2,	loss:6520.125118255615
2023-07-10 22:57:48,002 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:57:48,002 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:57:48,002 - temp:0	temp1:12	wrong_total:100	
2023-07-10 22:57:48,188 - epoch:3,	loss:3117.2703495025635
2023-07-10 22:57:58,262 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:57:58,262 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:57:58,262 - temp:0	temp1:19	wrong_total:100	
2023-07-10 22:57:58,446 - epoch:4,	loss:2669.9500164985657
2023-07-10 22:58:08,498 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:58:08,498 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:58:08,498 - temp:0	temp1:15	wrong_total:100	
2023-07-10 22:58:08,682 - epoch:5,	loss:2536.2154293060303
2023-07-10 22:58:18,643 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-10 22:58:18,644 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-10 22:58:18,644 - temp:0	temp1:15	wrong_total:100	
2023-07-10 22:58:18,830 - epoch:6,	loss:2421.5504627227783
2023-07-10 22:58:28,854 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-10 22:58:28,854 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:51	wrong_total:99	 wrong be tree ACC: 0.5151515151515151
2023-07-10 22:58:28,854 - temp:1	temp1:12	wrong_total:99	
2023-07-10 22:58:29,054 - epoch:7,	loss:2268.552360057831
2023-07-10 22:58:39,088 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 22:58:39,088 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
2023-07-10 22:58:39,088 - temp:42	temp1:30	wrong_total:96	
2023-07-10 22:58:39,091 - save best refiner model to ./output/test/best_model
2023-07-10 22:58:39,375 - epoch:8,	loss:2078.901617050171
2023-07-10 22:58:49,694 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:58:49,694 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:29	wrong_total:95	 wrong be tree ACC: 0.30526315789473685
2023-07-10 22:58:49,694 - temp:51	temp1:29	wrong_total:95	
2023-07-10 22:58:49,696 - save best refiner model to ./output/test/best_model
2023-07-10 22:58:49,882 - epoch:9,	loss:1883.9870772361755
2023-07-10 22:59:01,161 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:59:01,162 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:33	wrong_total:95	 wrong be tree ACC: 0.3473684210526316
2023-07-10 22:59:01,162 - temp:58	temp1:31	wrong_total:95	
2023-07-10 22:59:01,344 - epoch:10,	loss:1719.1484174728394
2023-07-10 22:59:16,481 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 22:59:16,481 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:34	wrong_total:94	 wrong be tree ACC: 0.3617021276595745
2023-07-10 22:59:16,481 - temp:64	temp1:37	wrong_total:94	
2023-07-10 22:59:16,484 - save best refiner model to ./output/test/best_model
2023-07-10 22:59:16,691 - epoch:11,	loss:1603.056390762329
2023-07-10 22:59:31,889 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 22:59:31,889 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-10 22:59:31,889 - temp:59	temp1:25	wrong_total:95	
2023-07-10 22:59:31,892 - save best refiner model to ./output/test/best_model
2023-07-10 22:59:32,075 - epoch:12,	loss:1515.1619235277176
2023-07-10 22:59:47,155 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 22:59:47,155 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:34	wrong_total:96	 wrong be tree ACC: 0.3541666666666667
2023-07-10 22:59:47,155 - temp:65	temp1:19	wrong_total:96	
2023-07-10 22:59:47,350 - epoch:13,	loss:1466.5394723415375
2023-07-10 23:00:02,650 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 23:00:02,651 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:43	wrong_total:95	 wrong be tree ACC: 0.45263157894736844
2023-07-10 23:00:02,651 - temp:63	temp1:30	wrong_total:95	
2023-07-10 23:00:02,846 - epoch:14,	loss:1432.7515001296997
2023-07-10 23:00:17,903 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-10 23:00:17,903 - right_codes_count:339	total:433	Code ACC: 0.7829099307159353	wrong_be_tree_count:40	wrong_total:93	 wrong be tree ACC: 0.43010752688172044
2023-07-10 23:00:17,903 - temp:63	temp1:17	wrong_total:93	
2023-07-10 23:00:17,906 - save best refiner model to ./output/test/best_model
2023-07-10 23:00:18,089 - epoch:15,	loss:1383.904574394226
2023-07-10 23:00:33,157 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 23:00:33,158 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-10 23:00:33,158 - temp:64	temp1:15	wrong_total:95	
2023-07-10 23:00:33,340 - epoch:16,	loss:1368.235543012619
2023-07-10 23:00:48,508 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 23:00:48,508 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-10 23:00:48,509 - temp:66	temp1:18	wrong_total:94	
2023-07-10 23:00:48,695 - epoch:17,	loss:1328.2531390190125
2023-07-10 23:01:03,767 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 23:01:03,767 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:96	 wrong be tree ACC: 0.4166666666666667
2023-07-10 23:01:03,767 - temp:64	temp1:22	wrong_total:96	
2023-07-10 23:01:03,949 - epoch:18,	loss:1298.9381363391876
2023-07-10 23:01:19,115 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-10 23:01:19,115 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:36	wrong_total:95	 wrong be tree ACC: 0.37894736842105264
2023-07-10 23:01:19,115 - temp:62	temp1:18	wrong_total:95	
2023-07-10 23:01:19,299 - epoch:19,	loss:1289.640280008316
2023-07-10 23:01:34,432 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 23:01:34,432 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:34	wrong_total:92	 wrong be tree ACC: 0.3695652173913043
2023-07-10 23:01:34,432 - temp:62	temp1:15	wrong_total:92	
2023-07-10 23:01:34,630 - epoch:20,	loss:1269.1712801456451
2023-07-10 23:01:49,711 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-10 23:01:49,711 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:36	wrong_total:92	 wrong be tree ACC: 0.391304347826087
2023-07-10 23:01:49,711 - temp:63	temp1:19	wrong_total:92	
2023-07-10 23:01:49,894 - epoch:21,	loss:1260.2106275558472
2023-07-10 23:02:05,237 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-10 23:02:05,238 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:41	wrong_total:97	 wrong be tree ACC: 0.422680412371134
2023-07-10 23:02:05,238 - temp:61	temp1:20	wrong_total:97	
2023-07-10 23:02:05,432 - epoch:22,	loss:1266.9761409759521
2023-07-10 23:02:20,344 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 23:02:20,345 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:38	wrong_total:96	 wrong be tree ACC: 0.3958333333333333
2023-07-10 23:02:20,345 - temp:62	temp1:24	wrong_total:96	
2023-07-10 23:02:20,531 - epoch:23,	loss:1241.1167500019073
2023-07-10 23:02:35,529 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 23:02:35,530 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:36	wrong_total:96	 wrong be tree ACC: 0.375
2023-07-10 23:02:35,530 - temp:59	temp1:20	wrong_total:96	
2023-07-10 23:02:35,713 - epoch:24,	loss:1215.0374138355255
2023-07-10 23:02:50,628 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-10 23:02:50,628 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:38	wrong_total:93	 wrong be tree ACC: 0.40860215053763443
2023-07-10 23:02:50,628 - temp:67	temp1:15	wrong_total:93	
2023-07-10 23:02:50,809 - epoch:25,	loss:1205.3718135356903
2023-07-10 23:03:06,162 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-10 23:03:06,162 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-10 23:03:06,162 - temp:45	temp1:12	wrong_total:96	
2023-07-10 23:03:06,342 - epoch:26,	loss:1198.5544216632843
2023-07-10 23:03:26,263 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-10 23:03:26,264 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:94	 wrong be tree ACC: 0.425531914893617
2023-07-10 23:03:26,264 - temp:66	temp1:20	wrong_total:94	
2023-07-10 23:03:26,447 - epoch:27,	loss:1179.2293229103088
2023-07-11 10:07:49,817 - 


2023-07-11 10:07:50,894 - get train data loader...
2023-07-11 10:07:51,193 - get dev data loader...
2023-07-11 10:07:51,350 - define model...
2023-07-11 10:07:55,410 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 10:08:11,034 - save best refiner model to ./output/test/best_model
2023-07-11 10:08:11,218 - epoch:0,	loss:12335.412826538086
2023-07-11 10:08:24,755 - epoch:1,	loss:11731.926147460938
2023-07-11 10:08:38,221 - epoch:2,	loss:10478.279243469238
2023-07-11 10:08:51,433 - save best refiner model to ./output/test/best_model
2023-07-11 10:08:51,613 - epoch:3,	loss:8172.95768737793
2023-07-11 10:09:05,102 - epoch:4,	loss:4965.716630935669
2023-07-11 10:09:17,554 - epoch:5,	loss:2584.7486610412598
2023-07-11 10:09:30,222 - epoch:6,	loss:1576.0205192565918
2023-07-11 10:09:43,696 - epoch:7,	loss:1245.2414963245392
2023-07-11 10:13:08,520 - 


2023-07-11 10:13:09,446 - get train data loader...
2023-07-11 10:13:09,753 - get dev data loader...
2023-07-11 10:13:09,901 - define model...
2023-07-11 10:13:13,970 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 10:13:29,266 - save best refiner model to ./output/test/best_model
2023-07-11 10:13:29,465 - epoch:0,	loss:68.58419120311737
2023-07-11 10:13:43,020 - epoch:1,	loss:65.20344853401184
2023-07-11 10:13:56,575 - epoch:2,	loss:58.13212847709656
2023-07-11 10:14:09,957 - save best refiner model to ./output/test/best_model
2023-07-11 10:14:10,141 - epoch:3,	loss:44.55914378166199
2023-07-11 10:14:23,662 - epoch:4,	loss:26.32967746257782
2023-07-11 10:14:36,067 - epoch:5,	loss:13.61569307744503
2023-07-11 10:22:38,907 - 


2023-07-11 10:22:39,549 - get train data loader...
2023-07-11 10:22:39,847 - get dev data loader...
2023-07-11 10:22:39,981 - define model...
2023-07-11 10:22:44,269 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 10:23:00,372 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 10:23:00,372 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-11 10:23:00,372 - temp:102	temp1:1	wrong_total:107	
2023-07-11 10:23:00,375 - save best refiner model to ./output/test/best_model
2023-07-11 10:23:00,559 - epoch:0,	loss:nan
2023-07-11 10:23:14,697 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:23:14,697 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:23:14,697 - temp:0	temp1:9	wrong_total:100	
2023-07-11 10:23:14,698 - save best refiner model to ./output/test/best_model
2023-07-11 10:23:14,884 - epoch:1,	loss:nan
2023-07-11 10:23:29,091 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:23:29,092 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:23:29,092 - temp:0	temp1:17	wrong_total:100	
2023-07-11 10:23:29,276 - epoch:2,	loss:17.160923898220062
2023-07-11 10:23:43,365 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:23:43,366 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:23:43,366 - temp:0	temp1:18	wrong_total:100	
2023-07-11 10:23:43,550 - epoch:3,	loss:nan
2023-07-11 10:23:57,231 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:23:57,231 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:23:57,231 - temp:0	temp1:20	wrong_total:100	
2023-07-11 10:23:57,414 - epoch:4,	loss:7.35646116733551
2023-07-11 10:24:10,246 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:24:10,246 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:24:10,247 - temp:0	temp1:12	wrong_total:100	
2023-07-11 10:24:10,430 - epoch:5,	loss:nan
2023-07-11 10:24:24,795 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:24:24,796 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:24:24,796 - temp:0	temp1:15	wrong_total:100	
2023-07-11 10:24:24,986 - epoch:6,	loss:nan
2023-07-11 10:24:39,040 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:24:39,040 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 10:24:39,040 - temp:0	temp1:17	wrong_total:100	
2023-07-11 10:24:39,223 - epoch:7,	loss:nan
2023-07-11 10:24:53,626 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:24:53,626 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:29	wrong_total:96	 wrong be tree ACC: 0.3020833333333333
2023-07-11 10:24:53,626 - temp:31	temp1:21	wrong_total:96	
2023-07-11 10:24:53,628 - save best refiner model to ./output/test/best_model
2023-07-11 10:24:53,919 - epoch:8,	loss:nan
2023-07-11 10:25:07,930 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:25:07,930 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:29	wrong_total:96	 wrong be tree ACC: 0.3020833333333333
2023-07-11 10:25:07,930 - temp:48	temp1:25	wrong_total:96	
2023-07-11 10:25:08,119 - epoch:9,	loss:nan
2023-07-11 10:25:22,251 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:25:22,252 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:27	wrong_total:95	 wrong be tree ACC: 0.28421052631578947
2023-07-11 10:25:22,252 - temp:37	temp1:19	wrong_total:95	
2023-07-11 10:25:22,253 - save best refiner model to ./output/test/best_model
2023-07-11 10:25:22,434 - epoch:10,	loss:nan
2023-07-11 10:26:22,508 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:26:22,508 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:36	wrong_total:95	 wrong be tree ACC: 0.37894736842105264
2023-07-11 10:26:22,508 - temp:63	temp1:23	wrong_total:95	
2023-07-11 10:26:22,691 - epoch:11,	loss:nan
2023-07-11 10:26:35,401 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 10:26:35,401 - right_codes_count:336	total:433	Code ACC: 0.7759815242494227	wrong_be_tree_count:32	wrong_total:92	 wrong be tree ACC: 0.34782608695652173
2023-07-11 10:26:35,401 - temp:60	temp1:25	wrong_total:92	
2023-07-11 10:26:35,403 - save best refiner model to ./output/test/best_model
2023-07-11 10:26:35,586 - epoch:12,	loss:nan
2023-07-11 10:26:49,697 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:26:49,697 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:34	wrong_total:96	 wrong be tree ACC: 0.3541666666666667
2023-07-11 10:26:49,697 - temp:71	temp1:23	wrong_total:96	
2023-07-11 10:26:49,881 - epoch:13,	loss:nan
2023-07-11 10:27:04,155 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:27:04,155 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-11 10:27:04,155 - temp:65	temp1:25	wrong_total:96	
2023-07-11 10:27:04,339 - epoch:14,	loss:nan
2023-07-11 10:27:18,545 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 10:27:18,545 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:38	wrong_total:93	 wrong be tree ACC: 0.40860215053763443
2023-07-11 10:27:18,545 - temp:62	temp1:24	wrong_total:93	
2023-07-11 10:27:18,729 - epoch:15,	loss:nan
2023-07-11 10:27:32,732 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:27:32,732 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-11 10:27:32,732 - temp:48	temp1:15	wrong_total:96	
2023-07-11 10:27:32,914 - epoch:16,	loss:3.8551650680601597
2023-07-11 10:27:47,000 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 10:27:47,000 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:36	wrong_total:91	 wrong be tree ACC: 0.3956043956043956
2023-07-11 10:27:47,000 - temp:58	temp1:19	wrong_total:91	
2023-07-11 10:27:47,002 - save best refiner model to ./output/test/best_model
2023-07-11 10:27:47,181 - epoch:17,	loss:nan
2023-07-11 10:28:00,322 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:28:00,322 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:37	wrong_total:95	 wrong be tree ACC: 0.3894736842105263
2023-07-11 10:28:00,322 - temp:58	temp1:20	wrong_total:95	
2023-07-11 10:28:00,511 - epoch:18,	loss:3.440525107085705
2023-07-11 10:28:14,187 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 10:28:14,187 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:34	wrong_total:92	 wrong be tree ACC: 0.3695652173913043
2023-07-11 10:28:14,188 - temp:62	temp1:20	wrong_total:92	
2023-07-11 10:28:14,377 - epoch:19,	loss:nan
2023-07-11 10:28:28,420 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:28:28,420 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:95	 wrong be tree ACC: 0.42105263157894735
2023-07-11 10:28:28,420 - temp:62	temp1:20	wrong_total:95	
2023-07-11 10:28:28,604 - epoch:20,	loss:3.44010092318058
2023-07-11 10:28:42,998 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:28:42,998 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:33	wrong_total:96	 wrong be tree ACC: 0.34375
2023-07-11 10:28:42,998 - temp:64	temp1:18	wrong_total:96	
2023-07-11 10:28:43,181 - epoch:21,	loss:nan
2023-07-11 10:28:57,159 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:28:57,159 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-11 10:28:57,159 - temp:62	temp1:26	wrong_total:96	
2023-07-11 10:28:57,340 - epoch:22,	loss:nan
2023-07-11 10:29:11,607 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 10:29:11,607 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-11 10:29:11,607 - temp:59	temp1:18	wrong_total:94	
2023-07-11 10:29:11,788 - epoch:23,	loss:nan
2023-07-11 10:29:24,884 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:29:24,884 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:41	wrong_total:96	 wrong be tree ACC: 0.4270833333333333
2023-07-11 10:29:24,885 - temp:66	temp1:20	wrong_total:96	
2023-07-11 10:29:25,066 - epoch:24,	loss:nan
2023-07-11 10:29:38,402 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:29:38,402 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-11 10:29:38,402 - temp:59	temp1:24	wrong_total:97	
2023-07-11 10:29:38,650 - epoch:25,	loss:nan
2023-07-11 10:29:53,012 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:29:53,012 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:45	wrong_total:97	 wrong be tree ACC: 0.4639175257731959
2023-07-11 10:29:53,012 - temp:58	temp1:15	wrong_total:97	
2023-07-11 10:29:53,196 - epoch:26,	loss:nan
2023-07-11 10:30:07,337 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 10:30:07,337 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:30	wrong_total:90	 wrong be tree ACC: 0.3333333333333333
2023-07-11 10:30:07,337 - temp:62	temp1:20	wrong_total:90	
2023-07-11 10:30:07,339 - save best refiner model to ./output/test/best_model
2023-07-11 10:30:07,526 - epoch:27,	loss:nan
2023-07-11 10:30:21,828 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 10:30:21,828 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-11 10:30:21,828 - temp:59	temp1:18	wrong_total:94	
2023-07-11 10:30:22,010 - epoch:28,	loss:nan
2023-07-11 10:30:36,009 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:30:36,009 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-11 10:30:36,010 - temp:55	temp1:17	wrong_total:98	
2023-07-11 10:30:36,194 - epoch:29,	loss:3.351328156888485
2023-07-11 10:30:49,714 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 10:30:49,714 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:36	wrong_total:92	 wrong be tree ACC: 0.391304347826087
2023-07-11 10:30:49,714 - temp:70	temp1:21	wrong_total:92	
2023-07-11 10:30:49,898 - epoch:30,	loss:3.172288905829191
2023-07-11 10:31:03,162 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 10:31:03,163 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
2023-07-11 10:31:03,163 - temp:60	temp1:21	wrong_total:91	
2023-07-11 10:31:03,348 - epoch:31,	loss:nan
2023-07-11 10:31:17,537 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:31:17,537 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:36	wrong_total:95	 wrong be tree ACC: 0.37894736842105264
2023-07-11 10:31:17,537 - temp:48	temp1:15	wrong_total:95	
2023-07-11 10:31:17,721 - epoch:32,	loss:nan
2023-07-11 10:31:31,937 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:31:31,937 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:40	wrong_total:96	 wrong be tree ACC: 0.4166666666666667
2023-07-11 10:31:31,937 - temp:52	temp1:14	wrong_total:96	
2023-07-11 10:31:32,124 - epoch:33,	loss:nan
2023-07-11 10:31:46,280 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 10:31:46,281 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:34	wrong_total:93	 wrong be tree ACC: 0.3655913978494624
2023-07-11 10:31:46,281 - temp:69	temp1:16	wrong_total:93	
2023-07-11 10:31:46,470 - epoch:34,	loss:nan
2023-07-11 10:32:00,600 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:32:00,601 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-11 10:32:00,601 - temp:60	temp1:28	wrong_total:95	
2023-07-11 10:32:00,783 - epoch:35,	loss:3.144852686673403
2023-07-11 10:32:14,594 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:32:14,594 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:43	wrong_total:97	 wrong be tree ACC: 0.44329896907216493
2023-07-11 10:32:14,594 - temp:61	temp1:25	wrong_total:97	
2023-07-11 10:32:14,780 - epoch:36,	loss:nan
2023-07-11 10:32:27,690 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:32:27,690 - right_codes_count:336	total:433	Code ACC: 0.7759815242494227	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-11 10:32:27,691 - temp:43	temp1:19	wrong_total:95	
2023-07-11 10:32:27,873 - epoch:37,	loss:nan
2023-07-11 10:32:41,869 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:32:41,870 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:98	 wrong be tree ACC: 0.40816326530612246
2023-07-11 10:32:41,870 - temp:61	temp1:28	wrong_total:98	
2023-07-11 10:32:42,054 - epoch:38,	loss:nan
2023-07-11 10:32:56,377 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:32:56,377 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:35	wrong_total:97	 wrong be tree ACC: 0.36082474226804123
2023-07-11 10:32:56,377 - temp:60	temp1:19	wrong_total:97	
2023-07-11 10:32:56,560 - epoch:39,	loss:nan
2023-07-11 10:33:10,951 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:33:10,951 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:96	 wrong be tree ACC: 0.4166666666666667
2023-07-11 10:33:10,952 - temp:72	temp1:21	wrong_total:96	
2023-07-11 10:33:11,135 - epoch:40,	loss:nan
2023-07-11 10:33:24,990 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:33:24,990 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:43	wrong_total:96	 wrong be tree ACC: 0.4479166666666667
2023-07-11 10:33:24,990 - temp:65	temp1:31	wrong_total:96	
2023-07-11 10:33:25,177 - epoch:41,	loss:nan
2023-07-11 10:33:39,494 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:33:39,494 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:41	wrong_total:96	 wrong be tree ACC: 0.4270833333333333
2023-07-11 10:33:39,494 - temp:66	temp1:26	wrong_total:96	
2023-07-11 10:33:39,677 - epoch:42,	loss:nan
2023-07-11 10:33:52,504 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:33:52,505 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:43	wrong_total:98	 wrong be tree ACC: 0.4387755102040816
2023-07-11 10:33:52,505 - temp:64	temp1:24	wrong_total:98	
2023-07-11 10:33:52,754 - epoch:43,	loss:nan
2023-07-11 10:34:06,136 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:34:06,136 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-11 10:34:06,136 - temp:63	temp1:18	wrong_total:97	
2023-07-11 10:34:06,319 - epoch:44,	loss:nan
2023-07-11 10:34:20,422 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:34:20,422 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:41	wrong_total:96	 wrong be tree ACC: 0.4270833333333333
2023-07-11 10:34:20,422 - temp:61	temp1:28	wrong_total:96	
2023-07-11 10:34:20,609 - epoch:45,	loss:nan
2023-07-11 10:34:35,181 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 10:34:35,181 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-11 10:34:35,182 - temp:59	temp1:21	wrong_total:94	
2023-07-11 10:34:35,365 - epoch:46,	loss:nan
2023-07-11 10:34:49,471 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:34:49,471 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:38	wrong_total:95	 wrong be tree ACC: 0.4
2023-07-11 10:34:49,471 - temp:64	temp1:22	wrong_total:95	
2023-07-11 10:34:49,657 - epoch:47,	loss:nan
2023-07-11 10:35:03,971 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:35:03,972 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:45	wrong_total:98	 wrong be tree ACC: 0.45918367346938777
2023-07-11 10:35:03,972 - temp:45	temp1:20	wrong_total:98	
2023-07-11 10:35:04,158 - epoch:48,	loss:nan
2023-07-11 10:35:17,582 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:35:17,582 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:38	wrong_total:100	 wrong be tree ACC: 0.38
2023-07-11 10:35:17,582 - temp:68	temp1:27	wrong_total:100	
2023-07-11 10:35:17,765 - epoch:49,	loss:nan
2023-07-11 10:35:30,969 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:35:30,969 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:42	wrong_total:97	 wrong be tree ACC: 0.4329896907216495
2023-07-11 10:35:30,969 - temp:65	temp1:26	wrong_total:97	
2023-07-11 10:35:31,151 - epoch:50,	loss:nan
2023-07-11 10:35:45,104 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 10:35:45,104 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:37	wrong_total:93	 wrong be tree ACC: 0.3978494623655914
2023-07-11 10:35:45,104 - temp:60	temp1:26	wrong_total:93	
2023-07-11 10:35:45,286 - epoch:51,	loss:nan
2023-07-11 10:35:59,758 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 10:35:59,758 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:41	wrong_total:94	 wrong be tree ACC: 0.43617021276595747
2023-07-11 10:35:59,758 - temp:50	temp1:12	wrong_total:94	
2023-07-11 10:35:59,959 - epoch:52,	loss:2.8905610106885433
2023-07-11 10:36:14,042 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:36:14,042 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:38	wrong_total:97	 wrong be tree ACC: 0.3917525773195876
2023-07-11 10:36:14,042 - temp:59	temp1:22	wrong_total:97	
2023-07-11 10:36:14,225 - epoch:53,	loss:2.8417993616312742
2023-07-11 10:36:28,301 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 10:36:28,301 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-11 10:36:28,301 - temp:48	temp1:17	wrong_total:96	
2023-07-11 10:36:28,485 - epoch:54,	loss:nan
2023-07-11 10:36:42,191 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:36:42,191 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:42	wrong_total:99	 wrong be tree ACC: 0.42424242424242425
2023-07-11 10:36:42,191 - temp:51	temp1:11	wrong_total:99	
2023-07-11 10:36:42,374 - epoch:55,	loss:nan
2023-07-11 10:36:55,308 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:36:55,309 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
2023-07-11 10:36:55,309 - temp:66	temp1:23	wrong_total:99	
2023-07-11 10:36:55,492 - epoch:56,	loss:nan
2023-07-11 10:37:09,560 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 10:37:09,560 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:43	wrong_total:97	 wrong be tree ACC: 0.44329896907216493
2023-07-11 10:37:09,560 - temp:66	temp1:29	wrong_total:97	
2023-07-11 10:37:09,743 - epoch:57,	loss:nan
2023-07-11 10:37:23,879 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:37:23,879 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:41	wrong_total:98	 wrong be tree ACC: 0.41836734693877553
2023-07-11 10:37:23,879 - temp:52	temp1:15	wrong_total:98	
2023-07-11 10:37:24,062 - epoch:58,	loss:2.582101659849286
2023-07-11 10:37:38,179 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:37:38,179 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:44	wrong_total:95	 wrong be tree ACC: 0.4631578947368421
2023-07-11 10:37:38,179 - temp:66	temp1:19	wrong_total:95	
2023-07-11 10:37:38,365 - epoch:59,	loss:nan
2023-07-11 10:37:52,833 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:37:52,833 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:40	wrong_total:99	 wrong be tree ACC: 0.40404040404040403
2023-07-11 10:37:52,833 - temp:66	temp1:23	wrong_total:99	
2023-07-11 10:37:53,015 - epoch:60,	loss:nan
2023-07-11 10:38:07,061 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:38:07,061 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:39	wrong_total:100	 wrong be tree ACC: 0.39
2023-07-11 10:38:07,061 - temp:55	temp1:14	wrong_total:100	
2023-07-11 10:38:07,307 - epoch:61,	loss:nan
2023-07-11 10:38:20,373 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:38:20,373 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:44	wrong_total:95	 wrong be tree ACC: 0.4631578947368421
2023-07-11 10:38:20,373 - temp:67	temp1:12	wrong_total:95	
2023-07-11 10:38:20,557 - epoch:62,	loss:nan
2023-07-11 10:38:34,170 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:38:34,170 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:41	wrong_total:99	 wrong be tree ACC: 0.41414141414141414
2023-07-11 10:38:34,170 - temp:49	temp1:16	wrong_total:99	
2023-07-11 10:38:34,354 - epoch:63,	loss:nan
2023-07-11 10:38:48,451 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 10:38:48,451 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:40	wrong_total:93	 wrong be tree ACC: 0.43010752688172044
2023-07-11 10:38:48,451 - temp:62	temp1:18	wrong_total:93	
2023-07-11 10:38:48,632 - epoch:64,	loss:nan
2023-07-11 10:39:02,825 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-11 10:39:02,825 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:53	wrong_total:101	 wrong be tree ACC: 0.5247524752475248
2023-07-11 10:39:02,825 - temp:51	temp1:15	wrong_total:101	
2023-07-11 10:39:03,009 - epoch:65,	loss:nan
2023-07-11 10:39:17,236 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:39:17,236 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:46	wrong_total:98	 wrong be tree ACC: 0.46938775510204084
2023-07-11 10:39:17,236 - temp:50	temp1:17	wrong_total:98	
2023-07-11 10:39:17,421 - epoch:66,	loss:nan
2023-07-11 10:39:31,538 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:39:31,539 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:53	wrong_total:100	 wrong be tree ACC: 0.53
2023-07-11 10:39:31,539 - temp:51	temp1:15	wrong_total:100	
2023-07-11 10:39:31,725 - epoch:67,	loss:nan
2023-07-11 10:39:45,034 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:39:45,034 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:44	wrong_total:98	 wrong be tree ACC: 0.4489795918367347
2023-07-11 10:39:45,034 - temp:66	temp1:16	wrong_total:98	
2023-07-11 10:39:45,221 - epoch:68,	loss:nan
2023-07-11 10:39:58,595 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 10:39:58,595 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:60	wrong_total:100	 wrong be tree ACC: 0.6
2023-07-11 10:39:58,595 - temp:63	temp1:19	wrong_total:100	
2023-07-11 10:39:58,779 - epoch:69,	loss:nan
2023-07-11 10:40:12,923 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 10:40:12,923 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:58	wrong_total:98	 wrong be tree ACC: 0.5918367346938775
2023-07-11 10:40:12,923 - temp:69	temp1:23	wrong_total:98	
2023-07-11 10:40:13,108 - epoch:70,	loss:nan
2023-07-11 10:40:27,510 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:40:27,510 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:58	wrong_total:99	 wrong be tree ACC: 0.5858585858585859
2023-07-11 10:40:27,510 - temp:70	temp1:26	wrong_total:99	
2023-07-11 10:40:27,698 - epoch:71,	loss:nan
2023-07-11 10:40:41,744 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 10:40:41,744 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:42	wrong_total:95	 wrong be tree ACC: 0.4421052631578947
2023-07-11 10:40:41,745 - temp:66	temp1:21	wrong_total:95	
2023-07-11 10:40:41,928 - epoch:72,	loss:nan
2023-07-11 10:40:56,197 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-11 10:40:56,198 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:57	wrong_total:99	 wrong be tree ACC: 0.5757575757575758
2023-07-11 10:40:56,198 - temp:57	temp1:20	wrong_total:99	
2023-07-11 10:40:56,381 - epoch:73,	loss:nan
2023-07-11 10:41:09,924 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-11 10:41:09,924 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:54	wrong_total:101	 wrong be tree ACC: 0.5346534653465347
2023-07-11 10:41:09,924 - temp:52	temp1:16	wrong_total:101	
2023-07-11 10:41:10,106 - epoch:74,	loss:nan
2023-07-11 10:41:10,106 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 10:41:10,106 - 


2023-07-11 10:41:10,106 - final_test
2023-07-11 10:41:17,256 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-11 10:41:17,257 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-11 10:41:17,257 - temp:73	temp1:34	wrong_total:86	
2023-07-11 10:51:46,635 - 


2023-07-11 10:51:47,108 - get train data loader...
2023-07-11 10:51:47,431 - get dev data loader...
2023-07-11 10:51:47,563 - define model...
2023-07-11 10:58:33,541 - 


2023-07-11 10:58:34,564 - get train data loader...
2023-07-11 10:58:34,872 - get dev data loader...
2023-07-11 10:58:35,022 - define model...
2023-07-11 11:01:24,436 - 


2023-07-11 11:01:24,909 - get train data loader...
2023-07-11 11:01:25,217 - get dev data loader...
2023-07-11 11:01:25,412 - define model...
2023-07-11 11:03:03,978 - 


2023-07-11 11:03:04,432 - get train data loader...
2023-07-11 11:03:04,745 - get dev data loader...
2023-07-11 11:03:04,884 - define model...
2023-07-11 11:05:19,629 - 


2023-07-11 11:05:20,068 - get train data loader...
2023-07-11 11:05:20,178 - get dev data loader...
2023-07-11 11:05:20,255 - define model...
2023-07-11 11:12:19,464 - 


2023-07-11 11:12:20,041 - get train data loader...
2023-07-11 11:12:20,345 - get dev data loader...
2023-07-11 11:12:20,486 - define model...
2023-07-11 11:12:28,601 - 


2023-07-11 11:12:29,042 - get train data loader...
2023-07-11 11:12:29,149 - get dev data loader...
2023-07-11 11:12:29,216 - define model...
2023-07-11 11:18:02,374 - 


2023-07-11 11:18:02,859 - get train data loader...
2023-07-11 11:18:03,035 - get dev data loader...
2023-07-11 11:18:03,189 - define model...
2023-07-11 14:12:18,779 - 


2023-07-11 14:12:19,391 - get train data loader...
2023-07-11 14:12:19,720 - get dev data loader...
2023-07-11 14:12:19,859 - define model...
2023-07-11 14:12:23,531 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:12:37,351 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:12:37,351 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-11 14:12:37,351 - temp:99	temp1:3	wrong_total:107	
2023-07-11 14:12:37,353 - save best refiner model to ./output/test/best_model
2023-07-11 14:12:37,535 - epoch:0,	loss:nan
2023-07-11 14:12:48,965 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-11 14:12:48,965 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:51	wrong_total:101	 wrong be tree ACC: 0.504950495049505
2023-07-11 14:12:48,965 - temp:12	temp1:13	wrong_total:101	
2023-07-11 14:12:48,966 - save best refiner model to ./output/test/best_model
2023-07-11 14:12:49,147 - epoch:1,	loss:nan
2023-07-11 14:13:00,055 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:13:00,056 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:13:00,056 - temp:0	temp1:26	wrong_total:100	
2023-07-11 14:13:00,057 - save best refiner model to ./output/test/best_model
2023-07-11 14:13:00,238 - epoch:2,	loss:19.805843144655228
2023-07-11 14:13:11,078 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:13:11,078 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:13:11,078 - temp:0	temp1:30	wrong_total:100	
2023-07-11 14:13:11,272 - epoch:3,	loss:nan
2023-07-11 14:13:23,041 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:13:23,041 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:13:23,041 - temp:0	temp1:21	wrong_total:100	
2023-07-11 14:13:23,225 - epoch:4,	loss:8.526658177375793
2023-07-11 14:13:35,021 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:13:35,021 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:13:35,021 - temp:0	temp1:18	wrong_total:100	
2023-07-11 14:13:35,208 - epoch:5,	loss:nan
2023-07-11 14:13:47,060 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 14:13:47,060 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:46	wrong_total:98	 wrong be tree ACC: 0.46938775510204084
2023-07-11 14:13:47,060 - temp:10	temp1:26	wrong_total:98	
2023-07-11 14:13:47,061 - save best refiner model to ./output/test/best_model
2023-07-11 14:13:47,246 - epoch:6,	loss:nan
2023-07-11 14:13:59,079 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 14:13:59,080 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:44	wrong_total:98	 wrong be tree ACC: 0.4489795918367347
2023-07-11 14:13:59,080 - temp:31	temp1:26	wrong_total:98	
2023-07-11 14:13:59,321 - epoch:7,	loss:nan
2023-07-11 14:14:10,998 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:14:10,998 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:35	wrong_total:97	 wrong be tree ACC: 0.36082474226804123
2023-07-11 14:14:10,998 - temp:33	temp1:28	wrong_total:97	
2023-07-11 14:14:11,000 - save best refiner model to ./output/test/best_model
2023-07-11 14:14:11,245 - epoch:8,	loss:nan
2023-07-11 14:14:23,181 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:14:23,181 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:32	wrong_total:95	 wrong be tree ACC: 0.3368421052631579
2023-07-11 14:14:23,181 - temp:43	temp1:33	wrong_total:95	
2023-07-11 14:14:23,182 - save best refiner model to ./output/test/best_model
2023-07-11 14:14:23,375 - epoch:9,	loss:nan
2023-07-11 14:14:35,410 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:14:35,410 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:30	wrong_total:95	 wrong be tree ACC: 0.3157894736842105
2023-07-11 14:14:35,410 - temp:52	temp1:33	wrong_total:95	
2023-07-11 14:14:35,598 - epoch:10,	loss:nan
2023-07-11 14:14:47,387 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:14:47,387 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:30	wrong_total:95	 wrong be tree ACC: 0.3157894736842105
2023-07-11 14:14:47,387 - temp:50	temp1:30	wrong_total:95	
2023-07-11 14:14:47,571 - epoch:11,	loss:nan
2023-07-11 14:14:58,692 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:14:58,692 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:30	wrong_total:94	 wrong be tree ACC: 0.3191489361702128
2023-07-11 14:14:58,692 - temp:53	temp1:35	wrong_total:94	
2023-07-11 14:14:58,694 - save best refiner model to ./output/test/best_model
2023-07-11 14:14:58,919 - epoch:12,	loss:nan
2023-07-11 14:15:09,825 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:15:09,826 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:33	wrong_total:93	 wrong be tree ACC: 0.3548387096774194
2023-07-11 14:15:09,826 - temp:57	temp1:35	wrong_total:93	
2023-07-11 14:15:09,827 - save best refiner model to ./output/test/best_model
2023-07-11 14:15:10,007 - epoch:13,	loss:nan
2023-07-11 14:15:21,365 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 14:15:21,366 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-11 14:15:21,366 - temp:54	temp1:35	wrong_total:96	
2023-07-11 14:15:21,550 - epoch:14,	loss:nan
2023-07-11 14:15:33,898 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:15:33,898 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:40	wrong_total:94	 wrong be tree ACC: 0.425531914893617
2023-07-11 14:15:33,898 - temp:60	temp1:31	wrong_total:94	
2023-07-11 14:15:34,080 - epoch:15,	loss:nan
2023-07-11 14:15:46,390 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:15:46,390 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:33	wrong_total:92	 wrong be tree ACC: 0.358695652173913
2023-07-11 14:15:46,390 - temp:53	temp1:22	wrong_total:92	
2023-07-11 14:15:46,391 - save best refiner model to ./output/test/best_model
2023-07-11 14:15:46,581 - epoch:16,	loss:3.417057391256094
2023-07-11 14:15:57,908 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:15:57,909 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:38	wrong_total:93	 wrong be tree ACC: 0.40860215053763443
2023-07-11 14:15:57,909 - temp:56	temp1:32	wrong_total:93	
2023-07-11 14:15:58,093 - epoch:17,	loss:nan
2023-07-11 14:16:09,929 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:16:09,929 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-11 14:16:09,929 - temp:63	temp1:38	wrong_total:94	
2023-07-11 14:16:10,113 - epoch:18,	loss:2.9961921758949757
2023-07-11 14:16:21,780 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:16:21,780 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:42	wrong_total:92	 wrong be tree ACC: 0.45652173913043476
2023-07-11 14:16:21,780 - temp:64	temp1:31	wrong_total:92	
2023-07-11 14:16:21,964 - epoch:19,	loss:nan
2023-07-11 14:16:34,251 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:16:34,251 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:42	wrong_total:95	 wrong be tree ACC: 0.4421052631578947
2023-07-11 14:16:34,251 - temp:63	temp1:31	wrong_total:95	
2023-07-11 14:16:34,433 - epoch:20,	loss:2.867695491760969
2023-07-11 14:16:46,275 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:16:46,275 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:47	wrong_total:91	 wrong be tree ACC: 0.5164835164835165
2023-07-11 14:16:46,275 - temp:57	temp1:34	wrong_total:91	
2023-07-11 14:16:46,277 - save best refiner model to ./output/test/best_model
2023-07-11 14:16:46,459 - epoch:21,	loss:nan
2023-07-11 14:16:57,481 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:16:57,481 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-11 14:16:57,481 - temp:57	temp1:25	wrong_total:94	
2023-07-11 14:16:57,668 - epoch:22,	loss:nan
2023-07-11 14:17:08,437 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:17:08,437 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:44	wrong_total:92	 wrong be tree ACC: 0.4782608695652174
2023-07-11 14:17:08,437 - temp:64	temp1:29	wrong_total:92	
2023-07-11 14:17:08,620 - epoch:23,	loss:nan
2023-07-11 14:17:20,096 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:17:20,096 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-11 14:17:20,096 - temp:60	temp1:28	wrong_total:92	
2023-07-11 14:17:20,290 - epoch:24,	loss:nan
2023-07-11 14:17:32,115 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:17:32,115 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:42	wrong_total:94	 wrong be tree ACC: 0.44680851063829785
2023-07-11 14:17:32,115 - temp:63	temp1:30	wrong_total:94	
2023-07-11 14:17:32,297 - epoch:25,	loss:nan
2023-07-11 14:17:44,722 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:17:44,722 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:43	wrong_total:93	 wrong be tree ACC: 0.46236559139784944
2023-07-11 14:17:44,722 - temp:53	temp1:25	wrong_total:93	
2023-07-11 14:17:44,979 - epoch:26,	loss:nan
2023-07-11 14:17:57,224 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:17:57,225 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-11 14:17:57,225 - temp:61	temp1:34	wrong_total:91	
2023-07-11 14:17:57,414 - epoch:27,	loss:nan
2023-07-11 14:18:09,412 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:18:09,412 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:47	wrong_total:90	 wrong be tree ACC: 0.5222222222222223
2023-07-11 14:18:09,412 - temp:60	temp1:28	wrong_total:90	
2023-07-11 14:18:09,415 - save best refiner model to ./output/test/best_model
2023-07-11 14:18:09,605 - epoch:28,	loss:nan
2023-07-11 14:18:21,637 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:18:21,637 - right_codes_count:336	total:433	Code ACC: 0.7759815242494227	wrong_be_tree_count:40	wrong_total:95	 wrong be tree ACC: 0.42105263157894735
2023-07-11 14:18:21,637 - temp:60	temp1:27	wrong_total:95	
2023-07-11 14:18:21,824 - epoch:29,	loss:2.4411390544846654
2023-07-11 14:18:33,850 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-11 14:18:33,850 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:37	wrong_total:88	 wrong be tree ACC: 0.42045454545454547
2023-07-11 14:18:33,850 - temp:62	temp1:32	wrong_total:88	
2023-07-11 14:18:33,852 - save best refiner model to ./output/test/best_model
2023-07-11 14:18:34,034 - epoch:30,	loss:2.3080556197091937
2023-07-11 14:18:46,417 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:18:46,417 - right_codes_count:336	total:433	Code ACC: 0.7759815242494227	wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-11 14:18:46,417 - temp:67	temp1:36	wrong_total:91	
2023-07-11 14:18:46,598 - epoch:31,	loss:nan
2023-07-11 14:18:58,218 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:18:58,218 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:43	wrong_total:93	 wrong be tree ACC: 0.46236559139784944
2023-07-11 14:18:58,218 - temp:56	temp1:25	wrong_total:93	
2023-07-11 14:18:58,398 - epoch:32,	loss:nan
2023-07-11 14:19:09,895 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 14:19:09,895 - right_codes_count:336	total:433	Code ACC: 0.7759815242494227	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
2023-07-11 14:19:09,895 - temp:63	temp1:34	wrong_total:89	
2023-07-11 14:19:10,078 - epoch:33,	loss:nan
2023-07-11 14:19:21,846 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:19:21,846 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 14:19:21,846 - temp:62	temp1:37	wrong_total:92	
2023-07-11 14:19:22,031 - epoch:34,	loss:nan
2023-07-11 14:19:33,838 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:19:33,839 - right_codes_count:335	total:433	Code ACC: 0.7736720554272517	wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-11 14:19:33,839 - temp:64	temp1:32	wrong_total:91	
2023-07-11 14:19:34,021 - epoch:35,	loss:2.2343943775631487
2023-07-11 14:19:45,975 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:19:45,976 - right_codes_count:337	total:433	Code ACC: 0.7782909930715936	wrong_be_tree_count:44	wrong_total:91	 wrong be tree ACC: 0.4835164835164835
2023-07-11 14:19:45,976 - temp:62	temp1:34	wrong_total:91	
2023-07-11 14:26:58,845 - 


2023-07-11 14:26:59,318 - get train data loader...
2023-07-11 14:26:59,625 - get dev data loader...
2023-07-11 14:26:59,766 - define model...
2023-07-11 14:27:03,333 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:27:16,404 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:27:16,404 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:103	wrong_total:107	 wrong be tree ACC: 0.9626168224299065
2023-07-11 14:27:16,404 - temp:98	temp1:1	wrong_total:107	
2023-07-11 14:27:16,407 - save best refiner model to ./output/test/best_model
2023-07-11 14:27:16,587 - epoch:0,	loss:nan
2023-07-11 14:27:28,330 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:27:28,331 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:102	 wrong be tree ACC: 0.5098039215686274
2023-07-11 14:27:28,331 - temp:19	temp1:13	wrong_total:102	
2023-07-11 14:27:28,334 - save best refiner model to ./output/test/best_model
2023-07-11 14:27:28,513 - epoch:1,	loss:nan
2023-07-11 14:31:16,831 - 


2023-07-11 14:31:17,408 - get train data loader...
2023-07-11 14:31:17,699 - get dev data loader...
2023-07-11 14:31:17,846 - define model...
2023-07-11 14:31:21,281 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:31:35,365 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:31:35,365 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:103	wrong_total:107	 wrong be tree ACC: 0.9626168224299065
2023-07-11 14:31:35,365 - temp:98	temp1:1	wrong_total:107	
2023-07-11 14:31:35,367 - save best refiner model to ./output/test/best_model
2023-07-11 14:31:35,550 - epoch:0,	loss:nan
2023-07-11 14:31:47,394 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:31:47,394 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:102	 wrong be tree ACC: 0.5098039215686274
2023-07-11 14:31:47,394 - temp:19	temp1:13	wrong_total:102	
2023-07-11 14:31:47,396 - save best refiner model to ./output/test/best_model
2023-07-11 14:31:47,579 - epoch:1,	loss:nan
2023-07-11 14:31:59,142 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:31:59,143 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:31:59,143 - temp:0	temp1:27	wrong_total:100	
2023-07-11 14:31:59,148 - save best refiner model to ./output/test/best_model
2023-07-11 14:31:59,334 - epoch:2,	loss:46.580615639686584
2023-07-11 14:32:10,895 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:32:10,895 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:32:10,895 - temp:0	temp1:30	wrong_total:100	
2023-07-11 14:32:11,080 - epoch:3,	loss:nan
2023-07-11 14:32:22,580 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:32:22,580 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:32:22,580 - temp:0	temp1:21	wrong_total:100	
2023-07-11 14:32:22,762 - epoch:4,	loss:35.25513672828674
2023-07-11 14:34:47,626 - 


2023-07-11 14:34:48,472 - get train data loader...
2023-07-11 14:34:48,767 - get dev data loader...
2023-07-11 14:34:48,919 - define model...
2023-07-11 14:34:52,722 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:35:06,683 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:35:06,684 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:103	wrong_total:107	 wrong be tree ACC: 0.9626168224299065
2023-07-11 14:35:06,684 - temp:98	temp1:1	wrong_total:107	
2023-07-11 14:35:06,685 - save best refiner model to ./output/test/best_model
2023-07-11 14:35:06,929 - epoch:0,	loss:nan
2023-07-11 14:35:18,390 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:35:18,390 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:102	 wrong be tree ACC: 0.5098039215686274
2023-07-11 14:35:18,390 - temp:19	temp1:13	wrong_total:102	
2023-07-11 14:35:18,392 - save best refiner model to ./output/test/best_model
2023-07-11 14:35:18,574 - epoch:1,	loss:nan
2023-07-11 14:35:29,549 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:35:29,549 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:35:29,549 - temp:0	temp1:27	wrong_total:100	
2023-07-11 14:35:29,551 - save best refiner model to ./output/test/best_model
2023-07-11 14:35:29,731 - epoch:2,	loss:46.580615639686584
2023-07-11 14:35:40,739 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:35:40,739 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:35:40,739 - temp:0	temp1:30	wrong_total:100	
2023-07-11 14:35:40,934 - epoch:3,	loss:nan
2023-07-11 14:39:15,858 - 


2023-07-11 14:39:16,340 - get train data loader...
2023-07-11 14:39:16,661 - get dev data loader...
2023-07-11 14:39:16,795 - define model...
2023-07-11 14:39:20,290 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:39:34,166 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:39:34,166 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-11 14:39:34,166 - temp:102	temp1:4	wrong_total:107	
2023-07-11 14:39:34,168 - save best refiner model to ./output/test/best_model
2023-07-11 14:39:34,354 - epoch:0,	loss:4702.779435575008
2023-07-11 14:39:45,751 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:39:45,752 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:50	wrong_total:102	 wrong be tree ACC: 0.49019607843137253
2023-07-11 14:39:45,752 - temp:22	temp1:13	wrong_total:102	
2023-07-11 14:39:45,753 - save best refiner model to ./output/test/best_model
2023-07-11 14:39:45,936 - epoch:1,	loss:4172.634451329708
2023-07-11 14:39:57,058 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:39:57,058 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:39:57,058 - temp:0	temp1:26	wrong_total:100	
2023-07-11 14:39:57,061 - save best refiner model to ./output/test/best_model
2023-07-11 14:39:57,242 - epoch:2,	loss:3227.748748779297
2023-07-11 14:40:08,574 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:40:08,574 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:40:08,574 - temp:0	temp1:27	wrong_total:100	
2023-07-11 14:40:08,760 - epoch:3,	loss:2169.2466354370117
2023-07-11 14:40:20,582 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:40:20,582 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:40:20,582 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:40:20,765 - epoch:4,	loss:1415.201479434967
2023-07-11 14:40:33,119 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:40:33,119 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:40:33,119 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:40:33,318 - epoch:5,	loss:1097.2050704360008
2023-07-11 14:40:45,762 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:40:45,762 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:40:45,762 - temp:1	temp1:19	wrong_total:100	
2023-07-11 14:40:45,948 - epoch:6,	loss:964.8385152816772
2023-07-11 14:40:57,964 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 14:40:57,964 - right_codes_count:331	total:433	Code ACC: 0.7644341801385681	wrong_be_tree_count:47	wrong_total:98	 wrong be tree ACC: 0.47959183673469385
2023-07-11 14:40:57,964 - temp:19	temp1:24	wrong_total:98	
2023-07-11 14:40:57,966 - save best refiner model to ./output/test/best_model
2023-07-11 14:40:58,148 - epoch:7,	loss:889.9957969784737
2023-07-11 14:41:09,940 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:41:09,940 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:39	wrong_total:97	 wrong be tree ACC: 0.4020618556701031
2023-07-11 14:41:09,940 - temp:41	temp1:31	wrong_total:97	
2023-07-11 14:41:09,943 - save best refiner model to ./output/test/best_model
2023-07-11 14:41:10,196 - epoch:8,	loss:825.0327717661858
2023-07-11 14:41:21,982 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:41:21,982 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:30	wrong_total:97	 wrong be tree ACC: 0.30927835051546393
2023-07-11 14:41:21,982 - temp:43	temp1:38	wrong_total:97	
2023-07-11 14:41:22,169 - epoch:9,	loss:772.9926114082336
2023-07-11 14:41:33,898 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:41:33,898 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:32	wrong_total:97	 wrong be tree ACC: 0.32989690721649484
2023-07-11 14:41:33,898 - temp:45	temp1:37	wrong_total:97	
2023-07-11 14:41:34,085 - epoch:10,	loss:725.4935713410378
2023-07-11 14:41:45,684 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 14:41:45,684 - right_codes_count:332	total:433	Code ACC: 0.766743648960739	wrong_be_tree_count:31	wrong_total:96	 wrong be tree ACC: 0.3229166666666667
2023-07-11 14:41:45,684 - temp:54	temp1:35	wrong_total:96	
2023-07-11 14:41:45,688 - save best refiner model to ./output/test/best_model
2023-07-11 14:41:45,878 - epoch:11,	loss:686.8524079322815
2023-07-11 14:41:57,153 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:41:57,154 - right_codes_count:333	total:433	Code ACC: 0.76905311778291	wrong_be_tree_count:31	wrong_total:93	 wrong be tree ACC: 0.3333333333333333
2023-07-11 14:41:57,154 - temp:51	temp1:34	wrong_total:93	
2023-07-11 14:41:57,155 - save best refiner model to ./output/test/best_model
2023-07-11 14:41:57,337 - epoch:12,	loss:648.3828732967377
2023-07-11 14:42:09,174 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:42:09,174 - right_codes_count:334	total:433	Code ACC: 0.7713625866050808	wrong_be_tree_count:34	wrong_total:94	 wrong be tree ACC: 0.3617021276595745
2023-07-11 14:42:09,174 - temp:56	temp1:33	wrong_total:94	
2023-07-11 14:42:09,356 - epoch:13,	loss:617.0193635225296
2023-07-11 14:47:45,989 - 


2023-07-11 14:47:46,444 - get train data loader...
2023-07-11 14:47:46,761 - get dev data loader...
2023-07-11 14:47:46,888 - define model...
2023-07-11 14:47:50,594 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:47:57,978 - epoch:0,	loss:4702.779435575008
2023-07-11 14:48:04,154 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:48:04,155 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-11 14:48:04,155 - temp:102	temp1:4	wrong_total:107	
2023-07-11 14:48:04,158 - save best refiner model to ./output/test/best_model
2023-07-11 14:48:09,751 - epoch:1,	loss:4172.634451329708
2023-07-11 14:48:16,170 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:48:16,171 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:50	wrong_total:102	 wrong be tree ACC: 0.49019607843137253
2023-07-11 14:48:16,171 - temp:22	temp1:13	wrong_total:102	
2023-07-11 14:48:21,852 - epoch:2,	loss:3227.748748779297
2023-07-11 14:48:28,573 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:48:28,573 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:48:28,573 - temp:0	temp1:26	wrong_total:100	
2023-07-11 14:48:34,566 - epoch:3,	loss:2169.2466354370117
2023-07-11 14:48:41,117 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:48:41,117 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:48:41,117 - temp:0	temp1:27	wrong_total:100	
2023-07-11 14:48:46,706 - epoch:4,	loss:1415.201479434967
2023-07-11 14:48:52,497 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:48:52,497 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:48:52,498 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:48:57,938 - epoch:5,	loss:1097.2050704360008
2023-07-11 14:49:03,837 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:49:03,837 - right_codes_count:330	total:433	Code ACC: 0.7621247113163973	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:49:03,837 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:49:09,016 - epoch:6,	loss:964.8385152816772
2023-07-11 14:51:03,924 - 


2023-07-11 14:51:04,389 - get train data loader...
2023-07-11 14:51:04,681 - get dev data loader...
2023-07-11 14:51:04,821 - define model...
2023-07-11 14:51:08,477 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:51:15,964 - epoch:0,	loss:4702.779435575008
2023-07-11 14:51:50,395 - 


2023-07-11 14:51:50,848 - get train data loader...
2023-07-11 14:51:51,138 - get dev data loader...
2023-07-11 14:51:51,290 - define model...
2023-07-11 14:51:54,676 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 14:52:01,993 - epoch:0,	loss:4702.779435575008
2023-07-11 14:52:08,671 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-11 14:52:08,671 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:104	wrong_total:107	 wrong be tree ACC: 0.9719626168224299
2023-07-11 14:52:08,671 - temp:102	temp1:4	wrong_total:107	
2023-07-11 14:52:08,672 - save best refiner model to ./output/test/best_model
2023-07-11 14:52:14,227 - epoch:1,	loss:4172.634451329708
2023-07-11 14:52:20,830 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-11 14:52:20,830 - right_codes_count:1752	total:1974	Code ACC: 0.8875379939209727	wrong_be_tree_count:50	wrong_total:102	 wrong be tree ACC: 0.49019607843137253
2023-07-11 14:52:20,830 - temp:22	temp1:13	wrong_total:102	
2023-07-11 14:52:20,832 - save best refiner model to ./output/test/best_model
2023-07-11 14:52:26,397 - epoch:2,	loss:3227.748748779297
2023-07-11 14:52:32,829 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:52:32,829 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:52:32,829 - temp:0	temp1:26	wrong_total:100	
2023-07-11 14:52:38,271 - epoch:3,	loss:2169.2466354370117
2023-07-11 14:52:44,712 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:52:44,713 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:52:44,713 - temp:0	temp1:27	wrong_total:100	
2023-07-11 14:52:50,404 - epoch:4,	loss:1415.201479434967
2023-07-11 14:52:56,818 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:52:56,818 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:52:56,819 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:53:02,976 - epoch:5,	loss:1097.2050704360008
2023-07-11 14:53:09,497 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:53:09,497 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:53:09,498 - temp:0	temp1:19	wrong_total:100	
2023-07-11 14:53:15,526 - epoch:6,	loss:964.8385152816772
2023-07-11 14:53:21,743 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-11 14:53:21,743 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:52	wrong_total:100	 wrong be tree ACC: 0.52
2023-07-11 14:53:21,743 - temp:1	temp1:19	wrong_total:100	
2023-07-11 14:53:27,842 - epoch:7,	loss:889.9957969784737
2023-07-11 14:53:33,669 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-11 14:53:33,669 - right_codes_count:1750	total:1974	Code ACC: 0.8865248226950354	wrong_be_tree_count:47	wrong_total:98	 wrong be tree ACC: 0.47959183673469385
2023-07-11 14:53:33,669 - temp:19	temp1:24	wrong_total:98	
2023-07-11 14:53:39,165 - epoch:8,	loss:825.0327717661858
2023-07-11 14:53:44,958 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:53:44,959 - right_codes_count:1753	total:1974	Code ACC: 0.8880445795339412	wrong_be_tree_count:39	wrong_total:97	 wrong be tree ACC: 0.4020618556701031
2023-07-11 14:53:44,959 - temp:41	temp1:31	wrong_total:97	
2023-07-11 14:53:44,960 - save best refiner model to ./output/test/best_model
2023-07-11 14:53:50,517 - epoch:9,	loss:772.9926114082336
2023-07-11 14:53:56,273 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:53:56,273 - right_codes_count:1757	total:1974	Code ACC: 0.8900709219858156	wrong_be_tree_count:30	wrong_total:97	 wrong be tree ACC: 0.30927835051546393
2023-07-11 14:53:56,273 - temp:43	temp1:38	wrong_total:97	
2023-07-11 14:53:56,275 - save best refiner model to ./output/test/best_model
2023-07-11 14:54:02,239 - epoch:10,	loss:725.4935713410378
2023-07-11 14:54:08,861 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-11 14:54:08,861 - right_codes_count:1756	total:1974	Code ACC: 0.889564336372847	wrong_be_tree_count:32	wrong_total:97	 wrong be tree ACC: 0.32989690721649484
2023-07-11 14:54:08,861 - temp:45	temp1:37	wrong_total:97	
2023-07-11 14:54:15,021 - epoch:11,	loss:686.8524079322815
2023-07-11 14:54:21,588 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 14:54:21,588 - right_codes_count:1757	total:1974	Code ACC: 0.8900709219858156	wrong_be_tree_count:31	wrong_total:96	 wrong be tree ACC: 0.3229166666666667
2023-07-11 14:54:21,588 - temp:54	temp1:35	wrong_total:96	
2023-07-11 14:54:27,301 - epoch:12,	loss:648.3828732967377
2023-07-11 14:54:33,574 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:54:33,574 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:31	wrong_total:93	 wrong be tree ACC: 0.3333333333333333
2023-07-11 14:54:33,574 - temp:51	temp1:34	wrong_total:93	
2023-07-11 14:54:33,577 - save best refiner model to ./output/test/best_model
2023-07-11 14:54:39,154 - epoch:13,	loss:617.0193635225296
2023-07-11 14:54:45,665 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:54:45,665 - right_codes_count:1760	total:1974	Code ACC: 0.8915906788247214	wrong_be_tree_count:34	wrong_total:94	 wrong be tree ACC: 0.3617021276595745
2023-07-11 14:54:45,665 - temp:56	temp1:33	wrong_total:94	
2023-07-11 14:54:51,262 - epoch:14,	loss:594.1370559334755
2023-07-11 14:54:57,750 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 14:54:57,750 - right_codes_count:1757	total:1974	Code ACC: 0.8900709219858156	wrong_be_tree_count:37	wrong_total:96	 wrong be tree ACC: 0.3854166666666667
2023-07-11 14:54:57,751 - temp:60	temp1:32	wrong_total:96	
2023-07-11 14:55:03,206 - epoch:15,	loss:561.9945932030678
2023-07-11 14:55:09,572 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:55:09,572 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
2023-07-11 14:55:09,572 - temp:59	temp1:31	wrong_total:90	
2023-07-11 14:55:09,574 - save best refiner model to ./output/test/best_model
2023-07-11 14:55:15,735 - epoch:16,	loss:543.6010645627975
2023-07-11 14:55:22,213 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:55:22,213 - right_codes_count:1759	total:1974	Code ACC: 0.8910840932117527	wrong_be_tree_count:37	wrong_total:94	 wrong be tree ACC: 0.39361702127659576
2023-07-11 14:55:22,213 - temp:54	temp1:32	wrong_total:94	
2023-07-11 14:55:28,275 - epoch:17,	loss:522.412651181221
2023-07-11 14:55:34,451 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 14:55:34,452 - right_codes_count:1758	total:1974	Code ACC: 0.8905775075987842	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 14:55:34,452 - temp:62	temp1:37	wrong_total:89	
2023-07-11 14:55:40,082 - epoch:18,	loss:505.9134591817856
2023-07-11 14:55:45,900 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:55:45,900 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:43	wrong_total:95	 wrong be tree ACC: 0.45263157894736844
2023-07-11 14:55:45,900 - temp:60	temp1:37	wrong_total:95	
2023-07-11 14:55:51,365 - epoch:19,	loss:495.44774663448334
2023-07-11 14:55:57,437 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 14:55:57,438 - right_codes_count:1762	total:1974	Code ACC: 0.8926038500506586	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
2023-07-11 14:55:57,438 - temp:59	temp1:31	wrong_total:89	
2023-07-11 14:56:02,939 - epoch:20,	loss:480.70350325107574
2023-07-11 14:56:09,350 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:56:09,350 - right_codes_count:1760	total:1974	Code ACC: 0.8915906788247214	wrong_be_tree_count:47	wrong_total:92	 wrong be tree ACC: 0.5108695652173914
2023-07-11 14:56:09,350 - temp:59	temp1:31	wrong_total:92	
2023-07-11 14:56:15,119 - epoch:21,	loss:469.44793182611465
2023-07-11 14:56:21,797 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:56:21,797 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:45	wrong_total:92	 wrong be tree ACC: 0.4891304347826087
2023-07-11 14:56:21,797 - temp:61	temp1:32	wrong_total:92	
2023-07-11 14:56:27,858 - epoch:22,	loss:462.7039910554886
2023-07-11 14:56:34,407 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-11 14:56:34,407 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:47	wrong_total:96	 wrong be tree ACC: 0.4895833333333333
2023-07-11 14:56:34,407 - temp:63	temp1:33	wrong_total:96	
2023-07-11 14:56:34,409 - save best refiner model to ./output/test/best_model
2023-07-11 14:56:40,160 - epoch:23,	loss:446.0795393586159
2023-07-11 14:56:46,321 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:56:46,321 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 14:56:46,321 - temp:62	temp1:34	wrong_total:92	
2023-07-11 14:56:51,992 - epoch:24,	loss:433.3955931663513
2023-07-11 14:56:58,329 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:56:58,330 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:40	wrong_total:90	 wrong be tree ACC: 0.4444444444444444
2023-07-11 14:56:58,330 - temp:65	temp1:34	wrong_total:90	
2023-07-11 14:56:58,331 - save best refiner model to ./output/test/best_model
2023-07-11 14:57:03,708 - epoch:25,	loss:425.96606785058975
2023-07-11 14:57:10,062 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:57:10,062 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:44	wrong_total:92	 wrong be tree ACC: 0.4782608695652174
2023-07-11 14:57:10,062 - temp:68	temp1:36	wrong_total:92	
2023-07-11 14:57:15,502 - epoch:26,	loss:420.1459624171257
2023-07-11 14:57:22,013 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-11 14:57:22,013 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:46	wrong_total:95	 wrong be tree ACC: 0.4842105263157895
2023-07-11 14:57:22,013 - temp:62	temp1:34	wrong_total:95	
2023-07-11 14:57:27,840 - epoch:27,	loss:412.2060321569443
2023-07-11 14:57:33,737 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:57:33,737 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:42	wrong_total:92	 wrong be tree ACC: 0.45652173913043476
2023-07-11 14:57:33,737 - temp:65	temp1:36	wrong_total:92	
2023-07-11 14:57:39,455 - epoch:28,	loss:405.2876960635185
2023-07-11 14:57:45,102 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:57:45,102 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:41	wrong_total:90	 wrong be tree ACC: 0.45555555555555555
2023-07-11 14:57:45,102 - temp:66	temp1:36	wrong_total:90	
2023-07-11 14:57:50,578 - epoch:29,	loss:395.8040109872818
2023-07-11 14:57:57,057 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-11 14:57:57,058 - right_codes_count:1766	total:1974	Code ACC: 0.894630192502533	wrong_be_tree_count:45	wrong_total:94	 wrong be tree ACC: 0.4787234042553192
2023-07-11 14:57:57,058 - temp:59	temp1:35	wrong_total:94	
2023-07-11 14:58:02,483 - epoch:30,	loss:383.02213102579117
2023-07-11 14:58:08,948 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:58:08,948 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 14:58:08,948 - temp:66	temp1:38	wrong_total:90	
2023-07-11 14:58:14,538 - epoch:31,	loss:381.04534780979156
2023-07-11 14:58:20,980 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:58:20,980 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
2023-07-11 14:58:20,980 - temp:73	temp1:40	wrong_total:90	
2023-07-11 14:58:26,850 - epoch:32,	loss:373.91599559783936
2023-07-11 14:58:33,416 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:58:33,416 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:42	wrong_total:91	 wrong be tree ACC: 0.46153846153846156
2023-07-11 14:58:33,416 - temp:60	temp1:28	wrong_total:91	
2023-07-11 14:58:33,418 - save best refiner model to ./output/test/best_model
2023-07-11 14:58:39,429 - epoch:33,	loss:365.8333452939987
2023-07-11 14:58:46,037 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:58:46,038 - right_codes_count:1767	total:1974	Code ACC: 0.8951367781155015	wrong_be_tree_count:39	wrong_total:91	 wrong be tree ACC: 0.42857142857142855
2023-07-11 14:58:46,038 - temp:69	temp1:37	wrong_total:91	
2023-07-11 14:58:51,594 - epoch:34,	loss:366.25243693590164
2023-07-11 14:58:58,045 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:58:58,045 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:39	wrong_total:91	 wrong be tree ACC: 0.42857142857142855
2023-07-11 14:58:58,045 - temp:69	temp1:35	wrong_total:91	
2023-07-11 14:59:03,487 - epoch:35,	loss:353.88979971408844
2023-07-11 14:59:09,820 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 14:59:09,820 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:43	wrong_total:93	 wrong be tree ACC: 0.46236559139784944
2023-07-11 14:59:09,820 - temp:67	temp1:35	wrong_total:93	
2023-07-11 14:59:15,310 - epoch:36,	loss:352.4852488040924
2023-07-11 14:59:21,430 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 14:59:21,431 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-11 14:59:21,431 - temp:68	temp1:37	wrong_total:92	
2023-07-11 14:59:27,017 - epoch:37,	loss:339.3321743607521
2023-07-11 14:59:32,862 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 14:59:32,863 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-11 14:59:32,863 - temp:62	temp1:31	wrong_total:91	
2023-07-11 14:59:38,593 - epoch:38,	loss:344.0984722971916
2023-07-11 14:59:44,572 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 14:59:44,572 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:38	wrong_total:90	 wrong be tree ACC: 0.4222222222222222
2023-07-11 14:59:44,572 - temp:73	temp1:40	wrong_total:90	
2023-07-11 14:59:50,534 - epoch:39,	loss:332.754794716835
2023-07-11 14:59:56,983 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 14:59:56,984 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
2023-07-11 14:59:56,984 - temp:67	temp1:30	wrong_total:89	
2023-07-11 15:00:02,476 - epoch:40,	loss:333.77401155233383
2023-07-11 15:00:08,837 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-11 15:00:08,837 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:39	wrong_total:88	 wrong be tree ACC: 0.4431818181818182
2023-07-11 15:00:08,837 - temp:70	temp1:31	wrong_total:88	
2023-07-11 15:00:14,295 - epoch:41,	loss:323.345301926136
2023-07-11 15:00:20,810 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-11 15:00:20,810 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:36	wrong_total:88	 wrong be tree ACC: 0.4090909090909091
2023-07-11 15:00:20,810 - temp:69	temp1:27	wrong_total:88	
2023-07-11 15:00:20,812 - save best refiner model to ./output/test/best_model
2023-07-11 15:00:26,605 - epoch:42,	loss:314.243173122406
2023-07-11 15:00:32,871 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:00:32,871 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:39	wrong_total:91	 wrong be tree ACC: 0.42857142857142855
2023-07-11 15:00:32,871 - temp:70	temp1:31	wrong_total:91	
2023-07-11 15:00:38,620 - epoch:43,	loss:315.212837934494
2023-07-11 15:00:45,225 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:00:45,225 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:35	wrong_total:89	 wrong be tree ACC: 0.39325842696629215
2023-07-11 15:00:45,225 - temp:64	temp1:34	wrong_total:89	
2023-07-11 15:00:51,372 - epoch:44,	loss:311.23966574668884
2023-07-11 15:00:57,968 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:00:57,968 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:36	wrong_total:90	 wrong be tree ACC: 0.4
2023-07-11 15:00:57,968 - temp:68	temp1:34	wrong_total:90	
2023-07-11 15:01:03,653 - epoch:45,	loss:309.2156471610069
2023-07-11 15:01:10,066 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:01:10,067 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:01:10,067 - temp:74	temp1:31	wrong_total:91	
2023-07-11 15:01:15,663 - epoch:46,	loss:297.6078503727913
2023-07-11 15:01:21,384 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:01:21,384 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:01:21,384 - temp:69	temp1:27	wrong_total:90	
2023-07-11 15:01:26,946 - epoch:47,	loss:305.433706343174
2023-07-11 15:01:32,843 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:01:32,843 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:90	 wrong be tree ACC: 0.4222222222222222
2023-07-11 15:01:32,843 - temp:72	temp1:29	wrong_total:90	
2023-07-11 15:01:38,380 - epoch:48,	loss:297.57577192783356
2023-07-11 15:01:44,943 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:01:44,943 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:90	 wrong be tree ACC: 0.4222222222222222
2023-07-11 15:01:44,943 - temp:61	temp1:25	wrong_total:90	
2023-07-11 15:01:51,041 - epoch:49,	loss:297.61811125278473
2023-07-11 15:01:57,653 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:01:57,654 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
2023-07-11 15:01:57,654 - temp:70	temp1:30	wrong_total:89	
2023-07-11 15:02:03,833 - epoch:50,	loss:286.5264506340027
2023-07-11 15:02:10,132 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:02:10,132 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-11 15:02:10,133 - temp:73	temp1:31	wrong_total:91	
2023-07-11 15:02:16,040 - epoch:51,	loss:289.51743680238724
2023-07-11 15:02:22,233 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:02:22,234 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-11 15:02:22,234 - temp:69	temp1:31	wrong_total:91	
2023-07-11 15:02:27,877 - epoch:52,	loss:285.86815798282623
2023-07-11 15:02:34,278 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:02:34,278 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-11 15:02:34,278 - temp:70	temp1:32	wrong_total:91	
2023-07-11 15:02:39,969 - epoch:53,	loss:280.7458846569061
2023-07-11 15:02:46,448 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-11 15:02:46,448 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:39	wrong_total:87	 wrong be tree ACC: 0.4482758620689655
2023-07-11 15:02:46,448 - temp:66	temp1:27	wrong_total:87	
2023-07-11 15:02:52,480 - epoch:54,	loss:276.45573300123215
2023-07-11 15:02:59,232 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:02:59,232 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:02:59,232 - temp:67	temp1:32	wrong_total:90	
2023-07-11 15:03:05,296 - epoch:55,	loss:275.1623651981354
2023-07-11 15:03:11,524 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:03:11,524 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 15:03:11,524 - temp:69	temp1:31	wrong_total:89	
2023-07-11 15:03:11,526 - save best refiner model to ./output/test/best_model
2023-07-11 15:03:17,007 - epoch:56,	loss:269.4283505678177
2023-07-11 15:03:22,829 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:03:22,830 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
2023-07-11 15:03:22,830 - temp:68	temp1:27	wrong_total:89	
2023-07-11 15:03:28,415 - epoch:57,	loss:270.1773512363434
2023-07-11 15:03:34,156 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:03:34,156 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-11 15:03:34,156 - temp:72	temp1:31	wrong_total:91	
2023-07-11 15:03:39,967 - epoch:58,	loss:261.42767012119293
2023-07-11 15:03:46,248 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:03:46,249 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
2023-07-11 15:03:46,249 - temp:67	temp1:29	wrong_total:89	
2023-07-11 15:03:51,859 - epoch:59,	loss:259.1637074947357
2023-07-11 15:03:58,581 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-11 15:03:58,581 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:37	wrong_total:87	 wrong be tree ACC: 0.42528735632183906
2023-07-11 15:03:58,581 - temp:63	temp1:26	wrong_total:87	
2023-07-11 15:04:04,632 - epoch:60,	loss:258.5966446995735
2023-07-11 15:04:11,161 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-11 15:04:11,161 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:88	 wrong be tree ACC: 0.42045454545454547
2023-07-11 15:04:11,161 - temp:68	temp1:28	wrong_total:88	
2023-07-11 15:04:17,234 - epoch:61,	loss:253.7564308643341
2023-07-11 15:04:23,466 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:04:23,466 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 15:04:23,466 - temp:64	temp1:25	wrong_total:89	
2023-07-11 15:04:29,216 - epoch:62,	loss:263.19609969854355
2023-07-11 15:04:35,787 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:04:35,787 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:04:35,787 - temp:69	temp1:27	wrong_total:91	
2023-07-11 15:04:41,311 - epoch:63,	loss:253.19365364313126
2023-07-11 15:04:47,733 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:04:47,733 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:35	wrong_total:89	 wrong be tree ACC: 0.39325842696629215
2023-07-11 15:04:47,733 - temp:68	temp1:21	wrong_total:89	
2023-07-11 15:04:53,429 - epoch:64,	loss:250.7401788830757
2023-07-11 15:04:59,888 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:04:59,889 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:41	wrong_total:89	 wrong be tree ACC: 0.4606741573033708
2023-07-11 15:04:59,889 - temp:69	temp1:25	wrong_total:89	
2023-07-11 15:05:05,974 - epoch:65,	loss:246.14984959363937
2023-07-11 15:05:11,986 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:05:11,986 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:05:11,986 - temp:66	temp1:23	wrong_total:90	
2023-07-11 15:05:17,640 - epoch:66,	loss:241.75312876701355
2023-07-11 15:05:23,878 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:05:23,878 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:89	 wrong be tree ACC: 0.4157303370786517
2023-07-11 15:05:23,878 - temp:63	temp1:25	wrong_total:89	
2023-07-11 15:05:29,588 - epoch:67,	loss:237.89946752786636
2023-07-11 15:05:36,811 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:05:36,811 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 15:05:36,811 - temp:68	temp1:23	wrong_total:89	
2023-07-11 15:05:43,082 - epoch:68,	loss:238.05616527795792
2023-07-11 15:05:50,041 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:05:50,041 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:05:50,041 - temp:69	temp1:28	wrong_total:92	
2023-07-11 15:05:56,235 - epoch:69,	loss:242.13305127620697
2023-07-11 15:06:03,353 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:06:03,353 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 15:06:03,353 - temp:64	temp1:25	wrong_total:89	
2023-07-11 15:06:09,764 - epoch:70,	loss:239.36851131916046
2023-07-11 15:06:16,645 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:06:16,645 - right_codes_count:1776	total:1974	Code ACC: 0.8996960486322189	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
2023-07-11 15:06:16,645 - temp:67	temp1:23	wrong_total:89	
2023-07-11 15:06:16,647 - save best refiner model to ./output/test/best_model
2023-07-11 15:06:22,910 - epoch:71,	loss:236.66266375780106
2023-07-11 15:06:30,135 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-11 15:06:30,135 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:36	wrong_total:88	 wrong be tree ACC: 0.4090909090909091
2023-07-11 15:06:30,135 - temp:67	temp1:24	wrong_total:88	
2023-07-11 15:06:36,076 - epoch:72,	loss:236.7292263507843
2023-07-11 15:06:42,400 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:06:42,400 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
2023-07-11 15:06:42,400 - temp:67	temp1:27	wrong_total:90	
2023-07-11 15:06:48,178 - epoch:73,	loss:230.89092701673508
2023-07-11 15:06:55,221 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:06:55,221 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
2023-07-11 15:06:55,222 - temp:66	temp1:29	wrong_total:89	
2023-07-11 15:07:01,609 - epoch:74,	loss:226.9056123495102
2023-07-11 15:07:08,605 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:07:08,606 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
2023-07-11 15:07:08,606 - temp:64	temp1:25	wrong_total:89	
2023-07-11 15:07:14,837 - epoch:75,	loss:223.80277347564697
2023-07-11 15:07:22,002 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:07:22,002 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:38	wrong_total:89	 wrong be tree ACC: 0.42696629213483145
2023-07-11 15:07:22,002 - temp:68	temp1:31	wrong_total:89	
2023-07-11 15:07:28,267 - epoch:76,	loss:223.2999750971794
2023-07-11 15:07:35,063 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:07:35,063 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:07:35,063 - temp:71	temp1:23	wrong_total:91	
2023-07-11 15:07:41,352 - epoch:77,	loss:219.56016170978546
2023-07-11 15:07:48,537 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:07:48,537 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:39	wrong_total:90	 wrong be tree ACC: 0.43333333333333335
2023-07-11 15:07:48,537 - temp:68	temp1:27	wrong_total:90	
2023-07-11 15:07:54,797 - epoch:78,	loss:221.65746921300888
2023-07-11 15:08:01,103 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:08:01,103 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:08:01,103 - temp:68	temp1:28	wrong_total:90	
2023-07-11 15:08:06,924 - epoch:79,	loss:226.17097985744476
2023-07-11 15:08:13,296 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:08:13,297 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:90	 wrong be tree ACC: 0.4444444444444444
2023-07-11 15:08:13,297 - temp:65	temp1:28	wrong_total:90	
2023-07-11 15:08:19,544 - epoch:80,	loss:225.0422945022583
2023-07-11 15:08:26,541 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:08:26,541 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-11 15:08:26,541 - temp:68	temp1:23	wrong_total:91	
2023-07-11 15:08:32,738 - epoch:81,	loss:221.98451280593872
2023-07-11 15:08:40,164 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:08:40,164 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:08:40,164 - temp:71	temp1:28	wrong_total:90	
2023-07-11 15:08:46,510 - epoch:82,	loss:215.96132212877274
2023-07-11 15:08:53,379 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:08:53,379 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:08:53,379 - temp:66	temp1:27	wrong_total:91	
2023-07-11 15:08:59,698 - epoch:83,	loss:217.9413388967514
2023-07-11 15:09:07,066 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 15:09:07,066 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
2023-07-11 15:09:07,066 - temp:69	temp1:27	wrong_total:93	
2023-07-11 15:09:13,535 - epoch:84,	loss:213.85817402601242
2023-07-11 15:09:20,120 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-11 15:09:20,120 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
2023-07-11 15:09:20,120 - temp:66	temp1:23	wrong_total:89	
2023-07-11 15:09:25,976 - epoch:85,	loss:211.03434097766876
2023-07-11 15:09:32,214 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:09:32,214 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:09:32,214 - temp:67	temp1:24	wrong_total:92	
2023-07-11 15:09:38,463 - epoch:86,	loss:214.76206076145172
2023-07-11 15:09:45,497 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:09:45,497 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-11 15:09:45,497 - temp:70	temp1:25	wrong_total:92	
2023-07-11 15:09:51,734 - epoch:87,	loss:209.21906876564026
2023-07-11 15:09:58,773 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:09:58,773 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:09:58,773 - temp:66	temp1:25	wrong_total:90	
2023-07-11 15:10:05,104 - epoch:88,	loss:210.82228523492813
2023-07-11 15:10:11,846 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:10:11,846 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:37	wrong_total:92	 wrong be tree ACC: 0.40217391304347827
2023-07-11 15:10:11,846 - temp:67	temp1:27	wrong_total:92	
2023-07-11 15:10:18,132 - epoch:89,	loss:205.5680124759674
2023-07-11 15:10:25,328 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-11 15:10:25,328 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:41	wrong_total:93	 wrong be tree ACC: 0.44086021505376344
2023-07-11 15:10:25,328 - temp:67	temp1:25	wrong_total:93	
2023-07-11 15:10:31,610 - epoch:90,	loss:209.3087722659111
2023-07-11 15:10:38,749 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:10:38,749 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:10:38,749 - temp:65	temp1:24	wrong_total:90	
2023-07-11 15:10:44,663 - epoch:91,	loss:210.81554716825485
2023-07-11 15:10:52,247 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:10:52,247 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:10:52,247 - temp:68	temp1:22	wrong_total:91	
2023-07-11 15:10:58,014 - epoch:92,	loss:202.10152238607407
2023-07-11 15:11:05,969 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:11:05,969 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:11:05,969 - temp:69	temp1:25	wrong_total:92	
2023-07-11 15:11:12,252 - epoch:93,	loss:205.73450821638107
2023-07-11 15:11:19,427 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:11:19,428 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:39	wrong_total:91	 wrong be tree ACC: 0.42857142857142855
2023-07-11 15:11:19,428 - temp:67	temp1:26	wrong_total:91	
2023-07-11 15:11:25,609 - epoch:94,	loss:209.3658241033554
2023-07-11 15:11:32,811 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:11:32,811 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:11:32,811 - temp:69	temp1:26	wrong_total:92	
2023-07-11 15:11:39,134 - epoch:95,	loss:205.29615169763565
2023-07-11 15:11:46,490 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:11:46,491 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:11:46,491 - temp:66	temp1:24	wrong_total:90	
2023-07-11 15:11:52,706 - epoch:96,	loss:207.15820771455765
2023-07-11 15:11:59,774 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:11:59,775 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:41	wrong_total:91	 wrong be tree ACC: 0.45054945054945056
2023-07-11 15:11:59,775 - temp:68	temp1:24	wrong_total:91	
2023-07-11 15:12:05,553 - epoch:97,	loss:202.02857464551926
2023-07-11 15:12:11,998 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:12:11,998 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:38	wrong_total:91	 wrong be tree ACC: 0.4175824175824176
2023-07-11 15:12:11,998 - temp:68	temp1:23	wrong_total:91	
2023-07-11 15:12:17,745 - epoch:98,	loss:207.15200197696686
2023-07-11 15:12:24,813 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:12:24,813 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:12:24,813 - temp:66	temp1:24	wrong_total:91	
2023-07-11 15:12:31,148 - epoch:99,	loss:202.7886615395546
2023-07-11 15:12:38,337 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:12:38,337 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:12:38,337 - temp:67	temp1:26	wrong_total:90	
2023-07-11 15:12:44,574 - epoch:100,	loss:198.3004046678543
2023-07-11 15:12:51,608 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:12:51,608 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:12:51,608 - temp:67	temp1:25	wrong_total:92	
2023-07-11 15:12:57,921 - epoch:101,	loss:200.67609024047852
2023-07-11 15:13:05,174 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:13:05,174 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:91	 wrong be tree ACC: 0.43956043956043955
2023-07-11 15:13:05,174 - temp:66	temp1:24	wrong_total:91	
2023-07-11 15:13:11,372 - epoch:102,	loss:201.97766834497452
2023-07-11 15:13:18,335 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:13:18,336 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:13:18,336 - temp:69	temp1:27	wrong_total:92	
2023-07-11 15:13:24,686 - epoch:103,	loss:199.2270844578743
2023-07-11 15:13:31,124 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:13:31,124 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:13:31,124 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:13:37,003 - epoch:104,	loss:200.95248579978943
2023-07-11 15:13:43,049 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:13:43,050 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-11 15:13:43,050 - temp:67	temp1:24	wrong_total:92	
2023-07-11 15:13:49,260 - epoch:105,	loss:198.50465267896652
2023-07-11 15:13:56,453 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-11 15:13:56,453 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-11 15:13:56,453 - temp:67	temp1:22	wrong_total:90	
2023-07-11 15:14:02,777 - epoch:106,	loss:193.52414578199387
2023-07-11 15:14:09,740 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-11 15:14:09,740 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-11 15:14:09,741 - temp:67	temp1:22	wrong_total:91	
2023-07-11 15:14:16,039 - epoch:107,	loss:196.75894743204117
2023-07-11 15:14:23,161 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:14:23,161 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:14:23,161 - temp:67	temp1:23	wrong_total:92	
2023-07-11 15:14:29,400 - epoch:108,	loss:198.65708547830582
2023-07-11 15:14:36,534 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:14:36,534 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:14:36,534 - temp:67	temp1:24	wrong_total:92	
2023-07-11 15:14:42,800 - epoch:109,	loss:196.10435938835144
2023-07-11 15:14:49,710 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:14:49,710 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:14:49,711 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:14:55,726 - epoch:110,	loss:197.8613702058792
2023-07-11 15:15:02,168 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:15:02,168 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:15:02,168 - temp:67	temp1:24	wrong_total:92	
2023-07-11 15:15:08,407 - epoch:111,	loss:192.2603954076767
2023-07-11 15:15:15,492 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:15:15,492 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:15:15,492 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:15:21,824 - epoch:112,	loss:196.40454053878784
2023-07-11 15:15:29,133 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:15:29,134 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:41	wrong_total:92	 wrong be tree ACC: 0.44565217391304346
2023-07-11 15:15:29,134 - temp:67	temp1:23	wrong_total:92	
2023-07-11 15:15:35,355 - epoch:113,	loss:196.28759652376175
2023-07-11 15:15:42,293 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:15:42,293 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:15:42,293 - temp:67	temp1:23	wrong_total:92	
2023-07-11 15:15:48,519 - epoch:114,	loss:194.5160677433014
2023-07-11 15:15:55,805 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:15:55,805 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:15:55,805 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:16:02,074 - epoch:115,	loss:194.5388720035553
2023-07-11 15:16:09,125 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:16:09,125 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:16:09,125 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:16:14,995 - epoch:116,	loss:194.9991900920868
2023-07-11 15:16:21,422 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:16:21,422 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:16:21,422 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:16:26,920 - epoch:117,	loss:196.25750106573105
2023-07-11 15:16:33,915 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:16:33,915 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:16:33,915 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:16:40,198 - epoch:118,	loss:189.57332575321198
2023-07-11 15:16:47,543 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:16:47,543 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:16:47,543 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:16:53,925 - epoch:119,	loss:193.18204182386398
2023-07-11 15:17:01,118 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:17:01,119 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:17:01,119 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:17:07,442 - epoch:120,	loss:195.89886736869812
2023-07-11 15:17:14,608 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:17:14,609 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:17:14,609 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:17:20,902 - epoch:121,	loss:193.62127894163132
2023-07-11 15:17:28,935 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:17:28,935 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:17:28,936 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:17:35,187 - epoch:122,	loss:193.9823233485222
2023-07-11 15:17:41,666 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:17:41,666 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:40	wrong_total:92	 wrong be tree ACC: 0.43478260869565216
2023-07-11 15:17:41,666 - temp:68	temp1:25	wrong_total:92	
2023-07-11 15:17:47,542 - epoch:123,	loss:193.98079830408096
2023-07-11 15:17:54,108 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:17:54,109 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:17:54,109 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:18:00,259 - epoch:124,	loss:195.71786260604858
2023-07-11 15:18:07,773 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:18:07,773 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:18:07,773 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:18:14,039 - epoch:125,	loss:194.24500441551208
2023-07-11 15:18:21,432 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:18:21,432 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:38	wrong_total:92	 wrong be tree ACC: 0.41304347826086957
2023-07-11 15:18:21,432 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:18:27,636 - epoch:126,	loss:195.30133652687073
2023-07-11 15:18:34,690 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:18:34,690 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:18:34,690 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:18:40,672 - epoch:127,	loss:195.88331997394562
2023-07-11 15:18:48,060 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:18:48,061 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:18:48,061 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:18:54,379 - epoch:128,	loss:196.2700161933899
2023-07-11 15:19:01,028 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:19:01,028 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:19:01,028 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:19:07,003 - epoch:129,	loss:191.95086085796356
2023-07-11 15:19:13,397 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-11 15:19:13,397 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:39	wrong_total:92	 wrong be tree ACC: 0.42391304347826086
2023-07-11 15:19:13,397 - temp:68	temp1:24	wrong_total:92	
2023-07-11 15:19:13,575 - 


2023-07-11 15:19:13,575 - final_test
2023-07-11 15:19:20,595 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-11 15:19:20,596 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-11 15:19:20,596 - temp:73	temp1:34	wrong_total:86	
2023-07-11 15:47:23,597 - 


2023-07-11 15:47:24,092 - get train data loader...
2023-07-11 15:47:24,563 - get dev data loader...
2023-07-11 15:47:24,783 - define model...
2023-07-11 15:47:43,963 - 


2023-07-11 15:47:44,449 - get train data loader...
2023-07-11 15:47:44,878 - get dev data loader...
2023-07-11 15:47:45,118 - define model...
2023-07-11 15:47:52,195 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 15:48:23,568 - 


2023-07-11 15:48:24,064 - get train data loader...
2023-07-11 15:48:24,583 - get dev data loader...
2023-07-11 15:48:24,807 - define model...
2023-07-11 15:48:29,090 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 15:50:36,481 - 


2023-07-11 15:50:37,030 - get train data loader...
2023-07-11 15:50:37,481 - get dev data loader...
2023-07-11 15:50:37,733 - define model...
2023-07-11 15:50:42,702 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-11 15:50:51,048 - epoch:0,	loss:195190.95782470703
2023-07-11 15:50:57,665 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-11 15:50:57,665 - right_codes_count:0	total:1974	Code ACC: 0.0	wrong_be_tree_count:429	wrong_total:433	 wrong be tree ACC: 0.9907621247113164
2023-07-11 15:50:57,665 - temp:384	temp1:71	wrong_total:433	
2023-07-11 15:50:57,719 - save best refiner model to ./output/test/best_model
2023-07-11 15:51:03,507 - epoch:1,	loss:163769.40380859375
2023-07-11 15:51:11,096 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-11 15:51:11,097 - right_codes_count:929	total:1974	Code ACC: 0.4706180344478217	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-11 15:51:11,098 - temp:80	temp1:19	wrong_total:433	
2023-07-11 15:51:17,660 - epoch:2,	loss:111385.16052246094
2023-07-11 15:51:25,390 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-11 15:51:25,391 - right_codes_count:921	total:1974	Code ACC: 0.46656534954407297	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-11 15:51:25,396 - temp:38	temp1:24	wrong_total:433	
2023-07-11 15:51:31,638 - epoch:3,	loss:60847.08190917969
2023-07-11 15:51:39,463 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-11 15:51:39,464 - right_codes_count:914	total:1974	Code ACC: 0.4630192502532928	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-11 15:51:39,465 - temp:23	temp1:144	wrong_total:433	
2023-07-11 15:51:45,953 - epoch:4,	loss:34702.531829833984
2023-07-11 15:51:53,752 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-11 15:51:53,752 - right_codes_count:908	total:1974	Code ACC: 0.45997973657548125	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-11 15:51:53,752 - temp:22	temp1:343	wrong_total:433	
2023-07-11 15:51:59,984 - epoch:5,	loss:24859.4761428833
2023-07-11 15:52:07,448 - right_count:111	total:433	 Answer ACC: 0.25635103926096997
2023-07-11 15:52:07,448 - right_codes_count:1309	total:1974	Code ACC: 0.6631205673758865	wrong_be_tree_count:160	wrong_total:322	 wrong be tree ACC: 0.4968944099378882
2023-07-11 15:52:07,448 - temp:30	temp1:213	wrong_total:322	
2023-07-11 15:52:07,452 - save best refiner model to ./output/test/best_model
2023-07-11 15:52:13,323 - epoch:6,	loss:19978.474266052246
2023-07-11 15:52:20,985 - right_count:149	total:433	 Answer ACC: 0.3441108545034642
2023-07-11 15:52:20,985 - right_codes_count:1445	total:1974	Code ACC: 0.732016210739615	wrong_be_tree_count:41	wrong_total:284	 wrong be tree ACC: 0.1443661971830986
2023-07-11 15:52:20,986 - temp:41	temp1:179	wrong_total:284	
2023-07-11 15:52:20,990 - save best refiner model to ./output/test/best_model
2023-07-11 15:52:26,799 - epoch:7,	loss:16843.29365158081
2023-07-11 15:52:35,339 - right_count:203	total:433	 Answer ACC: 0.46882217090069284
2023-07-11 15:52:35,339 - right_codes_count:1521	total:1974	Code ACC: 0.770516717325228	wrong_be_tree_count:27	wrong_total:230	 wrong be tree ACC: 0.11739130434782609
2023-07-11 15:52:35,339 - temp:43	temp1:161	wrong_total:230	
2023-07-11 15:52:35,347 - save best refiner model to ./output/test/best_model
2023-07-11 15:52:41,673 - epoch:8,	loss:14445.008419036865
2023-07-11 15:52:49,690 - right_count:251	total:433	 Answer ACC: 0.5796766743648961
2023-07-11 15:52:49,690 - right_codes_count:1580	total:1974	Code ACC: 0.8004052684903749	wrong_be_tree_count:21	wrong_total:182	 wrong be tree ACC: 0.11538461538461539
2023-07-11 15:52:49,690 - temp:44	temp1:115	wrong_total:182	
2023-07-11 15:52:49,692 - save best refiner model to ./output/test/best_model
2023-07-11 15:52:56,293 - epoch:9,	loss:12683.24422454834
2023-07-11 15:53:03,576 - right_count:262	total:433	 Answer ACC: 0.605080831408776
2023-07-11 15:53:03,576 - right_codes_count:1604	total:1974	Code ACC: 0.8125633232016211	wrong_be_tree_count:16	wrong_total:171	 wrong be tree ACC: 0.0935672514619883
2023-07-11 15:53:03,577 - temp:49	temp1:106	wrong_total:171	
2023-07-11 15:53:03,579 - save best refiner model to ./output/test/best_model
2023-07-11 15:53:09,983 - epoch:10,	loss:11329.6555519104
2023-07-11 15:53:16,830 - right_count:285	total:433	 Answer ACC: 0.6581986143187067
2023-07-11 15:53:16,830 - right_codes_count:1661	total:1974	Code ACC: 0.8414387031408308	wrong_be_tree_count:54	wrong_total:148	 wrong be tree ACC: 0.36486486486486486
2023-07-11 15:53:16,830 - temp:48	temp1:66	wrong_total:148	
2023-07-11 15:53:16,832 - save best refiner model to ./output/test/best_model
2023-07-11 15:53:23,175 - epoch:11,	loss:10266.088203430176
2023-07-11 15:53:30,242 - right_count:287	total:433	 Answer ACC: 0.6628175519630485
2023-07-11 15:53:30,243 - right_codes_count:1664	total:1974	Code ACC: 0.8429584599797366	wrong_be_tree_count:51	wrong_total:146	 wrong be tree ACC: 0.3493150684931507
2023-07-11 15:53:30,243 - temp:58	temp1:68	wrong_total:146	
2023-07-11 15:53:30,244 - save best refiner model to ./output/test/best_model
2023-07-11 15:53:36,272 - epoch:12,	loss:9421.345311164856
2023-07-11 15:53:43,136 - right_count:296	total:433	 Answer ACC: 0.6836027713625866
2023-07-11 15:53:43,136 - right_codes_count:1676	total:1974	Code ACC: 0.8490374873353597	wrong_be_tree_count:47	wrong_total:137	 wrong be tree ACC: 0.34306569343065696
2023-07-11 15:53:43,136 - temp:63	temp1:77	wrong_total:137	
2023-07-11 15:53:43,141 - save best refiner model to ./output/test/best_model
2023-07-11 15:53:48,948 - epoch:13,	loss:8763.231986999512
2023-07-11 15:53:56,604 - right_count:297	total:433	 Answer ACC: 0.6859122401847575
2023-07-11 15:53:56,605 - right_codes_count:1677	total:1974	Code ACC: 0.8495440729483282	wrong_be_tree_count:45	wrong_total:136	 wrong be tree ACC: 0.33088235294117646
2023-07-11 15:53:56,606 - temp:67	temp1:80	wrong_total:136	
2023-07-11 15:53:56,609 - save best refiner model to ./output/test/best_model
2023-07-11 15:54:03,124 - epoch:14,	loss:8298.551871299744
2023-07-11 15:54:10,442 - right_count:298	total:433	 Answer ACC: 0.6882217090069284
2023-07-11 15:54:10,442 - right_codes_count:1678	total:1974	Code ACC: 0.8500506585612969	wrong_be_tree_count:52	wrong_total:135	 wrong be tree ACC: 0.3851851851851852
2023-07-11 15:54:10,442 - temp:65	temp1:77	wrong_total:135	
2023-07-11 15:54:10,445 - save best refiner model to ./output/test/best_model
2023-07-11 15:54:16,776 - epoch:15,	loss:7822.267734050751
2023-07-11 15:54:24,766 - right_count:304	total:433	 Answer ACC: 0.7020785219399538
2023-07-11 15:54:24,766 - right_codes_count:1692	total:1974	Code ACC: 0.8571428571428571	wrong_be_tree_count:48	wrong_total:129	 wrong be tree ACC: 0.37209302325581395
2023-07-11 15:54:24,766 - temp:72	temp1:66	wrong_total:129	
2023-07-11 15:54:24,774 - save best refiner model to ./output/test/best_model
2023-07-11 15:54:31,177 - epoch:16,	loss:7476.613269805908
2023-07-11 15:54:38,545 - right_count:315	total:433	 Answer ACC: 0.7274826789838337
2023-07-11 15:54:38,546 - right_codes_count:1706	total:1974	Code ACC: 0.8642350557244174	wrong_be_tree_count:44	wrong_total:118	 wrong be tree ACC: 0.3728813559322034
2023-07-11 15:54:38,546 - temp:64	temp1:60	wrong_total:118	
2023-07-11 15:54:38,549 - save best refiner model to ./output/test/best_model
2023-07-11 15:54:44,959 - epoch:17,	loss:7243.833189964294
2023-07-11 15:54:52,841 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:54:52,841 - right_codes_count:1699	total:1974	Code ACC: 0.8606889564336373	wrong_be_tree_count:43	wrong_total:119	 wrong be tree ACC: 0.36134453781512604
2023-07-11 15:54:52,841 - temp:72	temp1:61	wrong_total:119	
2023-07-11 15:54:58,901 - epoch:18,	loss:6965.72985458374
2023-07-11 15:55:05,902 - right_count:317	total:433	 Answer ACC: 0.7321016166281755
2023-07-11 15:55:05,902 - right_codes_count:1707	total:1974	Code ACC: 0.8647416413373861	wrong_be_tree_count:46	wrong_total:116	 wrong be tree ACC: 0.39655172413793105
2023-07-11 15:55:05,902 - temp:77	temp1:61	wrong_total:116	
2023-07-11 15:55:05,904 - save best refiner model to ./output/test/best_model
2023-07-11 15:55:11,524 - epoch:19,	loss:6775.048319816589
2023-07-11 15:55:19,344 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-11 15:55:19,344 - right_codes_count:1713	total:1974	Code ACC: 0.8677811550151976	wrong_be_tree_count:51	wrong_total:117	 wrong be tree ACC: 0.4358974358974359
2023-07-11 15:55:19,344 - temp:75	temp1:55	wrong_total:117	
2023-07-11 15:55:25,945 - epoch:20,	loss:6594.248876571655
2023-07-11 15:55:33,380 - right_count:318	total:433	 Answer ACC: 0.7344110854503464
2023-07-11 15:55:33,380 - right_codes_count:1705	total:1974	Code ACC: 0.8637284701114488	wrong_be_tree_count:45	wrong_total:115	 wrong be tree ACC: 0.391304347826087
2023-07-11 15:55:33,380 - temp:76	temp1:61	wrong_total:115	
2023-07-11 15:55:33,385 - save best refiner model to ./output/test/best_model
2023-07-11 15:55:39,897 - epoch:21,	loss:6457.096866607666
2023-07-11 15:55:48,810 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-11 15:55:48,810 - right_codes_count:1709	total:1974	Code ACC: 0.8657548125633232	wrong_be_tree_count:47	wrong_total:117	 wrong be tree ACC: 0.4017094017094017
2023-07-11 15:55:48,816 - temp:77	temp1:60	wrong_total:117	
2023-07-11 15:55:55,311 - epoch:22,	loss:6358.937627792358
2023-07-11 15:56:02,929 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-11 15:56:02,929 - right_codes_count:1708	total:1974	Code ACC: 0.8652482269503546	wrong_be_tree_count:50	wrong_total:117	 wrong be tree ACC: 0.42735042735042733
2023-07-11 15:56:02,929 - temp:69	temp1:50	wrong_total:117	
2023-07-11 15:56:09,380 - epoch:23,	loss:6167.139614105225
2023-07-11 15:56:17,179 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:56:17,179 - right_codes_count:1716	total:1974	Code ACC: 0.8693009118541033	wrong_be_tree_count:60	wrong_total:119	 wrong be tree ACC: 0.5042016806722689
2023-07-11 15:56:17,179 - temp:72	temp1:51	wrong_total:119	
2023-07-11 15:56:23,168 - epoch:24,	loss:6000.013118207455
2023-07-11 15:56:29,908 - right_count:315	total:433	 Answer ACC: 0.7274826789838337
2023-07-11 15:56:29,908 - right_codes_count:1716	total:1974	Code ACC: 0.8693009118541033	wrong_be_tree_count:56	wrong_total:118	 wrong be tree ACC: 0.4745762711864407
2023-07-11 15:56:29,908 - temp:72	temp1:48	wrong_total:118	
2023-07-11 15:56:35,676 - epoch:25,	loss:5914.214819908142
2023-07-11 15:56:43,420 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:56:43,420 - right_codes_count:1701	total:1974	Code ACC: 0.8617021276595744	wrong_be_tree_count:48	wrong_total:119	 wrong be tree ACC: 0.40336134453781514
2023-07-11 15:56:43,427 - temp:72	temp1:58	wrong_total:119	
2023-07-11 15:56:49,782 - epoch:26,	loss:5810.958188056946
2023-07-11 15:56:58,195 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-11 15:56:58,195 - right_codes_count:1721	total:1974	Code ACC: 0.8718338399189463	wrong_be_tree_count:55	wrong_total:113	 wrong be tree ACC: 0.48672566371681414
2023-07-11 15:56:58,195 - temp:71	temp1:49	wrong_total:113	
2023-07-11 15:56:58,197 - save best refiner model to ./output/test/best_model
2023-07-11 15:57:04,720 - epoch:27,	loss:5738.9099197387695
2023-07-11 15:57:12,748 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:57:12,749 - right_codes_count:1710	total:1974	Code ACC: 0.8662613981762918	wrong_be_tree_count:53	wrong_total:119	 wrong be tree ACC: 0.44537815126050423
2023-07-11 15:57:12,753 - temp:73	temp1:54	wrong_total:119	
2023-07-11 15:57:19,309 - epoch:28,	loss:5663.536136627197
2023-07-11 15:57:27,198 - right_count:315	total:433	 Answer ACC: 0.7274826789838337
2023-07-11 15:57:27,198 - right_codes_count:1699	total:1974	Code ACC: 0.8606889564336373	wrong_be_tree_count:52	wrong_total:118	 wrong be tree ACC: 0.4406779661016949
2023-07-11 15:57:27,206 - temp:82	temp1:57	wrong_total:118	
2023-07-11 15:57:33,731 - epoch:29,	loss:5542.630352020264
2023-07-11 15:57:41,526 - right_count:311	total:433	 Answer ACC: 0.7182448036951501
2023-07-11 15:57:41,526 - right_codes_count:1712	total:1974	Code ACC: 0.867274569402229	wrong_be_tree_count:58	wrong_total:122	 wrong be tree ACC: 0.47540983606557374
2023-07-11 15:57:41,526 - temp:74	temp1:58	wrong_total:122	
2023-07-11 15:57:47,526 - epoch:30,	loss:5385.997394561768
2023-07-11 15:57:54,455 - right_count:311	total:433	 Answer ACC: 0.7182448036951501
2023-07-11 15:57:54,455 - right_codes_count:1696	total:1974	Code ACC: 0.8591691995947315	wrong_be_tree_count:48	wrong_total:122	 wrong be tree ACC: 0.39344262295081966
2023-07-11 15:57:54,455 - temp:81	temp1:53	wrong_total:122	
2023-07-11 15:58:00,836 - epoch:31,	loss:5402.340092658997
2023-07-11 15:58:08,552 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:58:08,552 - right_codes_count:1712	total:1974	Code ACC: 0.867274569402229	wrong_be_tree_count:51	wrong_total:119	 wrong be tree ACC: 0.42857142857142855
2023-07-11 15:58:08,552 - temp:73	temp1:50	wrong_total:119	
2023-07-11 15:58:14,905 - epoch:32,	loss:5286.597713470459
2023-07-11 15:58:22,745 - right_count:309	total:433	 Answer ACC: 0.7136258660508084
2023-07-11 15:58:22,746 - right_codes_count:1708	total:1974	Code ACC: 0.8652482269503546	wrong_be_tree_count:59	wrong_total:124	 wrong be tree ACC: 0.47580645161290325
2023-07-11 15:58:22,746 - temp:76	temp1:48	wrong_total:124	
2023-07-11 15:58:29,194 - epoch:33,	loss:5227.414520025253
2023-07-11 15:58:37,459 - right_count:312	total:433	 Answer ACC: 0.7205542725173211
2023-07-11 15:58:37,459 - right_codes_count:1707	total:1974	Code ACC: 0.8647416413373861	wrong_be_tree_count:60	wrong_total:121	 wrong be tree ACC: 0.49586776859504134
2023-07-11 15:58:37,466 - temp:82	temp1:52	wrong_total:121	
2023-07-11 15:58:43,987 - epoch:34,	loss:5220.526445388794
2023-07-11 15:58:52,161 - right_count:310	total:433	 Answer ACC: 0.7159353348729792
2023-07-11 15:58:52,161 - right_codes_count:1712	total:1974	Code ACC: 0.867274569402229	wrong_be_tree_count:59	wrong_total:123	 wrong be tree ACC: 0.4796747967479675
2023-07-11 15:58:52,162 - temp:74	temp1:43	wrong_total:123	
2023-07-11 15:58:58,756 - epoch:35,	loss:5109.802261352539
2023-07-11 15:59:06,436 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:59:06,436 - right_codes_count:1714	total:1974	Code ACC: 0.8682877406281662	wrong_be_tree_count:57	wrong_total:119	 wrong be tree ACC: 0.4789915966386555
2023-07-11 15:59:06,436 - temp:81	temp1:58	wrong_total:119	
2023-07-11 15:59:12,419 - epoch:36,	loss:5068.8582973480225
2023-07-11 15:59:18,943 - right_count:314	total:433	 Answer ACC: 0.7251732101616628
2023-07-11 15:59:18,943 - right_codes_count:1710	total:1974	Code ACC: 0.8662613981762918	wrong_be_tree_count:53	wrong_total:119	 wrong be tree ACC: 0.44537815126050423
2023-07-11 15:59:18,943 - temp:73	temp1:50	wrong_total:119	
2023-07-11 15:59:25,042 - epoch:37,	loss:4914.494153022766
2023-07-11 15:59:33,367 - right_count:310	total:433	 Answer ACC: 0.7159353348729792
2023-07-11 15:59:33,368 - right_codes_count:1711	total:1974	Code ACC: 0.8667679837892603	wrong_be_tree_count:60	wrong_total:123	 wrong be tree ACC: 0.4878048780487805
2023-07-11 15:59:33,368 - temp:75	temp1:49	wrong_total:123	
2023-07-11 15:59:39,702 - epoch:38,	loss:4972.156856536865
2023-07-11 15:59:47,904 - right_count:313	total:433	 Answer ACC: 0.7228637413394919
2023-07-11 15:59:47,904 - right_codes_count:1703	total:1974	Code ACC: 0.8627152988855117	wrong_be_tree_count:50	wrong_total:120	 wrong be tree ACC: 0.4166666666666667
2023-07-11 15:59:47,904 - temp:75	temp1:57	wrong_total:120	
2023-07-11 15:59:54,419 - epoch:39,	loss:4829.592361450195
2023-07-11 16:00:02,533 - right_count:318	total:433	 Answer ACC: 0.7344110854503464
2023-07-11 16:00:02,533 - right_codes_count:1717	total:1974	Code ACC: 0.869807497467072	wrong_be_tree_count:56	wrong_total:115	 wrong be tree ACC: 0.48695652173913045
2023-07-11 16:00:02,533 - temp:80	temp1:43	wrong_total:115	
2023-07-11 16:00:08,959 - epoch:40,	loss:4859.53239440918
2023-07-11 16:00:16,917 - right_count:318	total:433	 Answer ACC: 0.7344110854503464
2023-07-11 16:00:16,918 - right_codes_count:1719	total:1974	Code ACC: 0.8708206686930091	wrong_be_tree_count:56	wrong_total:115	 wrong be tree ACC: 0.48695652173913045
2023-07-11 16:00:16,918 - temp:79	temp1:48	wrong_total:115	
2023-07-11 16:00:23,398 - epoch:41,	loss:4735.174415588379
2023-07-11 16:00:31,042 - right_count:308	total:433	 Answer ACC: 0.7113163972286374
2023-07-11 16:00:31,042 - right_codes_count:1709	total:1974	Code ACC: 0.8657548125633232	wrong_be_tree_count:61	wrong_total:125	 wrong be tree ACC: 0.488
2023-07-11 16:00:31,042 - temp:81	temp1:44	wrong_total:125	
2023-07-11 16:00:37,097 - epoch:42,	loss:4648.978723526001
2023-07-11 16:00:44,629 - right_count:320	total:433	 Answer ACC: 0.7390300230946882
2023-07-11 16:00:44,629 - right_codes_count:1726	total:1974	Code ACC: 0.8743667679837892	wrong_be_tree_count:56	wrong_total:113	 wrong be tree ACC: 0.49557522123893805
2023-07-11 16:00:44,629 - temp:77	temp1:43	wrong_total:113	
2023-07-11 16:00:50,920 - epoch:43,	loss:4649.586380958557
2023-07-11 16:00:59,095 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-11 16:00:59,096 - right_codes_count:1714	total:1974	Code ACC: 0.8682877406281662	wrong_be_tree_count:53	wrong_total:117	 wrong be tree ACC: 0.452991452991453
2023-07-11 16:00:59,096 - temp:82	temp1:49	wrong_total:117	
2023-07-11 16:01:05,481 - epoch:44,	loss:4627.635349273682
2023-07-11 16:01:13,758 - right_count:313	total:433	 Answer ACC: 0.7228637413394919
2023-07-11 16:01:13,758 - right_codes_count:1710	total:1974	Code ACC: 0.8662613981762918	wrong_be_tree_count:57	wrong_total:120	 wrong be tree ACC: 0.475
2023-07-11 16:01:13,760 - temp:82	temp1:51	wrong_total:120	
2023-07-11 16:01:20,351 - epoch:45,	loss:4628.2787799835205
2023-07-11 16:01:29,157 - right_count:316	total:433	 Answer ACC: 0.7297921478060047
2023-07-11 16:01:29,158 - right_codes_count:1718	total:1974	Code ACC: 0.8703140830800405	wrong_be_tree_count:54	wrong_total:117	 wrong be tree ACC: 0.46153846153846156
2023-07-11 16:01:29,164 - temp:75	temp1:52	wrong_total:117	
2023-07-11 16:01:35,778 - epoch:46,	loss:4506.335186958313
2023-07-11 17:00:49,467 - 


2023-07-11 17:00:50,655 - get train data loader...
2023-07-11 17:00:50,930 - get dev data loader...
2023-07-11 17:00:51,010 - define model...
2023-07-11 17:05:19,902 - 


2023-07-11 17:05:20,511 - get train data loader...
2023-07-11 17:05:20,828 - get dev data loader...
2023-07-11 17:05:20,977 - define model...
2023-07-11 19:37:12,256 - 


2023-07-11 19:37:13,219 - get train data loader...
2023-07-11 19:37:13,372 - get dev data loader...
2023-07-11 19:37:13,402 - define model...
2023-07-11 19:41:55,001 - 


2023-07-11 19:41:55,875 - get train data loader...
2023-07-11 19:41:56,191 - get dev data loader...
2023-07-11 19:41:56,333 - define model...
2023-07-11 19:45:15,323 - 


2023-07-11 19:45:15,806 - get train data loader...
2023-07-11 19:45:16,120 - get dev data loader...
2023-07-11 19:45:16,253 - define model...
2023-07-11 19:46:26,373 - 


2023-07-11 19:46:26,856 - get train data loader...
2023-07-11 19:46:27,160 - get dev data loader...
2023-07-11 19:46:27,288 - define model...
2023-07-11 19:48:01,544 - 


2023-07-11 19:48:02,010 - get train data loader...
2023-07-11 19:48:02,314 - get dev data loader...
2023-07-11 19:48:02,458 - define model...
2023-07-11 19:49:05,420 - 


2023-07-11 19:49:05,882 - get train data loader...
2023-07-11 19:49:06,179 - get dev data loader...
2023-07-11 19:49:06,329 - define model...
2023-07-11 19:51:16,107 - 


2023-07-11 19:51:16,586 - get train data loader...
2023-07-11 19:51:16,895 - get dev data loader...
2023-07-11 19:51:17,035 - define model...
2023-07-11 19:53:18,862 - 


2023-07-11 19:53:19,315 - get train data loader...
2023-07-11 19:53:19,630 - get dev data loader...
2023-07-11 19:53:19,780 - define model...
2023-07-11 20:01:03,117 - 


2023-07-11 20:01:03,604 - get train data loader...
2023-07-11 20:01:03,903 - get dev data loader...
2023-07-11 20:01:04,034 - define model...
2023-07-11 20:15:13,495 - 


2023-07-11 20:15:14,076 - get train data loader...
2023-07-11 20:15:14,376 - get dev data loader...
2023-07-11 20:15:14,504 - define model...
2023-07-11 20:17:17,129 - 


2023-07-11 20:17:17,588 - get train data loader...
2023-07-11 20:17:17,879 - get dev data loader...
2023-07-11 20:17:18,011 - define model...
2023-07-11 20:18:39,825 - 


2023-07-11 20:18:40,281 - get train data loader...
2023-07-11 20:18:40,578 - get dev data loader...
2023-07-11 20:18:40,717 - define model...
2023-07-11 20:21:32,262 - 


2023-07-11 20:21:32,797 - get train data loader...
2023-07-11 20:21:32,918 - get dev data loader...
2023-07-11 20:21:33,008 - define model...
2023-07-11 20:24:15,501 - 


2023-07-11 20:24:15,955 - get train data loader...
2023-07-11 20:24:16,068 - get dev data loader...
2023-07-11 20:24:16,140 - define model...
2023-07-11 20:27:25,137 - 


2023-07-11 20:27:25,592 - get train data loader...
2023-07-11 20:27:25,701 - get dev data loader...
2023-07-11 20:27:25,775 - define model...
2023-07-11 20:29:41,004 - 


2023-07-11 20:29:41,458 - get train data loader...
2023-07-11 20:29:41,569 - get dev data loader...
2023-07-11 20:29:41,658 - define model...
2023-07-11 20:35:14,059 - 


2023-07-11 20:35:14,534 - get train data loader...
2023-07-11 20:35:14,678 - get dev data loader...
2023-07-11 20:35:14,758 - define model...
2023-07-11 21:14:17,979 - 


2023-07-11 21:14:18,816 - get train data loader...
2023-07-11 21:14:18,942 - get dev data loader...
2023-07-11 21:14:19,017 - define model...
2023-07-11 21:21:01,502 - 


2023-07-11 21:21:02,357 - get train data loader...
2023-07-11 21:21:02,682 - get dev data loader...
2023-07-11 21:21:02,815 - define model...
2023-07-11 21:31:53,560 - 


2023-07-11 21:31:54,007 - get train data loader...
2023-07-11 21:31:54,125 - get dev data loader...
2023-07-11 21:31:54,227 - define model...
2023-07-11 21:40:40,823 - 


2023-07-11 21:40:41,333 - get train data loader...
2023-07-11 21:40:41,439 - get dev data loader...
2023-07-11 21:40:41,516 - define model...
2023-07-11 21:46:17,202 - 


2023-07-11 21:46:18,027 - get train data loader...
2023-07-11 21:46:18,156 - get dev data loader...
2023-07-11 21:46:18,238 - define model...
2023-07-11 21:47:18,444 - 


2023-07-11 21:47:18,898 - get train data loader...
2023-07-11 21:47:19,012 - get dev data loader...
2023-07-11 21:47:19,086 - define model...
2023-07-11 21:55:12,962 - 


2023-07-11 21:55:13,823 - get train data loader...
2023-07-11 21:55:13,968 - get dev data loader...
2023-07-11 21:55:14,051 - define model...
2023-07-11 22:10:56,074 - 


2023-07-11 22:10:56,535 - get train data loader...
2023-07-11 22:10:56,724 - get dev data loader...
2023-07-11 22:10:56,811 - define model...
2023-07-11 22:12:06,275 - 


2023-07-11 22:12:06,729 - get train data loader...
2023-07-11 22:12:06,848 - get dev data loader...
2023-07-11 22:12:06,933 - define model...
2023-07-11 22:18:32,735 - 


2023-07-11 22:18:33,445 - get train data loader...
2023-07-11 22:18:33,555 - get dev data loader...
2023-07-11 22:18:33,623 - define model...
2023-07-11 22:24:06,041 - 


2023-07-11 22:24:06,487 - get train data loader...
2023-07-11 22:24:06,598 - get dev data loader...
2023-07-11 22:24:06,682 - define model...
2023-07-11 22:24:25,240 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-11 22:24:25,240 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-11 22:24:25,240 - temp:0	temp1:0	wrong_total:226	
2023-07-12 14:54:50,059 - 


2023-07-12 14:54:51,063 - get train data loader...
2023-07-12 14:54:51,359 - get dev data loader...
2023-07-12 14:54:51,494 - define model...
2023-07-12 14:55:15,244 - right_count:398	total:431	 Answer ACC: 0.9234338747099768
2023-07-12 14:55:15,244 - right_codes_count:1936	total:1985	Code ACC: 0.9753148614609571	wrong_be_tree_count:22	wrong_total:33	 wrong be tree ACC: 0.6666666666666666
2023-07-12 14:55:15,246 - temp:18	temp1:18	wrong_total:49	
2023-07-12 14:55:46,090 - 


2023-07-12 14:55:47,608 - get train data loader...
2023-07-12 14:55:47,903 - get dev data loader...
2023-07-12 14:55:48,056 - define model...
2023-07-12 14:56:08,214 - right_count:398	total:431	 Answer ACC: 0.9234338747099768
2023-07-12 14:56:08,215 - right_codes_count:1936	total:1985	Code ACC: 0.9753148614609571	wrong_be_tree_count:22	wrong_total:33	 wrong be tree ACC: 0.6666666666666666
2023-07-12 14:56:08,215 - temp:18	temp1:18	wrong_total:49	
2023-07-12 14:58:18,843 - 


2023-07-12 14:58:19,454 - get train data loader...
2023-07-12 14:58:19,765 - get dev data loader...
2023-07-12 14:58:19,894 - define model...
2023-07-12 15:48:28,221 - 


2023-07-12 15:48:29,243 - get train data loader...
2023-07-12 15:48:29,429 - get dev data loader...
2023-07-12 15:48:29,570 - define model...
2023-07-12 15:48:42,397 - right_count:354	total:433	 Answer ACC: 0.8175519630484989
2023-07-12 15:48:42,398 - right_codes_count:1790	total:1974	Code ACC: 0.9067882472137792	wrong_be_tree_count:34	wrong_total:79	 wrong be tree ACC: 0.43037974683544306
2023-07-12 15:48:42,398 - temp:73	temp1:18	wrong_total:184	
2023-07-18 16:16:10,163 - 


2023-07-18 16:16:11,261 - get train data loader...
2023-07-18 16:16:11,419 - get dev data loader...
2023-07-18 16:16:11,531 - define model...
2023-07-18 16:17:58,736 - 


2023-07-18 16:17:59,201 - get train data loader...
2023-07-18 16:17:59,347 - get dev data loader...
2023-07-18 16:17:59,428 - define model...
2023-07-18 16:20:18,134 - 


2023-07-18 16:20:18,919 - get train data loader...
2023-07-18 16:20:19,051 - get dev data loader...
2023-07-18 16:20:19,134 - define model...
2023-07-18 16:22:22,453 - 


2023-07-18 16:22:23,274 - get train data loader...
2023-07-18 16:22:23,416 - get dev data loader...
2023-07-18 16:22:23,489 - define model...
2023-07-18 16:25:05,686 - 


2023-07-18 16:25:06,440 - get train data loader...
2023-07-18 16:25:06,550 - get dev data loader...
2023-07-18 16:25:06,637 - define model...
2023-07-18 16:25:49,065 - 


2023-07-18 16:25:49,813 - get train data loader...
2023-07-18 16:25:49,925 - get dev data loader...
2023-07-18 16:25:49,996 - define model...
2023-07-18 16:32:56,156 - 


2023-07-18 16:32:57,152 - get train data loader...
2023-07-18 16:32:57,316 - get dev data loader...
2023-07-18 16:32:57,431 - define model...
2023-07-18 16:33:39,904 - 


2023-07-18 16:33:40,725 - get train data loader...
2023-07-18 16:33:40,887 - get dev data loader...
2023-07-18 16:33:41,009 - define model...
2023-07-18 16:34:36,258 - 


2023-07-18 16:34:36,703 - get train data loader...
2023-07-18 16:34:36,894 - get dev data loader...
2023-07-18 16:34:37,001 - define model...
2023-07-21 17:59:14,282 - 


2023-07-21 17:59:15,179 - get train data loader...
2023-07-21 17:59:15,814 - get dev data loader...
2023-07-21 17:59:15,911 - define model...
2023-07-21 17:59:36,734 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-21 17:59:54,842 - 

2023-07-21 17:59:54,843 - epoch:0,	loss:151852.98022460938	loss1:0
2023-07-21 18:01:18,982 - 


2023-07-21 18:01:19,431 - get train data loader...
2023-07-21 18:01:19,556 - get dev data loader...
2023-07-21 18:01:19,663 - define model...
2023-07-21 18:01:23,919 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-21 18:01:32,721 - 

2023-07-21 18:01:32,721 - epoch:0,	loss:151852.98022460938	loss1:0
2023-07-21 18:04:00,712 - 


2023-07-21 18:04:01,167 - get train data loader...
2023-07-21 18:04:01,307 - get dev data loader...
2023-07-21 18:04:01,399 - define model...
2023-07-21 18:04:05,496 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-21 18:04:14,293 - 

2023-07-21 18:04:14,293 - epoch:0,	loss:151852.98022460938	loss1:0
2023-07-21 18:07:05,869 - 


2023-07-21 18:07:06,404 - get train data loader...
2023-07-21 18:07:06,537 - get dev data loader...
2023-07-21 18:07:06,617 - define model...
2023-07-21 18:07:10,770 - 
>>>>>>>>>>>>>>>>>>>start train......
2023-07-21 18:07:19,420 - 

2023-07-21 18:07:19,420 - epoch:0,	loss:151852.98022460938	loss1:0
2023-07-21 18:07:27,342 - right_count:1	total:433	 Answer ACC: 0.0023094688221709007
2023-07-21 18:07:27,342 - right_codes_count:0	total:1974	Code ACC: 0.0	wrong_be_tree_count:418	wrong_total:432	 wrong be tree ACC: 0.9675925925925926
2023-07-21 18:07:27,342 - right_checker:0	total:1974	checker ACC: 0.0	temp:0	temp1:0	wrong_total:432	
2023-07-21 18:07:27,347 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:07:44,774 - 

2023-07-21 18:07:44,774 - epoch:1,	loss:117680.25030517578	loss1:0
2023-07-21 18:07:52,269 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-21 18:07:52,269 - right_codes_count:952	total:1974	Code ACC: 0.48226950354609927	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-21 18:07:52,269 - right_checker:952	total:1974	checker ACC: 0.4822695255279541	temp:0	temp1:0	wrong_total:433	
2023-07-21 18:08:04,485 - 

2023-07-21 18:08:04,485 - epoch:2,	loss:62909.558990478516	loss1:0
2023-07-21 18:08:12,000 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-21 18:08:12,000 - right_codes_count:572	total:1974	Code ACC: 0.28976697061803447	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-21 18:08:12,000 - right_checker:572	total:1974	checker ACC: 0.28976699709892273	temp:0	temp1:0	wrong_total:433	
2023-07-21 18:08:24,042 - 

2023-07-21 18:08:24,042 - epoch:3,	loss:26934.158721923828	loss1:0
2023-07-21 18:08:31,913 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-21 18:08:31,913 - right_codes_count:858	total:1974	Code ACC: 0.43465045592705165	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-21 18:08:31,915 - right_checker:858	total:1974	checker ACC: 0.4346504807472229	temp:0	temp1:0	wrong_total:433	
2023-07-21 18:08:44,166 - 

2023-07-21 18:08:44,166 - epoch:4,	loss:16024.05256652832	loss1:0
2023-07-21 18:08:52,272 - right_count:0	total:433	 Answer ACC: 0.0
2023-07-21 18:08:52,272 - right_codes_count:858	total:1974	Code ACC: 0.43465045592705165	wrong_be_tree_count:433	wrong_total:433	 wrong be tree ACC: 1.0
2023-07-21 18:08:52,272 - right_checker:858	total:1974	checker ACC: 0.4346504807472229	temp:0	temp1:0	wrong_total:433	
2023-07-21 18:09:04,526 - 

2023-07-21 18:09:04,526 - epoch:5,	loss:14082.283569335938	loss1:0
2023-07-21 18:09:12,386 - right_count:27	total:433	 Answer ACC: 0.06235565819861432
2023-07-21 18:09:12,387 - right_codes_count:1046	total:1974	Code ACC: 0.5298885511651469	wrong_be_tree_count:95	wrong_total:406	 wrong be tree ACC: 0.23399014778325122
2023-07-21 18:09:12,388 - right_checker:1046	total:1974	checker ACC: 0.5298885703086853	temp:0	temp1:0	wrong_total:406	
2023-07-21 18:09:12,394 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:09:29,466 - 

2023-07-21 18:09:29,466 - epoch:6,	loss:12726.491325378418	loss1:0
2023-07-21 18:09:37,769 - right_count:95	total:433	 Answer ACC: 0.21939953810623555
2023-07-21 18:09:37,769 - right_codes_count:1256	total:1974	Code ACC: 0.6362715298885512	wrong_be_tree_count:109	wrong_total:338	 wrong be tree ACC: 0.3224852071005917
2023-07-21 18:09:37,770 - right_checker:1256	total:1974	checker ACC: 0.6362715363502502	temp:0	temp1:0	wrong_total:338	
2023-07-21 18:09:37,772 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:09:54,598 - 

2023-07-21 18:09:54,599 - epoch:7,	loss:10532.908172607422	loss1:0
2023-07-21 18:10:02,652 - right_count:168	total:433	 Answer ACC: 0.38799076212471134
2023-07-21 18:10:02,653 - right_codes_count:1420	total:1974	Code ACC: 0.7193515704154002	wrong_be_tree_count:17	wrong_total:265	 wrong be tree ACC: 0.06415094339622641
2023-07-21 18:10:02,653 - right_checker:1420	total:1974	checker ACC: 0.719351589679718	temp:0	temp1:0	wrong_total:265	
2023-07-21 18:10:02,657 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:10:19,856 - 

2023-07-21 18:10:19,856 - epoch:8,	loss:9207.815002441406	loss1:2859.925274848938
2023-07-21 18:10:27,850 - right_count:189	total:433	 Answer ACC: 0.43648960739030024
2023-07-21 18:10:27,850 - right_codes_count:1480	total:1974	Code ACC: 0.7497467071935157	wrong_be_tree_count:31	wrong_total:244	 wrong be tree ACC: 0.12704918032786885
2023-07-21 18:10:27,850 - right_checker:1480	total:1974	checker ACC: 0.7497467398643494	temp:0	temp1:0	wrong_total:244	
2023-07-21 18:10:27,855 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:10:45,115 - 

2023-07-21 18:10:45,115 - epoch:9,	loss:8181.765064239502	loss1:2550.781632423401
2023-07-21 18:10:53,290 - right_count:227	total:433	 Answer ACC: 0.5242494226327945
2023-07-21 18:10:53,290 - right_codes_count:1545	total:1974	Code ACC: 0.7826747720364742	wrong_be_tree_count:42	wrong_total:206	 wrong be tree ACC: 0.20388349514563106
2023-07-21 18:10:53,290 - right_checker:1545	total:1974	checker ACC: 0.7826747894287109	temp:0	temp1:0	wrong_total:206	
2023-07-21 18:10:53,294 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:11:10,597 - 

2023-07-21 18:11:10,598 - epoch:10,	loss:7117.621662139893	loss1:2191.731385231018
2023-07-21 18:11:29,605 - right_count:231	total:433	 Answer ACC: 0.5334872979214781
2023-07-21 18:11:29,605 - right_codes_count:1584	total:1974	Code ACC: 0.8024316109422492	wrong_be_tree_count:42	wrong_total:202	 wrong be tree ACC: 0.2079207920792079
2023-07-21 18:11:29,607 - right_checker:1584	total:1974	checker ACC: 0.8024316430091858	temp:0	temp1:0	wrong_total:202	
2023-07-21 18:11:29,610 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:11:48,311 - 

2023-07-21 18:11:48,311 - epoch:11,	loss:6169.454099655151	loss1:1960.2202291488647
2023-07-21 18:12:05,317 - right_count:255	total:433	 Answer ACC: 0.5889145496535797
2023-07-21 18:12:05,317 - right_codes_count:1619	total:1974	Code ACC: 0.8201621073961499	wrong_be_tree_count:54	wrong_total:178	 wrong be tree ACC: 0.30337078651685395
2023-07-21 18:12:05,317 - right_checker:1619	total:1974	checker ACC: 0.8201621770858765	temp:0	temp1:0	wrong_total:178	
2023-07-21 18:12:05,320 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:12:33,530 - 

2023-07-21 18:12:33,530 - epoch:12,	loss:5376.279401779175	loss1:1671.8710079193115
2023-07-21 18:12:45,500 - right_count:282	total:433	 Answer ACC: 0.651270207852194
2023-07-21 18:12:45,501 - right_codes_count:1683	total:1974	Code ACC: 0.8525835866261399	wrong_be_tree_count:68	wrong_total:151	 wrong be tree ACC: 0.4503311258278146
2023-07-21 18:12:45,501 - right_checker:1683	total:1974	checker ACC: 0.852583646774292	temp:0	temp1:0	wrong_total:151	
2023-07-21 18:12:45,504 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:13:19,214 - 

2023-07-21 18:13:19,214 - epoch:13,	loss:4466.560436248779	loss1:1330.8425922393799
2023-07-21 18:13:31,548 - right_count:298	total:433	 Answer ACC: 0.6882217090069284
2023-07-21 18:13:31,548 - right_codes_count:1695	total:1974	Code ACC: 0.8586626139817629	wrong_be_tree_count:66	wrong_total:135	 wrong be tree ACC: 0.4888888888888889
2023-07-21 18:13:31,549 - right_checker:1695	total:1974	checker ACC: 0.8586626648902893	temp:0	temp1:0	wrong_total:135	
2023-07-21 18:13:31,551 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:14:02,092 - 

2023-07-21 18:14:02,093 - epoch:14,	loss:3965.4763526916504	loss1:1203.303518295288
2023-07-21 18:14:14,798 - right_count:319	total:433	 Answer ACC: 0.7367205542725174
2023-07-21 18:14:14,798 - right_codes_count:1729	total:1974	Code ACC: 0.875886524822695	wrong_be_tree_count:41	wrong_total:114	 wrong be tree ACC: 0.35964912280701755
2023-07-21 18:14:14,799 - right_checker:1729	total:1974	checker ACC: 0.8758865594863892	temp:0	temp1:0	wrong_total:114	
2023-07-21 18:14:14,801 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:14:47,123 - 

2023-07-21 18:14:47,123 - epoch:15,	loss:3476.87450504303	loss1:1038.3344812393188
2023-07-21 18:14:59,923 - right_count:325	total:433	 Answer ACC: 0.7505773672055427
2023-07-21 18:14:59,923 - right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:34	wrong_total:108	 wrong be tree ACC: 0.3148148148148148
2023-07-21 18:14:59,923 - right_checker:1736	total:1974	checker ACC: 0.8794326782226562	temp:0	temp1:0	wrong_total:108	
2023-07-21 18:14:59,926 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:15:35,412 - 

2023-07-21 18:15:35,413 - epoch:16,	loss:3205.117685317993	loss1:946.839056968689
2023-07-21 18:15:48,155 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-21 18:15:48,155 - right_codes_count:1740	total:1974	Code ACC: 0.8814589665653495	wrong_be_tree_count:41	wrong_total:106	 wrong be tree ACC: 0.3867924528301887
2023-07-21 18:15:48,156 - right_checker:1740	total:1974	checker ACC: 0.8814589977264404	temp:0	temp1:0	wrong_total:106	
2023-07-21 18:15:48,158 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:16:35,689 - 

2023-07-21 18:16:35,689 - epoch:17,	loss:2979.8530139923096	loss1:837.3218050003052
2023-07-21 18:16:47,593 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-21 18:16:47,593 - right_codes_count:1728	total:1974	Code ACC: 0.8753799392097265	wrong_be_tree_count:28	wrong_total:102	 wrong be tree ACC: 0.27450980392156865
2023-07-21 18:16:47,593 - right_checker:1728	total:1974	checker ACC: 0.8753799796104431	temp:0	temp1:0	wrong_total:102	
2023-07-21 18:16:47,596 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:17:33,959 - 

2023-07-21 18:17:33,959 - epoch:18,	loss:2587.1201934814453	loss1:763.8481998443604
2023-07-21 18:17:51,963 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-21 18:17:51,963 - right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:36	wrong_total:102	 wrong be tree ACC: 0.35294117647058826
2023-07-21 18:17:51,964 - right_checker:1741	total:1974	checker ACC: 0.8819655776023865	temp:0	temp1:0	wrong_total:102	
2023-07-21 18:17:51,966 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:18:49,861 - 

2023-07-21 18:18:49,862 - epoch:19,	loss:2332.626494884491	loss1:698.6923637390137
2023-07-21 18:19:04,319 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-21 18:19:04,319 - right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
2023-07-21 18:19:04,321 - right_checker:1737	total:1974	checker ACC: 0.8799392580986023	temp:0	temp1:0	wrong_total:95	
2023-07-21 18:19:04,323 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:20:01,027 - 

2023-07-21 18:20:01,028 - epoch:20,	loss:2247.5476183891296	loss1:682.056830406189
2023-07-21 18:20:15,304 - right_count:331	total:433	 Answer ACC: 0.7644341801385681
2023-07-21 18:20:15,304 - right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:37	wrong_total:102	 wrong be tree ACC: 0.3627450980392157
2023-07-21 18:20:15,306 - right_checker:1744	total:1974	checker ACC: 0.8834853768348694	temp:0	temp1:0	wrong_total:102	
2023-07-21 18:20:56,924 - 

2023-07-21 18:20:56,924 - epoch:21,	loss:2154.630640029907	loss1:657.1035308837891
2023-07-21 18:21:13,742 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-21 18:21:13,742 - right_codes_count:1752	total:1974	Code ACC: 0.8875379939209727	wrong_be_tree_count:36	wrong_total:97	 wrong be tree ACC: 0.3711340206185567
2023-07-21 18:21:13,744 - right_checker:1752	total:1974	checker ACC: 0.8875380158424377	temp:0	temp1:0	wrong_total:97	
2023-07-21 18:21:42,876 - 

2023-07-21 18:21:42,876 - epoch:22,	loss:1995.3043956756592	loss1:639.0817022323608
2023-07-21 18:22:07,779 - right_count:327	total:433	 Answer ACC: 0.7551963048498845
2023-07-21 18:22:07,780 - right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:34	wrong_total:106	 wrong be tree ACC: 0.32075471698113206
2023-07-21 18:22:07,780 - right_checker:1736	total:1974	checker ACC: 0.8794326782226562	temp:0	temp1:0	wrong_total:106	
2023-07-21 18:22:32,892 - 

2023-07-21 18:22:32,892 - epoch:23,	loss:1888.3275699615479	loss1:596.1065788269043
2023-07-21 18:22:56,526 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-21 18:22:56,526 - right_codes_count:1736	total:1974	Code ACC: 0.8794326241134752	wrong_be_tree_count:31	wrong_total:107	 wrong be tree ACC: 0.2897196261682243
2023-07-21 18:22:56,528 - right_checker:1736	total:1974	checker ACC: 0.8794326782226562	temp:0	temp1:0	wrong_total:107	
2023-07-21 18:23:11,989 - 

2023-07-21 18:23:11,989 - epoch:24,	loss:1797.5132701992989	loss1:572.5395746231079
2023-07-21 18:23:20,385 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-21 18:23:20,385 - right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:35	wrong_total:100	 wrong be tree ACC: 0.35
2023-07-21 18:23:20,385 - right_checker:1741	total:1974	checker ACC: 0.8819655776023865	temp:0	temp1:0	wrong_total:100	
2023-07-21 18:23:43,773 - 

2023-07-21 18:23:43,773 - epoch:25,	loss:1724.9840867519379	loss1:557.2903356552124
2023-07-21 18:23:56,727 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-21 18:23:56,727 - right_codes_count:1741	total:1974	Code ACC: 0.8819655521783182	wrong_be_tree_count:29	wrong_total:93	 wrong be tree ACC: 0.3118279569892473
2023-07-21 18:23:56,727 - right_checker:1741	total:1974	checker ACC: 0.8819655776023865	temp:0	temp1:0	wrong_total:93	
2023-07-21 18:23:56,731 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:24:48,600 - 

2023-07-21 18:24:48,600 - epoch:26,	loss:1630.6548428535461	loss1:530.9507455825806
2023-07-21 18:25:02,052 - right_count:332	total:433	 Answer ACC: 0.766743648960739
2023-07-21 18:25:02,052 - right_codes_count:1739	total:1974	Code ACC: 0.8809523809523809	wrong_be_tree_count:32	wrong_total:101	 wrong be tree ACC: 0.31683168316831684
2023-07-21 18:25:02,052 - right_checker:1739	total:1974	checker ACC: 0.8809524178504944	temp:0	temp1:0	wrong_total:101	
2023-07-21 18:25:39,496 - 

2023-07-21 18:25:39,496 - epoch:27,	loss:1535.437264919281	loss1:476.8852596282959
2023-07-21 18:25:55,634 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-21 18:25:55,634 - right_codes_count:1737	total:1974	Code ACC: 0.8799392097264438	wrong_be_tree_count:50	wrong_total:98	 wrong be tree ACC: 0.5102040816326531
2023-07-21 18:25:55,635 - right_checker:1737	total:1974	checker ACC: 0.8799392580986023	temp:0	temp1:0	wrong_total:98	
2023-07-21 18:26:27,246 - 

2023-07-21 18:26:27,247 - epoch:28,	loss:1450.519905090332	loss1:467.1812038421631
2023-07-21 18:26:43,640 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-21 18:26:43,640 - right_codes_count:1750	total:1974	Code ACC: 0.8865248226950354	wrong_be_tree_count:36	wrong_total:96	 wrong be tree ACC: 0.375
2023-07-21 18:26:43,642 - right_checker:1750	total:1974	checker ACC: 0.8865248560905457	temp:0	temp1:0	wrong_total:96	
2023-07-21 18:27:08,913 - 

2023-07-21 18:27:08,913 - epoch:29,	loss:1374.3266530036926	loss1:446.38678455352783
2023-07-21 18:27:31,741 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-21 18:27:31,742 - right_codes_count:1755	total:1974	Code ACC: 0.8890577507598785	wrong_be_tree_count:33	wrong_total:98	 wrong be tree ACC: 0.336734693877551
2023-07-21 18:27:31,742 - right_checker:1755	total:1974	checker ACC: 0.8890578150749207	temp:0	temp1:0	wrong_total:98	
2023-07-21 18:28:04,535 - 

2023-07-21 18:28:04,535 - epoch:30,	loss:1336.449231147766	loss1:450.5456705093384
2023-07-21 18:28:24,473 - right_count:334	total:433	 Answer ACC: 0.7713625866050808
2023-07-21 18:28:24,473 - right_codes_count:1746	total:1974	Code ACC: 0.8844984802431611	wrong_be_tree_count:44	wrong_total:99	 wrong be tree ACC: 0.4444444444444444
2023-07-21 18:28:24,474 - right_checker:1746	total:1974	checker ACC: 0.8844985365867615	temp:0	temp1:0	wrong_total:99	
2023-07-21 18:28:58,251 - 

2023-07-21 18:28:58,251 - epoch:31,	loss:1231.555591225624	loss1:417.27460289001465
2023-07-21 18:29:14,691 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-21 18:29:14,691 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:39	wrong_total:96	 wrong be tree ACC: 0.40625
2023-07-21 18:29:14,692 - right_checker:1761	total:1974	checker ACC: 0.8920972943305969	temp:0	temp1:0	wrong_total:96	
2023-07-21 18:29:54,328 - 

2023-07-21 18:29:54,328 - epoch:32,	loss:1173.8137836456299	loss1:408.95683765411377
2023-07-21 18:30:08,970 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 18:30:08,971 - right_codes_count:1762	total:1974	Code ACC: 0.8926038500506586	wrong_be_tree_count:35	wrong_total:90	 wrong be tree ACC: 0.3888888888888889
2023-07-21 18:30:08,972 - right_checker:1762	total:1974	checker ACC: 0.892603874206543	temp:0	temp1:0	wrong_total:90	
2023-07-21 18:30:08,976 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:30:43,827 - 

2023-07-21 18:30:43,827 - epoch:33,	loss:1125.4969465732574	loss1:363.2091245651245
2023-07-21 18:30:57,706 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-21 18:30:57,706 - right_codes_count:1749	total:1974	Code ACC: 0.8860182370820668	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-21 18:30:57,707 - right_checker:1749	total:1974	checker ACC: 0.8860182762145996	temp:0	temp1:0	wrong_total:97	
2023-07-21 18:31:29,927 - 

2023-07-21 18:31:29,928 - epoch:34,	loss:1115.667629957199	loss1:395.0938940048218
2023-07-21 18:31:43,969 - right_count:335	total:433	 Answer ACC: 0.7736720554272517
2023-07-21 18:31:43,969 - right_codes_count:1758	total:1974	Code ACC: 0.8905775075987842	wrong_be_tree_count:47	wrong_total:98	 wrong be tree ACC: 0.47959183673469385
2023-07-21 18:31:43,969 - right_checker:1758	total:1974	checker ACC: 0.8905775547027588	temp:0	temp1:0	wrong_total:98	
2023-07-21 18:32:19,832 - 

2023-07-21 18:32:19,832 - epoch:35,	loss:1074.5593566894531	loss1:359.0502405166626
2023-07-21 18:32:33,448 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:32:33,449 - right_codes_count:1753	total:1974	Code ACC: 0.8880445795339412	wrong_be_tree_count:37	wrong_total:94	 wrong be tree ACC: 0.39361702127659576
2023-07-21 18:32:33,449 - right_checker:1753	total:1974	checker ACC: 0.8880445957183838	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:33:13,045 - 

2023-07-21 18:33:13,046 - epoch:36,	loss:1000.5530667304993	loss1:353.5050630569458
2023-07-21 18:33:27,741 - right_count:333	total:433	 Answer ACC: 0.76905311778291
2023-07-21 18:33:27,741 - right_codes_count:1748	total:1974	Code ACC: 0.8855116514690983	wrong_be_tree_count:44	wrong_total:100	 wrong be tree ACC: 0.44
2023-07-21 18:33:27,742 - right_checker:1748	total:1974	checker ACC: 0.8855116963386536	temp:0	temp1:0	wrong_total:100	
2023-07-21 18:33:54,639 - 

2023-07-21 18:33:54,640 - epoch:37,	loss:946.3060663938522	loss1:309.14364433288574
2023-07-21 18:34:12,807 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:34:12,807 - right_codes_count:1758	total:1974	Code ACC: 0.8905775075987842	wrong_be_tree_count:30	wrong_total:91	 wrong be tree ACC: 0.32967032967032966
2023-07-21 18:34:12,808 - right_checker:1758	total:1974	checker ACC: 0.8905775547027588	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:34:37,903 - 

2023-07-21 18:34:37,904 - epoch:38,	loss:897.6551629304886	loss1:306.37105560302734
2023-07-21 18:34:56,642 - right_count:326	total:433	 Answer ACC: 0.7528868360277137
2023-07-21 18:34:56,643 - right_codes_count:1744	total:1974	Code ACC: 0.8834853090172239	wrong_be_tree_count:44	wrong_total:107	 wrong be tree ACC: 0.411214953271028
2023-07-21 18:34:56,644 - right_checker:1744	total:1974	checker ACC: 0.8834853768348694	temp:0	temp1:0	wrong_total:107	
2023-07-21 18:35:15,995 - 

2023-07-21 18:35:15,995 - epoch:39,	loss:934.3858134746552	loss1:304.9847602844238
2023-07-21 18:35:40,434 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-21 18:35:40,434 - right_codes_count:1755	total:1974	Code ACC: 0.8890577507598785	wrong_be_tree_count:35	wrong_total:95	 wrong be tree ACC: 0.3684210526315789
2023-07-21 18:35:40,435 - right_checker:1755	total:1974	checker ACC: 0.8890578150749207	temp:0	temp1:0	wrong_total:95	
2023-07-21 18:35:53,966 - 

2023-07-21 18:35:53,966 - epoch:40,	loss:855.4652736186981	loss1:286.96293449401855
2023-07-21 18:36:01,998 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-21 18:36:01,998 - right_codes_count:1766	total:1974	Code ACC: 0.894630192502533	wrong_be_tree_count:30	wrong_total:93	 wrong be tree ACC: 0.3225806451612903
2023-07-21 18:36:01,999 - right_checker:1766	total:1974	checker ACC: 0.8946302533149719	temp:0	temp1:0	wrong_total:93	
2023-07-21 18:36:23,828 - 

2023-07-21 18:36:23,828 - epoch:41,	loss:804.1847213506699	loss1:289.7355213165283
2023-07-21 18:36:37,090 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:36:37,090 - right_codes_count:1757	total:1974	Code ACC: 0.8900709219858156	wrong_be_tree_count:31	wrong_total:94	 wrong be tree ACC: 0.32978723404255317
2023-07-21 18:36:37,090 - right_checker:1757	total:1974	checker ACC: 0.8900709748268127	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:37:06,843 - 

2023-07-21 18:37:06,843 - epoch:42,	loss:810.4133898019791	loss1:291.12181758880615
2023-07-21 18:37:22,543 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-21 18:37:22,543 - right_codes_count:1756	total:1974	Code ACC: 0.889564336372847	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-21 18:37:22,544 - right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:97	
2023-07-21 18:37:53,345 - 

2023-07-21 18:37:53,345 - epoch:43,	loss:800.8255304098129	loss1:264.78222370147705
2023-07-21 18:38:07,431 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-21 18:38:07,431 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:40	wrong_total:97	 wrong be tree ACC: 0.41237113402061853
2023-07-21 18:38:07,433 - right_checker:1763	total:1974	checker ACC: 0.893110454082489	temp:0	temp1:0	wrong_total:97	
2023-07-21 18:38:46,653 - 

2023-07-21 18:38:46,653 - epoch:44,	loss:786.3958287239075	loss1:271.71369552612305
2023-07-21 18:39:02,713 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 18:39:02,714 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:31	wrong_total:85	 wrong be tree ACC: 0.36470588235294116
2023-07-21 18:39:02,714 - right_checker:1765	total:1974	checker ACC: 0.8941236734390259	temp:0	temp1:0	wrong_total:85	
2023-07-21 18:39:02,716 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:39:38,051 - 

2023-07-21 18:39:38,051 - epoch:45,	loss:752.5603084564209	loss1:241.21522045135498
2023-07-21 18:39:51,368 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-21 18:39:51,368 - right_codes_count:1754	total:1974	Code ACC: 0.8885511651469098	wrong_be_tree_count:32	wrong_total:95	 wrong be tree ACC: 0.3368421052631579
2023-07-21 18:39:51,369 - right_checker:1754	total:1974	checker ACC: 0.8885512351989746	temp:0	temp1:0	wrong_total:95	
2023-07-21 18:40:22,449 - 

2023-07-21 18:40:22,450 - epoch:46,	loss:677.7569614052773	loss1:237.05633640289307
2023-07-21 18:40:36,485 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-21 18:40:36,486 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:36	wrong_total:95	 wrong be tree ACC: 0.37894736842105264
2023-07-21 18:40:36,486 - right_checker:1761	total:1974	checker ACC: 0.8920972943305969	temp:0	temp1:0	wrong_total:95	
2023-07-21 18:41:13,819 - 

2023-07-21 18:41:13,820 - epoch:47,	loss:767.8320667743683	loss1:241.21521854400635
2023-07-21 18:41:27,507 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:41:27,507 - right_codes_count:1756	total:1974	Code ACC: 0.889564336372847	wrong_be_tree_count:33	wrong_total:91	 wrong be tree ACC: 0.3626373626373626
2023-07-21 18:41:27,508 - right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:42:03,583 - 

2023-07-21 18:42:03,583 - epoch:48,	loss:676.0286350250244	loss1:248.14669132232666
2023-07-21 18:42:17,725 - right_count:338	total:433	 Answer ACC: 0.7806004618937644
2023-07-21 18:42:17,726 - right_codes_count:1755	total:1974	Code ACC: 0.8890577507598785	wrong_be_tree_count:33	wrong_total:95	 wrong be tree ACC: 0.3473684210526316
2023-07-21 18:42:17,727 - right_checker:1755	total:1974	checker ACC: 0.8890578150749207	temp:0	temp1:0	wrong_total:95	
2023-07-21 18:42:49,273 - 

2023-07-21 18:42:49,273 - epoch:49,	loss:632.2103660106659	loss1:209.33044910430908
2023-07-21 18:43:03,246 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:43:03,246 - right_codes_count:1760	total:1974	Code ACC: 0.8915906788247214	wrong_be_tree_count:40	wrong_total:94	 wrong be tree ACC: 0.425531914893617
2023-07-21 18:43:03,248 - right_checker:1760	total:1974	checker ACC: 0.8915907144546509	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:43:36,171 - 

2023-07-21 18:43:36,171 - epoch:50,	loss:635.0479835271835	loss1:201.0126829147339
2023-07-21 18:43:49,281 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-21 18:43:49,281 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:33	wrong_total:92	 wrong be tree ACC: 0.358695652173913
2023-07-21 18:43:49,283 - right_checker:1763	total:1974	checker ACC: 0.893110454082489	temp:0	temp1:0	wrong_total:92	
2023-07-21 18:44:23,162 - 

2023-07-21 18:44:23,162 - epoch:51,	loss:643.6618021726608	loss1:202.3989772796631
2023-07-21 18:44:42,229 - right_count:337	total:433	 Answer ACC: 0.7782909930715936
2023-07-21 18:44:42,229 - right_codes_count:1751	total:1974	Code ACC: 0.8870314083080041	wrong_be_tree_count:42	wrong_total:96	 wrong be tree ACC: 0.4375
2023-07-21 18:44:42,231 - right_checker:1751	total:1974	checker ACC: 0.8870314359664917	temp:0	temp1:0	wrong_total:96	
2023-07-21 18:45:12,246 - 

2023-07-21 18:45:12,246 - epoch:52,	loss:566.3702080249786	loss1:212.10303783416748
2023-07-21 18:45:28,219 - right_count:340	total:433	 Answer ACC: 0.7852193995381063
2023-07-21 18:45:28,219 - right_codes_count:1759	total:1974	Code ACC: 0.8910840932117527	wrong_be_tree_count:35	wrong_total:93	 wrong be tree ACC: 0.3763440860215054
2023-07-21 18:45:28,219 - right_checker:1759	total:1974	checker ACC: 0.8910841345787048	temp:0	temp1:0	wrong_total:93	
2023-07-21 18:45:58,365 - 

2023-07-21 18:45:58,365 - epoch:53,	loss:563.5137701630592	loss1:188.5360336303711
2023-07-21 18:46:12,152 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:46:12,152 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:35	wrong_total:91	 wrong be tree ACC: 0.38461538461538464
2023-07-21 18:46:12,154 - right_checker:1764	total:1974	checker ACC: 0.8936170935630798	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:46:45,597 - 

2023-07-21 18:46:45,598 - epoch:54,	loss:594.2358727455139	loss1:194.0812110900879
2023-07-21 18:46:58,627 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:46:58,627 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:38	wrong_total:94	 wrong be tree ACC: 0.40425531914893614
2023-07-21 18:46:58,627 - right_checker:1761	total:1974	checker ACC: 0.8920972943305969	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:47:31,837 - 

2023-07-21 18:47:31,838 - epoch:55,	loss:565.3375423178077	loss1:182.9908561706543
2023-07-21 18:47:50,746 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 18:47:50,746 - right_codes_count:1768	total:1974	Code ACC: 0.8956433637284701	wrong_be_tree_count:35	wrong_total:86	 wrong be tree ACC: 0.4069767441860465
2023-07-21 18:47:50,746 - right_checker:1768	total:1974	checker ACC: 0.895643413066864	temp:0	temp1:0	wrong_total:86	
2023-07-21 18:48:34,574 - 

2023-07-21 18:48:34,574 - epoch:56,	loss:575.956870675087	loss1:181.6045618057251
2023-07-21 18:48:48,908 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:48:48,908 - right_codes_count:1753	total:1974	Code ACC: 0.8880445795339412	wrong_be_tree_count:42	wrong_total:94	 wrong be tree ACC: 0.44680851063829785
2023-07-21 18:48:48,908 - right_checker:1753	total:1974	checker ACC: 0.8880445957183838	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:49:19,032 - 

2023-07-21 18:49:19,033 - epoch:57,	loss:550.9391790889204	loss1:189.9223279953003
2023-07-21 18:49:37,845 - right_count:341	total:433	 Answer ACC: 0.7875288683602771
2023-07-21 18:49:37,845 - right_codes_count:1759	total:1974	Code ACC: 0.8910840932117527	wrong_be_tree_count:35	wrong_total:92	 wrong be tree ACC: 0.3804347826086957
2023-07-21 18:49:37,845 - right_checker:1759	total:1974	checker ACC: 0.8910841345787048	temp:0	temp1:0	wrong_total:92	
2023-07-21 18:50:12,382 - 

2023-07-21 18:50:12,382 - epoch:58,	loss:501.19464671611786	loss1:187.1497392654419
2023-07-21 18:50:25,800 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 18:50:25,800 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
2023-07-21 18:50:25,802 - right_checker:1769	total:1974	checker ACC: 0.8961499929428101	temp:0	temp1:0	wrong_total:85	
2023-07-21 18:50:25,804 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:50:59,882 - 

2023-07-21 18:50:59,882 - epoch:59,	loss:524.8346115350723	loss1:178.8319730758667
2023-07-21 18:51:10,049 - right_count:339	total:433	 Answer ACC: 0.7829099307159353
2023-07-21 18:51:10,049 - right_codes_count:1756	total:1974	Code ACC: 0.889564336372847	wrong_be_tree_count:35	wrong_total:94	 wrong be tree ACC: 0.3723404255319149
2023-07-21 18:51:10,049 - right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:94	
2023-07-21 18:51:38,272 - 

2023-07-21 18:51:38,272 - epoch:60,	loss:516.15662753582	loss1:199.6263885498047
2023-07-21 18:51:48,954 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:51:48,954 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:33	wrong_total:91	 wrong be tree ACC: 0.3626373626373626
2023-07-21 18:51:48,954 - right_checker:1763	total:1974	checker ACC: 0.893110454082489	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:52:14,184 - 

2023-07-21 18:52:14,184 - epoch:61,	loss:543.5082771778107	loss1:203.78527164459229
2023-07-21 18:52:29,510 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 18:52:29,510 - right_codes_count:1766	total:1974	Code ACC: 0.894630192502533	wrong_be_tree_count:35	wrong_total:90	 wrong be tree ACC: 0.3888888888888889
2023-07-21 18:52:29,512 - right_checker:1766	total:1974	checker ACC: 0.8946302533149719	temp:0	temp1:0	wrong_total:90	
2023-07-21 18:52:51,065 - 

2023-07-21 18:52:51,065 - epoch:62,	loss:506.844526052475	loss1:164.9690294265747
2023-07-21 18:53:05,721 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 18:53:05,721 - right_codes_count:1756	total:1974	Code ACC: 0.889564336372847	wrong_be_tree_count:37	wrong_total:90	 wrong be tree ACC: 0.4111111111111111
2023-07-21 18:53:05,723 - right_checker:1756	total:1974	checker ACC: 0.8895643949508667	temp:0	temp1:0	wrong_total:90	
2023-07-21 18:53:20,182 - 

2023-07-21 18:53:20,182 - epoch:63,	loss:465.7527545168996	loss1:185.7634449005127
2023-07-21 18:53:36,275 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-21 18:53:36,276 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:36	wrong_total:89	 wrong be tree ACC: 0.4044943820224719
2023-07-21 18:53:36,276 - right_checker:1761	total:1974	checker ACC: 0.8920972943305969	temp:0	temp1:0	wrong_total:89	
2023-07-21 18:53:57,289 - 

2023-07-21 18:53:57,289 - epoch:64,	loss:493.2560030221939	loss1:181.6045618057251
2023-07-21 18:54:11,427 - right_count:336	total:433	 Answer ACC: 0.7759815242494227
2023-07-21 18:54:11,427 - right_codes_count:1758	total:1974	Code ACC: 0.8905775075987842	wrong_be_tree_count:48	wrong_total:97	 wrong be tree ACC: 0.4948453608247423
2023-07-21 18:54:11,428 - right_checker:1758	total:1974	checker ACC: 0.8905775547027588	temp:0	temp1:0	wrong_total:97	
2023-07-21 18:54:39,193 - 

2023-07-21 18:54:39,193 - epoch:65,	loss:485.41020864248276	loss1:181.6045618057251
2023-07-21 18:54:51,599 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 18:54:51,599 - right_codes_count:1758	total:1974	Code ACC: 0.8905775075987842	wrong_be_tree_count:34	wrong_total:90	 wrong be tree ACC: 0.37777777777777777
2023-07-21 18:54:51,599 - right_checker:1758	total:1974	checker ACC: 0.8905775547027588	temp:0	temp1:0	wrong_total:90	
2023-07-21 18:55:17,869 - 

2023-07-21 18:55:17,869 - epoch:66,	loss:468.17920887470245	loss1:185.7634449005127
2023-07-21 18:55:29,654 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:55:29,655 - right_codes_count:1760	total:1974	Code ACC: 0.8915906788247214	wrong_be_tree_count:36	wrong_total:91	 wrong be tree ACC: 0.3956043956043956
2023-07-21 18:55:29,655 - right_checker:1760	total:1974	checker ACC: 0.8915907144546509	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:55:57,427 - 

2023-07-21 18:55:57,427 - epoch:67,	loss:491.8615354895592	loss1:164.9690294265747
2023-07-21 18:56:12,791 - right_count:344	total:433	 Answer ACC: 0.7944572748267898
2023-07-21 18:56:12,791 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:39	wrong_total:89	 wrong be tree ACC: 0.43820224719101125
2023-07-21 18:56:12,792 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:89	
2023-07-21 18:56:46,525 - 

2023-07-21 18:56:46,525 - epoch:68,	loss:503.2227174639702	loss1:181.6045627593994
2023-07-21 18:56:59,278 - right_count:342	total:433	 Answer ACC: 0.789838337182448
2023-07-21 18:56:59,278 - right_codes_count:1761	total:1974	Code ACC: 0.89209726443769	wrong_be_tree_count:37	wrong_total:91	 wrong be tree ACC: 0.4065934065934066
2023-07-21 18:56:59,278 - right_checker:1761	total:1974	checker ACC: 0.8920972943305969	temp:0	temp1:0	wrong_total:91	
2023-07-21 18:57:27,998 - 

2023-07-21 18:57:27,999 - epoch:69,	loss:459.6251614242792	loss1:163.5827350616455
2023-07-21 18:57:41,883 - right_count:351	total:433	 Answer ACC: 0.8106235565819861
2023-07-21 18:57:41,883 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:29	wrong_total:82	 wrong be tree ACC: 0.35365853658536583
2023-07-21 18:57:41,883 - right_checker:1773	total:1974	checker ACC: 0.8981763124465942	temp:0	temp1:0	wrong_total:82	
2023-07-21 18:57:41,888 - save best model to ./output/model_save_name_0/best_model
2023-07-21 18:58:18,316 - 

2023-07-21 18:58:18,317 - epoch:70,	loss:460.7443560361862	loss1:152.4923801422119
2023-07-21 18:58:29,066 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 18:58:29,067 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:30	wrong_total:87	 wrong be tree ACC: 0.3448275862068966
2023-07-21 18:58:29,067 - right_checker:1765	total:1974	checker ACC: 0.8941236734390259	temp:0	temp1:0	wrong_total:87	
2023-07-21 18:59:02,071 - 

2023-07-21 18:59:02,071 - epoch:71,	loss:465.2545607984066	loss1:173.2867956161499
2023-07-21 18:59:14,510 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 18:59:14,510 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
2023-07-21 18:59:14,511 - right_checker:1764	total:1974	checker ACC: 0.8936170935630798	temp:0	temp1:0	wrong_total:86	
2023-07-21 18:59:43,978 - 

2023-07-21 18:59:43,978 - epoch:72,	loss:435.82567846775055	loss1:144.17461395263672
2023-07-21 18:59:56,088 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 18:59:56,088 - right_codes_count:1763	total:1974	Code ACC: 0.8931104356636271	wrong_be_tree_count:33	wrong_total:87	 wrong be tree ACC: 0.3793103448275862
2023-07-21 18:59:56,088 - right_checker:1763	total:1974	checker ACC: 0.893110454082489	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:00:30,983 - 

2023-07-21 19:00:30,983 - epoch:73,	loss:432.6046048402786	loss1:156.6512632369995
2023-07-21 19:00:42,886 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:00:42,886 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
2023-07-21 19:00:42,886 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:01:16,842 - 

2023-07-21 19:01:16,843 - epoch:74,	loss:451.0649859011173	loss1:159.4238519668579
2023-07-21 19:01:29,012 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:01:29,012 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:33	wrong_total:85	 wrong be tree ACC: 0.38823529411764707
2023-07-21 19:01:29,012 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:01:58,882 - 

2023-07-21 19:01:58,882 - epoch:75,	loss:432.1235399544239	loss1:170.5142068862915
2023-07-21 19:02:11,461 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:02:11,461 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
2023-07-21 19:02:11,461 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:02:46,909 - 

2023-07-21 19:02:46,909 - epoch:76,	loss:411.43407952412963	loss1:146.94720268249512
2023-07-21 19:03:00,694 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 19:03:00,694 - right_codes_count:1764	total:1974	Code ACC: 0.8936170212765957	wrong_be_tree_count:31	wrong_total:90	 wrong be tree ACC: 0.34444444444444444
2023-07-21 19:03:00,694 - right_checker:1764	total:1974	checker ACC: 0.8936170935630798	temp:0	temp1:0	wrong_total:90	
2023-07-21 19:03:29,564 - 

2023-07-21 19:03:29,564 - epoch:77,	loss:418.4474785029888	loss1:162.1964406967163
2023-07-21 19:03:47,293 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:03:47,294 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:27	wrong_total:87	 wrong be tree ACC: 0.3103448275862069
2023-07-21 19:03:47,295 - right_checker:1765	total:1974	checker ACC: 0.8941236734390259	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:04:21,459 - 

2023-07-21 19:04:21,459 - epoch:78,	loss:422.7194214463234	loss1:152.4923801422119
2023-07-21 19:04:38,645 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:04:38,645 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:31	wrong_total:84	 wrong be tree ACC: 0.36904761904761907
2023-07-21 19:04:38,647 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:05:01,406 - 

2023-07-21 19:05:01,407 - epoch:79,	loss:431.448423743248	loss1:160.8101463317871
2023-07-21 19:05:20,425 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:05:20,425 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:35	wrong_total:84	 wrong be tree ACC: 0.4166666666666667
2023-07-21 19:05:20,426 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:05:42,931 - 

2023-07-21 19:05:42,932 - epoch:80,	loss:398.4065828472376	loss1:166.3553237915039
2023-07-21 19:06:02,892 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-21 19:06:02,892 - right_codes_count:1766	total:1974	Code ACC: 0.894630192502533	wrong_be_tree_count:33	wrong_total:88	 wrong be tree ACC: 0.375
2023-07-21 19:06:02,893 - right_checker:1766	total:1974	checker ACC: 0.8946302533149719	temp:0	temp1:0	wrong_total:88	
2023-07-21 19:06:31,268 - 

2023-07-21 19:06:31,268 - epoch:81,	loss:391.0474780499935	loss1:160.8101463317871
2023-07-21 19:06:49,829 - right_count:350	total:433	 Answer ACC: 0.8083140877598153
2023-07-21 19:06:49,829 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:27	wrong_total:83	 wrong be tree ACC: 0.3253012048192771
2023-07-21 19:06:49,830 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:83	
2023-07-21 19:07:17,165 - 

2023-07-21 19:07:17,165 - epoch:82,	loss:379.71308183670044	loss1:149.71979141235352
2023-07-21 19:07:39,244 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:07:39,244 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:28	wrong_total:84	 wrong be tree ACC: 0.3333333333333333
2023-07-21 19:07:39,244 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:08:16,361 - 

2023-07-21 19:08:16,361 - epoch:83,	loss:396.6044197976589	loss1:141.40202522277832
2023-07-21 19:08:32,935 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:08:32,935 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
2023-07-21 19:08:32,937 - right_checker:1769	total:1974	checker ACC: 0.8961499929428101	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:08:59,960 - 

2023-07-21 19:08:59,960 - epoch:84,	loss:385.4042295059189	loss1:145.56090831756592
2023-07-21 19:09:18,143 - right_count:343	total:433	 Answer ACC: 0.792147806004619
2023-07-21 19:09:18,143 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:30	wrong_total:90	 wrong be tree ACC: 0.3333333333333333
2023-07-21 19:09:18,145 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:90	
2023-07-21 19:09:35,760 - 

2023-07-21 19:09:35,760 - epoch:85,	loss:394.3996419329196	loss1:160.81014728546143
2023-07-21 19:10:00,720 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:10:00,720 - right_codes_count:1768	total:1974	Code ACC: 0.8956433637284701	wrong_be_tree_count:28	wrong_total:84	 wrong be tree ACC: 0.3333333333333333
2023-07-21 19:10:00,720 - right_checker:1768	total:1974	checker ACC: 0.895643413066864	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:10:13,850 - 

2023-07-21 19:10:13,850 - epoch:86,	loss:371.24045795202255	loss1:149.71979141235352
2023-07-21 19:10:34,540 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:10:34,541 - right_codes_count:1776	total:1974	Code ACC: 0.8996960486322189	wrong_be_tree_count:34	wrong_total:86	 wrong be tree ACC: 0.3953488372093023
2023-07-21 19:10:34,545 - right_checker:1776	total:1974	checker ACC: 0.8996961116790771	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:10:49,795 - 

2023-07-21 19:10:49,795 - epoch:87,	loss:375.1487251371145	loss1:135.85684776306152
2023-07-21 19:10:59,980 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:10:59,980 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:27	wrong_total:85	 wrong be tree ACC: 0.3176470588235294
2023-07-21 19:10:59,980 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:11:28,781 - 

2023-07-21 19:11:28,781 - epoch:88,	loss:388.95674911141396	loss1:145.56090831756592
2023-07-21 19:11:43,563 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:11:43,563 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:26	wrong_total:86	 wrong be tree ACC: 0.3023255813953488
2023-07-21 19:11:43,564 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:12:16,054 - 

2023-07-21 19:12:16,054 - epoch:89,	loss:400.1801301985979	loss1:141.40202522277832
2023-07-21 19:12:30,777 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:12:30,777 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:33	wrong_total:86	 wrong be tree ACC: 0.38372093023255816
2023-07-21 19:12:30,778 - right_checker:1774	total:1974	checker ACC: 0.8986829519271851	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:13:04,482 - 

2023-07-21 19:13:04,482 - epoch:90,	loss:383.1664924249053	loss1:144.17461395263672
2023-07-21 19:13:22,793 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:13:22,793 - right_codes_count:1765	total:1974	Code ACC: 0.8941236068895644	wrong_be_tree_count:30	wrong_total:87	 wrong be tree ACC: 0.3448275862068966
2023-07-21 19:13:22,793 - right_checker:1765	total:1974	checker ACC: 0.8941236734390259	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:13:58,522 - 

2023-07-21 19:13:58,522 - epoch:91,	loss:395.4322138428688	loss1:144.17461395263672
2023-07-21 19:14:14,062 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:14:14,062 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:34	wrong_total:85	 wrong be tree ACC: 0.4
2023-07-21 19:14:14,064 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:14:37,190 - 

2023-07-21 19:14:37,190 - epoch:92,	loss:393.7927223443985	loss1:146.94720268249512
2023-07-21 19:14:59,297 - right_count:345	total:433	 Answer ACC: 0.7967667436489607
2023-07-21 19:14:59,297 - right_codes_count:1768	total:1974	Code ACC: 0.8956433637284701	wrong_be_tree_count:35	wrong_total:88	 wrong be tree ACC: 0.3977272727272727
2023-07-21 19:14:59,297 - right_checker:1768	total:1974	checker ACC: 0.895643413066864	temp:0	temp1:0	wrong_total:88	
2023-07-21 19:15:18,804 - 

2023-07-21 19:15:18,804 - epoch:93,	loss:386.55793967098	loss1:134.47055339813232
2023-07-21 19:15:43,451 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:15:43,451 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:15:43,452 - right_checker:1775	total:1974	checker ACC: 0.8991895318031311	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:16:03,183 - 

2023-07-21 19:16:03,183 - epoch:94,	loss:363.54082067869604	loss1:144.17461395263672
2023-07-21 19:16:27,532 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:16:27,532 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:33	wrong_total:86	 wrong be tree ACC: 0.38372093023255816
2023-07-21 19:16:27,534 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:16:45,406 - 

2023-07-21 19:16:45,406 - epoch:95,	loss:372.75883504748344	loss1:140.01573085784912
2023-07-21 19:17:07,286 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:17:07,287 - right_codes_count:1768	total:1974	Code ACC: 0.8956433637284701	wrong_be_tree_count:32	wrong_total:87	 wrong be tree ACC: 0.367816091954023
2023-07-21 19:17:07,287 - right_checker:1768	total:1974	checker ACC: 0.895643413066864	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:17:22,591 - 

2023-07-21 19:17:22,591 - epoch:96,	loss:353.0886621773243	loss1:130.31167030334473
2023-07-21 19:17:31,180 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:17:31,180 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:29	wrong_total:84	 wrong be tree ACC: 0.34523809523809523
2023-07-21 19:17:31,182 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:17:53,914 - 

2023-07-21 19:17:53,914 - epoch:97,	loss:371.1745539009571	loss1:149.71979141235352
2023-07-21 19:18:07,799 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:18:07,800 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:85	 wrong be tree ACC: 0.36470588235294116
2023-07-21 19:18:07,801 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:18:38,270 - 

2023-07-21 19:18:38,270 - epoch:98,	loss:358.95095459371805	loss1:140.01573181152344
2023-07-21 19:18:52,420 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:18:52,420 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:35	wrong_total:87	 wrong be tree ACC: 0.40229885057471265
2023-07-21 19:18:52,420 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:19:25,417 - 

2023-07-21 19:19:25,417 - epoch:99,	loss:375.5799261890352	loss1:135.85684776306152
2023-07-21 19:19:38,830 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:19:38,830 - right_codes_count:1775	total:1974	Code ACC: 0.8991894630192503	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
2023-07-21 19:19:38,832 - right_checker:1775	total:1974	checker ACC: 0.8991895318031311	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:20:12,329 - 

2023-07-21 19:20:12,329 - epoch:100,	loss:363.47669792175293	loss1:140.01573085784912
2023-07-21 19:20:25,881 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:20:25,881 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
2023-07-21 19:20:25,883 - right_checker:1774	total:1974	checker ACC: 0.8986829519271851	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:21:01,524 - 

2023-07-21 19:21:01,524 - epoch:101,	loss:381.33540696650743	loss1:144.17461395263672
2023-07-21 19:21:15,909 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:21:15,909 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
2023-07-21 19:21:15,909 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:21:47,426 - 

2023-07-21 19:21:47,426 - epoch:102,	loss:397.9933352470398	loss1:140.01573085784912
2023-07-21 19:22:01,833 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:22:01,833 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:30	wrong_total:85	 wrong be tree ACC: 0.35294117647058826
2023-07-21 19:22:01,834 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:22:33,483 - 

2023-07-21 19:22:33,484 - epoch:103,	loss:372.69222492724657	loss1:137.24314212799072
2023-07-21 19:22:48,087 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:22:48,087 - right_codes_count:1769	total:1974	Code ACC: 0.8961499493414387	wrong_be_tree_count:32	wrong_total:86	 wrong be tree ACC: 0.37209302325581395
2023-07-21 19:22:48,088 - right_checker:1769	total:1974	checker ACC: 0.8961499929428101	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:23:28,675 - 

2023-07-21 19:23:28,675 - epoch:104,	loss:375.69121535122395	loss1:134.47055339813232
2023-07-21 19:23:43,029 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:23:43,030 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:27	wrong_total:87	 wrong be tree ACC: 0.3103448275862069
2023-07-21 19:23:43,030 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:24:17,630 - 

2023-07-21 19:24:17,630 - epoch:105,	loss:368.6665795966983	loss1:140.01573085784912
2023-07-21 19:24:32,222 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:24:32,223 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:30	wrong_total:86	 wrong be tree ACC: 0.3488372093023256
2023-07-21 19:24:32,223 - right_checker:1774	total:1974	checker ACC: 0.8986829519271851	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:25:05,901 - 

2023-07-21 19:25:05,901 - epoch:106,	loss:360.64124212693423	loss1:134.47055339813232
2023-07-21 19:25:20,987 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:25:20,987 - right_codes_count:1777	total:1974	Code ACC: 0.9002026342451874	wrong_be_tree_count:28	wrong_total:85	 wrong be tree ACC: 0.32941176470588235
2023-07-21 19:25:20,987 - right_checker:1777	total:1974	checker ACC: 0.9002026915550232	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:26:00,786 - 

2023-07-21 19:26:00,787 - epoch:107,	loss:387.5880572274327	loss1:142.78831958770752
2023-07-21 19:26:14,685 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:26:14,685 - right_codes_count:1774	total:1974	Code ACC: 0.8986828774062816	wrong_be_tree_count:29	wrong_total:84	 wrong be tree ACC: 0.34523809523809523
2023-07-21 19:26:14,685 - right_checker:1774	total:1974	checker ACC: 0.8986829519271851	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:26:48,172 - 

2023-07-21 19:26:48,173 - epoch:108,	loss:362.7229316085577	loss1:148.33349704742432
2023-07-21 19:27:02,781 - right_count:346	total:433	 Answer ACC: 0.7990762124711316
2023-07-21 19:27:02,781 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:28	wrong_total:87	 wrong be tree ACC: 0.3218390804597701
2023-07-21 19:27:02,782 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:87	
2023-07-21 19:27:33,864 - 

2023-07-21 19:27:33,864 - epoch:109,	loss:356.89444330334663	loss1:137.24314212799072
2023-07-21 19:27:50,013 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:27:50,014 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:84	 wrong be tree ACC: 0.36904761904761907
2023-07-21 19:27:50,014 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:28:30,540 - 

2023-07-21 19:28:30,540 - epoch:110,	loss:345.91428139805794	loss1:127.53908157348633
2023-07-21 19:28:45,253 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:28:45,253 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:29	wrong_total:86	 wrong be tree ACC: 0.3372093023255814
2023-07-21 19:28:45,254 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:29:14,655 - 

2023-07-21 19:29:14,655 - epoch:111,	loss:373.97731819935143	loss1:149.71979141235352
2023-07-21 19:29:31,298 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:29:31,298 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:29:31,299 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:29:53,583 - 

2023-07-21 19:29:53,583 - epoch:112,	loss:361.71173916757107	loss1:135.85684776306152
2023-07-21 19:30:15,357 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:30:15,358 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:31	wrong_total:84	 wrong be tree ACC: 0.36904761904761907
2023-07-21 19:30:15,358 - right_checker:1773	total:1974	checker ACC: 0.8981763124465942	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:30:31,387 - 

2023-07-21 19:30:31,387 - epoch:113,	loss:336.5725300759077	loss1:135.85684776306152
2023-07-21 19:30:52,727 - right_count:348	total:433	 Answer ACC: 0.8036951501154734
2023-07-21 19:30:52,727 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:29	wrong_total:85	 wrong be tree ACC: 0.3411764705882353
2023-07-21 19:30:52,728 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:85	
2023-07-21 19:31:30,236 - 

2023-07-21 19:31:30,236 - epoch:114,	loss:351.1827668771148	loss1:131.69796466827393
2023-07-21 19:31:54,792 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:31:54,793 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:31:54,793 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:32:11,364 - 

2023-07-21 19:32:11,364 - epoch:115,	loss:341.0862655714154	loss1:145.56090831756592
2023-07-21 19:32:32,747 - right_count:349	total:433	 Answer ACC: 0.8060046189376443
2023-07-21 19:32:32,747 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:29	wrong_total:84	 wrong be tree ACC: 0.34523809523809523
2023-07-21 19:32:32,747 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:84	
2023-07-21 19:32:47,971 - 

2023-07-21 19:32:47,971 - epoch:116,	loss:349.511814950034	loss1:138.62943649291992
2023-07-21 19:32:57,519 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:32:57,519 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:32:57,519 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:33:21,075 - 

2023-07-21 19:33:21,075 - epoch:117,	loss:366.5128504037857	loss1:146.94720268249512
2023-07-21 19:33:34,508 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:33:34,508 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:33:34,509 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:34:13,271 - 

2023-07-21 19:34:13,272 - epoch:118,	loss:338.98003647103906	loss1:134.47055339813232
2023-07-21 19:34:26,025 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:34:26,025 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:34:26,027 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:34:53,817 - 

2023-07-21 19:34:53,818 - epoch:119,	loss:337.92574935778975	loss1:141.40202522277832
2023-07-21 19:35:06,807 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:35:06,807 - right_codes_count:1770	total:1974	Code ACC: 0.8966565349544073	wrong_be_tree_count:32	wrong_total:86	 wrong be tree ACC: 0.37209302325581395
2023-07-21 19:35:06,811 - right_checker:1770	total:1974	checker ACC: 0.8966565728187561	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:35:33,071 - 

2023-07-21 19:35:33,071 - epoch:120,	loss:336.98831836879253	loss1:133.08425903320312
2023-07-21 19:35:49,570 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:35:49,570 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:32	wrong_total:86	 wrong be tree ACC: 0.37209302325581395
2023-07-21 19:35:49,574 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:36:10,258 - 

2023-07-21 19:36:10,258 - epoch:121,	loss:345.07624461501837	loss1:140.01573085784912
2023-07-21 19:36:21,594 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:36:21,594 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:36:21,596 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:36:46,265 - 

2023-07-21 19:36:46,265 - epoch:122,	loss:349.4099975824356	loss1:128.92537593841553
2023-07-21 19:36:59,650 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:36:59,650 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:36:59,650 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:37:31,903 - 

2023-07-21 19:37:31,903 - epoch:123,	loss:333.6192353963852	loss1:137.24314212799072
2023-07-21 19:37:45,298 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:37:45,298 - right_codes_count:1771	total:1974	Code ACC: 0.8971631205673759	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:37:45,299 - right_checker:1771	total:1974	checker ACC: 0.8971631526947021	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:38:13,377 - 

2023-07-21 19:38:13,378 - epoch:124,	loss:345.2059544734657	loss1:137.24314212799072
2023-07-21 19:38:26,843 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:38:26,843 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:38:26,844 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:38:53,752 - 

2023-07-21 19:38:53,752 - epoch:125,	loss:329.1936271637678	loss1:124.76649284362793
2023-07-21 19:39:06,327 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:39:06,328 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:39:06,328 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:39:33,473 - 

2023-07-21 19:39:33,473 - epoch:126,	loss:335.7274903729558	loss1:135.85684776306152
2023-07-21 19:39:47,037 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:39:47,037 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:39:47,037 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:40:14,751 - 

2023-07-21 19:40:14,751 - epoch:127,	loss:338.03120474144816	loss1:135.85684776306152
2023-07-21 19:40:28,217 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:40:28,217 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:40:28,217 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:40:55,715 - 

2023-07-21 19:40:55,715 - epoch:128,	loss:341.4835665039718	loss1:135.85684776306152
2023-07-21 19:41:08,918 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:41:08,918 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:41:08,919 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:41:35,430 - 

2023-07-21 19:41:35,430 - epoch:129,	loss:344.3973007425666	loss1:138.62943649291992
2023-07-21 19:41:48,619 - right_count:347	total:433	 Answer ACC: 0.8013856812933026
2023-07-21 19:41:48,619 - right_codes_count:1772	total:1974	Code ACC: 0.8976697061803445	wrong_be_tree_count:31	wrong_total:86	 wrong be tree ACC: 0.36046511627906974
2023-07-21 19:41:48,620 - right_checker:1772	total:1974	checker ACC: 0.8976697325706482	temp:0	temp1:0	wrong_total:86	
2023-07-21 19:41:58,993 - 


2023-07-21 19:41:58,994 - final_test
2023-07-21 19:42:21,049 - right_count:351	total:433	 Answer ACC: 0.8106235565819861
2023-07-21 19:42:21,049 - right_codes_count:1773	total:1974	Code ACC: 0.898176291793313	wrong_be_tree_count:29	wrong_total:82	 wrong be tree ACC: 0.35365853658536583
2023-07-21 19:42:21,049 - right_checker:1773	total:1974	checker ACC: 0.8981763124465942	temp:0	temp1:0	wrong_total:82	
