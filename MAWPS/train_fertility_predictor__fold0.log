nohup: ignoring input
2023-03-24 21:43:36,498 - src.Train - INFO - get train data loader...
total input dataset len: 1730
  0%|          | 0/1730 [00:00<?, ?it/s]100%|██████████| 1730/1730 [00:00<00:00, 70423.40it/s]
after process dataset len: 1730
total passed: 0
207 batches created
2023-03-24 21:43:36,595 - src.Train - INFO - get dev data loader...
total input dataset len: 433
  0%|          | 0/433 [00:00<?, ?it/s]100%|██████████| 433/433 [00:00<00:00, 51017.86it/s]
after process dataset len: 433
total passed: 0
52 batches created
2023-03-24 21:43:36,633 - src.Train - INFO - define model...
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-03-24 21:43:44,104 - src.Train - INFO - define optimizer...
2023-03-24 21:43:44,105 - src.Train - INFO - ===========================train setting parameters=========================
2023-03-24 21:43:44,107 - src.Train - INFO - bert.embeddings.word_embeddings.weight-torch.Size([30522, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.embeddings.position_embeddings.weight-torch.Size([512, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.embeddings.token_type_embeddings.weight-torch.Size([2, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.embeddings.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.embeddings.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,107 - src.Train - INFO - bert.encoder.layer.0.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.0.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.0.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.0.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.0.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.0.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.1.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.2.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.3.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.3.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,108 - src.Train - INFO - bert.encoder.layer.3.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.3.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.4.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.5.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.5.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.5.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.5.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,109 - src.Train - INFO - bert.encoder.layer.5.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.5.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.6.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,110 - src.Train - INFO - bert.encoder.layer.7.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.7.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.8.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,111 - src.Train - INFO - bert.encoder.layer.9.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.9.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.10.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.11.attention.self.query.weight-torch.Size([768, 768])
2023-03-24 21:43:44,112 - src.Train - INFO - bert.encoder.layer.11.attention.self.query.bias-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.self.key.weight-torch.Size([768, 768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.self.key.bias-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.self.value.weight-torch.Size([768, 768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.self.value.bias-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.output.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.attention.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,114 - src.Train - INFO - bert.encoder.layer.11.intermediate.dense.weight-torch.Size([3072, 768])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.encoder.layer.11.intermediate.dense.bias-torch.Size([3072])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.encoder.layer.11.output.dense.weight-torch.Size([768, 3072])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.encoder.layer.11.output.dense.bias-torch.Size([768])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.encoder.layer.11.output.LayerNorm.weight-torch.Size([768])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.encoder.layer.11.output.LayerNorm.bias-torch.Size([768])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.pooler.dense.weight-torch.Size([768, 768])
2023-03-24 21:43:44,115 - src.Train - INFO - bert.pooler.dense.bias-torch.Size([768])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer1.0.weight-torch.Size([2048, 1536])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer1.0.bias-torch.Size([2048])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer1.1.weight-torch.Size([2048])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer1.1.bias-torch.Size([2048])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer2.0.weight-torch.Size([1024, 2048])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer2.0.bias-torch.Size([1024])
2023-03-24 21:43:44,116 - src.Train - INFO - fc.layer2.1.weight-torch.Size([1024])
2023-03-24 21:43:44,125 - src.Train - INFO - fc.layer2.1.bias-torch.Size([1024])
2023-03-24 21:43:44,125 - src.Train - INFO - fc.layer3.0.weight-torch.Size([28, 1024])
2023-03-24 21:43:44,125 - src.Train - INFO - fc.layer3.0.bias-torch.Size([28])
/data/zhyma/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
2023-03-24 21:43:44,143 - src.Train - INFO - 
>>>>>>>>>>>>>>>>>>>start train......
2023-03-24 21:43:49,947 - src.Train - INFO - epoch:0,	steps20/207,	loss:0.4314497709274292
2023-03-24 21:43:52,497 - src.Train - INFO - epoch:0,	steps40/207,	loss:0.34995603561401367
2023-03-24 21:43:54,966 - src.Train - INFO - epoch:0,	steps60/207,	loss:0.38034331798553467
2023-03-24 21:43:57,366 - src.Train - INFO - epoch:0,	steps80/207,	loss:0.31112125515937805
2023-03-24 21:43:59,809 - src.Train - INFO - epoch:0,	steps100/207,	loss:0.3222958445549011
2023-03-24 21:44:02,217 - src.Train - INFO - epoch:0,	steps120/207,	loss:0.27049538493156433
2023-03-24 21:44:04,837 - src.Train - INFO - epoch:0,	steps140/207,	loss:0.23073972761631012
2023-03-24 21:44:07,202 - src.Train - INFO - epoch:0,	steps160/207,	loss:0.21977940201759338
2023-03-24 21:44:09,873 - src.Train - INFO - epoch:0,	steps180/207,	loss:0.2185133844614029
2023-03-24 21:44:12,250 - src.Train - INFO - epoch:0,	steps200/207,	loss:0.1870853751897812
2023-03-24 21:44:13,131 - src.Train - INFO - start evaluate...
2023-03-24 21:44:13,131 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:44:15,164 - src.Train - INFO - right: 9	total: 1022	M-tree codes acc: 0.008806262230919765
2023-03-24 21:44:15,166 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 when a [UNK] [UNK] is turned on, it can fill a tub in γ minutes. when the drain is open, a full [UNK] can empty in δ minutes. how many minutes would it take for the [UNK] to fill if the water were turned on with the drain left open? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:44:29,805 - src.Train - INFO - epoch:1,	steps13/207,	loss:0.1664440780878067
2023-03-24 21:44:32,147 - src.Train - INFO - epoch:1,	steps33/207,	loss:0.16242346167564392
2023-03-24 21:44:34,727 - src.Train - INFO - epoch:1,	steps53/207,	loss:0.16721369326114655
2023-03-24 21:44:37,070 - src.Train - INFO - epoch:1,	steps73/207,	loss:0.1338975578546524
2023-03-24 21:44:39,748 - src.Train - INFO - epoch:1,	steps93/207,	loss:0.1534012407064438
2023-03-24 21:44:42,116 - src.Train - INFO - epoch:1,	steps113/207,	loss:0.13461944460868835
2023-03-24 21:44:44,823 - src.Train - INFO - epoch:1,	steps133/207,	loss:0.12958864867687225
2023-03-24 21:44:47,149 - src.Train - INFO - epoch:1,	steps153/207,	loss:0.12515492737293243
2023-03-24 21:44:49,598 - src.Train - INFO - epoch:1,	steps173/207,	loss:0.11776261776685715
2023-03-24 21:44:52,012 - src.Train - INFO - epoch:1,	steps193/207,	loss:0.10374555736780167
2023-03-24 21:44:53,791 - src.Train - INFO - start evaluate...
2023-03-24 21:44:53,791 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:44:55,755 - src.Train - INFO - right: 1	total: 1022	M-tree codes acc: 0.0009784735812133072
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 edward started his own lawn [UNK] business. in the spring he made γ dollars [UNK] [UNK] and in the summer he made δ dollars. if he had to spend ε dollars buying supplies, how much money did he end up with? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[17, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:45:01,975 - src.Train - INFO - epoch:2,	steps6/207,	loss:0.10938108712434769
2023-03-24 21:45:04,459 - src.Train - INFO - epoch:2,	steps26/207,	loss:0.09277231246232986
2023-03-24 21:45:06,894 - src.Train - INFO - epoch:2,	steps46/207,	loss:0.0702904760837555
2023-03-24 21:45:09,444 - src.Train - INFO - epoch:2,	steps66/207,	loss:0.08830057084560394
2023-03-24 21:45:11,995 - src.Train - INFO - epoch:2,	steps86/207,	loss:0.06624085456132889
2023-03-24 21:45:14,384 - src.Train - INFO - epoch:2,	steps106/207,	loss:0.07421887665987015
2023-03-24 21:45:16,919 - src.Train - INFO - epoch:2,	steps126/207,	loss:0.06283603608608246
2023-03-24 21:45:19,285 - src.Train - INFO - epoch:2,	steps146/207,	loss:0.0712161511182785
2023-03-24 21:45:21,916 - src.Train - INFO - epoch:2,	steps166/207,	loss:0.055890679359436035
2023-03-24 21:45:24,319 - src.Train - INFO - epoch:2,	steps186/207,	loss:0.05362161993980408
2023-03-24 21:45:26,737 - src.Train - INFO - epoch:2,	steps206/207,	loss:0.04935792461037636
2023-03-24 21:45:26,804 - src.Train - INFO - start evaluate...
2023-03-24 21:45:26,804 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:45:28,856 - src.Train - INFO - right: 3	total: 1022	M-tree codes acc: 0.0029354207436399216
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 hoping to be named [UNK] of the month, rosa called the names from γ pages of the phone book last week. this week, she called the people listed on another δ pages of the same phone book. how many pages worth of people did rosa call in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:45:40,957 - src.Train - INFO - epoch:3,	steps19/207,	loss:0.046522945165634155
2023-03-24 21:45:43,318 - src.Train - INFO - epoch:3,	steps39/207,	loss:0.049191877245903015
2023-03-24 21:45:45,972 - src.Train - INFO - epoch:3,	steps59/207,	loss:0.04986284673213959
2023-03-24 21:45:48,256 - src.Train - INFO - epoch:3,	steps79/207,	loss:0.04053845256567001
2023-03-24 21:45:50,731 - src.Train - INFO - epoch:3,	steps99/207,	loss:0.04616421088576317
2023-03-24 21:45:53,213 - src.Train - INFO - epoch:3,	steps119/207,	loss:0.047796446830034256
2023-03-24 21:45:55,544 - src.Train - INFO - epoch:3,	steps139/207,	loss:0.042200732976198196
2023-03-24 21:45:58,167 - src.Train - INFO - epoch:3,	steps159/207,	loss:0.037527021020650864
2023-03-24 21:46:00,497 - src.Train - INFO - epoch:3,	steps179/207,	loss:0.042531345039606094
2023-03-24 21:46:03,105 - src.Train - INFO - epoch:3,	steps199/207,	loss:0.04533333703875542
2023-03-24 21:46:03,942 - src.Train - INFO - start evaluate...
2023-03-24 21:46:03,942 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:46:06,011 - src.Train - INFO - right: 52	total: 1022	M-tree codes acc: 0.050880626223091974
2023-03-24 21:46:06,012 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ [UNK] trees currently in the park. park workers will plant δ [UNK] trees today and ε [UNK] trees tomorrow. it took ζ workers to finish the work. how many [UNK] trees will the park have when the workers are finished? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[23, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:46:20,087 - src.Train - INFO - epoch:4,	steps12/207,	loss:0.05607577785849571
2023-03-24 21:46:22,513 - src.Train - INFO - epoch:4,	steps32/207,	loss:0.03232021629810333
2023-03-24 21:46:24,828 - src.Train - INFO - epoch:4,	steps52/207,	loss:0.03550156578421593
2023-03-24 21:46:27,172 - src.Train - INFO - epoch:4,	steps72/207,	loss:0.04788688197731972
2023-03-24 21:46:29,455 - src.Train - INFO - epoch:4,	steps92/207,	loss:0.03809651359915733
2023-03-24 21:46:31,818 - src.Train - INFO - epoch:4,	steps112/207,	loss:0.03537297621369362
2023-03-24 21:46:34,074 - src.Train - INFO - epoch:4,	steps132/207,	loss:0.033569879829883575
2023-03-24 21:46:36,372 - src.Train - INFO - epoch:4,	steps152/207,	loss:0.033887170255184174
2023-03-24 21:46:38,691 - src.Train - INFO - epoch:4,	steps172/207,	loss:0.03432426601648331
2023-03-24 21:46:40,981 - src.Train - INFO - epoch:4,	steps192/207,	loss:0.03576285392045975
2023-03-24 21:46:42,621 - src.Train - INFO - start evaluate...
2023-03-24 21:46:42,621 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:46:44,744 - src.Train - INFO - right: 229	total: 1022	M-tree codes acc: 0.22407045009784735
2023-03-24 21:46:44,745 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 47])
torch.Size([20, 47])
torch.Size([20, 47])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 paige and her friends were recycling paper for their class. for every γ pounds they recycled they earned one point. if paige recycled δ pounds and her friends recycled ε pounds, how many points did they earn? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[17, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:47:00,377 - src.Train - INFO - epoch:5,	steps5/207,	loss:0.0346050001680851
2023-03-24 21:47:02,338 - src.Train - INFO - epoch:5,	steps25/207,	loss:0.02938094176352024
2023-03-24 21:47:03,714 - src.Train - INFO - epoch:5,	steps45/207,	loss:0.029818309471011162
2023-03-24 21:47:05,078 - src.Train - INFO - epoch:5,	steps65/207,	loss:0.03245191276073456
2023-03-24 21:47:06,497 - src.Train - INFO - epoch:5,	steps85/207,	loss:0.03214180842041969
2023-03-24 21:47:07,864 - src.Train - INFO - epoch:5,	steps105/207,	loss:0.039705466479063034
2023-03-24 21:47:09,188 - src.Train - INFO - epoch:5,	steps125/207,	loss:0.028081785887479782
2023-03-24 21:47:10,559 - src.Train - INFO - epoch:5,	steps145/207,	loss:0.02809070609509945
2023-03-24 21:47:11,879 - src.Train - INFO - epoch:5,	steps165/207,	loss:0.027187954634428024
2023-03-24 21:47:13,215 - src.Train - INFO - epoch:5,	steps185/207,	loss:0.04007963463664055
2023-03-24 21:47:14,560 - src.Train - INFO - epoch:5,	steps205/207,	loss:0.02545391581952572
2023-03-24 21:47:14,668 - src.Train - INFO - start evaluate...
2023-03-24 21:47:14,668 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:47:15,708 - src.Train - INFO - right: 436	total: 1022	M-tree codes acc: 0.42661448140900193
2023-03-24 21:47:15,709 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 71])
torch.Size([20, 71])
torch.Size([20, 71])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 the sears tower in chicago is γ feet tall. the john hancock center in chicago is δ feet tall. suppose you are asked to build a small - scale replica of each. if you make the sears tower ε meter tall, what would be the approximate [UNK] of the john hancock replica? round your answer to the nearest [UNK]. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[21, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:47:28,810 - src.Train - INFO - epoch:6,	steps18/207,	loss:0.026337260380387306
2023-03-24 21:47:30,134 - src.Train - INFO - epoch:6,	steps38/207,	loss:0.029624322429299355
2023-03-24 21:47:31,511 - src.Train - INFO - epoch:6,	steps58/207,	loss:0.02375289984047413
2023-03-24 21:47:32,887 - src.Train - INFO - epoch:6,	steps78/207,	loss:0.02775387652218342
2023-03-24 21:47:34,263 - src.Train - INFO - epoch:6,	steps98/207,	loss:0.02074647881090641
2023-03-24 21:47:35,989 - src.Train - INFO - epoch:6,	steps118/207,	loss:0.02305532805621624
2023-03-24 21:47:38,726 - src.Train - INFO - epoch:6,	steps138/207,	loss:0.02539953775703907
2023-03-24 21:47:41,011 - src.Train - INFO - epoch:6,	steps158/207,	loss:0.025438131764531136
2023-03-24 21:47:44,020 - src.Train - INFO - epoch:6,	steps178/207,	loss:0.028411639854311943
2023-03-24 21:47:47,098 - src.Train - INFO - epoch:6,	steps198/207,	loss:0.02202867716550827
2023-03-24 21:47:48,363 - src.Train - INFO - start evaluate...
2023-03-24 21:47:48,363 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:47:50,869 - src.Train - INFO - right: 545	total: 1022	M-tree codes acc: 0.5332681017612525
2023-03-24 21:47:50,870 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jonathan wants to buy a dictionary that costs $ γ, a dinosaur book that costs $ δ, and a children [UNK] [UNK] that costs $ ε. he has saved $ ζ from his allowance. how much more money does jonathan need to buy all three books? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[21, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:48:04,419 - src.Train - INFO - epoch:7,	steps11/207,	loss:0.021056894212961197
2023-03-24 21:48:07,495 - src.Train - INFO - epoch:7,	steps31/207,	loss:0.0209508016705513
2023-03-24 21:48:10,609 - src.Train - INFO - epoch:7,	steps51/207,	loss:0.017057102173566818
2023-03-24 21:48:14,052 - src.Train - INFO - epoch:7,	steps71/207,	loss:0.02112163044512272
2023-03-24 21:48:18,382 - src.Train - INFO - epoch:7,	steps91/207,	loss:0.029353544116020203
2023-03-24 21:48:22,891 - src.Train - INFO - epoch:7,	steps111/207,	loss:0.029905803501605988
2023-03-24 21:48:27,522 - src.Train - INFO - epoch:7,	steps131/207,	loss:0.027032913640141487
2023-03-24 21:48:32,604 - src.Train - INFO - epoch:7,	steps151/207,	loss:0.023277075961232185
2023-03-24 21:48:37,400 - src.Train - INFO - epoch:7,	steps171/207,	loss:0.023265551775693893
2023-03-24 21:48:42,014 - src.Train - INFO - epoch:7,	steps191/207,	loss:0.024515241384506226
2023-03-24 21:48:45,585 - src.Train - INFO - start evaluate...
2023-03-24 21:48:45,586 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:48:49,675 - src.Train - INFO - right: 566	total: 1022	M-tree codes acc: 0.5538160469667319
2023-03-24 21:48:49,676 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:49:02,652 - src.Train - INFO - epoch:8,	steps4/207,	loss:0.018951665610074997
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 victor was helping the cafeteria workers pick up lunch [UNK], but he could only carry γ [UNK] at a time. if he had to pick up δ [UNK] from one ta [UNK] and ε [UNK] from another, how many trips will he make? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:49:07,068 - src.Train - INFO - epoch:8,	steps24/207,	loss:0.018493182957172394
2023-03-24 21:49:10,143 - src.Train - INFO - epoch:8,	steps44/207,	loss:0.03309379890561104
2023-03-24 21:49:12,941 - src.Train - INFO - epoch:8,	steps64/207,	loss:0.02798331342637539
2023-03-24 21:49:15,994 - src.Train - INFO - epoch:8,	steps84/207,	loss:0.02206607162952423
2023-03-24 21:49:19,032 - src.Train - INFO - epoch:8,	steps104/207,	loss:0.015378216281533241
2023-03-24 21:49:22,089 - src.Train - INFO - epoch:8,	steps124/207,	loss:0.02568727731704712
2023-03-24 21:49:25,039 - src.Train - INFO - epoch:8,	steps144/207,	loss:0.01883777230978012
2023-03-24 21:49:28,422 - src.Train - INFO - epoch:8,	steps164/207,	loss:0.02383030578494072
2023-03-24 21:49:31,756 - src.Train - INFO - epoch:8,	steps184/207,	loss:0.023003578186035156
2023-03-24 21:49:35,146 - src.Train - INFO - epoch:8,	steps204/207,	loss:0.02135448530316353
2023-03-24 21:49:35,581 - src.Train - INFO - start evaluate...
2023-03-24 21:49:35,581 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:49:38,447 - src.Train - INFO - right: 675	total: 1022	M-tree codes acc: 0.6604696673189824
2023-03-24 21:49:38,448 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 zach wants to ride the ferris wheel, the roller coaster, and the log ride. the ferris wheel costs γ tickets, the roller coaster costs δ tickets and the log ride costs ε ticket. zach has ζ ticket. how many more tickets should zach buy? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[32, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:49:59,639 - src.Train - INFO - epoch:9,	steps17/207,	loss:0.012718278914690018
2023-03-24 21:50:01,425 - src.Train - INFO - epoch:9,	steps37/207,	loss:0.015812948346138
2023-03-24 21:50:03,244 - src.Train - INFO - epoch:9,	steps57/207,	loss:0.02682529203593731
2023-03-24 21:50:05,086 - src.Train - INFO - epoch:9,	steps77/207,	loss:0.014870882034301758
2023-03-24 21:50:06,857 - src.Train - INFO - epoch:9,	steps97/207,	loss:0.015267997048795223
2023-03-24 21:50:08,682 - src.Train - INFO - epoch:9,	steps117/207,	loss:0.021171964704990387
2023-03-24 21:50:10,467 - src.Train - INFO - epoch:9,	steps137/207,	loss:0.014189627021551132
2023-03-24 21:50:12,243 - src.Train - INFO - epoch:9,	steps157/207,	loss:0.018786689266562462
2023-03-24 21:50:14,095 - src.Train - INFO - epoch:9,	steps177/207,	loss:0.014275239780545235
2023-03-24 21:50:16,208 - src.Train - INFO - epoch:9,	steps197/207,	loss:0.017476383596658707
2023-03-24 21:50:17,365 - src.Train - INFO - start evaluate...
2023-03-24 21:50:17,365 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:50:19,552 - src.Train - INFO - right: 756	total: 1022	M-tree codes acc: 0.7397260273972602
2023-03-24 21:50:19,553 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a new virus is released on the internet. the administrator of a department [UNK] lan is given γ minutes by a manager to estimate the impact. the administrator samples δ of the pcs connected to the lan and finds that ε are infected. use a proportion to estimate the number of infected pcs if there are a total of ζ pcs connected to the lan. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
====================
label:[46, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:50:34,750 - src.Train - INFO - epoch:10,	steps10/207,	loss:0.01697028987109661
2023-03-24 21:50:37,104 - src.Train - INFO - epoch:10,	steps30/207,	loss:0.015204010531306267
2023-03-24 21:50:39,621 - src.Train - INFO - epoch:10,	steps50/207,	loss:0.016925955191254616
2023-03-24 21:50:42,070 - src.Train - INFO - epoch:10,	steps70/207,	loss:0.013127471320331097
2023-03-24 21:50:44,470 - src.Train - INFO - epoch:10,	steps90/207,	loss:0.012238583527505398
2023-03-24 21:50:46,941 - src.Train - INFO - epoch:10,	steps110/207,	loss:0.017596522346138954
2023-03-24 21:50:49,367 - src.Train - INFO - epoch:10,	steps130/207,	loss:0.011199017986655235
2023-03-24 21:50:51,928 - src.Train - INFO - epoch:10,	steps150/207,	loss:0.013975095935165882
2023-03-24 21:50:54,338 - src.Train - INFO - epoch:10,	steps170/207,	loss:0.01939869299530983
2023-03-24 21:50:56,907 - src.Train - INFO - epoch:10,	steps190/207,	loss:0.010980688035488129
2023-03-24 21:50:58,962 - src.Train - INFO - start evaluate...
2023-03-24 21:50:58,962 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:51:00,951 - src.Train - INFO - right: 779	total: 1022	M-tree codes acc: 0.7622309197651663
2023-03-24 21:51:00,952 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:51:15,436 - src.Train - INFO - epoch:11,	steps3/207,	loss:0.012108447030186653
torch.Size([20, 87])
torch.Size([20, 87])
torch.Size([20, 87])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 about γ million households had one brand of personal computers in δ. the use of these computers grew at an average rate of ε million households a year. in ζ, a bout η millions households used another type of computer. the use of these computers grew at an average rate of θ million households a year. how long will it take for the ι types of computers to be in the same number of households? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:51:17,959 - src.Train - INFO - epoch:11,	steps23/207,	loss:0.020028332248330116
2023-03-24 21:51:20,466 - src.Train - INFO - epoch:11,	steps43/207,	loss:0.008827629499137402
2023-03-24 21:51:22,826 - src.Train - INFO - epoch:11,	steps63/207,	loss:0.012918703258037567
2023-03-24 21:51:25,502 - src.Train - INFO - epoch:11,	steps83/207,	loss:0.012052681297063828
2023-03-24 21:51:27,836 - src.Train - INFO - epoch:11,	steps103/207,	loss:0.012891224585473537
2023-03-24 21:51:30,437 - src.Train - INFO - epoch:11,	steps123/207,	loss:0.010211733169853687
2023-03-24 21:51:32,861 - src.Train - INFO - epoch:11,	steps143/207,	loss:0.009870772249996662
2023-03-24 21:51:35,372 - src.Train - INFO - epoch:11,	steps163/207,	loss:0.010907402262091637
2023-03-24 21:51:37,773 - src.Train - INFO - epoch:11,	steps183/207,	loss:0.008462575264275074
2023-03-24 21:51:40,138 - src.Train - INFO - epoch:11,	steps203/207,	loss:0.009687071666121483
2023-03-24 21:51:40,705 - src.Train - INFO - start evaluate...
2023-03-24 21:51:40,705 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:51:42,625 - src.Train - INFO - right: 786	total: 1022	M-tree codes acc: 0.7690802348336595
2023-03-24 21:51:42,626 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 shannon, brenda [UNK] neighbor, joined brenda in making [UNK]. she brought γ heart - shaped stones and wanted to have δ of this type of stone in each of the bracelet she makes. how many [UNK] with heart - shaped stones can shannon make? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[18, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:51:55,285 - src.Train - INFO - epoch:12,	steps16/207,	loss:0.008417039178311825
2023-03-24 21:51:57,783 - src.Train - INFO - epoch:12,	steps36/207,	loss:0.011333831585943699
2023-03-24 21:52:00,252 - src.Train - INFO - epoch:12,	steps56/207,	loss:0.005893892142921686
2023-03-24 21:52:02,763 - src.Train - INFO - epoch:12,	steps76/207,	loss:0.011048256419599056
2023-03-24 21:52:05,189 - src.Train - INFO - epoch:12,	steps96/207,	loss:0.007094624452292919
2023-03-24 21:52:07,646 - src.Train - INFO - epoch:12,	steps116/207,	loss:0.01267933938652277
2023-03-24 21:52:10,220 - src.Train - INFO - epoch:12,	steps136/207,	loss:0.011818082071840763
2023-03-24 21:52:12,651 - src.Train - INFO - epoch:12,	steps156/207,	loss:0.018364720046520233
2023-03-24 21:52:15,316 - src.Train - INFO - epoch:12,	steps176/207,	loss:0.015149802900850773
2023-03-24 21:52:17,619 - src.Train - INFO - epoch:12,	steps196/207,	loss:0.009355461224913597
2023-03-24 21:52:18,996 - src.Train - INFO - start evaluate...
2023-03-24 21:52:18,996 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:52:21,099 - src.Train - INFO - right: 795	total: 1022	M-tree codes acc: 0.7778864970645792
2023-03-24 21:52:21,100 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:52:34,886 - src.Train - INFO - epoch:13,	steps9/207,	loss:0.006581899244338274
torch.Size([20, 72])
torch.Size([20, 72])
torch.Size([20, 72])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 dalton wants to buy a jump rope that costs $ γ, a board game that costs $ δ, and a playground ball that costs $ ε. he has saved $ ζ from his allowance, and his uncle gave him $ η. how much more money does dalton need to buy the jump rope, the game, and the ball? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[22, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:52:37,483 - src.Train - INFO - epoch:13,	steps29/207,	loss:0.011891159228980541
2023-03-24 21:52:39,971 - src.Train - INFO - epoch:13,	steps49/207,	loss:0.011187960393726826
2023-03-24 21:52:42,392 - src.Train - INFO - epoch:13,	steps69/207,	loss:0.01220607291907072
2023-03-24 21:52:44,864 - src.Train - INFO - epoch:13,	steps89/207,	loss:0.011181465350091457
2023-03-24 21:52:47,298 - src.Train - INFO - epoch:13,	steps109/207,	loss:0.004368227440863848
2023-03-24 21:52:49,821 - src.Train - INFO - epoch:13,	steps129/207,	loss:0.003007955150678754
2023-03-24 21:52:52,188 - src.Train - INFO - epoch:13,	steps149/207,	loss:0.008519042283296585
2023-03-24 21:52:54,822 - src.Train - INFO - epoch:13,	steps169/207,	loss:0.007838964462280273
2023-03-24 21:52:57,212 - src.Train - INFO - epoch:13,	steps189/207,	loss:0.005169701296836138
2023-03-24 21:52:59,341 - src.Train - INFO - start evaluate...
2023-03-24 21:52:59,341 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:53:01,472 - src.Train - INFO - right: 792	total: 1022	M-tree codes acc: 0.7749510763209393
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:53:08,360 - src.Train - INFO - epoch:14,	steps2/207,	loss:0.011268229223787785
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a quiz is worth γ points. you want a δ point average for all ε [UNK]. you already took ζ [UNK] with scores of η, θ, ι and κ. what must your score be on your final quiz to reach your average? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[34, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:53:10,889 - src.Train - INFO - epoch:14,	steps22/207,	loss:0.010441743768751621
2023-03-24 21:53:13,413 - src.Train - INFO - epoch:14,	steps42/207,	loss:0.003833300666883588
2023-03-24 21:53:15,813 - src.Train - INFO - epoch:14,	steps62/207,	loss:0.008329713717103004
2023-03-24 21:53:18,293 - src.Train - INFO - epoch:14,	steps82/207,	loss:0.014938831329345703
2023-03-24 21:53:20,693 - src.Train - INFO - epoch:14,	steps102/207,	loss:0.008668490685522556
2023-03-24 21:53:23,338 - src.Train - INFO - epoch:14,	steps122/207,	loss:0.008613772690296173
2023-03-24 21:53:25,708 - src.Train - INFO - epoch:14,	steps142/207,	loss:0.008278821595013142
2023-03-24 21:53:28,318 - src.Train - INFO - epoch:14,	steps162/207,	loss:0.00833286065608263
2023-03-24 21:53:30,706 - src.Train - INFO - epoch:14,	steps182/207,	loss:0.005277971737086773
2023-03-24 21:53:33,377 - src.Train - INFO - epoch:14,	steps202/207,	loss:0.005237747449427843
2023-03-24 21:53:33,886 - src.Train - INFO - start evaluate...
2023-03-24 21:53:33,886 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:53:36,050 - src.Train - INFO - right: 821	total: 1022	M-tree codes acc: 0.8033268101761253
2023-03-24 21:53:36,052 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ maple trees and δ orange trees currently in the park. park workers will plant maple trees today. when the workers are finished there will be ε maple trees in the park. how many maple trees did the workers plant today? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[6, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:53:48,881 - src.Train - INFO - epoch:15,	steps15/207,	loss:0.0035785625223070383
2023-03-24 21:53:51,109 - src.Train - INFO - epoch:15,	steps35/207,	loss:0.007355604786425829
2023-03-24 21:53:53,352 - src.Train - INFO - epoch:15,	steps55/207,	loss:0.004661111626774073
2023-03-24 21:53:55,690 - src.Train - INFO - epoch:15,	steps75/207,	loss:0.005186501424759626
2023-03-24 21:53:58,006 - src.Train - INFO - epoch:15,	steps95/207,	loss:0.00623851316049695
2023-03-24 21:54:00,352 - src.Train - INFO - epoch:15,	steps115/207,	loss:0.006681766360998154
2023-03-24 21:54:02,661 - src.Train - INFO - epoch:15,	steps135/207,	loss:0.005282293539494276
2023-03-24 21:54:04,985 - src.Train - INFO - epoch:15,	steps155/207,	loss:0.010468801483511925
2023-03-24 21:54:07,305 - src.Train - INFO - epoch:15,	steps175/207,	loss:0.015671951696276665
2023-03-24 21:54:09,611 - src.Train - INFO - epoch:15,	steps195/207,	loss:0.008348515257239342
2023-03-24 21:54:10,934 - src.Train - INFO - start evaluate...
2023-03-24 21:54:10,934 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:54:12,944 - src.Train - INFO - right: 804	total: 1022	M-tree codes acc: 0.786692759295499
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:54:19,482 - src.Train - INFO - epoch:16,	steps8/207,	loss:0.010622959583997726
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 luke had γ pieces of clothing to wash. he put δ of them in one load, but decided to split the rest into ε equal loads. how many pieces of clothing could go in each of the small loads? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[29, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:54:21,787 - src.Train - INFO - epoch:16,	steps28/207,	loss:0.004211928229779005
2023-03-24 21:54:23,954 - src.Train - INFO - epoch:16,	steps48/207,	loss:0.008024587295949459
2023-03-24 21:54:26,159 - src.Train - INFO - epoch:16,	steps68/207,	loss:0.006600402761250734
2023-03-24 21:54:28,476 - src.Train - INFO - epoch:16,	steps88/207,	loss:0.006180826108902693
2023-03-24 21:54:30,777 - src.Train - INFO - epoch:16,	steps108/207,	loss:0.002238224260509014
2023-03-24 21:54:33,089 - src.Train - INFO - epoch:16,	steps128/207,	loss:0.01486230455338955
2023-03-24 21:54:35,411 - src.Train - INFO - epoch:16,	steps148/207,	loss:0.010718531906604767
2023-03-24 21:54:37,732 - src.Train - INFO - epoch:16,	steps168/207,	loss:0.00931360013782978
2023-03-24 21:54:40,100 - src.Train - INFO - epoch:16,	steps188/207,	loss:0.009553718380630016
2023-03-24 21:54:42,279 - src.Train - INFO - start evaluate...
2023-03-24 21:54:42,279 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:54:44,240 - src.Train - INFO - right: 820	total: 1022	M-tree codes acc: 0.8023483365949119
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:54:51,461 - src.Train - INFO - epoch:17,	steps1/207,	loss:0.00673074321821332
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 suppose you are starting an office cleaning service. you have spent γ dollars on equipment. to clean an office, you use δ dollars worth of supplies you purchased. you charge ε dollars per office. how many offices must you clean to break even? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[16, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:54:53,692 - src.Train - INFO - epoch:17,	steps21/207,	loss:0.007321134675294161
2023-03-24 21:54:56,024 - src.Train - INFO - epoch:17,	steps41/207,	loss:0.007793146185576916
2023-03-24 21:54:58,319 - src.Train - INFO - epoch:17,	steps61/207,	loss:0.006245749071240425
2023-03-24 21:55:00,639 - src.Train - INFO - epoch:17,	steps81/207,	loss:0.010362550616264343
2023-03-24 21:55:02,926 - src.Train - INFO - epoch:17,	steps101/207,	loss:0.0055374810472130775
2023-03-24 21:55:05,283 - src.Train - INFO - epoch:17,	steps121/207,	loss:0.004122225102037191
2023-03-24 21:55:08,846 - src.Train - INFO - epoch:17,	steps141/207,	loss:0.004656318575143814
2023-03-24 21:55:12,170 - src.Train - INFO - epoch:17,	steps161/207,	loss:0.008716069161891937
2023-03-24 21:55:16,053 - src.Train - INFO - epoch:17,	steps181/207,	loss:0.007726464886218309
2023-03-24 21:55:19,201 - src.Train - INFO - epoch:17,	steps201/207,	loss:0.005669873673468828
2023-03-24 21:55:20,322 - src.Train - INFO - start evaluate...
2023-03-24 21:55:20,322 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:55:23,510 - src.Train - INFO - right: 830	total: 1022	M-tree codes acc: 0.812133072407045
2023-03-24 21:55:23,511 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:55:38,826 - src.Train - INFO - epoch:18,	steps14/207,	loss:0.007363949436694384
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a quiz is worth γ points. you want a δ point average for all ε [UNK]. you already took ζ [UNK] with scores of η, θ, ι and κ. what must your score be on your final quiz to reach your average? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[36, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:55:42,766 - src.Train - INFO - epoch:18,	steps34/207,	loss:0.005396111868321896
2023-03-24 21:55:46,402 - src.Train - INFO - epoch:18,	steps54/207,	loss:0.010495019145309925
2023-03-24 21:55:50,009 - src.Train - INFO - epoch:18,	steps74/207,	loss:0.005954031832516193
2023-03-24 21:55:53,858 - src.Train - INFO - epoch:18,	steps94/207,	loss:0.00818614661693573
2023-03-24 21:55:57,600 - src.Train - INFO - epoch:18,	steps114/207,	loss:0.007458284962922335
2023-03-24 21:56:01,192 - src.Train - INFO - epoch:18,	steps134/207,	loss:0.007280365098267794
2023-03-24 21:56:05,113 - src.Train - INFO - epoch:18,	steps154/207,	loss:0.013910647481679916
2023-03-24 21:56:08,884 - src.Train - INFO - epoch:18,	steps174/207,	loss:0.010068749077618122
2023-03-24 21:56:12,573 - src.Train - INFO - epoch:18,	steps194/207,	loss:0.008879591710865498
2023-03-24 21:56:14,965 - src.Train - INFO - start evaluate...
2023-03-24 21:56:14,966 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:56:18,229 - src.Train - INFO - right: 842	total: 1022	M-tree codes acc: 0.8238747553816047
2023-03-24 21:56:18,230 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:56:43,440 - src.Train - INFO - epoch:19,	steps7/207,	loss:0.0038058424834161997
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a container ship left from [UNK] pier and traveled north. an aircraft carrier left γ hours later traveling at δ miles per hour in an effort to catch up to the container ship. after traveling for ε hours the aircraft carrier finally caught up. what was the container ship [UNK] average speed in miles per hour? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:56:45,662 - src.Train - INFO - epoch:19,	steps27/207,	loss:0.00768585130572319
2023-03-24 21:56:48,031 - src.Train - INFO - epoch:19,	steps47/207,	loss:0.0033013038337230682
2023-03-24 21:56:50,339 - src.Train - INFO - epoch:19,	steps67/207,	loss:0.0029218962881714106
2023-03-24 21:56:52,617 - src.Train - INFO - epoch:19,	steps87/207,	loss:0.00574311101809144
2023-03-24 21:56:54,979 - src.Train - INFO - epoch:19,	steps107/207,	loss:0.010325544513761997
2023-03-24 21:56:57,324 - src.Train - INFO - epoch:19,	steps127/207,	loss:0.0027262065559625626
2023-03-24 21:56:59,597 - src.Train - INFO - epoch:19,	steps147/207,	loss:0.004547103773802519
2023-03-24 21:57:01,924 - src.Train - INFO - epoch:19,	steps167/207,	loss:0.004547943361103535
2023-03-24 21:57:04,259 - src.Train - INFO - epoch:19,	steps187/207,	loss:0.003666602773591876
2023-03-24 21:57:06,450 - src.Train - INFO - epoch:19,	steps207/207,	loss:0.18192441761493683
2023-03-24 21:57:06,450 - src.Train - INFO - start evaluate...
2023-03-24 21:57:06,450 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:57:08,407 - src.Train - INFO - right: 842	total: 1022	M-tree codes acc: 0.8238747553816047
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 nancy went to γ football games this month. she went to δ games last month, and plans to go to ε games next month. she paid ζ dollars for the tickets. how many games will she attend in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[26, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:57:25,676 - src.Train - INFO - epoch:20,	steps20/207,	loss:0.009251306764781475
2023-03-24 21:57:28,152 - src.Train - INFO - epoch:20,	steps40/207,	loss:0.00600085174664855
2023-03-24 21:57:30,708 - src.Train - INFO - epoch:20,	steps60/207,	loss:0.004960266407579184
2023-03-24 21:57:33,304 - src.Train - INFO - epoch:20,	steps80/207,	loss:0.006966789718717337
2023-03-24 21:57:35,755 - src.Train - INFO - epoch:20,	steps100/207,	loss:0.0027734539471566677
2023-03-24 21:57:38,136 - src.Train - INFO - epoch:20,	steps120/207,	loss:0.0024423927534371614
2023-03-24 21:57:40,683 - src.Train - INFO - epoch:20,	steps140/207,	loss:0.004715514834970236
2023-03-24 21:57:43,062 - src.Train - INFO - epoch:20,	steps160/207,	loss:0.010384837165474892
2023-03-24 21:57:45,561 - src.Train - INFO - epoch:20,	steps180/207,	loss:0.002655407413840294
2023-03-24 21:57:48,013 - src.Train - INFO - epoch:20,	steps200/207,	loss:0.0033552860841155052
2023-03-24 21:57:48,823 - src.Train - INFO - start evaluate...
2023-03-24 21:57:48,823 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:57:50,816 - src.Train - INFO - right: 842	total: 1022	M-tree codes acc: 0.8238747553816047
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:58:02,077 - src.Train - INFO - epoch:21,	steps13/207,	loss:0.006388756912201643
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] had γ pieces of clothing to wash. he put δ of them in one load, but decided to split the rest into ε equal loads. how many pieces of clothing could go in each of the small loads? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[15, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:58:04,753 - src.Train - INFO - epoch:21,	steps33/207,	loss:0.003242812119424343
2023-03-24 21:58:07,208 - src.Train - INFO - epoch:21,	steps53/207,	loss:0.0051085129380226135
2023-03-24 21:58:09,555 - src.Train - INFO - epoch:21,	steps73/207,	loss:0.007188959047198296
2023-03-24 21:58:12,054 - src.Train - INFO - epoch:21,	steps93/207,	loss:0.004843377973884344
2023-03-24 21:58:14,430 - src.Train - INFO - epoch:21,	steps113/207,	loss:0.003949708770960569
2023-03-24 21:58:16,974 - src.Train - INFO - epoch:21,	steps133/207,	loss:0.008518500253558159
2023-03-24 21:58:19,436 - src.Train - INFO - epoch:21,	steps153/207,	loss:0.004295120015740395
2023-03-24 21:58:21,957 - src.Train - INFO - epoch:21,	steps173/207,	loss:0.007780737709254026
2023-03-24 21:58:24,375 - src.Train - INFO - epoch:21,	steps193/207,	loss:0.0031074821017682552
2023-03-24 21:58:26,008 - src.Train - INFO - start evaluate...
2023-03-24 21:58:26,008 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:58:28,114 - src.Train - INFO - right: 847	total: 1022	M-tree codes acc: 0.8287671232876712
2023-03-24 21:58:28,116 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:58:56,294 - src.Train - INFO - epoch:22,	steps6/207,	loss:0.0030782048124819994
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 olivia uploaded γ pictures from her phone and δ from her camera to facebook. if she sorted the [UNK] into ε different albums with the same amount of [UNK] in each album, how many pictures were in each of the albums? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[12, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 21:58:58,695 - src.Train - INFO - epoch:22,	steps26/207,	loss:0.010100005194544792
2023-03-24 21:59:01,195 - src.Train - INFO - epoch:22,	steps46/207,	loss:0.008051455020904541
2023-03-24 21:59:03,674 - src.Train - INFO - epoch:22,	steps66/207,	loss:0.0057069710455834866
2023-03-24 21:59:06,087 - src.Train - INFO - epoch:22,	steps86/207,	loss:0.0060228328220546246
2023-03-24 21:59:08,516 - src.Train - INFO - epoch:22,	steps106/207,	loss:0.005420207511633635
2023-03-24 21:59:10,893 - src.Train - INFO - epoch:22,	steps126/207,	loss:0.004227676894515753
2023-03-24 21:59:13,550 - src.Train - INFO - epoch:22,	steps146/207,	loss:0.0040093823336064816
2023-03-24 21:59:15,962 - src.Train - INFO - epoch:22,	steps166/207,	loss:0.006137407850474119
2023-03-24 21:59:18,245 - src.Train - INFO - epoch:22,	steps186/207,	loss:0.004092726390808821
2023-03-24 21:59:20,857 - src.Train - INFO - epoch:22,	steps206/207,	loss:0.0029380382038652897
2023-03-24 21:59:20,911 - src.Train - INFO - start evaluate...
2023-03-24 21:59:20,911 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 21:59:22,874 - src.Train - INFO - right: 848	total: 1022	M-tree codes acc: 0.8297455968688845
2023-03-24 21:59:22,875 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 21:59:57,909 - src.Train - INFO - epoch:23,	steps19/207,	loss:0.005214241798967123
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 an oil pipe in the sea broke. before engineers started to fix the pipe, γ [UNK] of oil leaked into the water. while the engineers worked, the pipe leaked δ more [UNK] of oil. in all, how many [UNK] of oil leaked into the water? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:00:00,378 - src.Train - INFO - epoch:23,	steps39/207,	loss:0.0030952568631619215
2023-03-24 22:00:02,961 - src.Train - INFO - epoch:23,	steps59/207,	loss:0.005945037119090557
2023-03-24 22:00:05,300 - src.Train - INFO - epoch:23,	steps79/207,	loss:0.0022626779973506927
2023-03-24 22:00:07,955 - src.Train - INFO - epoch:23,	steps99/207,	loss:0.005706344731152058
2023-03-24 22:00:10,319 - src.Train - INFO - epoch:23,	steps119/207,	loss:0.009393787011504173
2023-03-24 22:00:12,904 - src.Train - INFO - epoch:23,	steps139/207,	loss:0.004278871230781078
2023-03-24 22:00:15,273 - src.Train - INFO - epoch:23,	steps159/207,	loss:0.0050682867877185345
2023-03-24 22:00:17,744 - src.Train - INFO - epoch:23,	steps179/207,	loss:0.00219356594607234
2023-03-24 22:00:20,201 - src.Train - INFO - epoch:23,	steps199/207,	loss:0.004817971959710121
2023-03-24 22:00:21,195 - src.Train - INFO - start evaluate...
2023-03-24 22:00:21,196 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:00:23,200 - src.Train - INFO - right: 837	total: 1022	M-tree codes acc: 0.8189823874755382
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:00:40,505 - src.Train - INFO - epoch:24,	steps12/207,	loss:0.007480089087039232
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 kylie was collecting coins. she got γ coins from her [UNK] bank and δ coins from her brother. her father gave kylie ε coins. kylie gave ζ of the coins to her friend laura. how many coins did kylie have left? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[18, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:00:42,876 - src.Train - INFO - epoch:24,	steps32/207,	loss:0.008303238078951836
2023-03-24 22:00:45,375 - src.Train - INFO - epoch:24,	steps52/207,	loss:0.004456067457795143
2023-03-24 22:00:47,763 - src.Train - INFO - epoch:24,	steps72/207,	loss:0.0036505202297121286
2023-03-24 22:00:50,377 - src.Train - INFO - epoch:24,	steps92/207,	loss:0.0047232890501618385
2023-03-24 22:00:52,738 - src.Train - INFO - epoch:24,	steps112/207,	loss:0.01590878888964653
2023-03-24 22:00:55,322 - src.Train - INFO - epoch:24,	steps132/207,	loss:0.00545116513967514
2023-03-24 22:00:57,704 - src.Train - INFO - epoch:24,	steps152/207,	loss:0.0038770590908825397
2023-03-24 22:01:00,327 - src.Train - INFO - epoch:24,	steps172/207,	loss:0.0019884356297552586
2023-03-24 22:01:02,751 - src.Train - INFO - epoch:24,	steps192/207,	loss:0.0017324904911220074
2023-03-24 22:01:04,635 - src.Train - INFO - start evaluate...
2023-03-24 22:01:04,635 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:01:06,630 - src.Train - INFO - right: 845	total: 1022	M-tree codes acc: 0.8268101761252447
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:01:19,004 - src.Train - INFO - epoch:25,	steps5/207,	loss:0.005695623811334372
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 bonnie [UNK] science class recorded the rainfall each day. they recorded γ [UNK] of rain on monday, δ [UNK] of rain on tuesday, and ε [UNK] of rain on wednesday. how many centimeters of rain did the class record in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[16, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:01:21,444 - src.Train - INFO - epoch:25,	steps25/207,	loss:0.002928326604887843
2023-03-24 22:01:23,880 - src.Train - INFO - epoch:25,	steps45/207,	loss:0.00455993739888072
2023-03-24 22:01:26,349 - src.Train - INFO - epoch:25,	steps65/207,	loss:0.002364603104069829
2023-03-24 22:01:28,850 - src.Train - INFO - epoch:25,	steps85/207,	loss:0.0030014258809387684
2023-03-24 22:01:31,357 - src.Train - INFO - epoch:25,	steps105/207,	loss:0.0037665197160094976
2023-03-24 22:01:33,777 - src.Train - INFO - epoch:25,	steps125/207,	loss:0.005682817194610834
2023-03-24 22:01:36,061 - src.Train - INFO - epoch:25,	steps145/207,	loss:0.0033834739588201046
2023-03-24 22:01:38,455 - src.Train - INFO - epoch:25,	steps165/207,	loss:0.0024362385738641024
2023-03-24 22:01:40,734 - src.Train - INFO - epoch:25,	steps185/207,	loss:0.004653695039451122
2023-03-24 22:01:43,089 - src.Train - INFO - epoch:25,	steps205/207,	loss:0.011224864982068539
2023-03-24 22:01:43,221 - src.Train - INFO - start evaluate...
2023-03-24 22:01:43,221 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:01:45,249 - src.Train - INFO - right: 850	total: 1022	M-tree codes acc: 0.8317025440313112
2023-03-24 22:01:45,250 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:02:10,099 - src.Train - INFO - epoch:26,	steps18/207,	loss:0.0031296061351895332
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jason had to submit γ animation projects as per his [UNK] bus in the final [UNK]. he scored δ, ε, ζ, and η points out of θ in ι projects. what should be his score in the fifth project so that the average of his projects is at least κ? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
====================
label:[27, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:02:12,380 - src.Train - INFO - epoch:26,	steps38/207,	loss:0.006500127725303173
2023-03-24 22:02:14,689 - src.Train - INFO - epoch:26,	steps58/207,	loss:0.01172690000385046
2023-03-24 22:02:17,027 - src.Train - INFO - epoch:26,	steps78/207,	loss:0.0046507748775184155
2023-03-24 22:02:19,423 - src.Train - INFO - epoch:26,	steps98/207,	loss:0.006090155337005854
2023-03-24 22:02:21,807 - src.Train - INFO - epoch:26,	steps118/207,	loss:0.004364879801869392
2023-03-24 22:02:24,111 - src.Train - INFO - epoch:26,	steps138/207,	loss:0.0036638244055211544
2023-03-24 22:02:26,393 - src.Train - INFO - epoch:26,	steps158/207,	loss:0.0062318649142980576
2023-03-24 22:02:28,670 - src.Train - INFO - epoch:26,	steps178/207,	loss:0.005353687331080437
2023-03-24 22:02:30,978 - src.Train - INFO - epoch:26,	steps198/207,	loss:0.005343638360500336
2023-03-24 22:02:31,877 - src.Train - INFO - start evaluate...
2023-03-24 22:02:31,878 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:02:33,874 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
2023-03-24 22:02:33,875 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:02:52,750 - src.Train - INFO - epoch:27,	steps11/207,	loss:0.0016077554319053888
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ [UNK] trees currently in the park. park workers will plant δ [UNK] trees today and ε [UNK] trees tomorrow. it took ζ workers to finish the work. how many [UNK] trees will the park have when the workers are finished? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[18, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:02:56,533 - src.Train - INFO - epoch:27,	steps31/207,	loss:0.0018955463310703635
2023-03-24 22:03:00,353 - src.Train - INFO - epoch:27,	steps51/207,	loss:0.002517411485314369
2023-03-24 22:03:03,957 - src.Train - INFO - epoch:27,	steps71/207,	loss:0.004594971425831318
2023-03-24 22:03:07,619 - src.Train - INFO - epoch:27,	steps91/207,	loss:0.0019994827453047037
2023-03-24 22:03:11,296 - src.Train - INFO - epoch:27,	steps111/207,	loss:0.003452613018453121
2023-03-24 22:03:14,961 - src.Train - INFO - epoch:27,	steps131/207,	loss:0.0019317022524774075
2023-03-24 22:03:18,849 - src.Train - INFO - epoch:27,	steps151/207,	loss:0.007938401773571968
2023-03-24 22:03:22,444 - src.Train - INFO - epoch:27,	steps171/207,	loss:0.0016068739350885153
2023-03-24 22:03:26,349 - src.Train - INFO - epoch:27,	steps191/207,	loss:0.00392576539888978
2023-03-24 22:03:29,201 - src.Train - INFO - start evaluate...
2023-03-24 22:03:29,201 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:03:32,561 - src.Train - INFO - right: 853	total: 1022	M-tree codes acc: 0.8346379647749511
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:03:38,525 - src.Train - INFO - epoch:28,	steps4/207,	loss:0.004444899037480354
2023-03-24 22:03:42,232 - src.Train - INFO - epoch:28,	steps24/207,	loss:0.011020684614777565
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 hoping to be named [UNK] of the month, rosa called the names from γ pages of the phone book last week. this week, she called the people listed on another δ pages of the same phone book. how many pages worth of people did rosa call in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:03:45,896 - src.Train - INFO - epoch:28,	steps44/207,	loss:0.004411505069583654
2023-03-24 22:03:49,620 - src.Train - INFO - epoch:28,	steps64/207,	loss:0.0026955429930239916
2023-03-24 22:03:53,259 - src.Train - INFO - epoch:28,	steps84/207,	loss:0.004656193777918816
2023-03-24 22:03:56,884 - src.Train - INFO - epoch:28,	steps104/207,	loss:0.005849048029631376
2023-03-24 22:04:00,716 - src.Train - INFO - epoch:28,	steps124/207,	loss:0.0025405101478099823
2023-03-24 22:04:04,570 - src.Train - INFO - epoch:28,	steps144/207,	loss:0.00494240690022707
2023-03-24 22:04:08,223 - src.Train - INFO - epoch:28,	steps164/207,	loss:0.0033647953532636166
2023-03-24 22:04:12,270 - src.Train - INFO - epoch:28,	steps184/207,	loss:0.0012693324824795127
2023-03-24 22:04:15,913 - src.Train - INFO - epoch:28,	steps204/207,	loss:0.00409311568364501
2023-03-24 22:04:16,336 - src.Train - INFO - start evaluate...
2023-03-24 22:04:16,336 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:04:19,687 - src.Train - INFO - right: 852	total: 1022	M-tree codes acc: 0.8336594911937377
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:04:31,341 - src.Train - INFO - epoch:29,	steps17/207,	loss:0.0019733577501028776
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 tom bought γ tickets at the state fair. he spent δ tickets at the'[UNK] a clown'booth and decided to use the rest on rides. if each ride cost ε tickets, how many rides could he go on? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[38, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:04:33,637 - src.Train - INFO - epoch:29,	steps37/207,	loss:0.002388396067544818
2023-03-24 22:04:35,985 - src.Train - INFO - epoch:29,	steps57/207,	loss:0.004039605148136616
2023-03-24 22:04:38,315 - src.Train - INFO - epoch:29,	steps77/207,	loss:0.004276780411601067
2023-03-24 22:04:40,668 - src.Train - INFO - epoch:29,	steps97/207,	loss:0.0015615160809829831
2023-03-24 22:04:43,009 - src.Train - INFO - epoch:29,	steps117/207,	loss:0.0028893458656966686
2023-03-24 22:04:45,346 - src.Train - INFO - epoch:29,	steps137/207,	loss:0.0010059992782771587
2023-03-24 22:04:47,709 - src.Train - INFO - epoch:29,	steps157/207,	loss:0.002747828373685479
2023-03-24 22:04:50,144 - src.Train - INFO - epoch:29,	steps177/207,	loss:0.002297505736351013
2023-03-24 22:04:52,686 - src.Train - INFO - epoch:29,	steps197/207,	loss:0.004650698509067297
2023-03-24 22:04:53,847 - src.Train - INFO - start evaluate...
2023-03-24 22:04:53,847 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:04:55,805 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:05:02,373 - src.Train - INFO - epoch:30,	steps10/207,	loss:0.004210013896226883
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 victor was helping the cafeteria workers pick up lunch [UNK], but he could only carry γ [UNK] at a time. if he had to pick up δ [UNK] from one ta [UNK] and ε [UNK] from another, how many trips will he make? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:05:04,719 - src.Train - INFO - epoch:30,	steps30/207,	loss:0.0035265202168375254
2023-03-24 22:05:07,232 - src.Train - INFO - epoch:30,	steps50/207,	loss:0.004138226620852947
2023-03-24 22:05:09,738 - src.Train - INFO - epoch:30,	steps70/207,	loss:0.001772792893461883
2023-03-24 22:05:12,150 - src.Train - INFO - epoch:30,	steps90/207,	loss:0.0022374459076672792
2023-03-24 22:05:14,721 - src.Train - INFO - epoch:30,	steps110/207,	loss:0.004074909724295139
2023-03-24 22:05:17,099 - src.Train - INFO - epoch:30,	steps130/207,	loss:0.0029413909651339054
2023-03-24 22:05:19,732 - src.Train - INFO - epoch:30,	steps150/207,	loss:0.004683204926550388
2023-03-24 22:05:22,271 - src.Train - INFO - epoch:30,	steps170/207,	loss:0.0017651463858783245
2023-03-24 22:05:24,807 - src.Train - INFO - epoch:30,	steps190/207,	loss:0.002577017992734909
2023-03-24 22:05:26,778 - src.Train - INFO - start evaluate...
2023-03-24 22:05:26,778 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:05:28,981 - src.Train - INFO - right: 857	total: 1022	M-tree codes acc: 0.8385518590998043
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:05:34,614 - src.Train - INFO - epoch:31,	steps3/207,	loss:0.0025996905751526356
2023-03-24 22:05:37,042 - src.Train - INFO - epoch:31,	steps23/207,	loss:0.0016237220261245966
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a gas station owner has γ gallons of gasoline for which he charges δ dollars per gallon and some for which he charges ε dollars per gallon. how many gallons of the ζ dollars brand must the owner mix in to produce gasoline that costs η dollars per gallon? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
====================
label:[9, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:05:39,594 - src.Train - INFO - epoch:31,	steps43/207,	loss:0.004085425287485123
2023-03-24 22:05:42,118 - src.Train - INFO - epoch:31,	steps63/207,	loss:0.0031860722228884697
2023-03-24 22:05:44,649 - src.Train - INFO - epoch:31,	steps83/207,	loss:0.0015848185867071152
2023-03-24 22:05:46,936 - src.Train - INFO - epoch:31,	steps103/207,	loss:0.003064595628529787
2023-03-24 22:05:49,592 - src.Train - INFO - epoch:31,	steps123/207,	loss:0.002116868272423744
2023-03-24 22:05:52,043 - src.Train - INFO - epoch:31,	steps143/207,	loss:0.0019972939044237137
2023-03-24 22:05:54,734 - src.Train - INFO - epoch:31,	steps163/207,	loss:0.003547171363607049
2023-03-24 22:05:57,145 - src.Train - INFO - epoch:31,	steps183/207,	loss:0.008451057597994804
2023-03-24 22:05:59,623 - src.Train - INFO - epoch:31,	steps203/207,	loss:0.002178979804739356
2023-03-24 22:06:00,064 - src.Train - INFO - start evaluate...
2023-03-24 22:06:00,064 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:06:02,223 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:06:09,456 - src.Train - INFO - epoch:32,	steps16/207,	loss:0.0019828109070658684
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 chris has been saving his allowance to buy a new pair of soccer [UNK] and a ball. his grandmother gave chris $ γ for his birthday. his aunt and uncle gave chris $ δ and his parents gave him $ ε. now chris had $ ζ. how much money did chris have before his birthday? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[52, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:06:11,924 - src.Train - INFO - epoch:32,	steps36/207,	loss:0.00487805949524045
2023-03-24 22:06:14,484 - src.Train - INFO - epoch:32,	steps56/207,	loss:0.0016955824103206396
2023-03-24 22:06:16,760 - src.Train - INFO - epoch:32,	steps76/207,	loss:0.0014181069564074278
2023-03-24 22:06:19,343 - src.Train - INFO - epoch:32,	steps96/207,	loss:0.0020571912173181772
2023-03-24 22:06:21,784 - src.Train - INFO - epoch:32,	steps116/207,	loss:0.0054197306744754314
2023-03-24 22:06:24,288 - src.Train - INFO - epoch:32,	steps136/207,	loss:0.004455810412764549
2023-03-24 22:06:26,780 - src.Train - INFO - epoch:32,	steps156/207,	loss:0.0028499572072178125
2023-03-24 22:06:29,211 - src.Train - INFO - epoch:32,	steps176/207,	loss:0.0020393517334014177
2023-03-24 22:06:31,719 - src.Train - INFO - epoch:32,	steps196/207,	loss:0.004466312937438488
2023-03-24 22:06:33,005 - src.Train - INFO - start evaluate...
2023-03-24 22:06:33,005 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:06:35,190 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
2023-03-24 22:06:35,192 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:06:47,574 - src.Train - INFO - epoch:33,	steps9/207,	loss:0.004659892991185188
2023-03-24 22:06:50,182 - src.Train - INFO - epoch:33,	steps29/207,	loss:0.0023878803476691246
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 ellen made [UNK] in the [UNK]. she used γ of a cup of [UNK], δ of a cup of [UNK], and ε of a cup of orange juice. how many cups of ingredients did ellen use for the [UNK]? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[20, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:06:52,545 - src.Train - INFO - epoch:33,	steps49/207,	loss:0.0025124563835561275
2023-03-24 22:06:55,139 - src.Train - INFO - epoch:33,	steps69/207,	loss:0.002008596435189247
2023-03-24 22:06:57,518 - src.Train - INFO - epoch:33,	steps89/207,	loss:0.005109039600938559
2023-03-24 22:06:59,992 - src.Train - INFO - epoch:33,	steps109/207,	loss:0.001945780823007226
2023-03-24 22:07:02,555 - src.Train - INFO - epoch:33,	steps129/207,	loss:0.0016141623491421342
2023-03-24 22:07:04,957 - src.Train - INFO - epoch:33,	steps149/207,	loss:0.0018515550764277577
2023-03-24 22:07:07,562 - src.Train - INFO - epoch:33,	steps169/207,	loss:0.0018634272273629904
2023-03-24 22:07:09,916 - src.Train - INFO - epoch:33,	steps189/207,	loss:0.0025275934021919966
2023-03-24 22:07:12,121 - src.Train - INFO - start evaluate...
2023-03-24 22:07:12,121 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:07:14,259 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:07:19,867 - src.Train - INFO - epoch:34,	steps2/207,	loss:0.0014060337562114
2023-03-24 22:07:22,173 - src.Train - INFO - epoch:34,	steps22/207,	loss:0.001569100539200008
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a store had γ coloring books in stock. they ended up putting them on sale and getting rid of δ of them. the put the ones they still had onto shelves with ε on each shelf. how many shelves did they use? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[24, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:07:24,720 - src.Train - INFO - epoch:34,	steps42/207,	loss:0.0036570702213793993
2023-03-24 22:07:27,132 - src.Train - INFO - epoch:34,	steps62/207,	loss:0.0024011682253330946
2023-03-24 22:07:29,693 - src.Train - INFO - epoch:34,	steps82/207,	loss:0.004078326281160116
2023-03-24 22:07:32,253 - src.Train - INFO - epoch:34,	steps102/207,	loss:0.0014137073885649443
2023-03-24 22:07:34,969 - src.Train - INFO - epoch:34,	steps122/207,	loss:0.004361897241324186
2023-03-24 22:07:37,371 - src.Train - INFO - epoch:34,	steps142/207,	loss:0.004475499968975782
2023-03-24 22:07:39,919 - src.Train - INFO - epoch:34,	steps162/207,	loss:0.002914395183324814
2023-03-24 22:07:42,278 - src.Train - INFO - epoch:34,	steps182/207,	loss:0.0020105179864913225
2023-03-24 22:07:44,852 - src.Train - INFO - epoch:34,	steps202/207,	loss:0.007439770270138979
2023-03-24 22:07:45,373 - src.Train - INFO - start evaluate...
2023-03-24 22:07:45,373 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:07:47,617 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:07:55,096 - src.Train - INFO - epoch:35,	steps15/207,	loss:0.004556792788207531
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a container ship left from [UNK] pier and traveled north. an aircraft carrier left γ hours later traveling at δ miles per hour in an effort to catch up to the container ship. after traveling for ε hours the aircraft carrier finally caught up. what was the container ship [UNK] average speed in miles per hour? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:07:57,643 - src.Train - INFO - epoch:35,	steps35/207,	loss:0.0028338043484836817
2023-03-24 22:08:00,001 - src.Train - INFO - epoch:35,	steps55/207,	loss:0.0014109016628935933
2023-03-24 22:08:02,560 - src.Train - INFO - epoch:35,	steps75/207,	loss:0.0017881776439025998
2023-03-24 22:08:05,016 - src.Train - INFO - epoch:35,	steps95/207,	loss:0.002639926504343748
2023-03-24 22:08:07,659 - src.Train - INFO - epoch:35,	steps115/207,	loss:0.0045500039122998714
2023-03-24 22:08:10,061 - src.Train - INFO - epoch:35,	steps135/207,	loss:0.001983072841539979
2023-03-24 22:08:12,428 - src.Train - INFO - epoch:35,	steps155/207,	loss:0.007196931168437004
2023-03-24 22:08:14,925 - src.Train - INFO - epoch:35,	steps175/207,	loss:0.0037681604735553265
2023-03-24 22:08:17,331 - src.Train - INFO - epoch:35,	steps195/207,	loss:0.0014858980430290103
2023-03-24 22:08:19,003 - src.Train - INFO - start evaluate...
2023-03-24 22:08:19,003 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:08:20,947 - src.Train - INFO - right: 860	total: 1022	M-tree codes acc: 0.8414872798434442
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:08:27,319 - src.Train - INFO - epoch:36,	steps8/207,	loss:0.00431834114715457
2023-03-24 22:08:30,004 - src.Train - INFO - epoch:36,	steps28/207,	loss:0.0014766608364880085
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 last saturday, spencer walked all over town running [UNK]. first, he walked γ of a mile from his house to the library and δ of a mile from the library to the post office. then he walked ε of a mile from the post office back home. how many miles did spencer walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[45, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:08:32,427 - src.Train - INFO - epoch:36,	steps48/207,	loss:0.0014254080597311258
2023-03-24 22:08:34,950 - src.Train - INFO - epoch:36,	steps68/207,	loss:0.00367006310261786
2023-03-24 22:08:37,306 - src.Train - INFO - epoch:36,	steps88/207,	loss:0.0055818744003772736
2023-03-24 22:08:39,990 - src.Train - INFO - epoch:36,	steps108/207,	loss:0.0014692733529955149
2023-03-24 22:08:42,406 - src.Train - INFO - epoch:36,	steps128/207,	loss:0.003188518574461341
2023-03-24 22:08:45,080 - src.Train - INFO - epoch:36,	steps148/207,	loss:0.0019133099121972919
2023-03-24 22:08:47,424 - src.Train - INFO - epoch:36,	steps168/207,	loss:0.001415965030901134
2023-03-24 22:08:49,967 - src.Train - INFO - epoch:36,	steps188/207,	loss:0.003953493200242519
2023-03-24 22:08:52,277 - src.Train - INFO - start evaluate...
2023-03-24 22:08:52,277 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:08:54,423 - src.Train - INFO - right: 863	total: 1022	M-tree codes acc: 0.8444227005870841
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:08:59,791 - src.Train - INFO - epoch:37,	steps1/207,	loss:0.008170461282134056
2023-03-24 22:09:02,296 - src.Train - INFO - epoch:37,	steps21/207,	loss:0.004559572320431471
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 adam bought γ packages of cat food and δ packages of dog food. each package of cat food contained ε cans, and each package of dog food contained ζ cans. how many more cans of cat food than dog food did adam buy? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[24, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:09:04,876 - src.Train - INFO - epoch:37,	steps41/207,	loss:0.0010241918498650193
2023-03-24 22:09:07,158 - src.Train - INFO - epoch:37,	steps61/207,	loss:0.004911808762699366
2023-03-24 22:09:09,735 - src.Train - INFO - epoch:37,	steps81/207,	loss:0.005688556935638189
2023-03-24 22:09:12,120 - src.Train - INFO - epoch:37,	steps101/207,	loss:0.004823165945708752
2023-03-24 22:09:14,666 - src.Train - INFO - epoch:37,	steps121/207,	loss:0.0015498040011152625
2023-03-24 22:09:17,094 - src.Train - INFO - epoch:37,	steps141/207,	loss:0.008907601237297058
2023-03-24 22:09:19,630 - src.Train - INFO - epoch:37,	steps161/207,	loss:0.003166880924254656
2023-03-24 22:09:22,142 - src.Train - INFO - epoch:37,	steps181/207,	loss:0.003391128731891513
2023-03-24 22:09:24,542 - src.Train - INFO - epoch:37,	steps201/207,	loss:0.004640837199985981
2023-03-24 22:09:25,237 - src.Train - INFO - start evaluate...
2023-03-24 22:09:25,237 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:09:27,364 - src.Train - INFO - right: 862	total: 1022	M-tree codes acc: 0.8434442270058709
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:09:36,770 - src.Train - INFO - epoch:38,	steps14/207,	loss:0.004334229975938797
2023-03-24 22:09:39,248 - src.Train - INFO - epoch:38,	steps34/207,	loss:0.0011027926811948419
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 roger is at the library helping put away books. there are γ book to put away total but a librarian takes δ of them and leaves roger with the rest. if he can fit ε books on a shelf, how many shelves will he need? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[40, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:09:41,704 - src.Train - INFO - epoch:38,	steps54/207,	loss:0.0016201641410589218
2023-03-24 22:09:44,173 - src.Train - INFO - epoch:38,	steps74/207,	loss:0.004774447996169329
2023-03-24 22:09:46,567 - src.Train - INFO - epoch:38,	steps94/207,	loss:0.0015407695900648832
2023-03-24 22:09:49,250 - src.Train - INFO - epoch:38,	steps114/207,	loss:0.001498532947152853
2023-03-24 22:09:51,580 - src.Train - INFO - epoch:38,	steps134/207,	loss:0.005438510794192553
2023-03-24 22:09:54,118 - src.Train - INFO - epoch:38,	steps154/207,	loss:0.0021065042819827795
2023-03-24 22:09:56,568 - src.Train - INFO - epoch:38,	steps174/207,	loss:0.0016563733806833625
2023-03-24 22:09:58,879 - src.Train - INFO - epoch:38,	steps194/207,	loss:0.00217177951708436
2023-03-24 22:10:00,454 - src.Train - INFO - start evaluate...
2023-03-24 22:10:00,454 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:10:02,530 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:10:09,060 - src.Train - INFO - epoch:39,	steps7/207,	loss:0.001515902578830719
2023-03-24 22:10:11,421 - src.Train - INFO - epoch:39,	steps27/207,	loss:0.003178217215463519
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 zach wants to ride the ferris wheel, the roller coaster, and the log ride. the ferris wheel costs γ tickets, the roller coaster costs δ tickets and the log ride costs ε ticket. zach has ζ ticket. how many more tickets should zach buy? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[32, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:10:13,706 - src.Train - INFO - epoch:39,	steps47/207,	loss:0.002600700594484806
2023-03-24 22:10:16,005 - src.Train - INFO - epoch:39,	steps67/207,	loss:0.0013342027086764574
2023-03-24 22:10:18,287 - src.Train - INFO - epoch:39,	steps87/207,	loss:0.002803314942866564
2023-03-24 22:10:20,691 - src.Train - INFO - epoch:39,	steps107/207,	loss:0.003469813382253051
2023-03-24 22:10:22,952 - src.Train - INFO - epoch:39,	steps127/207,	loss:0.005392959341406822
2023-03-24 22:10:25,103 - src.Train - INFO - epoch:39,	steps147/207,	loss:0.0026596656534820795
2023-03-24 22:10:27,428 - src.Train - INFO - epoch:39,	steps167/207,	loss:0.0022013182751834393
2023-03-24 22:10:29,707 - src.Train - INFO - epoch:39,	steps187/207,	loss:0.0010237412061542273
2023-03-24 22:10:32,007 - src.Train - INFO - epoch:39,	steps207/207,	loss:0.22764672338962555
2023-03-24 22:10:32,008 - src.Train - INFO - start evaluate...
2023-03-24 22:10:32,008 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:10:33,906 - src.Train - INFO - right: 863	total: 1022	M-tree codes acc: 0.8444227005870841
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:10:41,146 - src.Train - INFO - epoch:40,	steps20/207,	loss:0.002915858058258891
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a study reported that in a random sampling of γ women over the age of δ, ε of the women were married ζ or more times. based on the study results, how many woman in a group of η women over the age of θ would likely be married ι or more times? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[13, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:10:43,490 - src.Train - INFO - epoch:40,	steps40/207,	loss:0.004920472390949726
2023-03-24 22:10:45,867 - src.Train - INFO - epoch:40,	steps60/207,	loss:0.0029961036052554846
2023-03-24 22:10:48,180 - src.Train - INFO - epoch:40,	steps80/207,	loss:0.003690431360155344
2023-03-24 22:10:50,738 - src.Train - INFO - epoch:40,	steps100/207,	loss:0.002944155363366008
2023-03-24 22:10:53,104 - src.Train - INFO - epoch:40,	steps120/207,	loss:0.002725962782278657
2023-03-24 22:10:55,459 - src.Train - INFO - epoch:40,	steps140/207,	loss:0.0021467178594321012
2023-03-24 22:10:57,742 - src.Train - INFO - epoch:40,	steps160/207,	loss:0.0009512522374279797
2023-03-24 22:11:00,019 - src.Train - INFO - epoch:40,	steps180/207,	loss:0.0011055266950279474
2023-03-24 22:11:02,205 - src.Train - INFO - epoch:40,	steps200/207,	loss:0.0014776967000216246
2023-03-24 22:11:02,942 - src.Train - INFO - start evaluate...
2023-03-24 22:11:02,942 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:11:04,968 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:11:11,902 - src.Train - INFO - epoch:41,	steps13/207,	loss:0.002907899674028158
2023-03-24 22:11:15,329 - src.Train - INFO - epoch:41,	steps33/207,	loss:0.005318382754921913
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a study reported that in a random sampling of γ women over the age of δ, ε of the women were married ζ or more times. based on the study results, how many woman in a group of η women over the age of θ would likely be married ι or more times? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[45, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:11:19,014 - src.Train - INFO - epoch:41,	steps53/207,	loss:0.002084858249872923
2023-03-24 22:11:22,650 - src.Train - INFO - epoch:41,	steps73/207,	loss:0.003813578514382243
2023-03-24 22:11:26,597 - src.Train - INFO - epoch:41,	steps93/207,	loss:0.0028054057620465755
2023-03-24 22:11:30,433 - src.Train - INFO - epoch:41,	steps113/207,	loss:0.0015157266752794385
2023-03-24 22:11:34,043 - src.Train - INFO - epoch:41,	steps133/207,	loss:0.0013314650859683752
2023-03-24 22:11:37,848 - src.Train - INFO - epoch:41,	steps153/207,	loss:0.0030568134970963
2023-03-24 22:11:41,552 - src.Train - INFO - epoch:41,	steps173/207,	loss:0.0020076693035662174
2023-03-24 22:11:45,255 - src.Train - INFO - epoch:41,	steps193/207,	loss:0.0020164314191788435
2023-03-24 22:11:47,830 - src.Train - INFO - start evaluate...
2023-03-24 22:11:47,830 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:11:51,051 - src.Train - INFO - right: 862	total: 1022	M-tree codes acc: 0.8434442270058709
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:11:58,593 - src.Train - INFO - epoch:42,	steps6/207,	loss:0.004228144884109497
2023-03-24 22:12:02,331 - src.Train - INFO - epoch:42,	steps26/207,	loss:0.003547254716977477
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ [UNK] trees currently in the park. park workers will plant δ [UNK] trees today and ε [UNK] trees tomorrow. it took ζ workers to finish the work. how many [UNK] trees will the park have when the workers are finished? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[18, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:12:06,113 - src.Train - INFO - epoch:42,	steps46/207,	loss:0.0037409185897558928
2023-03-24 22:12:09,712 - src.Train - INFO - epoch:42,	steps66/207,	loss:0.0022652451880276203
2023-03-24 22:12:13,307 - src.Train - INFO - epoch:42,	steps86/207,	loss:0.004288253840059042
2023-03-24 22:12:17,060 - src.Train - INFO - epoch:42,	steps106/207,	loss:0.0015411009080708027
2023-03-24 22:12:21,028 - src.Train - INFO - epoch:42,	steps126/207,	loss:0.001767165376804769
2023-03-24 22:12:24,801 - src.Train - INFO - epoch:42,	steps146/207,	loss:0.005071834195405245
2023-03-24 22:12:28,517 - src.Train - INFO - epoch:42,	steps166/207,	loss:0.0014408568385988474
2023-03-24 22:12:32,304 - src.Train - INFO - epoch:42,	steps186/207,	loss:0.0037664149422198534
2023-03-24 22:12:35,857 - src.Train - INFO - epoch:42,	steps206/207,	loss:0.0059430766850709915
2023-03-24 22:12:35,921 - src.Train - INFO - start evaluate...
2023-03-24 22:12:35,921 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:12:39,109 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:12:50,035 - src.Train - INFO - epoch:43,	steps19/207,	loss:0.00430197874084115
2023-03-24 22:12:53,186 - src.Train - INFO - epoch:43,	steps39/207,	loss:0.004247322212904692
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 emily was playing a [UNK] game. in the first round she scored γ points and in the second round she scored δ points. in the last round she lost ε points. how many points did she have at the end of the game? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[17, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:12:55,464 - src.Train - INFO - epoch:43,	steps59/207,	loss:0.0017542849527671933
2023-03-24 22:12:57,784 - src.Train - INFO - epoch:43,	steps79/207,	loss:0.0058907498605549335
2023-03-24 22:13:00,106 - src.Train - INFO - epoch:43,	steps99/207,	loss:0.0029196960385888815
2023-03-24 22:13:02,406 - src.Train - INFO - epoch:43,	steps119/207,	loss:0.0018411350902169943
2023-03-24 22:13:04,785 - src.Train - INFO - epoch:43,	steps139/207,	loss:0.003057431895285845
2023-03-24 22:13:07,043 - src.Train - INFO - epoch:43,	steps159/207,	loss:0.003222548868507147
2023-03-24 22:13:09,390 - src.Train - INFO - epoch:43,	steps179/207,	loss:0.0015713457250967622
2023-03-24 22:13:11,892 - src.Train - INFO - epoch:43,	steps199/207,	loss:0.0027196670416742563
2023-03-24 22:13:12,817 - src.Train - INFO - start evaluate...
2023-03-24 22:13:12,817 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:13:14,804 - src.Train - INFO - right: 857	total: 1022	M-tree codes acc: 0.8385518590998043
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:13:23,492 - src.Train - INFO - epoch:44,	steps12/207,	loss:0.0019200799288228154
2023-03-24 22:13:25,983 - src.Train - INFO - epoch:44,	steps32/207,	loss:0.0022219372913241386
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 martha wants to buy a digital camera from her γ month savings. to do this she needs to maintain an average saving of δ in each month. she saves ε in the first month and ζ in the second month. find the amount she should save in the third month, in dollars, to buy a digital camera at the end of η months. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
====================
label:[41, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:13:28,450 - src.Train - INFO - epoch:44,	steps52/207,	loss:0.001307843835093081
2023-03-24 22:13:30,770 - src.Train - INFO - epoch:44,	steps72/207,	loss:0.0011012941831722856
2023-03-24 22:13:33,379 - src.Train - INFO - epoch:44,	steps92/207,	loss:0.0021899056155234575
2023-03-24 22:13:35,760 - src.Train - INFO - epoch:44,	steps112/207,	loss:0.006860614754259586
2023-03-24 22:13:38,384 - src.Train - INFO - epoch:44,	steps132/207,	loss:0.006642559077590704
2023-03-24 22:13:40,792 - src.Train - INFO - epoch:44,	steps152/207,	loss:0.010328727774322033
2023-03-24 22:13:43,260 - src.Train - INFO - epoch:44,	steps172/207,	loss:0.0031228812877088785
2023-03-24 22:13:45,781 - src.Train - INFO - epoch:44,	steps192/207,	loss:0.001348295365460217
2023-03-24 22:13:47,722 - src.Train - INFO - start evaluate...
2023-03-24 22:13:47,723 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:13:49,816 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:13:55,792 - src.Train - INFO - epoch:45,	steps5/207,	loss:0.003874502144753933
2023-03-24 22:13:58,212 - src.Train - INFO - epoch:45,	steps25/207,	loss:0.002157593844458461
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 martha wants to buy a digital camera from her γ month savings. to do this she needs to maintain an average saving of δ in each month. she saves ε in the first month and ζ in the second month. find the amount she should save in the third month, in dollars, to buy a digital camera at the end of η months. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
====================
label:[28, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:14:00,818 - src.Train - INFO - epoch:45,	steps45/207,	loss:0.0025902693159878254
2023-03-24 22:14:03,337 - src.Train - INFO - epoch:45,	steps65/207,	loss:0.0035880464129149914
2023-03-24 22:14:05,855 - src.Train - INFO - epoch:45,	steps85/207,	loss:0.004913782235234976
2023-03-24 22:14:08,220 - src.Train - INFO - epoch:45,	steps105/207,	loss:0.0034430401865392923
2023-03-24 22:14:10,828 - src.Train - INFO - epoch:45,	steps125/207,	loss:0.0026190197095274925
2023-03-24 22:14:13,251 - src.Train - INFO - epoch:45,	steps145/207,	loss:0.0017469627782702446
2023-03-24 22:14:15,592 - src.Train - INFO - epoch:45,	steps165/207,	loss:0.0019356587436050177
2023-03-24 22:14:18,218 - src.Train - INFO - epoch:45,	steps185/207,	loss:0.001252157730050385
2023-03-24 22:14:20,573 - src.Train - INFO - epoch:45,	steps205/207,	loss:0.0015390068292617798
2023-03-24 22:14:20,777 - src.Train - INFO - start evaluate...
2023-03-24 22:14:20,778 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:14:22,937 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:14:30,414 - src.Train - INFO - epoch:46,	steps18/207,	loss:0.0008796295733191073
2023-03-24 22:14:32,991 - src.Train - INFO - epoch:46,	steps38/207,	loss:0.0010980316437780857
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] [UNK] [UNK] offers scenic tours on horseback. a γ [UNK] tour averaged δ miles per hour. if the average rate was ε miles per hour for the first ζ hours, what was the average rate for the last hour? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[14, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:14:35,484 - src.Train - INFO - epoch:46,	steps58/207,	loss:0.003096081083640456
2023-03-24 22:14:37,917 - src.Train - INFO - epoch:46,	steps78/207,	loss:0.004004165064543486
2023-03-24 22:14:40,349 - src.Train - INFO - epoch:46,	steps98/207,	loss:0.0006724395789206028
2023-03-24 22:14:42,981 - src.Train - INFO - epoch:46,	steps118/207,	loss:0.0012498641153797507
2023-03-24 22:14:45,311 - src.Train - INFO - epoch:46,	steps138/207,	loss:0.0037177293561398983
2023-03-24 22:14:48,003 - src.Train - INFO - epoch:46,	steps158/207,	loss:0.0031131943687796593
2023-03-24 22:14:50,376 - src.Train - INFO - epoch:46,	steps178/207,	loss:0.0017260268796235323
2023-03-24 22:14:52,949 - src.Train - INFO - epoch:46,	steps198/207,	loss:0.0044541428796947
2023-03-24 22:14:54,028 - src.Train - INFO - start evaluate...
2023-03-24 22:14:54,028 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:14:56,019 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:15:02,798 - src.Train - INFO - epoch:47,	steps11/207,	loss:0.002881622640416026
2023-03-24 22:15:05,383 - src.Train - INFO - epoch:47,	steps31/207,	loss:0.002014480298385024
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ walnut trees currently in the park. park workers will plant more walnut trees today. when the workers are finished there will be δ walnut trees in the park. how many walnut trees did the workers plant today? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[31, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:15:07,843 - src.Train - INFO - epoch:47,	steps51/207,	loss:0.002250331686809659
2023-03-24 22:15:10,245 - src.Train - INFO - epoch:47,	steps71/207,	loss:0.0012115673162043095
2023-03-24 22:15:12,824 - src.Train - INFO - epoch:47,	steps91/207,	loss:0.0014113046927377582
2023-03-24 22:15:15,165 - src.Train - INFO - epoch:47,	steps111/207,	loss:0.002662109676748514
2023-03-24 22:15:17,683 - src.Train - INFO - epoch:47,	steps131/207,	loss:0.0030160199385136366
2023-03-24 22:15:20,121 - src.Train - INFO - epoch:47,	steps151/207,	loss:0.0024527921341359615
2023-03-24 22:15:22,644 - src.Train - INFO - epoch:47,	steps171/207,	loss:0.003341278061270714
2023-03-24 22:15:25,114 - src.Train - INFO - epoch:47,	steps191/207,	loss:0.0023202861193567514
2023-03-24 22:15:27,109 - src.Train - INFO - start evaluate...
2023-03-24 22:15:27,110 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:15:29,241 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:15:36,792 - src.Train - INFO - epoch:48,	steps4/207,	loss:0.001443972927518189
2023-03-24 22:15:39,264 - src.Train - INFO - epoch:48,	steps24/207,	loss:0.0013398178853094578
2023-03-24 22:15:41,873 - src.Train - INFO - epoch:48,	steps44/207,	loss:0.0009603134240023792
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 wild and crazy productions wants to purchase a new cd producing machine. it [UNK] cost is γ dollars. if their la [UNK] and other unit costs are δ dollars per cd and they can sell the cd for ε dollars each, how many must they manufacture before they pay for their new machine? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:15:44,296 - src.Train - INFO - epoch:48,	steps64/207,	loss:0.0010070409625768661
2023-03-24 22:15:46,893 - src.Train - INFO - epoch:48,	steps84/207,	loss:0.0037644740659743547
2023-03-24 22:15:49,366 - src.Train - INFO - epoch:48,	steps104/207,	loss:0.0021450421772897243
2023-03-24 22:15:51,911 - src.Train - INFO - epoch:48,	steps124/207,	loss:0.0022031529806554317
2023-03-24 22:15:54,299 - src.Train - INFO - epoch:48,	steps144/207,	loss:0.0012563528725877404
2023-03-24 22:15:56,906 - src.Train - INFO - epoch:48,	steps164/207,	loss:0.002023053588345647
2023-03-24 22:15:59,235 - src.Train - INFO - epoch:48,	steps184/207,	loss:0.004966223146766424
2023-03-24 22:16:01,945 - src.Train - INFO - epoch:48,	steps204/207,	loss:0.003897775197401643
2023-03-24 22:16:02,197 - src.Train - INFO - start evaluate...
2023-03-24 22:16:02,197 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:16:04,314 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:16:15,708 - src.Train - INFO - epoch:49,	steps17/207,	loss:0.0035703671164810658
2023-03-24 22:16:18,131 - src.Train - INFO - epoch:49,	steps37/207,	loss:0.004114001058042049
torch.Size([20, 71])
torch.Size([20, 71])
torch.Size([20, 71])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 γ [UNK] are making cold calls to potential customers regarding a hot [UNK]. one of the [UNK] is a [UNK] to get a new client every δ hour, and the other is a [UNK] to get a new client every ε hour. at what rate, in clients per hour, are the new clients being acquired when both are working? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:16:20,723 - src.Train - INFO - epoch:49,	steps57/207,	loss:0.0017724890494719148
2023-03-24 22:16:23,131 - src.Train - INFO - epoch:49,	steps77/207,	loss:0.0033124545589089394
2023-03-24 22:16:25,611 - src.Train - INFO - epoch:49,	steps97/207,	loss:0.0019793768879026175
2023-03-24 22:16:28,037 - src.Train - INFO - epoch:49,	steps117/207,	loss:0.0037046163342893124
2023-03-24 22:16:30,560 - src.Train - INFO - epoch:49,	steps137/207,	loss:0.004389655776321888
2023-03-24 22:16:33,014 - src.Train - INFO - epoch:49,	steps157/207,	loss:0.000864569447003305
2023-03-24 22:16:35,570 - src.Train - INFO - epoch:49,	steps177/207,	loss:0.0016627318691462278
2023-03-24 22:16:38,162 - src.Train - INFO - epoch:49,	steps197/207,	loss:0.001973985228687525
2023-03-24 22:16:39,293 - src.Train - INFO - start evaluate...
2023-03-24 22:16:39,293 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:16:41,313 - src.Train - INFO - right: 863	total: 1022	M-tree codes acc: 0.8444227005870841
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:16:48,101 - src.Train - INFO - epoch:50,	steps10/207,	loss:0.0028883388731628656
2023-03-24 22:16:50,442 - src.Train - INFO - epoch:50,	steps30/207,	loss:0.009351118467748165
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a quiz is worth γ points. you want a δ point average for all ε [UNK]. you already took ζ [UNK] with scores of η, θ, ι and κ. what must your score be on your final quiz to reach your average? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[30, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:16:52,901 - src.Train - INFO - epoch:50,	steps50/207,	loss:0.0009553515701554716
2023-03-24 22:16:55,489 - src.Train - INFO - epoch:50,	steps70/207,	loss:0.002391031477600336
2023-03-24 22:16:57,928 - src.Train - INFO - epoch:50,	steps90/207,	loss:0.005180903244763613
2023-03-24 22:17:00,481 - src.Train - INFO - epoch:50,	steps110/207,	loss:0.0013148320140317082
2023-03-24 22:17:02,878 - src.Train - INFO - epoch:50,	steps130/207,	loss:0.002304978435859084
2023-03-24 22:17:05,399 - src.Train - INFO - epoch:50,	steps150/207,	loss:0.001738461316563189
2023-03-24 22:17:07,790 - src.Train - INFO - epoch:50,	steps170/207,	loss:0.0010130290174856782
2023-03-24 22:17:10,429 - src.Train - INFO - epoch:50,	steps190/207,	loss:0.00336475414223969
2023-03-24 22:17:12,524 - src.Train - INFO - start evaluate...
2023-03-24 22:17:12,525 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:17:14,475 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:17:20,191 - src.Train - INFO - epoch:51,	steps3/207,	loss:0.0033687467221170664
2023-03-24 22:17:22,603 - src.Train - INFO - epoch:51,	steps23/207,	loss:0.0019354854011908174
2023-03-24 22:17:25,113 - src.Train - INFO - epoch:51,	steps43/207,	loss:0.0017284722998738289
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 49])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 haley was planting [UNK] [UNK] in her garden. she started with γ seeds and planted δ of them in the big garden and in each of her small gardens put ε seeds each. how many small gardens did haley have? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[16, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:17:27,479 - src.Train - INFO - epoch:51,	steps63/207,	loss:0.001266967155970633
2023-03-24 22:17:30,045 - src.Train - INFO - epoch:51,	steps83/207,	loss:0.0034467128571122885
2023-03-24 22:17:32,454 - src.Train - INFO - epoch:51,	steps103/207,	loss:0.004064755979925394
2023-03-24 22:17:34,864 - src.Train - INFO - epoch:51,	steps123/207,	loss:0.00312340771779418
2023-03-24 22:17:37,443 - src.Train - INFO - epoch:51,	steps143/207,	loss:0.001948272343724966
2023-03-24 22:17:39,993 - src.Train - INFO - epoch:51,	steps163/207,	loss:0.001955472631379962
2023-03-24 22:17:42,500 - src.Train - INFO - epoch:51,	steps183/207,	loss:0.004337315913289785
2023-03-24 22:17:44,925 - src.Train - INFO - epoch:51,	steps203/207,	loss:0.0010075507452711463
2023-03-24 22:17:45,462 - src.Train - INFO - start evaluate...
2023-03-24 22:17:45,462 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:17:47,435 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:17:55,926 - src.Train - INFO - epoch:52,	steps16/207,	loss:0.0029177239630371332
2023-03-24 22:17:58,418 - src.Train - INFO - epoch:52,	steps36/207,	loss:0.0009680226212367415
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 the first agency charges γ dollars per day and δ dollars per mile. the second agency charges ε dollars per day and ζ dollars per mile. how many miles would you have to drive before the first agency is less expensive than the second? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[8, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:18:00,958 - src.Train - INFO - epoch:52,	steps56/207,	loss:0.003910221625119448
2023-03-24 22:18:03,464 - src.Train - INFO - epoch:52,	steps76/207,	loss:0.00491172494366765
2023-03-24 22:18:05,798 - src.Train - INFO - epoch:52,	steps96/207,	loss:0.0014025830896571279
2023-03-24 22:18:08,312 - src.Train - INFO - epoch:52,	steps116/207,	loss:0.0007235145894810557
2023-03-24 22:18:10,767 - src.Train - INFO - epoch:52,	steps136/207,	loss:0.0017862764652818441
2023-03-24 22:18:13,425 - src.Train - INFO - epoch:52,	steps156/207,	loss:0.001969327451661229
2023-03-24 22:18:15,852 - src.Train - INFO - epoch:52,	steps176/207,	loss:0.002485083881765604
2023-03-24 22:18:18,273 - src.Train - INFO - epoch:52,	steps196/207,	loss:0.005416207481175661
2023-03-24 22:18:19,659 - src.Train - INFO - start evaluate...
2023-03-24 22:18:19,659 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:18:21,709 - src.Train - INFO - right: 863	total: 1022	M-tree codes acc: 0.8444227005870841
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:18:27,995 - src.Train - INFO - epoch:53,	steps9/207,	loss:0.0013434445718303323
2023-03-24 22:18:30,282 - src.Train - INFO - epoch:53,	steps29/207,	loss:0.0032063331454992294
2023-03-24 22:18:32,648 - src.Train - INFO - epoch:53,	steps49/207,	loss:0.001506468397565186
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 karin [UNK] science class weighed plastic rings for an experiment. they found that the orange ring weighed γ of an ounce, the purple ring weighed δ of an ounce, and the white ring weighed ε of an ounce. what was the total weight of the plastic rings? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[31, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:18:34,889 - src.Train - INFO - epoch:53,	steps69/207,	loss:0.00412765983492136
2023-03-24 22:18:37,195 - src.Train - INFO - epoch:53,	steps89/207,	loss:0.0008206480415537953
2023-03-24 22:18:39,527 - src.Train - INFO - epoch:53,	steps109/207,	loss:0.0018293870380148292
2023-03-24 22:18:41,828 - src.Train - INFO - epoch:53,	steps129/207,	loss:0.0017650766531005502
2023-03-24 22:18:44,106 - src.Train - INFO - epoch:53,	steps149/207,	loss:0.0011034248163923621
2023-03-24 22:18:46,415 - src.Train - INFO - epoch:53,	steps169/207,	loss:0.002183109987527132
2023-03-24 22:18:48,781 - src.Train - INFO - epoch:53,	steps189/207,	loss:0.0023707912769168615
2023-03-24 22:18:50,891 - src.Train - INFO - start evaluate...
2023-03-24 22:18:50,891 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:18:52,942 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:19:01,412 - src.Train - INFO - epoch:54,	steps2/207,	loss:0.003093674313277006
2023-03-24 22:19:03,775 - src.Train - INFO - epoch:54,	steps22/207,	loss:0.004338675178587437
2023-03-24 22:19:06,052 - src.Train - INFO - epoch:54,	steps42/207,	loss:0.0013964104000478983
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 hoping to be named [UNK] of the month, rosa called the names from γ pages of the phone book last week. this week, she called the people listed on another δ pages of the same phone book. how many pages worth of people did rosa call in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:19:08,205 - src.Train - INFO - epoch:54,	steps62/207,	loss:0.002286770846694708
2023-03-24 22:19:10,621 - src.Train - INFO - epoch:54,	steps82/207,	loss:0.001054672640748322
2023-03-24 22:19:12,922 - src.Train - INFO - epoch:54,	steps102/207,	loss:0.0010920213535428047
2023-03-24 22:19:15,166 - src.Train - INFO - epoch:54,	steps122/207,	loss:0.0013209856115281582
2023-03-24 22:19:17,374 - src.Train - INFO - epoch:54,	steps142/207,	loss:0.0012439994607120752
2023-03-24 22:19:19,656 - src.Train - INFO - epoch:54,	steps162/207,	loss:0.0008498047827742994
2023-03-24 22:19:21,996 - src.Train - INFO - epoch:54,	steps182/207,	loss:0.0016140610678121448
2023-03-24 22:19:24,312 - src.Train - INFO - epoch:54,	steps202/207,	loss:0.003189805196598172
2023-03-24 22:19:24,844 - src.Train - INFO - start evaluate...
2023-03-24 22:19:24,844 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:19:26,856 - src.Train - INFO - right: 862	total: 1022	M-tree codes acc: 0.8434442270058709
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:19:35,882 - src.Train - INFO - epoch:55,	steps15/207,	loss:0.0017338140169158578
2023-03-24 22:19:39,464 - src.Train - INFO - epoch:55,	steps35/207,	loss:0.0026002542581409216
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 shannon and her family use up a lot of strawberry and [UNK] jelly, since they eat toast every morning. at the moment, they have a combined total of γ grams of jelly. if they have δ grams of [UNK] jelly, how many grams of strawberry jelly do they have? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[35, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:19:43,060 - src.Train - INFO - epoch:55,	steps55/207,	loss:0.0018822712590917945
2023-03-24 22:19:46,697 - src.Train - INFO - epoch:55,	steps75/207,	loss:0.0021765269339084625
2023-03-24 22:19:50,639 - src.Train - INFO - epoch:55,	steps95/207,	loss:0.0009571826085448265
2023-03-24 22:19:54,332 - src.Train - INFO - epoch:55,	steps115/207,	loss:0.0012810970656573772
2023-03-24 22:19:58,016 - src.Train - INFO - epoch:55,	steps135/207,	loss:0.010152221657335758
2023-03-24 22:20:01,788 - src.Train - INFO - epoch:55,	steps155/207,	loss:0.0020404793322086334
2023-03-24 22:20:05,572 - src.Train - INFO - epoch:55,	steps175/207,	loss:0.004893567878752947
2023-03-24 22:20:09,138 - src.Train - INFO - epoch:55,	steps195/207,	loss:0.0027417237870395184
2023-03-24 22:20:11,204 - src.Train - INFO - start evaluate...
2023-03-24 22:20:11,204 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:20:14,566 - src.Train - INFO - right: 863	total: 1022	M-tree codes acc: 0.8444227005870841
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:20:21,889 - src.Train - INFO - epoch:56,	steps8/207,	loss:0.0025248813908547163
2023-03-24 22:20:25,746 - src.Train - INFO - epoch:56,	steps28/207,	loss:0.0011868036817759275
2023-03-24 22:20:29,460 - src.Train - INFO - epoch:56,	steps48/207,	loss:0.001675513107329607
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 last saturday, spencer walked all over town running [UNK]. first, he walked γ mile from his house to the library and δ mile from the library to the post office. then he walked ε mile from the post office back home. how many miles did spencer walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[41, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:20:33,123 - src.Train - INFO - epoch:56,	steps68/207,	loss:0.004124080296605825
2023-03-24 22:20:36,854 - src.Train - INFO - epoch:56,	steps88/207,	loss:0.002193212741985917
2023-03-24 22:20:40,584 - src.Train - INFO - epoch:56,	steps108/207,	loss:0.0047241742722690105
2023-03-24 22:20:44,313 - src.Train - INFO - epoch:56,	steps128/207,	loss:0.0020187371410429478
2023-03-24 22:20:47,974 - src.Train - INFO - epoch:56,	steps148/207,	loss:0.0030643336940556765
2023-03-24 22:20:51,918 - src.Train - INFO - epoch:56,	steps168/207,	loss:0.00501715112477541
2023-03-24 22:20:55,544 - src.Train - INFO - epoch:56,	steps188/207,	loss:0.0014228799846023321
2023-03-24 22:20:58,981 - src.Train - INFO - start evaluate...
2023-03-24 22:20:58,982 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:21:02,149 - src.Train - INFO - right: 856	total: 1022	M-tree codes acc: 0.837573385518591
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:21:07,597 - src.Train - INFO - epoch:57,	steps1/207,	loss:0.003458629595115781
2023-03-24 22:21:11,232 - src.Train - INFO - epoch:57,	steps21/207,	loss:0.004495122004300356
2023-03-24 22:21:14,653 - src.Train - INFO - epoch:57,	steps41/207,	loss:0.0026216907426714897
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 last saturday, spencer walked all over town running [UNK]. first, he walked γ of a mile from his house to the library and δ of a mile from the library to the post office. then he walked ε of a mile from the post office back home. how many miles did spencer walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[45, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:21:17,014 - src.Train - INFO - epoch:57,	steps61/207,	loss:0.0013497828040271997
2023-03-24 22:21:19,460 - src.Train - INFO - epoch:57,	steps81/207,	loss:0.0005061895353719592
2023-03-24 22:21:21,700 - src.Train - INFO - epoch:57,	steps101/207,	loss:0.0012712521711364388
2023-03-24 22:21:23,989 - src.Train - INFO - epoch:57,	steps121/207,	loss:0.0028901933692395687
2023-03-24 22:21:26,210 - src.Train - INFO - epoch:57,	steps141/207,	loss:0.002389084780588746
2023-03-24 22:21:28,535 - src.Train - INFO - epoch:57,	steps161/207,	loss:0.0020203879103064537
2023-03-24 22:21:30,788 - src.Train - INFO - epoch:57,	steps181/207,	loss:0.0025173374451696873
2023-03-24 22:21:33,174 - src.Train - INFO - epoch:57,	steps201/207,	loss:0.0009913179092109203
2023-03-24 22:21:33,852 - src.Train - INFO - start evaluate...
2023-03-24 22:21:33,852 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:21:35,851 - src.Train - INFO - right: 857	total: 1022	M-tree codes acc: 0.8385518590998043
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:21:44,819 - src.Train - INFO - epoch:58,	steps14/207,	loss:0.0010178715456277132
2023-03-24 22:21:47,425 - src.Train - INFO - epoch:58,	steps34/207,	loss:0.0012490517692640424
2023-03-24 22:21:49,782 - src.Train - INFO - epoch:58,	steps54/207,	loss:0.0026006153784692287
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 karin [UNK] science class weighed plastic rings for an experiment. they found that the orange ring weighed γ of an ounce, the purple ring weighed δ of an ounce, and the white ring weighed ε of an ounce. what was the total weight of the plastic rings? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[41, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:21:52,430 - src.Train - INFO - epoch:58,	steps74/207,	loss:0.0021222305949777365
2023-03-24 22:21:54,778 - src.Train - INFO - epoch:58,	steps94/207,	loss:0.0012237963965162635
2023-03-24 22:21:57,404 - src.Train - INFO - epoch:58,	steps114/207,	loss:0.0011590335052460432
2023-03-24 22:21:59,762 - src.Train - INFO - epoch:58,	steps134/207,	loss:0.002360591199249029
2023-03-24 22:22:02,217 - src.Train - INFO - epoch:58,	steps154/207,	loss:0.0019615369383245707
2023-03-24 22:22:04,677 - src.Train - INFO - epoch:58,	steps174/207,	loss:0.0018304717959836125
2023-03-24 22:22:07,197 - src.Train - INFO - epoch:58,	steps194/207,	loss:0.002435230417177081
2023-03-24 22:22:08,805 - src.Train - INFO - start evaluate...
2023-03-24 22:22:08,805 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:22:10,834 - src.Train - INFO - right: 856	total: 1022	M-tree codes acc: 0.837573385518591
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:22:16,689 - src.Train - INFO - epoch:59,	steps7/207,	loss:0.005381416063755751
2023-03-24 22:22:18,602 - src.Train - INFO - epoch:59,	steps27/207,	loss:0.0008468799642287195
2023-03-24 22:22:20,463 - src.Train - INFO - epoch:59,	steps47/207,	loss:0.0020703363697975874
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 γ cars leave the same point, traveling in opposite directions. if one travels at a constant speed of δ miles per hour and the other travels at a constant speed of ε miles per hour. in how many hours will they be ζ miles apart? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
====================
label:[37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:22:22,225 - src.Train - INFO - epoch:59,	steps67/207,	loss:0.001531351706944406
2023-03-24 22:22:24,056 - src.Train - INFO - epoch:59,	steps87/207,	loss:0.005528601352125406
2023-03-24 22:22:25,970 - src.Train - INFO - epoch:59,	steps107/207,	loss:0.002728173043578863
2023-03-24 22:22:27,892 - src.Train - INFO - epoch:59,	steps127/207,	loss:0.0017810147255659103
2023-03-24 22:22:29,704 - src.Train - INFO - epoch:59,	steps147/207,	loss:0.004234703257679939
2023-03-24 22:22:31,541 - src.Train - INFO - epoch:59,	steps167/207,	loss:0.0023436304181814194
2023-03-24 22:22:33,382 - src.Train - INFO - epoch:59,	steps187/207,	loss:0.0016345612239092588
2023-03-24 22:22:35,145 - src.Train - INFO - epoch:59,	steps207/207,	loss:0.11612740159034729
2023-03-24 22:22:35,145 - src.Train - INFO - start evaluate...
2023-03-24 22:22:35,145 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:22:36,690 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:22:43,758 - src.Train - INFO - epoch:60,	steps20/207,	loss:0.0017519862158223987
2023-03-24 22:22:45,576 - src.Train - INFO - epoch:60,	steps40/207,	loss:0.0015911506488919258
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 lexie [UNK] younger brother helped pick up all the paper clips in lexie [UNK] room. he was a [UNK] to collect γ paper clips. if he wants to distribute the paper clips in δ boxes, how many paper clips will each box contain? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:22:47,480 - src.Train - INFO - epoch:60,	steps60/207,	loss:0.0015467162011191249
2023-03-24 22:22:49,358 - src.Train - INFO - epoch:60,	steps80/207,	loss:0.004603060893714428
2023-03-24 22:22:51,294 - src.Train - INFO - epoch:60,	steps100/207,	loss:0.008461186662316322
2023-03-24 22:22:53,034 - src.Train - INFO - epoch:60,	steps120/207,	loss:0.000651180453132838
2023-03-24 22:22:54,821 - src.Train - INFO - epoch:60,	steps140/207,	loss:0.0021726731210947037
2023-03-24 22:22:56,695 - src.Train - INFO - epoch:60,	steps160/207,	loss:0.0026267992798238993
2023-03-24 22:22:58,571 - src.Train - INFO - epoch:60,	steps180/207,	loss:0.0012426353059709072
2023-03-24 22:23:00,422 - src.Train - INFO - epoch:60,	steps200/207,	loss:0.0016997110797092319
2023-03-24 22:23:01,004 - src.Train - INFO - start evaluate...
2023-03-24 22:23:01,004 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:23:02,532 - src.Train - INFO - right: 862	total: 1022	M-tree codes acc: 0.8434442270058709
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:23:10,222 - src.Train - INFO - epoch:61,	steps13/207,	loss:0.001724802190437913
2023-03-24 22:23:12,028 - src.Train - INFO - epoch:61,	steps33/207,	loss:0.00426553376019001
2023-03-24 22:23:13,883 - src.Train - INFO - epoch:61,	steps53/207,	loss:0.0007077539339661598
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jason had to submit γ animation projects as per his [UNK] bus in the final [UNK]. he scored δ, ε, ζ, and η points out of θ in ι projects. what should be his score in the fifth project so that the average of his projects is at least κ? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
====================
label:[58, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:23:15,685 - src.Train - INFO - epoch:61,	steps73/207,	loss:0.002275007078424096
2023-03-24 22:23:17,502 - src.Train - INFO - epoch:61,	steps93/207,	loss:0.0011674504494294524
2023-03-24 22:23:19,401 - src.Train - INFO - epoch:61,	steps113/207,	loss:0.0029450294096022844
2023-03-24 22:23:21,276 - src.Train - INFO - epoch:61,	steps133/207,	loss:0.0019236317602917552
2023-03-24 22:23:23,206 - src.Train - INFO - epoch:61,	steps153/207,	loss:0.0029694102704524994
2023-03-24 22:23:26,367 - src.Train - INFO - epoch:61,	steps173/207,	loss:0.0007329728687182069
2023-03-24 22:23:28,989 - src.Train - INFO - epoch:61,	steps193/207,	loss:0.0033715227618813515
2023-03-24 22:23:31,224 - src.Train - INFO - start evaluate...
2023-03-24 22:23:31,224 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:23:34,115 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:23:40,112 - src.Train - INFO - epoch:62,	steps6/207,	loss:0.0022016377188265324
2023-03-24 22:23:43,525 - src.Train - INFO - epoch:62,	steps26/207,	loss:0.00162790366448462
2023-03-24 22:23:46,850 - src.Train - INFO - epoch:62,	steps46/207,	loss:0.0031706581357866526
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 karin [UNK] science class weighed plastic rings for an experiment. they found that the orange ring weighed γ of an ounce, the purple ring weighed δ of an ounce, and the white ring weighed ε of an ounce. what was the total weight of the plastic rings? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[22, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:23:50,282 - src.Train - INFO - epoch:62,	steps66/207,	loss:0.0030735405161976814
2023-03-24 22:23:53,551 - src.Train - INFO - epoch:62,	steps86/207,	loss:0.001214889925904572
2023-03-24 22:23:56,861 - src.Train - INFO - epoch:62,	steps106/207,	loss:0.0022376831620931625
2023-03-24 22:24:00,342 - src.Train - INFO - epoch:62,	steps126/207,	loss:0.0012652336154133081
2023-03-24 22:24:03,639 - src.Train - INFO - epoch:62,	steps146/207,	loss:0.0019337177509441972
2023-03-24 22:24:07,108 - src.Train - INFO - epoch:62,	steps166/207,	loss:0.0034436637070029974
2023-03-24 22:24:10,374 - src.Train - INFO - epoch:62,	steps186/207,	loss:0.001275939168408513
2023-03-24 22:24:13,759 - src.Train - INFO - epoch:62,	steps206/207,	loss:0.0011493756901472807
2023-03-24 22:24:13,824 - src.Train - INFO - start evaluate...
2023-03-24 22:24:13,824 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:24:16,707 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:24:27,115 - src.Train - INFO - epoch:63,	steps19/207,	loss:0.006587484385818243
2023-03-24 22:24:30,482 - src.Train - INFO - epoch:63,	steps39/207,	loss:0.0031945384107530117
2023-03-24 22:24:33,801 - src.Train - INFO - epoch:63,	steps59/207,	loss:0.0017787724500522017
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 ned was trying to expand his game collection. he bought γ games from a friend and bought δ more at a garage sale. if ε of the games did [UNK] work, how many good games did he end up with? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[15, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:24:37,126 - src.Train - INFO - epoch:63,	steps79/207,	loss:0.002699269913136959
2023-03-24 22:24:40,544 - src.Train - INFO - epoch:63,	steps99/207,	loss:0.0037102345377206802
2023-03-24 22:24:43,866 - src.Train - INFO - epoch:63,	steps119/207,	loss:0.0014222583267837763
2023-03-24 22:24:47,261 - src.Train - INFO - epoch:63,	steps139/207,	loss:0.0010440654587000608
2023-03-24 22:24:50,692 - src.Train - INFO - epoch:63,	steps159/207,	loss:0.00221316353417933
2023-03-24 22:24:53,376 - src.Train - INFO - epoch:63,	steps179/207,	loss:0.0029214208479970694
2023-03-24 22:24:55,233 - src.Train - INFO - epoch:63,	steps199/207,	loss:0.003267299383878708
2023-03-24 22:24:55,874 - src.Train - INFO - start evaluate...
2023-03-24 22:24:55,874 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:24:57,494 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:25:03,760 - src.Train - INFO - epoch:64,	steps12/207,	loss:0.002100890502333641
2023-03-24 22:25:05,581 - src.Train - INFO - epoch:64,	steps32/207,	loss:0.0028404335025697947
2023-03-24 22:25:07,440 - src.Train - INFO - epoch:64,	steps52/207,	loss:0.0038186649326235056
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 grace has γ [UNK] in her pocket. she has δ red ones, ε green ones, and ζ blue ones. what is the minimum number of [UNK] she must take out of her pocket to ensure that she has one of each color? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:25:09,266 - src.Train - INFO - epoch:64,	steps72/207,	loss:0.0030860155820846558
2023-03-24 22:25:11,152 - src.Train - INFO - epoch:64,	steps92/207,	loss:0.0025564180687069893
2023-03-24 22:25:13,009 - src.Train - INFO - epoch:64,	steps112/207,	loss:0.0010922217043116689
2023-03-24 22:25:14,797 - src.Train - INFO - epoch:64,	steps132/207,	loss:0.0025370956864207983
2023-03-24 22:25:16,559 - src.Train - INFO - epoch:64,	steps152/207,	loss:0.001298591261729598
2023-03-24 22:25:17,872 - src.Train - INFO - epoch:64,	steps172/207,	loss:0.0007969788857735693
2023-03-24 22:25:19,258 - src.Train - INFO - epoch:64,	steps192/207,	loss:0.0012070031370967627
2023-03-24 22:25:20,940 - src.Train - INFO - start evaluate...
2023-03-24 22:25:20,940 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:25:23,074 - src.Train - INFO - right: 862	total: 1022	M-tree codes acc: 0.8434442270058709
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:25:28,967 - src.Train - INFO - epoch:65,	steps5/207,	loss:0.0009565904620103538
2023-03-24 22:25:31,313 - src.Train - INFO - epoch:65,	steps25/207,	loss:0.0023589704651385546
2023-03-24 22:25:33,656 - src.Train - INFO - epoch:65,	steps45/207,	loss:0.001048030680976808
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jason had to submit γ animation projects as per his [UNK] bus in the final [UNK]. he scored δ, ε, ζ, and η points out of θ in ι projects. what should be his score in the fifth project so that the average of his projects is at least κ? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
====================
label:[58, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:25:35,988 - src.Train - INFO - epoch:65,	steps65/207,	loss:0.003020124277099967
2023-03-24 22:25:38,291 - src.Train - INFO - epoch:65,	steps85/207,	loss:0.0012925784103572369
2023-03-24 22:25:40,563 - src.Train - INFO - epoch:65,	steps105/207,	loss:0.0025779707357287407
2023-03-24 22:25:42,886 - src.Train - INFO - epoch:65,	steps125/207,	loss:0.002534463768824935
2023-03-24 22:25:45,068 - src.Train - INFO - epoch:65,	steps145/207,	loss:0.002261779038235545
2023-03-24 22:25:47,276 - src.Train - INFO - epoch:65,	steps165/207,	loss:0.0027589488308876753
2023-03-24 22:25:49,634 - src.Train - INFO - epoch:65,	steps185/207,	loss:0.0030437244568020105
2023-03-24 22:25:51,881 - src.Train - INFO - epoch:65,	steps205/207,	loss:0.0014646797208115458
2023-03-24 22:25:52,029 - src.Train - INFO - start evaluate...
2023-03-24 22:25:52,029 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:25:54,113 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:26:04,981 - src.Train - INFO - epoch:66,	steps18/207,	loss:0.0011823963141068816
2023-03-24 22:26:07,274 - src.Train - INFO - epoch:66,	steps38/207,	loss:0.003963700495660305
2023-03-24 22:26:09,632 - src.Train - INFO - epoch:66,	steps58/207,	loss:0.0029602129943668842
torch.Size([20, 72])
torch.Size([20, 72])
torch.Size([20, 72])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 dalton wants to buy a jump rope that costs $ γ, a board game that costs $ δ, and a playground ball that costs $ ε. he has saved $ ζ from his allowance, and his uncle gave him $ η. how much more money does dalton need to buy the jump rope, the game, and the ball? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[14, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:26:11,969 - src.Train - INFO - epoch:66,	steps78/207,	loss:0.0011462924303486943
2023-03-24 22:26:14,310 - src.Train - INFO - epoch:66,	steps98/207,	loss:0.0025663143023848534
2023-03-24 22:26:16,595 - src.Train - INFO - epoch:66,	steps118/207,	loss:0.0014650565572082996
2023-03-24 22:26:18,874 - src.Train - INFO - epoch:66,	steps138/207,	loss:0.001216687960550189
2023-03-24 22:26:21,191 - src.Train - INFO - epoch:66,	steps158/207,	loss:0.0019734830129891634
2023-03-24 22:26:23,480 - src.Train - INFO - epoch:66,	steps178/207,	loss:0.0012088464573025703
2023-03-24 22:26:25,858 - src.Train - INFO - epoch:66,	steps198/207,	loss:0.0015842235879972577
2023-03-24 22:26:27,402 - src.Train - INFO - start evaluate...
2023-03-24 22:26:27,402 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:26:30,073 - src.Train - INFO - right: 861	total: 1022	M-tree codes acc: 0.8424657534246576
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:26:36,836 - src.Train - INFO - epoch:67,	steps11/207,	loss:0.0008169785141944885
2023-03-24 22:26:40,438 - src.Train - INFO - epoch:67,	steps31/207,	loss:0.0021738100331276655
2023-03-24 22:26:44,239 - src.Train - INFO - epoch:67,	steps51/207,	loss:0.0049171713180840015
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] hilt and her sister drove to a concert γ miles away. they drove δ miles and then stopped for gas. her sister put ε gallons of gas in the car. how many miles did they have left to drive? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:26:48,189 - src.Train - INFO - epoch:67,	steps71/207,	loss:0.00227046525105834
2023-03-24 22:26:51,794 - src.Train - INFO - epoch:67,	steps91/207,	loss:0.002326668705791235
2023-03-24 22:26:55,478 - src.Train - INFO - epoch:67,	steps111/207,	loss:0.001858001109212637
2023-03-24 22:26:59,262 - src.Train - INFO - epoch:67,	steps131/207,	loss:0.002085562562569976
2023-03-24 22:27:03,082 - src.Train - INFO - epoch:67,	steps151/207,	loss:0.001371548161841929
2023-03-24 22:27:06,786 - src.Train - INFO - epoch:67,	steps171/207,	loss:0.0010962046217173338
2023-03-24 22:27:10,532 - src.Train - INFO - epoch:67,	steps191/207,	loss:0.002098529599606991
2023-03-24 22:27:13,366 - src.Train - INFO - start evaluate...
2023-03-24 22:27:13,366 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:27:16,755 - src.Train - INFO - right: 859	total: 1022	M-tree codes acc: 0.8405088062622309
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:27:23,108 - src.Train - INFO - epoch:68,	steps4/207,	loss:0.0010870706755667925
2023-03-24 22:27:26,893 - src.Train - INFO - epoch:68,	steps24/207,	loss:0.0013317940756678581
2023-03-24 22:27:30,616 - src.Train - INFO - epoch:68,	steps44/207,	loss:0.00168254179880023
2023-03-24 22:27:34,568 - src.Train - INFO - epoch:68,	steps64/207,	loss:0.0012471737572923303
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 logan recorded the snowfall every day during a [UNK]. he recorded γ of a [UNK] on wednesday, δ of a [UNK] on thursday, and ε of a [UNK] on friday. how many total centimeters of snow did logan record? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[23, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:27:38,277 - src.Train - INFO - epoch:68,	steps84/207,	loss:0.0015586442314088345
2023-03-24 22:27:42,140 - src.Train - INFO - epoch:68,	steps104/207,	loss:0.0023166832979768515
2023-03-24 22:27:45,697 - src.Train - INFO - epoch:68,	steps124/207,	loss:0.004029081668704748
2023-03-24 22:27:49,485 - src.Train - INFO - epoch:68,	steps144/207,	loss:0.0012548957020044327
2023-03-24 22:27:53,198 - src.Train - INFO - epoch:68,	steps164/207,	loss:0.001316916081123054
2023-03-24 22:27:56,723 - src.Train - INFO - epoch:68,	steps184/207,	loss:0.0018944863695651293
2023-03-24 22:28:00,403 - src.Train - INFO - epoch:68,	steps204/207,	loss:0.0011056468356400728
2023-03-24 22:28:00,877 - src.Train - INFO - start evaluate...
2023-03-24 22:28:00,877 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:28:04,043 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:28:15,889 - src.Train - INFO - epoch:69,	steps17/207,	loss:0.0010015047155320644
2023-03-24 22:28:18,211 - src.Train - INFO - epoch:69,	steps37/207,	loss:0.0012840734561905265
2023-03-24 22:28:20,511 - src.Train - INFO - epoch:69,	steps57/207,	loss:0.0020740083418786526
torch.Size([20, 80])
torch.Size([20, 80])
torch.Size([20, 80])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 customers of a phone company can choose between γ service plans for long distance calls. the first plan has a δ dollars monthly fee and charges an additional ε dollars for each minute of calls. the second plan has an ζ dollars monthly fee and charges an additional η dollars for each minute of calls. for how many minutes of calls will the costs of the θ plans be equal? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:28:22,819 - src.Train - INFO - epoch:69,	steps77/207,	loss:0.001842195400968194
2023-03-24 22:28:25,123 - src.Train - INFO - epoch:69,	steps97/207,	loss:0.002786761848255992
2023-03-24 22:28:27,346 - src.Train - INFO - epoch:69,	steps117/207,	loss:0.001952053396962583
2023-03-24 22:28:30,043 - src.Train - INFO - epoch:69,	steps137/207,	loss:0.0023803773801773787
2023-03-24 22:28:32,679 - src.Train - INFO - epoch:69,	steps157/207,	loss:0.0018477612175047398
2023-03-24 22:28:35,657 - src.Train - INFO - epoch:69,	steps177/207,	loss:0.0034680375829339027
2023-03-24 22:28:38,470 - src.Train - INFO - epoch:69,	steps197/207,	loss:0.0017910830210894346
2023-03-24 22:28:39,793 - src.Train - INFO - start evaluate...
2023-03-24 22:28:39,793 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:28:41,992 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:28:50,114 - src.Train - INFO - epoch:70,	steps10/207,	loss:0.0010273990919813514
2023-03-24 22:28:52,486 - src.Train - INFO - epoch:70,	steps30/207,	loss:0.002845159498974681
2023-03-24 22:28:55,100 - src.Train - INFO - epoch:70,	steps50/207,	loss:0.0011290060356259346
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a study reported that in a random sampling of γ women over the age of δ, ε of the women were married ζ or more times. based on the study results, how many woman in a group of η women over the age of θ would likely be married ι or more times? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[21, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:28:57,527 - src.Train - INFO - epoch:70,	steps70/207,	loss:0.0007143121911212802
2023-03-24 22:28:59,862 - src.Train - INFO - epoch:70,	steps90/207,	loss:0.0016368846409022808
2023-03-24 22:29:02,559 - src.Train - INFO - epoch:70,	steps110/207,	loss:0.0025535966269671917
2023-03-24 22:29:04,958 - src.Train - INFO - epoch:70,	steps130/207,	loss:0.0030051313806325197
2023-03-24 22:29:07,485 - src.Train - INFO - epoch:70,	steps150/207,	loss:0.0035600385162979364
2023-03-24 22:29:09,868 - src.Train - INFO - epoch:70,	steps170/207,	loss:0.0019960948266088963
2023-03-24 22:29:12,487 - src.Train - INFO - epoch:70,	steps190/207,	loss:0.00246878108009696
2023-03-24 22:29:14,534 - src.Train - INFO - start evaluate...
2023-03-24 22:29:14,534 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:29:16,520 - src.Train - INFO - right: 859	total: 1022	M-tree codes acc: 0.8405088062622309
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:29:22,004 - src.Train - INFO - epoch:71,	steps3/207,	loss:0.0014882670948281884
2023-03-24 22:29:24,317 - src.Train - INFO - epoch:71,	steps23/207,	loss:0.0037886551581323147
2023-03-24 22:29:26,975 - src.Train - INFO - epoch:71,	steps43/207,	loss:0.0008731406996957958
2023-03-24 22:29:29,363 - src.Train - INFO - epoch:71,	steps63/207,	loss:0.0017348970286548138
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 adam bought γ packages of cat food and δ packages of dog food. each package of cat food contained ε cans, and each package of dog food contained ζ cans. how many more cans of cat food than dog food did adam buy? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[12, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:29:31,912 - src.Train - INFO - epoch:71,	steps83/207,	loss:0.0018728194991126657
2023-03-24 22:29:34,392 - src.Train - INFO - epoch:71,	steps103/207,	loss:0.0049795182421803474
2023-03-24 22:29:36,936 - src.Train - INFO - epoch:71,	steps123/207,	loss:0.0020852722227573395
2023-03-24 22:29:39,272 - src.Train - INFO - epoch:71,	steps143/207,	loss:0.002568753669038415
2023-03-24 22:29:41,612 - src.Train - INFO - epoch:71,	steps163/207,	loss:0.0009754524799063802
2023-03-24 22:29:44,325 - src.Train - INFO - epoch:71,	steps183/207,	loss:0.001560525968670845
2023-03-24 22:29:46,739 - src.Train - INFO - epoch:71,	steps203/207,	loss:0.002031827112659812
2023-03-24 22:29:47,237 - src.Train - INFO - start evaluate...
2023-03-24 22:29:47,238 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:29:49,238 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:29:56,909 - src.Train - INFO - epoch:72,	steps16/207,	loss:0.0040778894908726215
2023-03-24 22:29:59,382 - src.Train - INFO - epoch:72,	steps36/207,	loss:0.002945759566500783
2023-03-24 22:30:01,899 - src.Train - INFO - epoch:72,	steps56/207,	loss:0.0020737196318805218
torch.Size([20, 69])
torch.Size([20, 69])
torch.Size([20, 69])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 student council wants to rent a banquet hall for the prom. caesar [UNK] charges γ dollars to rent the room and δ dollars for each meal. venus hall charges ε dollars to rent the room and ζ dollars for each meal. how many guests must attend the prom for the costs of the η halls to be the same? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[35, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:30:04,482 - src.Train - INFO - epoch:72,	steps76/207,	loss:0.0032145704608410597
2023-03-24 22:30:06,994 - src.Train - INFO - epoch:72,	steps96/207,	loss:0.0006131447735242546
2023-03-24 22:30:09,395 - src.Train - INFO - epoch:72,	steps116/207,	loss:0.0011016824282705784
2023-03-24 22:30:11,958 - src.Train - INFO - epoch:72,	steps136/207,	loss:0.0012972531840205193
2023-03-24 22:30:14,334 - src.Train - INFO - epoch:72,	steps156/207,	loss:0.003286744700744748
2023-03-24 22:30:16,882 - src.Train - INFO - epoch:72,	steps176/207,	loss:0.0015389297623187304
2023-03-24 22:30:19,282 - src.Train - INFO - epoch:72,	steps196/207,	loss:0.0013625508872792125
2023-03-24 22:30:20,588 - src.Train - INFO - start evaluate...
2023-03-24 22:30:20,588 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:30:22,701 - src.Train - INFO - right: 864	total: 1022	M-tree codes acc: 0.8454011741682974
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:30:29,731 - src.Train - INFO - epoch:73,	steps9/207,	loss:0.002159164985641837
2023-03-24 22:30:32,059 - src.Train - INFO - epoch:73,	steps29/207,	loss:0.0004969482542946935
2023-03-24 22:30:34,554 - src.Train - INFO - epoch:73,	steps49/207,	loss:0.0016877477755770087
2023-03-24 22:30:37,052 - src.Train - INFO - epoch:73,	steps69/207,	loss:0.0015913224779069424
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 54])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 as part of a lesson on earthquakes, a science class is researching the movement of a nearby fault line. the fault line moved γ inches during the past year and δ inches the year before. how far did the fault line move in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[36, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:30:39,452 - src.Train - INFO - epoch:73,	steps89/207,	loss:0.0005464200512506068
2023-03-24 22:30:42,124 - src.Train - INFO - epoch:73,	steps109/207,	loss:0.0021791020408272743
2023-03-24 22:30:44,491 - src.Train - INFO - epoch:73,	steps129/207,	loss:0.0006320922402665019
2023-03-24 22:30:47,032 - src.Train - INFO - epoch:73,	steps149/207,	loss:0.0025360635481774807
2023-03-24 22:30:49,360 - src.Train - INFO - epoch:73,	steps169/207,	loss:0.002022162079811096
2023-03-24 22:30:51,860 - src.Train - INFO - epoch:73,	steps189/207,	loss:0.00179688585922122
2023-03-24 22:30:54,079 - src.Train - INFO - start evaluate...
2023-03-24 22:30:54,079 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:30:56,088 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:31:01,769 - src.Train - INFO - epoch:74,	steps2/207,	loss:0.0027264279779046774
2023-03-24 22:31:04,208 - src.Train - INFO - epoch:74,	steps22/207,	loss:0.0011355977039784193
2023-03-24 22:31:06,688 - src.Train - INFO - epoch:74,	steps42/207,	loss:0.0005055268993601203
2023-03-24 22:31:09,250 - src.Train - INFO - epoch:74,	steps62/207,	loss:0.0018323546973988414
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a gas station owner has γ gallons of gasoline for which he charges δ dollars per gallon and some for which he charges ε dollars per gallon. how many gallons of the ζ dollars brand must the owner mix in to produce gasoline that costs η dollars per gallon? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
====================
label:[17, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:31:11,578 - src.Train - INFO - epoch:74,	steps82/207,	loss:0.0010049139382317662
2023-03-24 22:31:14,220 - src.Train - INFO - epoch:74,	steps102/207,	loss:0.0029413241427391768
2023-03-24 22:31:16,663 - src.Train - INFO - epoch:74,	steps122/207,	loss:0.0012087221257388592
2023-03-24 22:31:19,149 - src.Train - INFO - epoch:74,	steps142/207,	loss:0.0022033483255654573
2023-03-24 22:31:21,621 - src.Train - INFO - epoch:74,	steps162/207,	loss:0.0009954865090548992
2023-03-24 22:31:23,920 - src.Train - INFO - epoch:74,	steps182/207,	loss:0.0017497908556833863
2023-03-24 22:31:26,451 - src.Train - INFO - epoch:74,	steps202/207,	loss:0.0032913757022470236
2023-03-24 22:31:26,903 - src.Train - INFO - start evaluate...
2023-03-24 22:31:26,903 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:31:28,975 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
2023-03-24 22:31:28,976 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:31:44,449 - src.Train - INFO - epoch:75,	steps15/207,	loss:0.0008560942951589823
2023-03-24 22:31:47,036 - src.Train - INFO - epoch:75,	steps35/207,	loss:0.0017129209591075778
2023-03-24 22:31:49,431 - src.Train - INFO - epoch:75,	steps55/207,	loss:0.002276624785736203
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a study reported that in a random sampling of γ women over the age of δ, ε of the women were married ζ or more times. based on the study results, how many woman in a group of η women over the age of θ would likely be married ι or more times? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[45, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:31:51,917 - src.Train - INFO - epoch:75,	steps75/207,	loss:0.0035748397931456566
2023-03-24 22:31:54,474 - src.Train - INFO - epoch:75,	steps95/207,	loss:0.0015594257274642587
2023-03-24 22:31:56,917 - src.Train - INFO - epoch:75,	steps115/207,	loss:0.0008385410765185952
2023-03-24 22:31:59,471 - src.Train - INFO - epoch:75,	steps135/207,	loss:0.0010873848805204034
2023-03-24 22:32:02,001 - src.Train - INFO - epoch:75,	steps155/207,	loss:0.002544095739722252
2023-03-24 22:32:04,481 - src.Train - INFO - epoch:75,	steps175/207,	loss:0.0006657197372987866
2023-03-24 22:32:06,898 - src.Train - INFO - epoch:75,	steps195/207,	loss:0.006298915483057499
2023-03-24 22:32:08,433 - src.Train - INFO - start evaluate...
2023-03-24 22:32:08,433 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:32:10,377 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:32:16,144 - src.Train - INFO - epoch:76,	steps8/207,	loss:0.0029955361969769
2023-03-24 22:32:18,772 - src.Train - INFO - epoch:76,	steps28/207,	loss:0.0029612614307552576
2023-03-24 22:32:21,139 - src.Train - INFO - epoch:76,	steps48/207,	loss:0.0009580582263879478
2023-03-24 22:32:23,740 - src.Train - INFO - epoch:76,	steps68/207,	loss:0.002014713129028678
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 58])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 during a school play, jonah staffed the snack bar. he served γ of a pitcher of [UNK] during the first [UNK], δ of a pitcher during the second, and ε of a pitcher during the third. how many pitchers of [UNK] did jonah pour in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[28, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:32:26,188 - src.Train - INFO - epoch:76,	steps88/207,	loss:0.0015049946960061789
2023-03-24 22:32:28,752 - src.Train - INFO - epoch:76,	steps108/207,	loss:0.0018514245748519897
2023-03-24 22:32:31,114 - src.Train - INFO - epoch:76,	steps128/207,	loss:0.002066398039460182
2023-03-24 22:32:33,557 - src.Train - INFO - epoch:76,	steps148/207,	loss:0.0015824167057871819
2023-03-24 22:32:36,051 - src.Train - INFO - epoch:76,	steps168/207,	loss:0.0035702758468687534
2023-03-24 22:32:38,438 - src.Train - INFO - epoch:76,	steps188/207,	loss:0.003263237187638879
2023-03-24 22:32:40,933 - src.Train - INFO - start evaluate...
2023-03-24 22:32:40,933 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:32:42,908 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:32:49,969 - src.Train - INFO - epoch:77,	steps1/207,	loss:0.00265610427595675
2023-03-24 22:32:52,402 - src.Train - INFO - epoch:77,	steps21/207,	loss:0.0023501268588006496
2023-03-24 22:32:54,922 - src.Train - INFO - epoch:77,	steps41/207,	loss:0.0020396301988512278
2023-03-24 22:32:57,420 - src.Train - INFO - epoch:77,	steps61/207,	loss:0.0018505017505958676
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 fred loves trading cards. he bought γ packs of football cards for $ δ each, a pack of pokemon cards for $ ε, and a deck of baseball cards for $ ζ. how much did fred spend on cards? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[38, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:32:59,823 - src.Train - INFO - epoch:77,	steps81/207,	loss:0.0020675882697105408
2023-03-24 22:33:02,419 - src.Train - INFO - epoch:77,	steps101/207,	loss:0.0017956693191081285
2023-03-24 22:33:04,794 - src.Train - INFO - epoch:77,	steps121/207,	loss:0.003434901125729084
2023-03-24 22:33:07,397 - src.Train - INFO - epoch:77,	steps141/207,	loss:0.0015965343918651342
2023-03-24 22:33:09,734 - src.Train - INFO - epoch:77,	steps161/207,	loss:0.0016524408711120486
2023-03-24 22:33:12,062 - src.Train - INFO - epoch:77,	steps181/207,	loss:0.0029440803918987513
2023-03-24 22:33:14,785 - src.Train - INFO - epoch:77,	steps201/207,	loss:0.0014671554090455174
2023-03-24 22:33:15,433 - src.Train - INFO - start evaluate...
2023-03-24 22:33:15,433 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:33:17,463 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:33:23,779 - src.Train - INFO - epoch:78,	steps14/207,	loss:0.0019343852763995528
2023-03-24 22:33:26,223 - src.Train - INFO - epoch:78,	steps34/207,	loss:0.004052517469972372
2023-03-24 22:33:28,526 - src.Train - INFO - epoch:78,	steps54/207,	loss:0.005513553041964769
2023-03-24 22:33:31,212 - src.Train - INFO - epoch:78,	steps74/207,	loss:0.0010758608113974333
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 harry hound had a terrible [UNK] yesterday. when i peered into his ears yesterday, i found γ [UNK] [UNK] having a party in his right ear and δ ba by [UNK] sleeping peacefully in his left ear. i cleaned out harry hound [UNK] ears. how many [UNK] perished? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[22, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:33:33,626 - src.Train - INFO - epoch:78,	steps94/207,	loss:0.002688819542527199
2023-03-24 22:33:36,146 - src.Train - INFO - epoch:78,	steps114/207,	loss:0.0023728003725409508
2023-03-24 22:33:38,560 - src.Train - INFO - epoch:78,	steps134/207,	loss:0.0033782669343054295
2023-03-24 22:33:41,054 - src.Train - INFO - epoch:78,	steps154/207,	loss:0.0011575812241062522
2023-03-24 22:33:43,356 - src.Train - INFO - epoch:78,	steps174/207,	loss:0.00377147039398551
2023-03-24 22:33:45,670 - src.Train - INFO - epoch:78,	steps194/207,	loss:0.002011986682191491
2023-03-24 22:33:47,156 - src.Train - INFO - start evaluate...
2023-03-24 22:33:47,156 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:33:49,145 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:33:55,061 - src.Train - INFO - epoch:79,	steps7/207,	loss:0.0030564339831471443
2023-03-24 22:33:57,380 - src.Train - INFO - epoch:79,	steps27/207,	loss:0.0021806317381560802
2023-03-24 22:33:59,734 - src.Train - INFO - epoch:79,	steps47/207,	loss:0.0017342313658446074
2023-03-24 22:34:01,934 - src.Train - INFO - epoch:79,	steps67/207,	loss:0.0011262421030551195
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 martha wants to buy a digital camera from her γ month savings. to do this she needs to maintain an average saving of δ in each month. she saves ε in the first month and ζ in the second month. find the amount she should save in the third month, in dollars, to buy a digital camera at the end of η months. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
====================
label:[28, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:34:04,239 - src.Train - INFO - epoch:79,	steps87/207,	loss:0.001534211914986372
2023-03-24 22:34:06,560 - src.Train - INFO - epoch:79,	steps107/207,	loss:0.001728760777041316
2023-03-24 22:34:08,857 - src.Train - INFO - epoch:79,	steps127/207,	loss:0.001015102257952094
2023-03-24 22:34:11,261 - src.Train - INFO - epoch:79,	steps147/207,	loss:0.002534943399950862
2023-03-24 22:34:13,542 - src.Train - INFO - epoch:79,	steps167/207,	loss:0.0011272404808551073
2023-03-24 22:34:15,819 - src.Train - INFO - epoch:79,	steps187/207,	loss:0.002335399854928255
2023-03-24 22:34:18,160 - src.Train - INFO - epoch:79,	steps207/207,	loss:0.026462174952030182
2023-03-24 22:34:18,160 - src.Train - INFO - start evaluate...
2023-03-24 22:34:18,160 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:34:20,201 - src.Train - INFO - right: 872	total: 1022	M-tree codes acc: 0.8532289628180039
2023-03-24 22:34:20,202 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:34:35,077 - src.Train - INFO - epoch:80,	steps20/207,	loss:0.0018148439703509212
2023-03-24 22:34:37,178 - src.Train - INFO - epoch:80,	steps40/207,	loss:0.001387653173878789
2023-03-24 22:34:39,457 - src.Train - INFO - epoch:80,	steps60/207,	loss:0.0035162412095814943
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a plane travels due east at γ miles per hour and another plane travels due west at δ miles per hour. if they leave at the same time, and from the same place, in how many hours will they be ε miles apart? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
====================
label:[47, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:34:41,724 - src.Train - INFO - epoch:80,	steps80/207,	loss:0.003128503914922476
2023-03-24 22:34:44,042 - src.Train - INFO - epoch:80,	steps100/207,	loss:0.0011468244483694434
2023-03-24 22:34:46,803 - src.Train - INFO - epoch:80,	steps120/207,	loss:0.0036497116088867188
2023-03-24 22:34:50,090 - src.Train - INFO - epoch:80,	steps140/207,	loss:0.00170680892188102
2023-03-24 22:34:53,795 - src.Train - INFO - epoch:80,	steps160/207,	loss:0.0013843874912708998
2023-03-24 22:34:57,493 - src.Train - INFO - epoch:80,	steps180/207,	loss:0.001498217461630702
2023-03-24 22:35:01,231 - src.Train - INFO - epoch:80,	steps200/207,	loss:0.0016780751757323742
2023-03-24 22:35:02,483 - src.Train - INFO - start evaluate...
2023-03-24 22:35:02,484 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:35:05,701 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:35:12,763 - src.Train - INFO - epoch:81,	steps13/207,	loss:0.002195684937760234
2023-03-24 22:35:16,370 - src.Train - INFO - epoch:81,	steps33/207,	loss:0.0015583172207698226
2023-03-24 22:35:20,176 - src.Train - INFO - epoch:81,	steps53/207,	loss:0.0006317720981314778
2023-03-24 22:35:24,004 - src.Train - INFO - epoch:81,	steps73/207,	loss:0.002426240826025605
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 ned was trying to expand his game collection. he bought γ games from a friend and bought δ more at a garage sale. if ε of the games did [UNK] work, how many good games did he end up with? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[30, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:35:27,572 - src.Train - INFO - epoch:81,	steps93/207,	loss:0.0010556442430242896
2023-03-24 22:35:31,433 - src.Train - INFO - epoch:81,	steps113/207,	loss:0.0025387355126440525
2023-03-24 22:35:35,224 - src.Train - INFO - epoch:81,	steps133/207,	loss:0.0009445600444450974
2023-03-24 22:35:38,947 - src.Train - INFO - epoch:81,	steps153/207,	loss:0.0019142745295539498
2023-03-24 22:35:42,472 - src.Train - INFO - epoch:81,	steps173/207,	loss:0.004016123712062836
2023-03-24 22:35:46,293 - src.Train - INFO - epoch:81,	steps193/207,	loss:0.0016230285400524735
2023-03-24 22:35:48,739 - src.Train - INFO - start evaluate...
2023-03-24 22:35:48,739 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:35:51,900 - src.Train - INFO - right: 874	total: 1022	M-tree codes acc: 0.8551859099804305
2023-03-24 22:35:51,901 - src.Train - INFO - save best model to ./output/model_save_name0/best_model
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:36:04,202 - src.Train - INFO - epoch:82,	steps6/207,	loss:0.003772604977712035
2023-03-24 22:36:07,895 - src.Train - INFO - epoch:82,	steps26/207,	loss:0.0014878024812787771
2023-03-24 22:36:11,501 - src.Train - INFO - epoch:82,	steps46/207,	loss:0.0021032618824392557
2023-03-24 22:36:15,187 - src.Train - INFO - epoch:82,	steps66/207,	loss:0.0036088295746594667
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 nina did a running drill to get in shape for soccer season. first, nina ran γ of a mile. then she ran δ of a mile and ε of a mile more. how many miles did nina run in total? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[29, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:36:19,059 - src.Train - INFO - epoch:82,	steps86/207,	loss:0.0021527165081351995
2023-03-24 22:36:22,688 - src.Train - INFO - epoch:82,	steps106/207,	loss:0.001454532379284501
2023-03-24 22:36:26,374 - src.Train - INFO - epoch:82,	steps126/207,	loss:0.0018639100017026067
2023-03-24 22:36:28,737 - src.Train - INFO - epoch:82,	steps146/207,	loss:0.002110517118126154
2023-03-24 22:36:31,086 - src.Train - INFO - epoch:82,	steps166/207,	loss:0.002295277314260602
2023-03-24 22:36:33,393 - src.Train - INFO - epoch:82,	steps186/207,	loss:0.003374480875208974
2023-03-24 22:36:35,704 - src.Train - INFO - epoch:82,	steps206/207,	loss:0.0039018159732222557
2023-03-24 22:36:35,749 - src.Train - INFO - start evaluate...
2023-03-24 22:36:35,749 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:36:37,650 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:36:44,229 - src.Train - INFO - epoch:83,	steps19/207,	loss:0.0012603705981746316
2023-03-24 22:36:46,497 - src.Train - INFO - epoch:83,	steps39/207,	loss:0.0014833195600658655
2023-03-24 22:36:48,800 - src.Train - INFO - epoch:83,	steps59/207,	loss:0.0016742902807891369
2023-03-24 22:36:51,381 - src.Train - INFO - epoch:83,	steps79/207,	loss:0.006175847724080086
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 last saturday, spencer walked all over town running [UNK]. first, he walked γ of a mile from his house to the library and δ of a mile from the library to the post office. then he walked ε of a mile from the post office back home. how many miles did spencer walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:36:53,780 - src.Train - INFO - epoch:83,	steps99/207,	loss:0.0013041526544839144
2023-03-24 22:36:56,412 - src.Train - INFO - epoch:83,	steps119/207,	loss:0.0014160231221467257
2023-03-24 22:36:58,808 - src.Train - INFO - epoch:83,	steps139/207,	loss:0.0011486653238534927
2023-03-24 22:37:01,411 - src.Train - INFO - epoch:83,	steps159/207,	loss:0.001663633855059743
2023-03-24 22:37:03,836 - src.Train - INFO - epoch:83,	steps179/207,	loss:0.0037699579261243343
2023-03-24 22:37:06,295 - src.Train - INFO - epoch:83,	steps199/207,	loss:0.0012561860494315624
2023-03-24 22:37:07,222 - src.Train - INFO - start evaluate...
2023-03-24 22:37:07,223 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:37:09,298 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:37:20,035 - src.Train - INFO - epoch:84,	steps12/207,	loss:0.0035763008054345846
2023-03-24 22:37:22,442 - src.Train - INFO - epoch:84,	steps32/207,	loss:0.0012862503062933683
2023-03-24 22:37:24,981 - src.Train - INFO - epoch:84,	steps52/207,	loss:0.0010139496298506856
2023-03-24 22:37:27,303 - src.Train - INFO - epoch:84,	steps72/207,	loss:0.0026842972729355097
torch.Size([20, 56])
torch.Size([20, 56])
torch.Size([20, 56])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 mika had γ [UNK]. she bought δ [UNK] from a store in the mall and got ε [UNK] for her birthday. then mika gave ζ of the [UNK] to her sister and used η to decorate a greeting card. how many [UNK] does mika have left? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[11, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:37:29,735 - src.Train - INFO - epoch:84,	steps92/207,	loss:0.0014144490705803037
2023-03-24 22:37:32,287 - src.Train - INFO - epoch:84,	steps112/207,	loss:0.003114013932645321
2023-03-24 22:37:34,737 - src.Train - INFO - epoch:84,	steps132/207,	loss:0.001559823751449585
2023-03-24 22:37:37,262 - src.Train - INFO - epoch:84,	steps152/207,	loss:0.0018161903135478497
2023-03-24 22:37:39,732 - src.Train - INFO - epoch:84,	steps172/207,	loss:0.0008453515474684536
2023-03-24 22:37:42,275 - src.Train - INFO - epoch:84,	steps192/207,	loss:0.0027417780365794897
2023-03-24 22:37:44,129 - src.Train - INFO - start evaluate...
2023-03-24 22:37:44,130 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:37:46,103 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:37:51,584 - src.Train - INFO - epoch:85,	steps5/207,	loss:0.0012262602103874087
2023-03-24 22:37:54,035 - src.Train - INFO - epoch:85,	steps25/207,	loss:0.0028780843131244183
2023-03-24 22:37:56,646 - src.Train - INFO - epoch:85,	steps45/207,	loss:0.001058785361237824
2023-03-24 22:37:59,048 - src.Train - INFO - epoch:85,	steps65/207,	loss:0.003620343515649438
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jonathan wants to buy a dictionary that costs $ γ, a dinosaur book that costs $ δ, and a children [UNK] [UNK] that costs $ ε. he has saved $ ζ from his allowance. how much more money does jonathan need to buy all three books? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:38:01,663 - src.Train - INFO - epoch:85,	steps85/207,	loss:0.0011886825086548924
2023-03-24 22:38:03,942 - src.Train - INFO - epoch:85,	steps105/207,	loss:0.0027256959583610296
2023-03-24 22:38:06,432 - src.Train - INFO - epoch:85,	steps125/207,	loss:0.0007235488155856729
2023-03-24 22:38:08,942 - src.Train - INFO - epoch:85,	steps145/207,	loss:0.0009028194472193718
2023-03-24 22:38:11,273 - src.Train - INFO - epoch:85,	steps165/207,	loss:0.0010232161730527878
2023-03-24 22:38:13,828 - src.Train - INFO - epoch:85,	steps185/207,	loss:0.0004260942805558443
2023-03-24 22:38:16,289 - src.Train - INFO - epoch:85,	steps205/207,	loss:0.0019771757069975138
2023-03-24 22:38:16,511 - src.Train - INFO - start evaluate...
2023-03-24 22:38:16,511 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:38:18,673 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:38:25,921 - src.Train - INFO - epoch:86,	steps18/207,	loss:0.0014440530212596059
2023-03-24 22:38:28,435 - src.Train - INFO - epoch:86,	steps38/207,	loss:0.006058243103325367
2023-03-24 22:38:30,790 - src.Train - INFO - epoch:86,	steps58/207,	loss:0.001860728021711111
2023-03-24 22:38:33,287 - src.Train - INFO - epoch:86,	steps78/207,	loss:0.002666223794221878
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 62])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jason had to submit γ animation projects as per his [UNK] bus in the final [UNK]. he scored δ, ε, ζ, and η points out of θ in ι projects. what should be his score in the fifth project so that the average of his projects is at least κ? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
====================
label:[8, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:38:35,680 - src.Train - INFO - epoch:86,	steps98/207,	loss:0.0035185145679861307
2023-03-24 22:38:38,157 - src.Train - INFO - epoch:86,	steps118/207,	loss:0.0011419615475460887
2023-03-24 22:38:40,664 - src.Train - INFO - epoch:86,	steps138/207,	loss:0.0014062619302421808
2023-03-24 22:38:43,234 - src.Train - INFO - epoch:86,	steps158/207,	loss:0.001168660819530487
2023-03-24 22:38:45,726 - src.Train - INFO - epoch:86,	steps178/207,	loss:0.0012030389625579119
2023-03-24 22:38:48,244 - src.Train - INFO - epoch:86,	steps198/207,	loss:0.0022233258932828903
2023-03-24 22:38:49,281 - src.Train - INFO - start evaluate...
2023-03-24 22:38:49,281 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:38:51,306 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:38:59,465 - src.Train - INFO - epoch:87,	steps11/207,	loss:0.0021576196886599064
2023-03-24 22:39:01,836 - src.Train - INFO - epoch:87,	steps31/207,	loss:0.0008496943628415465
2023-03-24 22:39:04,356 - src.Train - INFO - epoch:87,	steps51/207,	loss:0.0011113816872239113
2023-03-24 22:39:06,806 - src.Train - INFO - epoch:87,	steps71/207,	loss:0.0006846347823739052
torch.Size([20, 56])
torch.Size([20, 56])
torch.Size([20, 56])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] [UNK] [UNK] company purchased pieces of marble from a quarry. the weights of the pieces they purchased were γ of a ton, δ of a ton, and ε of a ton. how many tons of marble did [UNK] [UNK] [UNK] company purchase in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[35, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:39:09,282 - src.Train - INFO - epoch:87,	steps91/207,	loss:0.0010386520298197865
2023-03-24 22:39:11,847 - src.Train - INFO - epoch:87,	steps111/207,	loss:0.002183443633839488
2023-03-24 22:39:14,197 - src.Train - INFO - epoch:87,	steps131/207,	loss:0.0027900475542992353
2023-03-24 22:39:16,757 - src.Train - INFO - epoch:87,	steps151/207,	loss:0.003425400471314788
2023-03-24 22:39:19,265 - src.Train - INFO - epoch:87,	steps171/207,	loss:0.0017479185480624437
2023-03-24 22:39:21,761 - src.Train - INFO - epoch:87,	steps191/207,	loss:0.0009405927849002182
2023-03-24 22:39:23,672 - src.Train - INFO - start evaluate...
2023-03-24 22:39:23,673 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:39:25,662 - src.Train - INFO - right: 872	total: 1022	M-tree codes acc: 0.8532289628180039
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:39:31,789 - src.Train - INFO - epoch:88,	steps4/207,	loss:0.0038794483989477158
2023-03-24 22:39:34,194 - src.Train - INFO - epoch:88,	steps24/207,	loss:0.0024479730054736137
2023-03-24 22:39:36,697 - src.Train - INFO - epoch:88,	steps44/207,	loss:0.003362212097272277
2023-03-24 22:39:39,102 - src.Train - INFO - epoch:88,	steps64/207,	loss:0.0010571471648290753
2023-03-24 22:39:41,737 - src.Train - INFO - epoch:88,	steps84/207,	loss:0.00213373894803226
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 when jake had γ cat, he needed to serve δ can of cat food each day. now that jake has adopted a second cat, he needs to serve a total of ε can each day. how much extra food is needed to feed the second cat? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[14, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:39:44,090 - src.Train - INFO - epoch:88,	steps104/207,	loss:0.001164811896160245
2023-03-24 22:39:46,558 - src.Train - INFO - epoch:88,	steps124/207,	loss:0.0012394828954711556
2023-03-24 22:39:49,052 - src.Train - INFO - epoch:88,	steps144/207,	loss:0.001194106531329453
2023-03-24 22:39:51,569 - src.Train - INFO - epoch:88,	steps164/207,	loss:0.0019516227766871452
2023-03-24 22:39:54,090 - src.Train - INFO - epoch:88,	steps184/207,	loss:0.0012492452515289187
2023-03-24 22:39:56,426 - src.Train - INFO - epoch:88,	steps204/207,	loss:0.0008670101524330676
2023-03-24 22:39:56,827 - src.Train - INFO - start evaluate...
2023-03-24 22:39:56,827 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:39:58,835 - src.Train - INFO - right: 871	total: 1022	M-tree codes acc: 0.8522504892367906
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:40:05,877 - src.Train - INFO - epoch:89,	steps17/207,	loss:0.0009367463062517345
2023-03-24 22:40:08,290 - src.Train - INFO - epoch:89,	steps37/207,	loss:0.0027434194926172495
2023-03-24 22:40:10,892 - src.Train - INFO - epoch:89,	steps57/207,	loss:0.000505877542309463
2023-03-24 22:40:13,171 - src.Train - INFO - epoch:89,	steps77/207,	loss:0.0020323898643255234
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 henry was helping the cafeteria workers pick up lunch [UNK], but he could only carry γ [UNK] at a time. if he had to pick up δ [UNK] from one ta [UNK] and ε [UNK] from another, how many trips will he make? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:40:15,767 - src.Train - INFO - epoch:89,	steps97/207,	loss:0.0019715495873242617
2023-03-24 22:40:18,187 - src.Train - INFO - epoch:89,	steps117/207,	loss:0.000959716213401407
2023-03-24 22:40:20,637 - src.Train - INFO - epoch:89,	steps137/207,	loss:0.0018401405541226268
2023-03-24 22:40:23,228 - src.Train - INFO - epoch:89,	steps157/207,	loss:0.001648845849558711
2023-03-24 22:40:25,632 - src.Train - INFO - epoch:89,	steps177/207,	loss:0.002510701771825552
2023-03-24 22:40:28,183 - src.Train - INFO - epoch:89,	steps197/207,	loss:0.002169269137084484
2023-03-24 22:40:29,302 - src.Train - INFO - start evaluate...
2023-03-24 22:40:29,302 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:40:31,247 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:40:38,868 - src.Train - INFO - epoch:90,	steps10/207,	loss:0.0016309177735820413
2023-03-24 22:40:41,380 - src.Train - INFO - epoch:90,	steps30/207,	loss:0.00110198138281703
2023-03-24 22:40:43,937 - src.Train - INFO - epoch:90,	steps50/207,	loss:0.0013787103816866875
2023-03-24 22:40:46,303 - src.Train - INFO - epoch:90,	steps70/207,	loss:0.0010940918000414968
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jerry is at the library helping put away books. there are γ book to put away total but a librarian takes δ of them and leaves jerry with the rest. if he can fit ε books on a shelf, how many shelves will he need? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[40, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:40:48,784 - src.Train - INFO - epoch:90,	steps90/207,	loss:0.000955432013142854
2023-03-24 22:40:51,183 - src.Train - INFO - epoch:90,	steps110/207,	loss:0.0019649947062134743
2023-03-24 22:40:53,689 - src.Train - INFO - epoch:90,	steps130/207,	loss:0.0017669601365923882
2023-03-24 22:40:56,215 - src.Train - INFO - epoch:90,	steps150/207,	loss:0.002096927724778652
2023-03-24 22:40:58,666 - src.Train - INFO - epoch:90,	steps170/207,	loss:0.004903402179479599
2023-03-24 22:41:01,200 - src.Train - INFO - epoch:90,	steps190/207,	loss:0.0017145763849839568
2023-03-24 22:41:03,229 - src.Train - INFO - start evaluate...
2023-03-24 22:41:03,230 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:41:05,345 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:41:10,112 - src.Train - INFO - epoch:91,	steps3/207,	loss:0.003618793096393347
2023-03-24 22:41:12,797 - src.Train - INFO - epoch:91,	steps23/207,	loss:0.0013444619253277779
2023-03-24 22:41:15,201 - src.Train - INFO - epoch:91,	steps43/207,	loss:0.0023498479276895523
2023-03-24 22:41:17,817 - src.Train - INFO - epoch:91,	steps63/207,	loss:0.0020201022271066904
2023-03-24 22:41:20,293 - src.Train - INFO - epoch:91,	steps83/207,	loss:0.0008659718441776931
torch.Size([20, 81])
torch.Size([20, 81])
torch.Size([20, 81])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 on her vacation last summer, [UNK] walked all over new york city to buy [UNK]. first, she walked γ of a mile from her hotel to a [UNK] shop. then she walked δ of a mile from the [UNK] shop to a t - shirt shop and ε of a mile from the t - shirt shop back to the hotel. how many miles did [UNK] walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[40, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:41:22,868 - src.Train - INFO - epoch:91,	steps103/207,	loss:0.000803752220235765
2023-03-24 22:41:25,268 - src.Train - INFO - epoch:91,	steps123/207,	loss:0.002454065252095461
2023-03-24 22:41:27,647 - src.Train - INFO - epoch:91,	steps143/207,	loss:0.0031878435984253883
2023-03-24 22:41:30,147 - src.Train - INFO - epoch:91,	steps163/207,	loss:0.0012784338323399425
2023-03-24 22:41:32,572 - src.Train - INFO - epoch:91,	steps183/207,	loss:0.0023710201494395733
2023-03-24 22:41:35,133 - src.Train - INFO - epoch:91,	steps203/207,	loss:0.002422480145469308
2023-03-24 22:41:35,488 - src.Train - INFO - start evaluate...
2023-03-24 22:41:35,488 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:41:37,616 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:41:44,126 - src.Train - INFO - epoch:92,	steps16/207,	loss:0.001006556791253388
2023-03-24 22:41:46,578 - src.Train - INFO - epoch:92,	steps36/207,	loss:0.0018143139313906431
2023-03-24 22:41:49,119 - src.Train - INFO - epoch:92,	steps56/207,	loss:0.002310436684638262
2023-03-24 22:41:51,530 - src.Train - INFO - epoch:92,	steps76/207,	loss:0.0025223251432180405
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 edward bought γ tickets at the state fair. he spent δ tickets at the'[UNK] a clown'booth and decided to use the rest on rides. if each ride cost ε tickets, how many rides could he go on? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[38, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:41:53,916 - src.Train - INFO - epoch:92,	steps96/207,	loss:0.0018823964055627584
2023-03-24 22:41:56,565 - src.Train - INFO - epoch:92,	steps116/207,	loss:0.002693625632673502
2023-03-24 22:41:58,931 - src.Train - INFO - epoch:92,	steps136/207,	loss:0.00224291137419641
2023-03-24 22:42:01,389 - src.Train - INFO - epoch:92,	steps156/207,	loss:0.001962909009307623
2023-03-24 22:42:03,830 - src.Train - INFO - epoch:92,	steps176/207,	loss:0.004625752568244934
2023-03-24 22:42:06,250 - src.Train - INFO - epoch:92,	steps196/207,	loss:0.002713909838348627
2023-03-24 22:42:07,477 - src.Train - INFO - start evaluate...
2023-03-24 22:42:07,478 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:42:09,395 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:42:18,244 - src.Train - INFO - epoch:93,	steps9/207,	loss:0.0031462779734283686
2023-03-24 22:42:20,520 - src.Train - INFO - epoch:93,	steps29/207,	loss:0.0009546297951601446
2023-03-24 22:42:22,720 - src.Train - INFO - epoch:93,	steps49/207,	loss:0.00415061553940177
2023-03-24 22:42:25,043 - src.Train - INFO - epoch:93,	steps69/207,	loss:0.0013293506344780326
2023-03-24 22:42:27,368 - src.Train - INFO - epoch:93,	steps89/207,	loss:0.003061817027628422
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 the first agency charges γ dollars per day and δ dollars per mile. the second agency charges ε dollars per day and ζ dollars per mile. how many miles would you have to drive before the first agency is less expensive than the second? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[22, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:42:29,747 - src.Train - INFO - epoch:93,	steps109/207,	loss:0.0010539634386077523
2023-03-24 22:42:32,074 - src.Train - INFO - epoch:93,	steps129/207,	loss:0.0009487707866355777
2023-03-24 22:42:34,335 - src.Train - INFO - epoch:93,	steps149/207,	loss:0.0025272651109844446
2023-03-24 22:42:36,641 - src.Train - INFO - epoch:93,	steps169/207,	loss:0.004881392698734999
2023-03-24 22:42:38,815 - src.Train - INFO - epoch:93,	steps189/207,	loss:0.0017383150989189744
2023-03-24 22:42:40,843 - src.Train - INFO - start evaluate...
2023-03-24 22:42:40,843 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:42:42,834 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:42:48,240 - src.Train - INFO - epoch:94,	steps2/207,	loss:0.0021398221142590046
2023-03-24 22:42:50,459 - src.Train - INFO - epoch:94,	steps22/207,	loss:0.001132322009652853
2023-03-24 22:42:52,665 - src.Train - INFO - epoch:94,	steps42/207,	loss:0.0010696726385504007
2023-03-24 22:42:54,943 - src.Train - INFO - epoch:94,	steps62/207,	loss:0.0011158176930621266
2023-03-24 22:42:57,212 - src.Train - INFO - epoch:94,	steps82/207,	loss:0.0008748290711082518
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 61])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 when a [UNK] [UNK] is turned on, it can fill a tub in γ minutes. when the drain is open, a full [UNK] can empty in δ minutes. how many minutes would it take for the [UNK] to fill if the water were turned on with the drain left open? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:42:59,563 - src.Train - INFO - epoch:94,	steps102/207,	loss:0.0026580290868878365
2023-03-24 22:43:01,915 - src.Train - INFO - epoch:94,	steps122/207,	loss:0.0010818045120686293
2023-03-24 22:43:04,294 - src.Train - INFO - epoch:94,	steps142/207,	loss:0.002789607737213373
2023-03-24 22:43:06,611 - src.Train - INFO - epoch:94,	steps162/207,	loss:0.001277743373066187
2023-03-24 22:43:08,928 - src.Train - INFO - epoch:94,	steps182/207,	loss:0.0014224685728549957
2023-03-24 22:43:11,198 - src.Train - INFO - epoch:94,	steps202/207,	loss:0.0013015916338190436
2023-03-24 22:43:11,690 - src.Train - INFO - start evaluate...
2023-03-24 22:43:11,690 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:43:14,646 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:43:22,049 - src.Train - INFO - epoch:95,	steps15/207,	loss:0.00343554955907166
2023-03-24 22:43:25,948 - src.Train - INFO - epoch:95,	steps35/207,	loss:0.001487751491367817
2023-03-24 22:43:29,628 - src.Train - INFO - epoch:95,	steps55/207,	loss:0.0009107168298214674
2023-03-24 22:43:33,254 - src.Train - INFO - epoch:95,	steps75/207,	loss:0.002416359493508935
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 hoping to be named [UNK] of the month, rosa called the names from γ pages of the phone book last week. this week, she called the people listed on another δ pages of the same phone book. how many pages worth of people did rosa call in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[18, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:43:36,974 - src.Train - INFO - epoch:95,	steps95/207,	loss:0.0016727213514968753
2023-03-24 22:43:40,873 - src.Train - INFO - epoch:95,	steps115/207,	loss:0.005366393364965916
2023-03-24 22:43:44,566 - src.Train - INFO - epoch:95,	steps135/207,	loss:0.0022751016076654196
2023-03-24 22:43:48,282 - src.Train - INFO - epoch:95,	steps155/207,	loss:0.001809848821721971
2023-03-24 22:43:52,155 - src.Train - INFO - epoch:95,	steps175/207,	loss:0.002681475831195712
2023-03-24 22:43:55,858 - src.Train - INFO - epoch:95,	steps195/207,	loss:0.002257262822240591
2023-03-24 22:43:57,822 - src.Train - INFO - start evaluate...
2023-03-24 22:43:57,822 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:44:01,021 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:44:07,835 - src.Train - INFO - epoch:96,	steps8/207,	loss:0.0010140954982489347
2023-03-24 22:44:11,454 - src.Train - INFO - epoch:96,	steps28/207,	loss:0.0018754159100353718
2023-03-24 22:44:15,303 - src.Train - INFO - epoch:96,	steps48/207,	loss:0.0009673117310740054
2023-03-24 22:44:19,083 - src.Train - INFO - epoch:96,	steps68/207,	loss:0.0030283541418612003
2023-03-24 22:44:22,803 - src.Train - INFO - epoch:96,	steps88/207,	loss:0.0011823896784335375
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 there are γ maple trees and δ orange trees currently in the park. park workers will plant maple trees today. when the workers are finished there will be ε maple trees in the park. how many maple trees did the workers plant today? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[6, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:44:26,463 - src.Train - INFO - epoch:96,	steps108/207,	loss:0.002008743118494749
2023-03-24 22:44:30,382 - src.Train - INFO - epoch:96,	steps128/207,	loss:0.0019653989002108574
2023-03-24 22:44:34,112 - src.Train - INFO - epoch:96,	steps148/207,	loss:0.0007568490109406412
2023-03-24 22:44:37,706 - src.Train - INFO - epoch:96,	steps168/207,	loss:0.002296196296811104
2023-03-24 22:44:41,578 - src.Train - INFO - epoch:96,	steps188/207,	loss:0.00113495287951082
2023-03-24 22:44:44,983 - src.Train - INFO - start evaluate...
2023-03-24 22:44:44,983 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:44:48,261 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:44:52,988 - src.Train - INFO - epoch:97,	steps1/207,	loss:0.0029251528903841972
2023-03-24 22:44:55,306 - src.Train - INFO - epoch:97,	steps21/207,	loss:0.001620523282326758
2023-03-24 22:44:57,669 - src.Train - INFO - epoch:97,	steps41/207,	loss:0.0008987648179754615
2023-03-24 22:44:59,821 - src.Train - INFO - epoch:97,	steps61/207,	loss:0.002011011354625225
2023-03-24 22:45:02,038 - src.Train - INFO - epoch:97,	steps81/207,	loss:0.0017118448158726096
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 57])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 jonathan wants to buy a dictionary that costs $ γ, a dinosaur book that costs $ δ, and a children [UNK] [UNK] that costs $ ε. he has saved $ ζ from his allowance. how much more money does jonathan need to buy all three books? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[37, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:45:04,423 - src.Train - INFO - epoch:97,	steps101/207,	loss:0.002638918114826083
2023-03-24 22:45:06,658 - src.Train - INFO - epoch:97,	steps121/207,	loss:0.0028322581201791763
2023-03-24 22:45:09,010 - src.Train - INFO - epoch:97,	steps141/207,	loss:0.002913801232352853
2023-03-24 22:45:11,331 - src.Train - INFO - epoch:97,	steps161/207,	loss:0.0036745574325323105
2023-03-24 22:45:13,648 - src.Train - INFO - epoch:97,	steps181/207,	loss:0.0008125895983539522
2023-03-24 22:45:15,955 - src.Train - INFO - epoch:97,	steps201/207,	loss:0.0036563242319971323
2023-03-24 22:45:16,506 - src.Train - INFO - start evaluate...
2023-03-24 22:45:16,506 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:45:18,540 - src.Train - INFO - right: 874	total: 1022	M-tree codes acc: 0.8551859099804305
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:45:24,727 - src.Train - INFO - epoch:98,	steps14/207,	loss:0.001486554741859436
2023-03-24 22:45:27,275 - src.Train - INFO - epoch:98,	steps34/207,	loss:0.0006357826059684157
2023-03-24 22:45:29,690 - src.Train - INFO - epoch:98,	steps54/207,	loss:0.00189449661411345
2023-03-24 22:45:32,256 - src.Train - INFO - epoch:98,	steps74/207,	loss:0.0011333851143717766
2023-03-24 22:45:34,692 - src.Train - INFO - epoch:98,	steps94/207,	loss:0.0016557093476876616
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 51])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] started his own lawn [UNK] business. in the spring he made γ dollars [UNK] [UNK] and in the summer he made δ dollars. if he had to spend ε dollars buying supplies, how much money did he end up with? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[27, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:45:37,088 - src.Train - INFO - epoch:98,	steps114/207,	loss:0.0032378595788031816
2023-03-24 22:45:39,746 - src.Train - INFO - epoch:98,	steps134/207,	loss:0.0022158033680170774
2023-03-24 22:45:42,145 - src.Train - INFO - epoch:98,	steps154/207,	loss:0.0024235746823251247
2023-03-24 22:45:44,695 - src.Train - INFO - epoch:98,	steps174/207,	loss:0.0018114954000338912
2023-03-24 22:45:47,059 - src.Train - INFO - epoch:98,	steps194/207,	loss:0.0016233499627560377
2023-03-24 22:45:48,640 - src.Train - INFO - start evaluate...
2023-03-24 22:45:48,640 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:45:50,643 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:45:57,885 - src.Train - INFO - epoch:99,	steps7/207,	loss:0.0029992542695254087
2023-03-24 22:46:00,286 - src.Train - INFO - epoch:99,	steps27/207,	loss:0.0038671186193823814
2023-03-24 22:46:02,667 - src.Train - INFO - epoch:99,	steps47/207,	loss:0.0014748662943020463
2023-03-24 22:46:05,346 - src.Train - INFO - epoch:99,	steps67/207,	loss:0.0016935747116804123
2023-03-24 22:46:07,689 - src.Train - INFO - epoch:99,	steps87/207,	loss:0.0015340959653258324
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 suppose you are starting an office cleaning service. you have spent γ dollars on equipment. to clean an office, you use δ dollars worth of supplies you purchased. you charge ε dollars per office. how many offices must you clean to break even? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[16, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:46:10,160 - src.Train - INFO - epoch:99,	steps107/207,	loss:0.0017604698659852147
2023-03-24 22:46:12,586 - src.Train - INFO - epoch:99,	steps127/207,	loss:0.0014197356067597866
2023-03-24 22:46:15,108 - src.Train - INFO - epoch:99,	steps147/207,	loss:0.0006512582767754793
2023-03-24 22:46:17,578 - src.Train - INFO - epoch:99,	steps167/207,	loss:0.0021840508561581373
2023-03-24 22:46:20,047 - src.Train - INFO - epoch:99,	steps187/207,	loss:0.0006313406047411263
2023-03-24 22:46:22,572 - src.Train - INFO - epoch:99,	steps207/207,	loss:0.013164201751351357
2023-03-24 22:46:22,572 - src.Train - INFO - start evaluate...
2023-03-24 22:46:22,572 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:46:24,505 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:46:32,100 - src.Train - INFO - epoch:100,	steps20/207,	loss:0.0015775851206853986
2023-03-24 22:46:34,519 - src.Train - INFO - epoch:100,	steps40/207,	loss:0.002159883501008153
2023-03-24 22:46:36,966 - src.Train - INFO - epoch:100,	steps60/207,	loss:0.002360817976295948
2023-03-24 22:46:39,571 - src.Train - INFO - epoch:100,	steps80/207,	loss:0.0009405540768057108
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 67])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 last saturday, spencer walked all over town running [UNK]. first, he walked γ of a mile from his house to the library and δ of a mile from the library to the post office. then he walked ε of a mile from the post office back home. how many miles did spencer walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:46:42,080 - src.Train - INFO - epoch:100,	steps100/207,	loss:0.0034921730402857065
2023-03-24 22:46:44,673 - src.Train - INFO - epoch:100,	steps120/207,	loss:0.0006276362109929323
2023-03-24 22:46:47,155 - src.Train - INFO - epoch:100,	steps140/207,	loss:0.0009853936498984694
2023-03-24 22:46:49,715 - src.Train - INFO - epoch:100,	steps160/207,	loss:0.0018413421930745244
2023-03-24 22:46:52,034 - src.Train - INFO - epoch:100,	steps180/207,	loss:0.0009788458701223135
2023-03-24 22:46:54,411 - src.Train - INFO - epoch:100,	steps200/207,	loss:0.002174931578338146
2023-03-24 22:46:55,170 - src.Train - INFO - start evaluate...
2023-03-24 22:46:55,170 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:46:57,313 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:47:04,100 - src.Train - INFO - epoch:101,	steps13/207,	loss:0.0010705357417464256
2023-03-24 22:47:06,683 - src.Train - INFO - epoch:101,	steps33/207,	loss:0.001192366937175393
2023-03-24 22:47:08,980 - src.Train - INFO - epoch:101,	steps53/207,	loss:0.0020869201980531216
2023-03-24 22:47:11,451 - src.Train - INFO - epoch:101,	steps73/207,	loss:0.0011934508802369237
2023-03-24 22:47:13,930 - src.Train - INFO - epoch:101,	steps93/207,	loss:0.003669201396405697
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 chris has been saving his allowance to buy a new pair of soccer [UNK] and a ball. his grandmother gave chris $ γ for his birthday. his aunt and uncle gave chris $ δ and his parents gave him $ ε. now chris had $ ζ. how much money did chris have before his birthday? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[27, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:47:16,257 - src.Train - INFO - epoch:101,	steps113/207,	loss:0.006131458096206188
2023-03-24 22:47:18,779 - src.Train - INFO - epoch:101,	steps133/207,	loss:0.0033152287360280752
2023-03-24 22:47:21,205 - src.Train - INFO - epoch:101,	steps153/207,	loss:0.0030196646694093943
2023-03-24 22:47:23,740 - src.Train - INFO - epoch:101,	steps173/207,	loss:0.0023047563154250383
2023-03-24 22:47:26,201 - src.Train - INFO - epoch:101,	steps193/207,	loss:0.002648202935233712
2023-03-24 22:47:27,937 - src.Train - INFO - start evaluate...
2023-03-24 22:47:27,937 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:47:29,986 - src.Train - INFO - right: 871	total: 1022	M-tree codes acc: 0.8522504892367906
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:47:37,129 - src.Train - INFO - epoch:102,	steps6/207,	loss:0.0015114203561097383
2023-03-24 22:47:39,744 - src.Train - INFO - epoch:102,	steps26/207,	loss:0.001489506452344358
2023-03-24 22:47:42,123 - src.Train - INFO - epoch:102,	steps46/207,	loss:0.0010439896723255515
2023-03-24 22:47:44,700 - src.Train - INFO - epoch:102,	steps66/207,	loss:0.0007113215979188681
2023-03-24 22:47:47,119 - src.Train - INFO - epoch:102,	steps86/207,	loss:0.0023021399974823
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 mike is at the library helping put away books. there are γ book to put away total but a librarian takes δ of them and leaves mike with the rest. if he can fit ε books on a shelf, how many shelves will he need? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[16, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:47:49,491 - src.Train - INFO - epoch:102,	steps106/207,	loss:0.002342963358387351
2023-03-24 22:47:52,049 - src.Train - INFO - epoch:102,	steps126/207,	loss:0.001285399543121457
2023-03-24 22:47:54,456 - src.Train - INFO - epoch:102,	steps146/207,	loss:0.0036770182196050882
2023-03-24 22:47:56,963 - src.Train - INFO - epoch:102,	steps166/207,	loss:0.0013306996552273631
2023-03-24 22:47:59,302 - src.Train - INFO - epoch:102,	steps186/207,	loss:0.0010551137384027243
2023-03-24 22:48:01,865 - src.Train - INFO - epoch:102,	steps206/207,	loss:0.004105523694306612
2023-03-24 22:48:01,923 - src.Train - INFO - start evaluate...
2023-03-24 22:48:01,923 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:48:03,928 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:48:10,830 - src.Train - INFO - epoch:103,	steps19/207,	loss:0.0018232942093163729
2023-03-24 22:48:13,248 - src.Train - INFO - epoch:103,	steps39/207,	loss:0.0013923200313001871
2023-03-24 22:48:15,795 - src.Train - INFO - epoch:103,	steps59/207,	loss:0.0006379471742548048
2023-03-24 22:48:18,315 - src.Train - INFO - epoch:103,	steps79/207,	loss:0.004133112728595734
2023-03-24 22:48:20,839 - src.Train - INFO - epoch:103,	steps99/207,	loss:0.002371947979554534
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 lexie [UNK] younger brother helped pick up all the paper clips in lexie [UNK] room. he was a [UNK] to collect γ paper clips. if he wants to distribute the paper clips in δ boxes, how many paper clips will each box contain? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:48:23,174 - src.Train - INFO - epoch:103,	steps119/207,	loss:0.0009934930130839348
2023-03-24 22:48:25,823 - src.Train - INFO - epoch:103,	steps139/207,	loss:0.002682541962713003
2023-03-24 22:48:28,162 - src.Train - INFO - epoch:103,	steps159/207,	loss:0.005764112342149019
2023-03-24 22:48:30,717 - src.Train - INFO - epoch:103,	steps179/207,	loss:0.003702035639435053
2023-03-24 22:48:33,180 - src.Train - INFO - epoch:103,	steps199/207,	loss:0.0021111888345330954
2023-03-24 22:48:34,108 - src.Train - INFO - start evaluate...
2023-03-24 22:48:34,108 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:48:36,045 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:48:42,675 - src.Train - INFO - epoch:104,	steps12/207,	loss:0.002490427577868104
2023-03-24 22:48:45,255 - src.Train - INFO - epoch:104,	steps32/207,	loss:0.002678891643881798
2023-03-24 22:48:47,698 - src.Train - INFO - epoch:104,	steps52/207,	loss:0.0017448775470256805
2023-03-24 22:48:50,057 - src.Train - INFO - epoch:104,	steps72/207,	loss:0.0019036770099774003
2023-03-24 22:48:52,713 - src.Train - INFO - epoch:104,	steps92/207,	loss:0.001822104793973267
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 grace has γ [UNK] in her pocket. she has δ red ones, ε green ones, and ζ blue ones. what is the minimum number of [UNK] she must take out of her pocket to ensure that she has one of each color? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:48:55,099 - src.Train - INFO - epoch:104,	steps112/207,	loss:0.002109692431986332
2023-03-24 22:48:57,794 - src.Train - INFO - epoch:104,	steps132/207,	loss:0.0025545817334204912
2023-03-24 22:49:00,138 - src.Train - INFO - epoch:104,	steps152/207,	loss:0.0008437827927991748
2023-03-24 22:49:02,658 - src.Train - INFO - epoch:104,	steps172/207,	loss:0.0009573745774105191
2023-03-24 22:49:05,146 - src.Train - INFO - epoch:104,	steps192/207,	loss:0.0014154018135741353
2023-03-24 22:49:06,962 - src.Train - INFO - start evaluate...
2023-03-24 22:49:06,962 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:49:09,032 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:49:14,287 - src.Train - INFO - epoch:105,	steps5/207,	loss:0.001882201642729342
2023-03-24 22:49:16,820 - src.Train - INFO - epoch:105,	steps25/207,	loss:0.004110833629965782
2023-03-24 22:49:19,288 - src.Train - INFO - epoch:105,	steps45/207,	loss:0.0013581088278442621
2023-03-24 22:49:21,832 - src.Train - INFO - epoch:105,	steps65/207,	loss:0.0013205434661358595
2023-03-24 22:49:24,273 - src.Train - INFO - epoch:105,	steps85/207,	loss:0.0013663402060046792
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 63])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 wild and crazy productions wants to purchase a new cd producing machine. it [UNK] cost is γ dollars. if their la [UNK] and other unit costs are δ dollars per cd and they can sell the cd for ε dollars each, how many must they manufacture before they pay for their new machine? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:49:26,845 - src.Train - INFO - epoch:105,	steps105/207,	loss:0.0014113530050963163
2023-03-24 22:49:29,310 - src.Train - INFO - epoch:105,	steps125/207,	loss:0.0021967554930597544
2023-03-24 22:49:31,865 - src.Train - INFO - epoch:105,	steps145/207,	loss:0.0009145053336396813
2023-03-24 22:49:34,263 - src.Train - INFO - epoch:105,	steps165/207,	loss:0.005817572120577097
2023-03-24 22:49:36,779 - src.Train - INFO - epoch:105,	steps185/207,	loss:0.0019449591636657715
2023-03-24 22:49:39,131 - src.Train - INFO - epoch:105,	steps205/207,	loss:0.0022040673065930605
2023-03-24 22:49:39,261 - src.Train - INFO - start evaluate...
2023-03-24 22:49:39,262 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:49:41,250 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:49:47,864 - src.Train - INFO - epoch:106,	steps18/207,	loss:0.0015071373200044036
2023-03-24 22:49:50,281 - src.Train - INFO - epoch:106,	steps38/207,	loss:0.0013678772374987602
2023-03-24 22:49:52,741 - src.Train - INFO - epoch:106,	steps58/207,	loss:0.001562935416586697
2023-03-24 22:49:55,463 - src.Train - INFO - epoch:106,	steps78/207,	loss:0.0011592247756198049
2023-03-24 22:49:57,940 - src.Train - INFO - epoch:106,	steps98/207,	loss:0.002287487266585231
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 55])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 at the beach, [UNK] and her sister both built [UNK] and then measured their heights. [UNK] [UNK] [UNK] was γ of a foot tall and her sister [UNK] was δ of a foot tall. how much taller was [UNK] [UNK] [UNK] than her sister [UNK]? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[35, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:50:00,417 - src.Train - INFO - epoch:106,	steps118/207,	loss:0.000662020465824753
2023-03-24 22:50:02,804 - src.Train - INFO - epoch:106,	steps138/207,	loss:0.0014118803665041924
2023-03-24 22:50:05,160 - src.Train - INFO - epoch:106,	steps158/207,	loss:0.000384944723919034
2023-03-24 22:50:07,591 - src.Train - INFO - epoch:106,	steps178/207,	loss:0.0014510008040815592
2023-03-24 22:50:10,134 - src.Train - INFO - epoch:106,	steps198/207,	loss:0.0013291587820276618
2023-03-24 22:50:11,203 - src.Train - INFO - start evaluate...
2023-03-24 22:50:11,203 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:50:13,364 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:50:19,747 - src.Train - INFO - epoch:107,	steps11/207,	loss:0.006258279085159302
2023-03-24 22:50:22,135 - src.Train - INFO - epoch:107,	steps31/207,	loss:0.003559951903298497
2023-03-24 22:50:24,695 - src.Train - INFO - epoch:107,	steps51/207,	loss:0.0029048845171928406
2023-03-24 22:50:27,159 - src.Train - INFO - epoch:107,	steps71/207,	loss:0.0014937504893168807
2023-03-24 22:50:29,737 - src.Train - INFO - epoch:107,	steps91/207,	loss:0.004544267430901527
torch.Size([20, 60])
torch.Size([20, 60])
torch.Size([20, 60])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a waitress put [UNK] [UNK] into the fridge on thursday night. she noticed that the restaurant had γ of a [UNK] filled with [UNK], δ of a [UNK] filled with [UNK], and ε of a [UNK] filled with [UNK]. how many [UNK] [UNK] did the restaurant have in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[39, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:50:31,973 - src.Train - INFO - epoch:107,	steps111/207,	loss:0.001679970882833004
2023-03-24 22:50:34,258 - src.Train - INFO - epoch:107,	steps131/207,	loss:0.0008333229925483465
2023-03-24 22:50:36,435 - src.Train - INFO - epoch:107,	steps151/207,	loss:0.0052694943733513355
2023-03-24 22:50:38,743 - src.Train - INFO - epoch:107,	steps171/207,	loss:0.0021748377475887537
2023-03-24 22:50:41,074 - src.Train - INFO - epoch:107,	steps191/207,	loss:0.0019682704005390406
2023-03-24 22:50:42,864 - src.Train - INFO - start evaluate...
2023-03-24 22:50:42,865 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:50:44,892 - src.Train - INFO - right: 871	total: 1022	M-tree codes acc: 0.8522504892367906
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:50:52,277 - src.Train - INFO - epoch:108,	steps4/207,	loss:0.002783991163596511
2023-03-24 22:50:54,574 - src.Train - INFO - epoch:108,	steps24/207,	loss:0.0021009331103414297
2023-03-24 22:50:56,934 - src.Train - INFO - epoch:108,	steps44/207,	loss:0.003386571304872632
2023-03-24 22:50:59,243 - src.Train - INFO - epoch:108,	steps64/207,	loss:0.003676221240311861
2023-03-24 22:51:01,663 - src.Train - INFO - epoch:108,	steps84/207,	loss:0.0009327584411948919
2023-03-24 22:51:03,854 - src.Train - INFO - epoch:108,	steps104/207,	loss:0.003917344380170107
torch.Size([20, 48])
torch.Size([20, 48])
torch.Size([20, 48])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 lana [UNK] favorite band was holding a concert where tickets were γ dollars each. lana bought δ tickets for herself and her friends and ε extra tickets in case anyone else wanted to go. how much did she spend? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[29, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:51:06,054 - src.Train - INFO - epoch:108,	steps124/207,	loss:0.0017321952618658543
2023-03-24 22:51:08,420 - src.Train - INFO - epoch:108,	steps144/207,	loss:0.0005843325634486973
2023-03-24 22:51:10,703 - src.Train - INFO - epoch:108,	steps164/207,	loss:0.002753503853455186
2023-03-24 22:51:13,018 - src.Train - INFO - epoch:108,	steps184/207,	loss:0.0024381254334002733
2023-03-24 22:51:15,305 - src.Train - INFO - epoch:108,	steps204/207,	loss:0.0008787950500845909
2023-03-24 22:51:15,529 - src.Train - INFO - start evaluate...
2023-03-24 22:51:15,529 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:51:17,662 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:51:26,139 - src.Train - INFO - epoch:109,	steps17/207,	loss:0.001920765032991767
2023-03-24 22:51:28,418 - src.Train - INFO - epoch:109,	steps37/207,	loss:0.0012222264194861054
2023-03-24 22:51:30,806 - src.Train - INFO - epoch:109,	steps57/207,	loss:0.0010844491189345717
2023-03-24 22:51:32,984 - src.Train - INFO - epoch:109,	steps77/207,	loss:0.001236655400134623
2023-03-24 22:51:35,180 - src.Train - INFO - epoch:109,	steps97/207,	loss:0.005785335786640644
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 66])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a container ship left from [UNK] pier and traveled north. an aircraft carrier left γ hours later traveling at δ miles per hour in an effort to catch up to the container ship. after traveling for ε hours the aircraft carrier finally caught up. what was the container ship [UNK] average speed in miles per hour? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:51:37,685 - src.Train - INFO - epoch:109,	steps117/207,	loss:0.0027780854143202305
2023-03-24 22:51:40,758 - src.Train - INFO - epoch:109,	steps137/207,	loss:0.002613326534628868
2023-03-24 22:51:44,208 - src.Train - INFO - epoch:109,	steps157/207,	loss:0.0006500012241303921
2023-03-24 22:51:48,049 - src.Train - INFO - epoch:109,	steps177/207,	loss:0.001186580746434629
2023-03-24 22:51:51,747 - src.Train - INFO - epoch:109,	steps197/207,	loss:0.0012532855616882443
2023-03-24 22:51:53,537 - src.Train - INFO - start evaluate...
2023-03-24 22:51:53,537 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:51:56,832 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:52:04,847 - src.Train - INFO - epoch:110,	steps10/207,	loss:0.0009334576898254454
2023-03-24 22:52:08,668 - src.Train - INFO - epoch:110,	steps30/207,	loss:0.0016583126271143556
2023-03-24 22:52:12,360 - src.Train - INFO - epoch:110,	steps50/207,	loss:0.0014267282094806433
2023-03-24 22:52:16,300 - src.Train - INFO - epoch:110,	steps70/207,	loss:0.0009546905639581382
2023-03-24 22:52:20,011 - src.Train - INFO - epoch:110,	steps90/207,	loss:0.0010465418454259634
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 martha wants to buy a digital camera from her γ month savings. to do this she needs to maintain an average saving of δ in each month. she saves ε in the first month and ζ in the second month. find the amount she should save in the third month, in dollars, to buy a digital camera at the end of η months. [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
====================
label:[28, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:52:23,648 - src.Train - INFO - epoch:110,	steps110/207,	loss:0.0034836509730666876
2023-03-24 22:52:27,459 - src.Train - INFO - epoch:110,	steps130/207,	loss:0.002570537617430091
2023-03-24 22:52:31,205 - src.Train - INFO - epoch:110,	steps150/207,	loss:0.0007790089584887028
2023-03-24 22:52:34,876 - src.Train - INFO - epoch:110,	steps170/207,	loss:0.0017473121406510472
2023-03-24 22:52:38,552 - src.Train - INFO - epoch:110,	steps190/207,	loss:0.0012472999515011907
2023-03-24 22:52:41,697 - src.Train - INFO - start evaluate...
2023-03-24 22:52:41,697 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:52:45,014 - src.Train - INFO - right: 873	total: 1022	M-tree codes acc: 0.8542074363992173
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:52:50,274 - src.Train - INFO - epoch:111,	steps3/207,	loss:0.004682236351072788
2023-03-24 22:52:53,977 - src.Train - INFO - epoch:111,	steps23/207,	loss:0.002454793779179454
2023-03-24 22:52:57,800 - src.Train - INFO - epoch:111,	steps43/207,	loss:0.0024610194377601147
2023-03-24 22:53:01,714 - src.Train - INFO - epoch:111,	steps63/207,	loss:0.001649576355703175
2023-03-24 22:53:05,380 - src.Train - INFO - epoch:111,	steps83/207,	loss:0.002132480964064598
2023-03-24 22:53:08,998 - src.Train - INFO - epoch:111,	steps103/207,	loss:0.001438623876310885
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 grace has γ [UNK] in her pocket. she has δ red ones, ε green ones, and ζ blue ones. what is the minimum number of [UNK] she must take out of her pocket to ensure that she has one of each color? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[23, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:53:12,911 - src.Train - INFO - epoch:111,	steps123/207,	loss:0.0038208297919481993
2023-03-24 22:53:16,599 - src.Train - INFO - epoch:111,	steps143/207,	loss:0.0009810228366404772
2023-03-24 22:53:20,205 - src.Train - INFO - epoch:111,	steps163/207,	loss:0.0012619165936484933
2023-03-24 22:53:22,881 - src.Train - INFO - epoch:111,	steps183/207,	loss:0.0017013894394040108
2023-03-24 22:53:25,188 - src.Train - INFO - epoch:111,	steps203/207,	loss:0.002470567123964429
2023-03-24 22:53:25,596 - src.Train - INFO - start evaluate...
2023-03-24 22:53:25,596 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:53:27,560 - src.Train - INFO - right: 865	total: 1022	M-tree codes acc: 0.8463796477495108
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:53:34,741 - src.Train - INFO - epoch:112,	steps16/207,	loss:0.0021235186140984297
2023-03-24 22:53:36,991 - src.Train - INFO - epoch:112,	steps36/207,	loss:0.001965017756447196
2023-03-24 22:53:39,191 - src.Train - INFO - epoch:112,	steps56/207,	loss:0.0003267936990596354
2023-03-24 22:53:41,713 - src.Train - INFO - epoch:112,	steps76/207,	loss:0.00407560495659709
2023-03-24 22:53:44,141 - src.Train - INFO - epoch:112,	steps96/207,	loss:0.001306494465097785
torch.Size([20, 47])
torch.Size([20, 47])
torch.Size([20, 47])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a truck leaves a town traveling at γ miles per hour. δ hours later a car leaves, traveling along the same road at ε miles per hour. in how many hours will the car catch the truck? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[29, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:53:46,715 - src.Train - INFO - epoch:112,	steps116/207,	loss:0.0008892841869965196
2023-03-24 22:53:49,140 - src.Train - INFO - epoch:112,	steps136/207,	loss:0.003726491704583168
2023-03-24 22:53:51,734 - src.Train - INFO - epoch:112,	steps156/207,	loss:0.001021507428959012
2023-03-24 22:53:54,147 - src.Train - INFO - epoch:112,	steps176/207,	loss:0.0007808023365214467
2023-03-24 22:53:56,669 - src.Train - INFO - epoch:112,	steps196/207,	loss:0.0008340019849129021
2023-03-24 22:53:58,037 - src.Train - INFO - start evaluate...
2023-03-24 22:53:58,037 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:53:59,967 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:54:06,311 - src.Train - INFO - epoch:113,	steps9/207,	loss:0.0012303245021030307
2023-03-24 22:54:08,838 - src.Train - INFO - epoch:113,	steps29/207,	loss:0.0008878241060301661
2023-03-24 22:54:11,371 - src.Train - INFO - epoch:113,	steps49/207,	loss:0.0015307177091017365
2023-03-24 22:54:13,865 - src.Train - INFO - epoch:113,	steps69/207,	loss:0.0013891607522964478
2023-03-24 22:54:16,212 - src.Train - INFO - epoch:113,	steps89/207,	loss:0.0006567901582457125
2023-03-24 22:54:18,791 - src.Train - INFO - epoch:113,	steps109/207,	loss:0.0019197091460227966
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 53])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 allen, [UNK] [UNK] brother, likes to play with blocks. [UNK] [UNK] allen [UNK] old blocks in different colors. if allen has γ identical blocks and there are δ blocks for every color of paint used, how many colors did [UNK] use? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[29, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:54:21,130 - src.Train - INFO - epoch:113,	steps129/207,	loss:0.002198206027969718
2023-03-24 22:54:23,687 - src.Train - INFO - epoch:113,	steps149/207,	loss:0.0019425420323386788
2023-03-24 22:54:26,211 - src.Train - INFO - epoch:113,	steps169/207,	loss:0.0021327491849660873
2023-03-24 22:54:28,790 - src.Train - INFO - epoch:113,	steps189/207,	loss:0.0006905636400915682
2023-03-24 22:54:30,961 - src.Train - INFO - start evaluate...
2023-03-24 22:54:30,961 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:54:32,949 - src.Train - INFO - right: 866	total: 1022	M-tree codes acc: 0.8473581213307241
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:54:38,524 - src.Train - INFO - epoch:114,	steps2/207,	loss:0.00354883074760437
2023-03-24 22:54:40,899 - src.Train - INFO - epoch:114,	steps22/207,	loss:0.0010278443805873394
2023-03-24 22:54:43,427 - src.Train - INFO - epoch:114,	steps42/207,	loss:0.0038339607417583466
2023-03-24 22:54:45,871 - src.Train - INFO - epoch:114,	steps62/207,	loss:0.0019027816597372293
2023-03-24 22:54:48,422 - src.Train - INFO - epoch:114,	steps82/207,	loss:0.0007830634713172913
2023-03-24 22:54:50,875 - src.Train - INFO - epoch:114,	steps102/207,	loss:0.002907180693000555
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 59])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 harry hound had a terrible [UNK] yesterday. when i peered into his ears yesterday, i found γ [UNK] [UNK] having a party in his right ear and δ ba by [UNK] sleeping peacefully in his left ear. i cleaned out harry hound [UNK] ears. how many [UNK] perished? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[33, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:54:53,437 - src.Train - INFO - epoch:114,	steps122/207,	loss:0.0010484308004379272
2023-03-24 22:54:55,909 - src.Train - INFO - epoch:114,	steps142/207,	loss:0.002409077947959304
2023-03-24 22:54:58,304 - src.Train - INFO - epoch:114,	steps162/207,	loss:0.0009712953469716012
2023-03-24 22:55:00,886 - src.Train - INFO - epoch:114,	steps182/207,	loss:0.0024516384582966566
2023-03-24 22:55:03,371 - src.Train - INFO - epoch:114,	steps202/207,	loss:0.0020409640856087208
2023-03-24 22:55:03,999 - src.Train - INFO - start evaluate...
2023-03-24 22:55:04,000 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:55:05,945 - src.Train - INFO - right: 872	total: 1022	M-tree codes acc: 0.8532289628180039
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:55:13,002 - src.Train - INFO - epoch:115,	steps15/207,	loss:0.0015713744796812534
2023-03-24 22:55:15,679 - src.Train - INFO - epoch:115,	steps35/207,	loss:0.0013823070330545306
2023-03-24 22:55:18,140 - src.Train - INFO - epoch:115,	steps55/207,	loss:0.0022910155821591616
2023-03-24 22:55:20,718 - src.Train - INFO - epoch:115,	steps75/207,	loss:0.001855650800280273
2023-03-24 22:55:23,130 - src.Train - INFO - epoch:115,	steps95/207,	loss:0.005019991658627987
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 52])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a construction company is [UNK] a damaged road. so far, they have [UNK] a total of γ inches of the road. today, they [UNK] δ inches of the road. how many inches of the road had they [UNK] before today? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[22, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:55:25,748 - src.Train - INFO - epoch:115,	steps115/207,	loss:0.0009990385733544827
2023-03-24 22:55:28,184 - src.Train - INFO - epoch:115,	steps135/207,	loss:0.0009368225000798702
2023-03-24 22:55:30,675 - src.Train - INFO - epoch:115,	steps155/207,	loss:0.0029825707897543907
2023-03-24 22:55:32,997 - src.Train - INFO - epoch:115,	steps175/207,	loss:0.0009037366835400462
2023-03-24 22:55:35,625 - src.Train - INFO - epoch:115,	steps195/207,	loss:0.0025893384590744972
2023-03-24 22:55:37,003 - src.Train - INFO - start evaluate...
2023-03-24 22:55:37,003 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:55:39,024 - src.Train - INFO - right: 868	total: 1022	M-tree codes acc: 0.8493150684931506
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:55:44,556 - src.Train - INFO - epoch:116,	steps8/207,	loss:0.002273951191455126
2023-03-24 22:55:47,111 - src.Train - INFO - epoch:116,	steps28/207,	loss:0.0018722031963989139
2023-03-24 22:55:49,520 - src.Train - INFO - epoch:116,	steps48/207,	loss:0.0026732657570391893
2023-03-24 22:55:52,132 - src.Train - INFO - epoch:116,	steps68/207,	loss:0.0022588984575122595
2023-03-24 22:55:54,575 - src.Train - INFO - epoch:116,	steps88/207,	loss:0.0013768798671662807
2023-03-24 22:55:57,032 - src.Train - INFO - epoch:116,	steps108/207,	loss:0.001798479468561709
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 john was trying to expand his game collection. he bought γ games from a friend and bought δ more at a garage sale. if ε of the games did [UNK] work, how many good games did he end up with? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[30, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:55:59,522 - src.Train - INFO - epoch:116,	steps128/207,	loss:0.002206535078585148
2023-03-24 22:56:01,866 - src.Train - INFO - epoch:116,	steps148/207,	loss:0.000988248037174344
2023-03-24 22:56:04,465 - src.Train - INFO - epoch:116,	steps168/207,	loss:0.001623445306904614
2023-03-24 22:56:06,823 - src.Train - INFO - epoch:116,	steps188/207,	loss:0.0010414529824629426
2023-03-24 22:56:09,093 - src.Train - INFO - start evaluate...
2023-03-24 22:56:09,093 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:56:11,278 - src.Train - INFO - right: 869	total: 1022	M-tree codes acc: 0.850293542074364
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:56:16,481 - src.Train - INFO - epoch:117,	steps1/207,	loss:0.0008511926862411201
2023-03-24 22:56:19,030 - src.Train - INFO - epoch:117,	steps21/207,	loss:0.0022960195783525705
2023-03-24 22:56:21,489 - src.Train - INFO - epoch:117,	steps41/207,	loss:0.0017267437651753426
2023-03-24 22:56:24,138 - src.Train - INFO - epoch:117,	steps61/207,	loss:0.004381921608000994
2023-03-24 22:56:26,476 - src.Train - INFO - epoch:117,	steps81/207,	loss:0.0010360709857195616
2023-03-24 22:56:28,945 - src.Train - INFO - epoch:117,	steps101/207,	loss:0.002245033159852028
torch.Size([20, 68])
torch.Size([20, 68])
torch.Size([20, 68])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 a small publishing company has a γ time product cost for editing and printing of δ dollars. [UNK] [UNK] cost per book is ε dollars. the publisher is selling the book to the store for ζ dollars. how many books must the publisher print and sell so that the production cost will equal the money obtained from sells? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[19, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:56:31,356 - src.Train - INFO - epoch:117,	steps121/207,	loss:0.0018770034657791257
2023-03-24 22:56:33,686 - src.Train - INFO - epoch:117,	steps141/207,	loss:0.004139076918363571
2023-03-24 22:56:36,328 - src.Train - INFO - epoch:117,	steps161/207,	loss:0.0020804493688046932
2023-03-24 22:56:38,731 - src.Train - INFO - epoch:117,	steps181/207,	loss:0.0008532559149898589
2023-03-24 22:56:41,233 - src.Train - INFO - epoch:117,	steps201/207,	loss:0.003641934832558036
2023-03-24 22:56:41,849 - src.Train - INFO - start evaluate...
2023-03-24 22:56:41,849 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:56:44,025 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:56:51,009 - src.Train - INFO - epoch:118,	steps14/207,	loss:0.0008077103993855417
2023-03-24 22:56:53,507 - src.Train - INFO - epoch:118,	steps34/207,	loss:0.004488875158131123
2023-03-24 22:56:55,939 - src.Train - INFO - epoch:118,	steps54/207,	loss:0.0012146010994911194
2023-03-24 22:56:58,626 - src.Train - INFO - epoch:118,	steps74/207,	loss:0.0009709438891150057
2023-03-24 22:57:01,017 - src.Train - INFO - epoch:118,	steps94/207,	loss:0.002779357833787799
2023-03-24 22:57:03,503 - src.Train - INFO - epoch:118,	steps114/207,	loss:0.001213326584547758
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 75])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 on her vacation last summer, [UNK] walked all over new york city to buy [UNK]. first, she walked γ mile from her hotel to a [UNK] shop. then she walked δ mile from the [UNK] shop to a t - shirt shop and ε mile from the t - shirt shop back to the hotel. how many miles did [UNK] walk in all? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[51, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:57:06,000 - src.Train - INFO - epoch:118,	steps134/207,	loss:0.0030940938740968704
2023-03-24 22:57:08,587 - src.Train - INFO - epoch:118,	steps154/207,	loss:0.0028437571600079536
2023-03-24 22:57:10,993 - src.Train - INFO - epoch:118,	steps174/207,	loss:0.0026214218232780695
2023-03-24 22:57:13,324 - src.Train - INFO - epoch:118,	steps194/207,	loss:0.001664762501604855
2023-03-24 22:57:15,061 - src.Train - INFO - start evaluate...
2023-03-24 22:57:15,061 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:57:17,033 - src.Train - INFO - right: 870	total: 1022	M-tree codes acc: 0.8512720156555773
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
2023-03-24 22:57:24,808 - src.Train - INFO - epoch:119,	steps7/207,	loss:0.0012650609714910388
2023-03-24 22:57:27,236 - src.Train - INFO - epoch:119,	steps27/207,	loss:0.000769370177295059
2023-03-24 22:57:29,694 - src.Train - INFO - epoch:119,	steps47/207,	loss:0.0009344969294033945
2023-03-24 22:57:32,229 - src.Train - INFO - epoch:119,	steps67/207,	loss:0.0015658780466765165
2023-03-24 22:57:34,657 - src.Train - INFO - epoch:119,	steps87/207,	loss:0.001886892132461071
2023-03-24 22:57:37,208 - src.Train - INFO - epoch:119,	steps107/207,	loss:0.0016043689101934433
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 50])
torch.Size([20, 29])
input_ids: [CLS] α 。 β 。 [UNK] hilt baked [UNK] last weekend for a holiday dinner. she baked γ [UNK] [UNK] and δ apples [UNK]. if she wants to arrange all of the [UNK] in rows of ε [UNK] each, how many rows will she have? [SEP]
====================
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
====================
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
====================
label:[21, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2023-03-24 22:57:39,555 - src.Train - INFO - epoch:119,	steps127/207,	loss:0.0016379390144720674
2023-03-24 22:57:42,103 - src.Train - INFO - epoch:119,	steps147/207,	loss:0.0010925618698820472
2023-03-24 22:57:44,452 - src.Train - INFO - epoch:119,	steps167/207,	loss:0.0022576667834073305
2023-03-24 22:57:47,043 - src.Train - INFO - epoch:119,	steps187/207,	loss:0.001062719151377678
2023-03-24 22:57:49,406 - src.Train - INFO - epoch:119,	steps207/207,	loss:0.017382485792040825
2023-03-24 22:57:49,406 - src.Train - INFO - start evaluate...
2023-03-24 22:57:49,406 - src.Train - INFO - ====================dev data set====================
dev labels.shape: (1022, 28)
dev all_logits.shape: (1022, 28)
2023-03-24 22:57:51,617 - src.Train - INFO - right: 867	total: 1022	M-tree codes acc: 0.8483365949119374
train_data_loader shuffling......
train_data_loader shuffling......
207 batches created
